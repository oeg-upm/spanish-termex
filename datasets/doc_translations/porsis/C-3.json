{
    "id": "C-3",
    "original_text": "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic. One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application. Another problem is adaptation to the changing characteristics of the grid environment. Existing solutions to these two problems require that a performance model for an application is known. However, constructing such models is a complex task. In this paper, we investigate an approach that does not require performance models. We start an application on any set of resources. During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics. Then, we adjust the resource set to better fit the application needs. This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements. We evaluate our approach in a number of scenarios typical for the Grid. Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1. Introduction In recent years, grid computing has become a real alternative to traditional parallel computing. A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20). However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers. One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance. Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion. In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs). Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application. Also, new, better resources may become available. To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions. The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available. This approach has been adopted by a number of systems (5; 14; 18). For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution. Predicting the application runtime on a given set of resources, however, requires knowledge about the application. Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have. In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model. We start an application on any set of resources. During the application run, we periodically collect information about the communication times and idle times of the processors. We use these statistics to automatically estimate the resource requirements of the application. Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters. Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory. Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment. A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing. It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)). It should not use static load balancing or be very sensitive to wide121 area latencies. We have applied our ideas to divide-and-conquer applications, which satisfy these requirements. Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20). We believe that our approach can be extended to other classes of applications with the given assumptions. We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20). We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios. The rest of this paper is structured as follows. In Section 2, we explain what assumptions we are making about the applications and grid resources. In Section 3, we present our resource selection and adaptation strategy. In Section 4, we describe its implementation in the Satin framework. In Section 5, we evaluate our approach in a number of grid scenarios. In Section 6, we compare our approach with the related work. Finally, in Section 7, we conclude and describe future work. 2. Background and assumptions In this section, we describe our assumptions about the applications and their resources. We assume the following resource model. The applications are running on multiple sites at the same time, where sites are clusters or supercomputers. We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3). Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth. The different sites are connected by a WAN. Communication between sites suffers from high latencies. We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths. We studied the adaptation problem in the context of divide-andconquer applications. However, we believe that our methodology can be used for other types of applications as well. In this section we summarize the assumptions about applications that are important to our approach. The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation. In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable. Processors can be added or removed at any point in the computation with little overhead. The second assumption is that the application can efficiently run on processors with different speeds. This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19). Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)). We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources. Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3. Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment. In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator. The adaptation coordinator periodically collects performance statistics from the application processors. We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources. The coordinator uses statistics from application processors to compute the weighted average efficiency. If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors. A heuristic formula is used to decide which processors have to be removed. During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors. These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency. Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating. Efficiency indicates the benefit of using multiple processors. Typically, the efficiency drops as new processors are added to the computation. Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10). The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized. Adding processors beyond this number yields little benefit. This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%. Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains. For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor. The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1. Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle. Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors. In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors. Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle. The computation is divided into monitoring periods. After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period. Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication. To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used. Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks. Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size. This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard. In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application. Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines). There is a trade-off between the accuracy of speed measurements and the overhead it incurs. The longer the benchmark, the greater the accuracy of the measurement. The more often it is run, the faster changes in processor speed are detected. In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause. Processors run the benchmark at such frequency so as not to exceed the specified overhead. In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected. This optimization will further reduce the benchmarking overhead. Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size. The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period. Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure. The sizes of tasks can vary by many orders of magnitude. At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator. Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster. The clocks of the processors are not synchronized with each other or with the clock of the coordinator. Each processor decides separately when it is time to send data. Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors. This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax. When it exceeds Emax, the coordinator requests new processors from the scheduler. The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested. The coordinator starts removing processors when the weighted average efficiency drops below Emin. The number of nodes that are removed again depends on the weighted average efficiency. The lower the efficiency, the more nodes are removed. The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%. Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors. In that case, removing bad processors will be beneficial for the application. Such low efficiency might also indicate that we simply have too many processors. In that case, removing some processors may not be beneficial but it will not harm the application. The coordinator always tries to remove the worst processors. The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead). High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient. Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication. Therefore, processors belonging to the worst cluster are preferred. Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise. The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster. The ic overhead of a cluster is an average of processor inter-cluster overheads. The α, β and γ coefficients determine the relative importance of the terms. Those coefficients are established empirically. Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation. Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application. In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes. After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation. Figure 1 shows a schematic view of the adaptation strategy. Dashed lines indicate a part that is not supported yet, as will be explained below. This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available). Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed. After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources. Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed. If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.) Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2. The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1. Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted. Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22). For example, adding nodes to a computation can be improved. Currently, we add any nodes the scheduler gives us. However, it would be more efficient to ask for the fastest processors among the available ones. This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way. Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous. An alternative approach would be ranking the processors based on parameters such as clock speed and cache size. This approach is sometimes used for resource selection for sequential applications (14). However, it is less accurate than using an application specific benchmark. Also, during application execution, we can learn some application requirements and pass them to the scheduler. One example is minimal bandwidth required by the application. The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed. The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum. Alternatively, information from a grid monitoring system can be used. Such bounds can be passed to the scheduler to avoid adding inappropriate resources. It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed. Currently we use blacklisting - we simply do not allow adding resources we removed before. This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes. We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered. If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available. Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available. Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality. The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications. We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4. Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications. With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code. Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing. Satin also provides transparent fault tolerance and malleability (23). With Satin, removing and adding processors from/to an ongoing computation incurs little overhead. We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator. The coordinator is implemented as a separate process. Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21). The core of Ibis is also implemented in Java. The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid. Ibis also provides the Ibis Registry. The Registry provides, among others, a membership service to the processors taking part in the computation. The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other. The Registry also offers fault detection (additional to the fault detection provided by the communication channels). Finally, the Registry provides the possibility to send signals to application processes. The coordinator uses this functionality to notify the processors that they need to leave the computation. Currently the Registry is implemented as a centralized server. For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers. Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency. In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system. Zorilla can be easily replaced with another grid scheduler. In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5. Performance evaluation In this section, we will evaluate our approach. We will demonstrate the performance of our mechanism in a few scenarios. The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur. This scenario allows us to measure the overhead of the adaptation support. The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links. For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version. In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed. In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3. Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4. Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes. This allows us to measure the overhead of benchmarking and collecting statistics. In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications. All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities. One of the clusters consists of 72 nodes, the others of 32 nodes. Each node contains two 1 GHz Pentium processors. Within a cluster, the nodes are connected by Fast Ethernet. The clusters are connected by the Dutch university Internet backbone. In our experiments, we used the Barnes-Hut N-body simulation. BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces. The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes. The nodes are equally divided over 3 clusters (12 nodes in each cluster). On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes. As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3). Those runtimes are shown in Figure 2, first group of bars. The comparison between runtime 3 and 1 shows the overhead of adaptation support. In this experiment it is around 15%. Almost all overhead comes from benchmarking. The benchmark is run 1-2 times per monitoring period. This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency. The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes). Using longer running applications would not allow us to finish the experimentation in a reasonable time. However, real-world grid applications typically need hours, days or even weeks to complete. For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower. For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%. Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use. This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started. We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c). The nodes were located in 1 or 2 clusters. In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters. This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version. Those runtimes are shown in Figure 2. Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3. Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters. After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters. Such a situation may happen when an application with a higher priority is started on some of the resources. Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions. After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5. Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6. Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3. Also, the iteration times became very variable. The adaptive version reacted by removing the overloaded nodes. After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes. So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values. This reduced the total runtime by 14%. The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters. We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s. To simulate low bandwidth we use the traffic-shaping techniques described in (6). The iteration durations in this experiment are shown in Figure 5. The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds. The adaptive version removed the badly connected cluster after the first monitoring period. As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38. This brought the iteration times down to around 100 seconds. The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters. Again, we simulated an overloaded uplink to one of the clusters. Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters. The iteration durations are shown in Figure 6. Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds. The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average. After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%. Since this value lies between Emin and Emax, no nodes are added or removed. This example illustrates what the advantages of opportunistic migration would be. There were faster nodes available in the system. If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further. Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters. After 500 seconds, 2 out of 3 clusters crash. The iteration durations are shown in Figure 7. After the crash, the iteration duration raised from 100 to 200 seconds. The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version. The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds. The total runtime was reduced by 13% (Figure 2). 6. Related work A number of Grid projects address the question of resource selection and adaptation. In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes. In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected. If performance degradation is detected during the computation, the resource selection phase is repeated. GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance. ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator. The main difference between these approaches and our approach is the use of performance models. The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach. However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7. Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete. Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal. As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller. Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications. Cactus (2) and GridWay (14) do not use performance models. However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus). In that case, the resource selection problem boils down to selecting the fastest machine or cluster. Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected. The application is migrated if performance degradation is detected or better resources are discovered. Both Cactus and GridWay use the number of iterations per time unit as the performance indicator. The main limitation of this methodology is that it is suitable only for sequential or single-site applications. Moreover, resource selection based on clock speed is not always accurate. Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems. The resource selection problem was also studied by the AppLeS project (5). In the context of this project, a number of applications were studied and performance models for these applications were created. Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set. AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application. Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications. Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied. The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account. Therefore, the problem is reduced to finding the right number of workers. The approach here is similar to ours in that no performance model is used. Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7. Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments. Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources. However, creating performance models is inherently difficult and requires knowledge about the application. We propose an approach that does not require in-depth knowledge about the application. We start the application on an arbitrary set of resources and monitor its performance. The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements. We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary. This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors. Our approach also allows the application to adapt to the changing grid conditions. The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines. If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes. The badness of the nodes is defined by a heuristic formula. If the weighted average efficiency raises above a certain level, new nodes are added. Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc. The application adapts fully automatically to changing conditions. We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments). Future work will involve extending our adaptation strategy to support opportunistic migration. This, however, requires grid schedulers with more sophisticated functionality than currently exists. Further research is also needed to decrease the benchmarking overhead. For example, the information about CPU load could be used to decrease the benchmarking frequency. Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run. For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions. Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands). This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators. Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl). This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ). References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo. Parallel program/component adaptivity management. In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf. The cactus worm: Experiments with resource discovery and allocation in a grid environment. Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor. Enabling applications on the grid - a gridlab overview. Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A. Brewer. ATLAS: An Infrastructure for Global Computing. In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov. Adaptive Computing on the Grid Using AppLeS. IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley. Experiences in programming a traffic shaper. In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski. GridSAT: A Chaff-based Distributed SAT Solver for the Grid. In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal. Simple localityaware co-allocation in peer-to-peer supercomputing. In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska. Speedup versus efficiency in parallel systems. IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I. Foster. Globus toolkit version 4: Software for serviceoriented systems. In IFIP International Conference on Network and Parallel Computing, pages 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth. An Enabling Framework for Master-Worker Applications on the Computational Grid. In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny. Adaptive scheduling for master-worker applications on the computational grid. In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227. Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente. A framework for adaptive execution in grids. Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema. Experiences with the KOALA Co-Allocating Scheduler in Multiclusters. In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman. Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects. In 5th Intl Symp. On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat. A performance analysis of transposition-table-driven work scheduling in distributed search. IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra. Self adaptivity in Grid computing. Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal. Efficient load balancing for wide-area divide-and-conquer applications. In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal. Satin: Simple and Efficient Java-based Grid Programming. Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal. Ibis: a Flexible and Efficient Java-based Grid Programming Environment. Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes. The network weather service: A distributed resource performance forecasting service for metacomputing. Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal. Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid. In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129",
    "original_translation": "Aplicaciones autoadaptativas en la cuadrícula Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de los sistemas informáticos, Vrije Universiteit Amsterdam {Gosia, Jason, balth@cs.vu.nl Las cuadrículas abstractas son inherentemente heterogéneas y dinámicas. Un problema importante en la informática de la red es la selección de recursos, es decir, encontrar un conjunto de recursos apropiado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la cuadrícula. Las soluciones existentes a estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Comenzamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la solicitud, periódicamente recopilamos las estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación de estas estadísticas. Luego, ajustamos el conjunto de recursos para ajustar mejor las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos y, por lo tanto, puede producir mejoras significativas de rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos de la cuadrícula. Categorías y descriptores de sujetos C.2.4 [Redes de comunicación informática]: aplicaciones distribuidas de sistemas distribuidos;C.4 [rendimiento de los sistemas]: técnicas de medición, técnicas de modelado algoritmos de términos generales, medición, rendimiento, experimentación 1. Introducción En los últimos años, la informática de la red se ha convertido en una alternativa real a la informática paralela tradicional. Una cuadrícula proporciona mucha potencia computacional y, por lo tanto, ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo (7; 15; 20). Sin embargo, la complejidad de los entornos de la cuadrícula también es muchas veces más grande que la de las máquinas paralelas tradicionales como grupos y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cómputo de modo que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera de prueba y error. En un entorno de la cuadrícula, este problema es aún más difícil, debido a la heterogeneidad de los recursos: los nodos de cómputo tienen varias velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local de baja latencia y alto ancho de banda (LAN) hasta altas-Latencia y posiblemente redes de área ancha de ancho de banda bajo (WAN). Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la cuadrícula varían con el tiempo: los enlaces de red o los nodos de cómputo pueden sobrecargarse, o los nodos de cálculo pueden no estar disponibles debido a los bloqueos o porque han sido reclamados por una aplicación de mayor prioridad. Además, pueden estar disponibles nuevos y mejores recursos. Para mantener un nivel de rendimiento razonable, la aplicación debe adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares o cuando se detecta un problema de rendimiento, o cuando se dispone de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, el tiempo de ejecución de la aplicación se estima para algunos conjuntos de recursos y el conjunto que produce el tiempo de ejecución más corto se selecciona para la ejecución. Sin embargo, predecir el tiempo de ejecución de la aplicación en un conjunto de recursos determinado requiere conocimiento sobre la aplicación. Por lo general, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere una experiencia que los programadores de aplicaciones puedan no tener. En este documento, presentamos y evaluamos un enfoque alternativo para la adaptación de la aplicación y la selección de recursos que no necesita un modelo de rendimiento. Comenzamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, periódicamente recopilamos información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos que la aplicación se ejecuta agregando o eliminando nodos de cómputo o incluso grupos completos. Nuestra estrategia de adaptación utiliza el trabajo de Anic et al.(10) para determinar la eficiencia y los intentos de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para permanecer entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación de la red. Maneja todos los siguientes casos: • Adaptando automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante el cálculo • migrar (parte de) un cálculo lejos de los recursos sobrecargados • Eliminar recursos con pobresLos enlaces de comunicación que ralentizan el cálculo • Agregar nuevos recursos para reemplazar los recursos que han bloqueado nuestro trabajo supone que la aplicación es maleable y puede ejecutarse (de manera eficiente) en múltiples sitios de una cuadrícula (es decir, usar co-asignación (15)). No debe usar el equilibrio de carga estática o ser muy sensible a las latencias de área Wide121. Hemos aplicado nuestras ideas para dividir y vencer aplicaciones, que satisfacen estos requisitos. Se ha demostrado que Divide-and-Conquer es un paradigma atractivo para la programación de aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede extenderse a otras clases de aplicaciones con los supuestos dados. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones divididas y conquistar habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y mostraremos que nuestro enfoque produce principales mejoras de rendimiento (aproximadamente 10-60 %) en los escenarios anteriores. El resto del artículo se estructura de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco satinado. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro.2. Antecedentes y supuestos En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se ejecutan en varios sitios al mismo tiempo, donde los sitios son grupos o supercomputadoras. También suponemos que se pueden acceder a los procesadores de los sitios utilizando un sistema de programación de cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores que pertenecen a un sitio están conectados por una LAN rápida con una baja latencia y un alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la red troncal de Internet podrían convertirse en cuellos de botella que hacen que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y conquistar. Sin embargo, creemos que nuestra metodología también puede usarse para otros tipos de aplicaciones. En esta sección resumimos los supuestos sobre aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y dejan el cálculo continuo. En (23), mostramos cómo las aplicaciones de divide y conquistar pueden ser tolerantes y maleables. Los procesadores se pueden agregar o eliminar en cualquier punto del cálculo con poca sobrecarga. La segunda suposición es que la aplicación puede ejecutarse de manera eficiente en procesadores con diferentes velocidades. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámica, como el robo del trabajo utilizado por aplicaciones divididas y conquistadoras (19). Además, las aplicaciones de trabajadores maestros generalmente utilizan estrategias dinámicas de equilibrio de carga (por ejemplo, MW, un marco para escribir aplicaciones de trabajadores maestros en cuadrícula (12)). Encontramos una suposición razonable para una aplicación de la red, ya que las aplicaciones para la cual el procesador más lento se convierte en un cuello de botella no podrán utilizar de manera eficiente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de área ancha, por lo que puede funcionar de manera eficiente en una cuadrícula de Widearea (16; 17).3. Autoadaptación en esta sección Explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación determinada y para adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional al cálculo que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de solicitudes. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de procesadores de aplicación para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o eliminar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben eliminarse. Durante este proceso, el coordinador aprende los requisitos de la aplicación al recordar las características de los procesadores eliminados. Estos requisitos se utilizan para guiar la adición de nuevos procesadores.3.1 Eficiencia promedio ponderada en la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan haciendo un trabajo útil en lugar de estar inactivo o comunicarse con otros procesadores (10).Eficiencia = 1 n ∗ n i = 0 (1 - sobrecarga) donde n es el número de procesadores y la sobrecarga es la fracción de tiempo que el procesador ésimo gasta en inactivo o comunicando. La eficiencia indica el beneficio de usar múltiples procesadores. Por lo general, la eficiencia cae a medida que se agregan nuevos procesadores al cálculo. Por lo tanto, lograr una alta velocidad (y, por lo tanto, un tiempo de ejecución bajo) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es el número para el cual se maximiza la relación de eficiencia y el tiempo de ejecución. Agregar procesadores más allá de este número produce poco beneficio. Este número es típicamente difícil de encontrar, pero en (10) se demostró teóricamente que si se usa el número óptimo de procesadores, la eficiencia es al menos 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias de rendimiento significativas. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada.WA Eficiencia = 1 N ∗ N I = 0 Speedi ∗ (1 - Sobrevei) El trabajo útil realizado por un procesador (1 - Sobrevei) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene velocidad = 1, para otros se mantiene: 0 <velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como los rápidos que pasan una gran fracción del tiempo que está inactivo. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficio que agregar procesadores rápidos. En el mundo heterogéneo, no es beneficioso agregar procesadores si la eficiencia es inferior al 50% a menos que el procesador agregado sea más rápido que algunos de los procesadores utilizados actualmente. Agregar procesadores más rápidos puede ser beneficioso independientemente de la eficiencia.3.2 Monitoreo de la aplicación Cada procesador mide el tiempo que pasa comunicando o está inactivo. El cálculo se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan su sobrecarga durante este período como el porcentaje del tiempo que pasaron en inactivo o comunicándose en este período. Además de la sobrecarga total, cada procesador también calcula la sobrecarga de la comunicación entre grupos e intracluster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, que dependen de la aplicación y el tamaño del problema utilizado. Dado que no es práctico ejecutar la aplicación completa 122 en cada procesador por separado, utilizamos los puntos de referencia específicos de aplicaciones. Actualmente usamos la misma aplicación con un pequeño tamaño de problema como punto de referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional del programador para encontrar el tamaño del problema correcto y posiblemente para producir archivos de entrada para este tamaño de problema, lo que puede ser difícil. En el futuro, estamos planeando generar puntos de referencia automáticamente eligiendo un subconjunto aleatorio del gráfico de tareas de la aplicación original. Los puntos de referencia deben volver a ejecutar periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga por otra aplicación (para máquinas compartidas). Existe una compensación entre la precisión de las mediciones de velocidad y la sobrecarga en la que incurre. Cuanto más tiempo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más a menudo se ejecuta, se detectan cambios más rápidos en la velocidad del procesador. En nuestra implementación actual, el programador de aplicaciones especifica la longitud del punto de referencia (al especificar su tamaño de problema) y la sobrecarga máxima que puede causar. Los procesadores ejecutan el punto de referencia a tal frecuencia para no exceder la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador que nos permitiría evitar ejecutar el punto de referencia si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de evaluación comparativa. Tenga en cuenta que la sobrecarga de evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones de trabajadores maestros con tareas de tamaño igual o similar. La velocidad del procesador podría medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de división y conquista generalmente exhiben una estructura muy irregular. Los tamaños de las tareas pueden variar según muchos órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades del procesador al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como los gastos generales o gastos generales entre clúster promedio en cada clúster. Los relojes de los procesadores no están sincronizados entre sí o con el reloj del coordinador. Cada procesador decide por separado cuando es hora de enviar datos. Ocasionalmente, el coordinador puede perder datos al final de un período de monitoreo, por lo que tiene que usar datos del período de monitoreo anterior para estos procesadores. Esto causa pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación.3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede EMAX, el coordinador solicita nuevos procesadores del planificador. El número de procesadores solicitados depende de la eficiencia actual: cuanto mayor sea la eficiencia, más procesadores se solicitan. El coordinador comienza a eliminar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que usamos son EMAX = 50%, porque sabemos que agregar procesadores cuando la eficiencia es menor no tiene sentido, y emin = 30%. La eficiencia del 30% o menos puede indicar problemas de rendimiento, como procesadores de bajo ancho de banda o sobrecarga. En ese caso, la eliminación de procesadores malos será beneficioso para la aplicación. Tal baja eficiencia también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, eliminar algunos procesadores puede no ser beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los peores procesadores. La maldad de un procesador está determinada por la siguiente fórmula: PROC Badnessi = α ∗ 1 Speedi + β ∗ IC Overheadi + γ ∗ InW Orstcluster (i) El procesador se considera malo si tiene baja velocidad (1 velocidad es grande) y altaOverhead entre clúster (sobrecarga IC). La sobrecarga de alta intergrupa indica que el ancho de banda de este clúster de procesadores es insuficiente. La eliminación de procesadores ubicados en un solo grupo es deseable ya que disminuye la cantidad de comunicación de área ancha. Por lo tanto, se prefieren los procesadores que pertenecen al peor grupo. La función inW OrstCluster (i) devuelve 1 para procesadores que pertenecen al peor clúster y 0 de lo contrario. La maldad de los clústeres se calcula de manera similar a la maldad de los procesadores: la mala mala calidad del clúster = α ∗ 1 Speedi + β β IC Sobre la velocidad de un clúster es la suma de las velocidades del procesador normalizadas a la velocidad del grupo más rápido. La sobrecarga de IC de un clúster es un promedio de sobrecargas entre grupos del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen empíricamente. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, según la observación de que la sobrecarga de IC> 0.2 indica problemas de ancho de banda y procesadores con velocidad <0.05 no contribuyen al cálculo. Además, cuando uno de los clústeres tiene una sobrecarga entre clúster excepcionalmente alta (más de 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la red troncal de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el clúster en lugar de calcular la maldad del nodo y eliminar los peores nodos. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos dejan el cálculo. La Figura 1 muestra una visión esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no es compatible, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas de la red: • Si se inicia una aplicación en menos procesadores que su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como hay recursos adicionales disponibles.). Por el contrario, si se inicia una aplicación en más procesadores de los que puede usar de manera eficiente, se lanzará una parte de los procesadores.• Si una aplicación se ejecuta en un conjunto apropiado de recursos, pero después de un tiempo, algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, se eliminarán los recursos sobrecargados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral EMAX y el Coordinador de adaptación intentará agregar nuevos recursos. Por lo tanto, la aplicación se migrará de los recursos sobrecargados.• Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados se eliminarán. Si es necesario, el componente de adaptación intentará agregar otros recursos.• Si durante el cálculo se bloqueará una parte sustancial de los procesadores, el componente de adaptación intentará agregar nuevos recursos para reemplazar los procesadores bloqueados.123 0 2000 4000 6000 de ejecución (secs.) Escenario 0 A B C Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, los escenarios 0-5 Agregar nodos nodos más rápidos disponibles si calculan la eficiencia promedio ponderada e WA Wa Wait y recolectan los nodos de rango de rango Elimine los peores nodos wae ewa y n y arriba si es abajo si emin maxe figura 1. Estrategia de adaptación • Si el grado de aplicación de paralelismo está cambiando durante el cálculo, el número de nodos en los que se ejecuta la aplicación se ajustará automáticamente. Son posibles mejoras adicionales, pero requieren una funcionalidad adicional del programador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar los nodos a un cálculo. Actualmente, agregamos cualquier nodo que nos brinde el programador. Sin embargo, sería más eficiente pedir los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, al pasar un punto de referencia al planificador de la cuadrícula, para que pueda medir las velocidades del procesador de una manera específica de la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los grupos y las supercomputadoras son generalmente homogéneas. Un enfoque alternativo sería clasificar los procesadores en función de parámetros como la velocidad del reloj y el tamaño de la memoria caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que usar un punto de referencia específico de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se aprieta cada vez que se elimina un clúster con alto nivel entre clúster. El ancho de banda entre cada par de grupos se estima durante el cálculo midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como un mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de cuadrícula. Dichos límites se pueden pasar al planificador para evitar agregar recursos inapropiados. Es especialmente importante cuando migra de los recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente usamos Blacklisting: simplemente no permitimos agregar recursos que eliminamos antes. Esto significa, sin embargo, que no podemos usar estos recursos, incluso si la causa del problema de rendimiento desaparece, p.El ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar una migración oportunista, migrando a mejores recursos cuando se descubren. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no realizará ninguna acción, incluso si hay mejores recursos disponibles. Habilitar la migración oportunista requiere, nuevamente, la capacidad de especificar al programador qué mejores recursos son (más rápido, con un cierto ancho de banda mínimo) y recibir notificaciones cuando dichos recursos están disponibles. Los programadores de cuadrícula existentes como el Gram del Kit de herramientas Globus (11) no admiten dicha funcionalidad. Los desarrolladores del Koala Metascheduler (15) han comenzado recientemente un proyecto cuyo objetivo es brindar apoyo para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de extender nuestra adaptividad Strat124 Egy para apoyar la migración oportunista y mejorar la selección inicial de recursos.4. Implementación Incorporamos nuestro mecanismo de adaptación en Satin, un marco Java para crear aplicaciones divididas y conquistar habilitadas para la red. Con el satén, el programador anota el código secuencial con primitivas divididas y conquistas y compila el código anotado con un compilador de satén especial que genera la comunicación necesaria y el código de equilibrio de carga. El satén utiliza un algoritmo de equilibrio de carga de carga muy eficiente y consciente de la cuadrícula-Robado aleatorio con consumo de clúster (CRS) (19), que oculta latencias de área amplia al superponer el robo local y remoto. El satén también proporciona tolerancia a fallas transparente y maleabilidad (23). Con satén, eliminar y agregar procesadores de/a un cálculo continuo incurre en poca sobrecarga. Instrumentamos el sistema de tiempo de ejecución de satén para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como el satén se implementan completamente en Java sobre la Biblioteca de Comunicación IBIS (21). El núcleo de IBIS también se implementa en Java. Por lo tanto, el sistema resultante es altamente portátil (debido a la escritura de Javas una vez, ejecuta la propiedad en cualquier lugar), lo que permite que el software se ejecute sin modificar en una cuadrícula heterogénea. IBIS también proporciona el registro de IBIS. El registro proporciona, entre otros, un servicio de membresía a los procesadores que participan en el cálculo. El Coordinador de adaptación utiliza el registro para descubrir los procesos de solicitud, y los procesos de solicitud usan este servicio para descubrir entre sí. El registro también ofrece detección de fallas (adicional a la detección de fallas proporcionada por los canales de comunicación). Finalmente, el registro proporciona la posibilidad de enviar señales a los procesos de solicitud. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan para dejar el cálculo. Actualmente, el registro se implementa como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9), un middleware de supercomputación entre pares que permite una asignación directa de procesadores en múltiples grupos y/o supercomputadoras. Zorilla proporciona la programación de la localidad, que intenta asignar procesadores que se encuentran cerca entre sí en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación del ancho de banda, lo que trata de maximizar el ancho de banda total en el sistema. El zorilla se puede reemplazar fácilmente con otro planificador de cuadrícula. En el futuro, estamos planeando integrar nuestro componente de adaptación con GAT (3) que se está convirtiendo en un estándar en la comunidad de la red y koala (15) un programador que proporciona co-asignación sobre el middleware de la red estándar, como el kit de herramientas Globus(11).5. Evaluación del desempeño En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de modo que la eficiencia es de alrededor del 50%) y no se producen problemas como redes y procesadores sobrecargados, procesadores de bloqueo, etc. Este escenario nos permite medir la sobrecarga del soporte de adaptación. Los escenarios restantes son típicos para los entornos de la red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento serios, como procesadores sobrecargados o enlaces de red. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza la evaluación comparativa (para medir velocidades del procesador). En el escenario ideal, 0 5 10 15 Número de iteración 0 200 400 600 iteración Duración (secs.) Comenzando en 8 nodos que comienzan en 16 nodos que comienzan en 24 nodos que comienzan en 8 nodos que comienzan en 16 nodos que comienzan en 24 nodos} sin adaptación} con adaptación con adaptaciónFigura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (SECS). Sin adaptación con adaptación la carga de la CPU introducida los nodos sobrecargados eliminados comenzó a agregar nodos 36 nodos alcanzados en la Figura 4. Duraciones de iteración de Barnes-Hut con/sin adaptación, CPU sobrecargadas, además, medimos el rendimiento de una aplicación con la recopilación de estadísticas y la evaluación comparativa activada pero sin hacer la adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir la sobrecarga de la evaluación comparativa y la recolección de estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área ancha DAS-2 (8), que consta de cinco grupos ubicados en cinco versidades holandesas UNI125. Uno de los grupos consta de 72 nodos, los otros de 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los grupos están conectados por la columna vertebral de Internet de la Universidad holandesa. En nuestros experimentos, utilizamos la simulación Barnes-Hut N-Body. Barneshut simula la evolución de un gran conjunto de cuerpos bajo la influencia de las fuerzas (gravitacionales o electrostáticas). La evolución de N organismos se simula en iteraciones de pasos de tiempo discretos.5.1 Escenario 0: Sobre la superación de adaptación En este escenario, la aplicación se inicia en 36 nodos. Los nodos están igualmente divididos en 3 grupos (12 nodos en cada clúster). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, colección de estadísticas y benchmarking) se enciendepero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Esos tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra la sobrecarga del soporte de adaptación. En este experimento es alrededor del 15%. Casi todo lo alto proviene de la evaluación comparativa. El punto de referencia se ejecuta 1-2 veces por período de monitoreo. Esta sobrecarga se puede hacer más pequeña aumentando la longitud del período de monitoreo y disminuyendo la frecuencia de evaluación comparativa. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, porque el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de ejecución más larga no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de cuadrícula del mundo real generalmente necesitan horas, días o incluso semanas para completar. Para tales aplicaciones, se puede usar un período de monitoreo mucho más largo y la sobrecarga de adaptación puede mantenerse mucho más baja. Por ejemplo, con la aplicación Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga cae al 6%. Tenga en cuenta que combinar la evaluación comparativa con la carga del procesador de monitoreo (como se describe en la Sección 3.2) reduciría la sobrecarga de evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los puntos de referencia solo deberían ejecutarse al comienzo del cálculo.5.2 Escenario 1: Al expandirse a más nodos en este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede usar de manera eficiente. Esto puede suceder porque el usuario no conoce el número correcto de nodos o porque los nodos insuficientes estaban disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1A), 16 (Escenario 1B) y 24 (Escenario 1C). Los nodos se ubicaron en 1 o 2 grupos. En cada uno de los tres sub-escenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 grupos. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (escenario 1A), 35% (escenario 1b) y 12% (escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (escenario 1a), 1.7 (escenario 1b) y 1.2 (escenario 1c) que nos permite concluir que las ganancias en el tiempo de ejecución total serían aún mayores si la aplicación se ejecutara más larga que para15 iteraciones.5.3 Escenario 2: procesadores sobrecargados En este escenario, comenzamos la aplicación en 36 nodos en 3 grupos. Después de 200 segundos, presentamos una carga pesada y artificial en los procesadores en uno de los grupos. Tal situación puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de iteración de las versiones adaptativas y no adaptativas. Después de introducir la carga, la iteración 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (SECS.) Sin adaptación con adaptación Un clúster está mal conectado mal conectado Cluster eliminado Comenzó a agregar nodos 36 nodos alcanzados a la Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (Secs.) Sin adaptación con adaptación Un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados mal connected 2 Lightly 2 Lightly Lightly LightlyNodos sobrecargados Figura 6. Las duraciones de la iteración de Barnes-Hut con/sin adaptación, CPU sobrecargadas y una duración de enlace de red sobrecargada aumentó en un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que activó agregar nuevos nodos y la aplicación se expandió a 38 nodos. Entonces, los nodos sobrecargados fueron reemplazados por mejores nodos, lo que llevó la duración de la iteración a los valores iniciales. Esto redujo el tiempo de ejecución total en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: Enlace de red sobrecargado En este escenario, ejecutamos la aplicación en 36 nodos en 3 clústeres. Simulamos que el enlace ascendente a uno de los grupos estaba sobrecargado y el ancho de banda en este enlace ascendente se redujo a aproximadamente 100 kb/s. Para simular un bajo ancho de banda, utilizamos las técnicas de forma de tráfico descritas en (6). Las duraciones de la iteración en este experimento se muestran en la Figura 5. Las duraciones de iteración de la versión no adaptativa exhiben una enorme variación: de 170 a 890 segundos. La versión adaptativa eliminó el clúster mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y los nodos nuevos se agregaron gradualmente hasta que su número alcanzó 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo de ejecución total se redujo en un 60% (Figura 2).5.5 Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado En este escenario, ejecutamos la aplicación en 36 nodos en 3 clústeres. Nuevamente, simulamos un enlace ascendente sobrecargado a uno de los grupos. Además, simulamos procesadores con velocidades heterogéneas insertando una carga artificial relativamente ligera en los procesadores en uno de los grupos restantes. Las duraciones de la iteración se muestran en la Figura 6. Nuevamente, la versión no adaptativa exhibe una gran variación en la duración de la iteración: de 200 a 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, ya que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada aumenta solo a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se agregan ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si estos nodos se agregaran a la aplicación (que podría activar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Aún así, la adaptación redujo el tiempo de ejecución total en un 30% (Figura 2).5.6 Escenario 5: Nodos bloqueados En el último escenario, también ejecutamos la aplicación en 36 nodos en 3 grupos. Después de 500 segundos, 2 de 3 clústeres se bloquean. Las duraciones de la iteración se muestran en la Figura 7. Después del accidente, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó agregar nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que llevó la duración de la iteración a alrededor de 100 segundos. El tiempo de ejecución total se redujo en el 13% (Figura 2).6. Trabajo relacionado Varios proyectos de cuadrícula abordan la cuestión de la selección y adaptación de recursos. En Grads (18) y Assist (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examinan varios conjuntos de recursos posibles y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta la degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. Grads utiliza la relación de los tiempos de ejecución predichos (de ciertas fases de aplicación) a los tiempos de ejecución reales como un indicador del rendimiento de la aplicación. Assist utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares de trabajadores maestros) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (SECS.) Sin adaptación con la adaptación 2 de 3 clústeres, el bloqueo comenzó a agregar nodos 36 nodos alcanzados en la Figura 7. Duraciones de iteración de Barnes-Hut con/sin adaptación, se conoce el modelo de CPU de bloqueo, el problema de encontrar un conjunto de recursos óptimo (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-Complete. Actualmente, tanto los graduados como la asistencia examinan solo un subconjunto de todos los conjuntos de recursos posibles y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la cuadrícula disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que se puede examinar en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas o regulares. El cactus (2) y la red de cuadrícula (14) no usan modelos de rendimiento. Sin embargo, estos marcos solo son adecuados para aplicaciones secuenciales (reducción de cuadrícula) o de un solo sitio (cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y varios procesadores en un clúster (cactus) se utilizan para clasificar los recursos y se selecciona el recurso con el rango más alto. La aplicación se migra si se detecta la degradación del rendimiento o se descubren mejores recursos. Tanto el cactus como la red utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que es adecuada solo para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede usarse para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el Proyecto Apple (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basado en dicho modelo, se crea un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor programa de aplicaciones en este conjunto. Los agentes de programación de manzanas se escriben caso por caso y no se pueden reutilizar para otra solicitud. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, las aplicaciones maestras (plantilla AMWAT) y barrido de parámetros (plantilla APST). La migración no es compatible con el software de manzanas.127 En (13), se estudia el problema de programar aplicaciones de trabajadores maestros. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar el número correcto de trabajadores. El enfoque aquí es similar al nuestro en que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de aplicación en tiempo de ejecución y ajusta el número de trabajadores para abordar el número ideal.7. Conclusiones y trabajo futuro En este documento, investigamos el problema de la selección y adaptación de recursos en entornos de cuadrícula. Los enfoques existentes de estos problemas generalmente asumen la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Comenzamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite aprender ciertos requisitos de aplicación, como el número de procesadores que necesitan la aplicación o los requisitos de ancho de banda de aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no da como resultado el conjunto de recursos óptimo, sino en un conjunto de recursos razonable, es decir, un conjunto libre de varios cuellos de botella de rendimiento, como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la red. Las decisiones de adaptación se basan en la eficiencia promedio ponderada: una extensión del concepto de eficiencia paralela definida para máquinas paralelas homogéneas tradicionales. Si la eficiencia promedio ponderada cae por debajo de un cierto nivel, el coordinador de adaptación comienza a eliminar los peores nodos. La maldad de los nodos se define por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se agregan nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos de entornos de cuadrícula: expandirse a más nodos o encoger a menos nodos si la aplicación se inició en una cantidad inapropiada de procesadores, elimine los nodos inadecuados y los reemplace con mejores, reemplace procesadores bloqueados,etc. La aplicación se adapta completamente automáticamente a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de división y conquista satinada y lo evaluamos en la supercomputadora distribuida DAS-2 y demostramos que nuestro enfoque puede producir mejoras de rendimiento significativas (hasta el 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Esto, sin embargo, requiere programadores de cuadrícula con una funcionalidad más sofisticada de lo que existe actualmente. También se necesita más investigación para disminuir la sobrecarga de evaluación comparativa. Por ejemplo, la información sobre la carga de la CPU podría usarse para disminuir la frecuencia de evaluación comparativa. Otra línea de investigación que deseamos investigar es utilizar el control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de la mala gala de nodos podría refinarse en el tiempo de ejecución en función de la efectividad de las decisiones de adaptación anteriores. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en grandes cantidades de nodos (cientos o miles). Este problema se puede resolver implementando una jerarquía de coordinadores: un subcoordinador por grupo que recopila y procesa estadísticas de su grupo y un coordinador principal que recopila la información de los sub-coordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del Laboratorio Virtual para el Proyecto E-Science (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencias holandeses (OC&W) y es parte del Programa de Innovación de TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptividad de programa/componente paralelo. En Parco 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano Cactus: experimentos con descubrimiento de recursos y asignación en un entorno de cuadrícula. Intl Journal of High Performance Computing Applications, 15 (4): 345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J.Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la cuadrícula: una descripción general de GridLab. Intl Journal of High-Performance Computing Applications, 17 (4): 449-466, agosto de 2003. [4] J. E. Baldeschwieler, R. D. Blumafe y E. A. Atlas: una infraestructura para la informática global. En el 7º Taller Europeo de Sigops Sigops sobre soporte del sistema para aplicaciones mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la cuadrícula usando manzanas. IEEE Trans.en sistemas paralelos y distribuidos, 14 (4): 369-382, abril de 2003. [6] D.-M.Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en la programación de un shaper de tráfico. En 5to IEEE Symp.En computadoras y comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. Gridsat: un solucionador SAT distribuido a base de paja para la cuadrícula. En la Conferencia ACM/IEEE de 2003 sobre Supercomputación, página 37, 2003. [8] La supercomputadora ASCI distribuida (DAS).http://www.cs.vu.nl/das2/.[9] N. Drost, R. V. Van Nieuwport y H. E. Bal. CO-asignación de localidad simple en supercomputación entre pares. En el 6to Taller INTL sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eazing, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. Transacciones IEEE en computadoras, 38 (3): 408-423, marzo de 1989. [11] I. Globus Toolkit Versión 4: Software para sistemas orientados al servicio. En la Conferencia Internacional de IFIP sobre red y computación paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P.Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones de trabajadores maestros en la cuadrícula computacional. En el noveno IEEE INTL Symp.En computación distribuida de alto rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones de trabajadores maestros en la red computacional. En el primer taller internacional IEEE/ACM sobre computación en la red, páginas 214-227. Springer Verlag Lncs 1971, 2000. 128 [14] E. Huedo, R. S. Montero e I. M. Llorente. Un marco para la ejecución adaptativa en cuadrículas. Software - Práctica y experiencia, 34 (7): 631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el programador de co-asignación de Koala en multiclusters. En 5º IEEE/ACM INTL Symp.En Cluster Computing y The Grid, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de aplicaciones paralelas a grandes diferencias en el ancho de banda y la latencia en las interconexiones de dos capas. Sobre la arquitectura informática de alto rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por la tabla de transposición en la búsqueda distribuida. IEEE Trans.en Sistemas Paralelos y Distribuidos, 13 (5): 447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Auto adaptabilidad en la informática de la cuadrícula. Concurrencia y cálculo: Práctica y experiencia, 17 (2-4): 235-257, 2005. [19] R. V. Van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio eficiente de carga para aplicaciones de división y conquista de área amplia. En el octavo ACM Sigplan Symp.Sobre principios y prácticas de programación paralela, páginas 34-43, 2001. [20] R. V. Van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satinado: programación de cuadrícula basada en Java simple y eficiente. Computación escalable: Práctica y experiencia, 6 (3): 19-32, septiembre de 2004. [21] R. V. Van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. IBIS: un entorno de programación de cuadrícula flexible y eficiente basado en Java. Concurrencia y computación: Práctica y experiencia, 17 (78): 1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio meteorológico de la red: un servicio de pronóstico de rendimiento de recursos distribuido para metacomputación. Journal of Future Generation Computing Systems, 15 (5-6): 757-768, octubre de 1999. [23] G. Wrzesinska, R. V. Van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallas, maleabilidad y migración para aplicaciones conquistadoras de divididos en la red. En INTL Paralelo y Simposio de procesamiento distribuido, abril de 2005. 129",
    "original_sentences": [
        "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
        "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
        "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
        "Another problem is adaptation to the changing characteristics of the grid environment.",
        "Existing solutions to these two problems require that a performance model for an application is known.",
        "However, constructing such models is a complex task.",
        "In this paper, we investigate an approach that does not require performance models.",
        "We start an application on any set of resources.",
        "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
        "Then, we adjust the resource set to better fit the application needs.",
        "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
        "We evaluate our approach in a number of scenarios typical for the Grid.",
        "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
        "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
        "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
        "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
        "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
        "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
        "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
        "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
        "Also, new, better resources may become available.",
        "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
        "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
        "This approach has been adopted by a number of systems (5; 14; 18).",
        "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
        "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
        "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
        "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
        "We start an application on any set of resources.",
        "During the application run, we periodically collect information about the communication times and idle times of the processors.",
        "We use these statistics to automatically estimate the resource requirements of the application.",
        "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
        "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
        "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
        "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
        "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
        "It should not use static load balancing or be very sensitive to wide121 area latencies.",
        "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
        "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
        "We believe that our approach can be extended to other classes of applications with the given assumptions.",
        "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
        "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
        "The rest of this paper is structured as follows.",
        "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
        "In Section 3, we present our resource selection and adaptation strategy.",
        "In Section 4, we describe its implementation in the Satin framework.",
        "In Section 5, we evaluate our approach in a number of grid scenarios.",
        "In Section 6, we compare our approach with the related work.",
        "Finally, in Section 7, we conclude and describe future work. 2.",
        "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
        "We assume the following resource model.",
        "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
        "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
        "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
        "The different sites are connected by a WAN.",
        "Communication between sites suffers from high latencies.",
        "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
        "We studied the adaptation problem in the context of divide-andconquer applications.",
        "However, we believe that our methodology can be used for other types of applications as well.",
        "In this section we summarize the assumptions about applications that are important to our approach.",
        "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
        "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
        "Processors can be added or removed at any point in the computation with little overhead.",
        "The second assumption is that the application can efficiently run on processors with different speeds.",
        "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
        "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
        "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
        "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
        "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
        "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
        "The adaptation coordinator periodically collects performance statistics from the application processors.",
        "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
        "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
        "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
        "A heuristic formula is used to decide which processors have to be removed.",
        "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
        "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
        "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
        "Efficiency indicates the benefit of using multiple processors.",
        "Typically, the efficiency drops as new processors are added to the computation.",
        "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
        "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
        "Adding processors beyond this number yields little benefit.",
        "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
        "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
        "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
        "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
        "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
        "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
        "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
        "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
        "The computation is divided into monitoring periods.",
        "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
        "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
        "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
        "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
        "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
        "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
        "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
        "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
        "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
        "The longer the benchmark, the greater the accuracy of the measurement.",
        "The more often it is run, the faster changes in processor speed are detected.",
        "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
        "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
        "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
        "This optimization will further reduce the benchmarking overhead.",
        "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
        "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
        "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
        "The sizes of tasks can vary by many orders of magnitude.",
        "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
        "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
        "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
        "Each processor decides separately when it is time to send data.",
        "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
        "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
        "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
        "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
        "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
        "The number of nodes that are removed again depends on the weighted average efficiency.",
        "The lower the efficiency, the more nodes are removed.",
        "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
        "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
        "In that case, removing bad processors will be beneficial for the application.",
        "Such low efficiency might also indicate that we simply have too many processors.",
        "In that case, removing some processors may not be beneficial but it will not harm the application.",
        "The coordinator always tries to remove the worst processors.",
        "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
        "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
        "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
        "Therefore, processors belonging to the worst cluster are preferred.",
        "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
        "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
        "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
        "The α, β and γ coefficients determine the relative importance of the terms.",
        "Those coefficients are established empirically.",
        "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
        "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
        "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
        "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
        "Figure 1 shows a schematic view of the adaptation strategy.",
        "Dashed lines indicate a part that is not supported yet, as will be explained below.",
        "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
        "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
        "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
        "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
        "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
        "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
        "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
        "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
        "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
        "For example, adding nodes to a computation can be improved.",
        "Currently, we add any nodes the scheduler gives us.",
        "However, it would be more efficient to ask for the fastest processors among the available ones.",
        "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
        "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
        "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
        "This approach is sometimes used for resource selection for sequential applications (14).",
        "However, it is less accurate than using an application specific benchmark.",
        "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
        "One example is minimal bandwidth required by the application.",
        "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
        "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
        "Alternatively, information from a grid monitoring system can be used.",
        "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
        "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
        "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
        "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
        "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
        "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
        "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
        "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
        "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
        "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
        "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
        "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
        "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
        "Satin also provides transparent fault tolerance and malleability (23).",
        "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
        "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
        "The coordinator is implemented as a separate process.",
        "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
        "The core of Ibis is also implemented in Java.",
        "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
        "Ibis also provides the Ibis Registry.",
        "The Registry provides, among others, a membership service to the processors taking part in the computation.",
        "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
        "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
        "Finally, the Registry provides the possibility to send signals to application processes.",
        "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
        "Currently the Registry is implemented as a centralized server.",
        "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
        "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
        "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
        "Zorilla can be easily replaced with another grid scheduler.",
        "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
        "Performance evaluation In this section, we will evaluate our approach.",
        "We will demonstrate the performance of our mechanism in a few scenarios.",
        "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
        "This scenario allows us to measure the overhead of the adaptation support.",
        "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
        "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
        "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
        "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
        "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
        "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
        "This allows us to measure the overhead of benchmarking and collecting statistics.",
        "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
        "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
        "One of the clusters consists of 72 nodes, the others of 32 nodes.",
        "Each node contains two 1 GHz Pentium processors.",
        "Within a cluster, the nodes are connected by Fast Ethernet.",
        "The clusters are connected by the Dutch university Internet backbone.",
        "In our experiments, we used the Barnes-Hut N-body simulation.",
        "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
        "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
        "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
        "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
        "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
        "Those runtimes are shown in Figure 2, first group of bars.",
        "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
        "In this experiment it is around 15%.",
        "Almost all overhead comes from benchmarking.",
        "The benchmark is run 1-2 times per monitoring period.",
        "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
        "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
        "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
        "However, real-world grid applications typically need hours, days or even weeks to complete.",
        "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
        "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
        "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
        "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
        "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
        "The nodes were located in 1 or 2 clusters.",
        "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
        "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
        "Those runtimes are shown in Figure 2.",
        "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
        "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
        "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
        "Such a situation may happen when an application with a higher priority is started on some of the resources.",
        "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
        "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
        "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
        "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
        "Also, the iteration times became very variable.",
        "The adaptive version reacted by removing the overloaded nodes.",
        "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
        "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
        "This reduced the total runtime by 14%.",
        "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
        "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
        "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
        "The iteration durations in this experiment are shown in Figure 5.",
        "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
        "The adaptive version removed the badly connected cluster after the first monitoring period.",
        "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
        "This brought the iteration times down to around 100 seconds.",
        "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
        "Again, we simulated an overloaded uplink to one of the clusters.",
        "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
        "The iteration durations are shown in Figure 6.",
        "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
        "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
        "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
        "Since this value lies between Emin and Emax, no nodes are added or removed.",
        "This example illustrates what the advantages of opportunistic migration would be.",
        "There were faster nodes available in the system.",
        "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
        "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
        "After 500 seconds, 2 out of 3 clusters crash.",
        "The iteration durations are shown in Figure 7.",
        "After the crash, the iteration duration raised from 100 to 200 seconds.",
        "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
        "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
        "The total runtime was reduced by 13% (Figure 2). 6.",
        "Related work A number of Grid projects address the question of resource selection and adaptation.",
        "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
        "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
        "If performance degradation is detected during the computation, the resource selection phase is repeated.",
        "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
        "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
        "The main difference between these approaches and our approach is the use of performance models.",
        "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
        "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
        "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
        "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
        "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
        "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
        "Cactus (2) and GridWay (14) do not use performance models.",
        "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
        "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
        "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
        "The application is migrated if performance degradation is detected or better resources are discovered.",
        "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
        "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
        "Moreover, resource selection based on clock speed is not always accurate.",
        "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
        "The resource selection problem was also studied by the AppLeS project (5).",
        "In the context of this project, a number of applications were studied and performance models for these applications were created.",
        "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
        "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
        "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
        "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
        "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
        "Therefore, the problem is reduced to finding the right number of workers.",
        "The approach here is similar to ours in that no performance model is used.",
        "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
        "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
        "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
        "However, creating performance models is inherently difficult and requires knowledge about the application.",
        "We propose an approach that does not require in-depth knowledge about the application.",
        "We start the application on an arbitrary set of resources and monitor its performance.",
        "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
        "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
        "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
        "Our approach also allows the application to adapt to the changing grid conditions.",
        "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
        "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
        "The badness of the nodes is defined by a heuristic formula.",
        "If the weighted average efficiency raises above a certain level, new nodes are added.",
        "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
        "The application adapts fully automatically to changing conditions.",
        "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
        "Future work will involve extending our adaptation strategy to support opportunistic migration.",
        "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
        "Further research is also needed to decrease the benchmarking overhead.",
        "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
        "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
        "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
        "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
        "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
        "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
        "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
        "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
        "Parallel program/component adaptivity management.",
        "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
        "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
        "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
        "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
        "Enabling applications on the grid - a gridlab overview.",
        "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
        "Brewer.",
        "ATLAS: An Infrastructure for Global Computing.",
        "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
        "Adaptive Computing on the Grid Using AppLeS.",
        "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
        "Experiences in programming a traffic shaper.",
        "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
        "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
        "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
        "Simple localityaware co-allocation in peer-to-peer supercomputing.",
        "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
        "Speedup versus efficiency in parallel systems.",
        "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
        "Foster.",
        "Globus toolkit version 4: Software for serviceoriented systems.",
        "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
        "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
        "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
        "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
        "Adaptive scheduling for master-worker applications on the computational grid.",
        "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
        "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
        "A framework for adaptive execution in grids.",
        "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
        "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
        "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
        "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
        "In 5th Intl Symp.",
        "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
        "A performance analysis of transposition-table-driven work scheduling in distributed search.",
        "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
        "Self adaptivity in Grid computing.",
        "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
        "Efficient load balancing for wide-area divide-and-conquer applications.",
        "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
        "Satin: Simple and Efficient Java-based Grid Programming.",
        "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
        "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
        "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
        "The network weather service: A distributed resource performance forecasting service for metacomputing.",
        "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
        "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
        "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
    ],
    "error_count": 0,
    "keys": {
        "grid computing": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in <br>grid computing</br> is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, <br>grid computing</br> has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for <br>grid computing</br>.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on <br>grid computing</br>, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in <br>grid computing</br>.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Un problema importante en la \"Computación de la cuadrícula\" es la selección de recursos, es decir, encontrar un conjunto de recursos apropiado para la aplicación.computación de la cuadrícula",
                "Introducción En los últimos años, la \"computación de la cuadrícula\" se ha convertido en una alternativa real a la informática paralela tradicional.computación de la cuadrícula",
                "Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la \"computación de la cuadrícula\".computación de la cuadrícula",
                "En el primer taller internacional IEEE/ACM sobre \"Computación de la cuadrícula\", páginas 214-227.computación de la cuadrícula",
                "Auto adaptabilidad en \"Computación de la cuadrícula\".computación de la cuadrícula"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "resource selection": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is <br>resource selection</br>, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is <br>resource selection</br> - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the <br>resource selection</br> problem: the <br>resource selection</br> phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For <br>resource selection</br>, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and <br>resource selection</br> which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our <br>resource selection</br> and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for <br>resource selection</br> for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial <br>resource selection</br>. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of <br>resource selection</br> and adaptation.",
                "In GrADS (18) and ASSIST (1), <br>resource selection</br> and adaptation requires a performance model that allows predicting application runtimes.",
                "In the <br>resource selection</br> phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the <br>resource selection</br> phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the <br>resource selection</br> problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, <br>resource selection</br> based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The <br>resource selection</br> problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of <br>resource selection</br> and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Un problema importante en la informática de la red es la \"selección de recursos\", es decir, encontrar un conjunto de recursos apropiado para la aplicación.selección de recursos",
                "Un problema importante es la \"selección de recursos\": seleccionar un conjunto de nodos de cómputo de modo que la aplicación logre un buen rendimiento.selección de recursos",
                "El problema de adaptación puede reducirse al problema de \"selección de recursos\": la fase de \"selección de recursos\" se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares o cuando se detecta un problema de rendimiento, o cuando los nuevos recursos están disponibles.selección de recursos",
                "Para la \"selección de recursos\", el tiempo de ejecución de la aplicación se estima para algunos conjuntos de recursos y el conjunto que produce el tiempo de ejecución más corto se selecciona para la ejecución.selección de recursos",
                "En este documento, presentamos y evaluamos un enfoque alternativo para la adaptación de la aplicación y la \"selección de recursos\" que no necesita un modelo de rendimiento.selección de recursos",
                "En la Sección 3, presentamos nuestra \"Selección de recursos\" y estrategia de adaptación.selección de recursos",
                "Este enfoque a veces se utiliza para la \"selección de recursos\" para aplicaciones secuenciales (14).selección de recursos",
                "Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de extender nuestra adaptativa Strat124 Egy para apoyar la migración oportunista y mejorar la \"selección de recursos\" inicial.4. Selección de recursos",
                "Trabajo relacionado Varios proyectos de cuadrícula abordan la cuestión de la \"selección de recursos\" y la adaptación.selección de recursos",
                "En Grads (18) y Assist (1), la \"selección de recursos\" y la adaptación requieren un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación.selección de recursos"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "grid environment": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the <br>grid environment</br>.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a <br>grid environment</br> this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the <br>grid environment</br>.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a <br>grid environment</br>.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Otro problema es la adaptación a las características cambiantes del \"entorno de la cuadrícula\".ambiente de cuadrícula",
                "En un \"entorno de la cuadrícula\", este problema es aún más difícil, debido a la heterogeneidad de los recursos: los nodos de cómputo tienen varias velocidades y la calidad de las conexiones de red entre ellos varía de las redes (LAN) de área local de baja latencia y alto ancho de la banda (LAN)a redes de alta latencia y posiblemente de bajo ancho de banda ancha (Wans).ambiente de cuadrícula",
                "Autoadaptación En esta sección explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación determinada y para adaptarnos a las condiciones cambiantes en el \"entorno de la cuadrícula\".ambiente de cuadrícula",
                "El gusano Cactus: experimentos con descubrimiento de recursos y asignación en un \"entorno de cuadrícula\".ambiente de cuadrícula"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "parallel computing": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional <br>parallel computing</br>.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional <br>parallel computing</br>, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and <br>parallel computing</br>, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Introducción En los últimos años, la computación de la red se ha convertido en una verdadera alternativa a la \"computación paralela\" tradicional.computación paralela",
                "Estos requisitos se utilizan para guiar la adición de nuevos procesadores.3.1 Eficiencia promedio ponderada en la \"computación paralela\" tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia.computación paralela",
                "En la Conferencia Internacional de IFIP sobre red y \"Computación paralela\", páginas 2-13.computación paralela"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "homogeneous parallel environment": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, <br>homogeneous parallel environment</br>s, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Incluso en el \"entorno paralelo homogéneo\" tradicional, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera de prueba y error.ambiente paralelo homogéneo"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "heterogeneity of resource": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the <br>heterogeneity of resource</br>s: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En un entorno de la cuadrícula, este problema es aún más difícil, debido a la \"heterogeneidad de los recursos\": los nodos de cómputo tienen varias velocidades y la calidad de las conexiones de red entre ellos varía de las redes de área local de baja latencia y alto ancho de banda (LANS) a redes de alta latencia y posiblemente de bajo ancho de banda ancha (Wans).heterogeneidad de los recursos"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "resource heterogeneity": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "high-bandwidth local-area network": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and <br>high-bandwidth local-area network</br>s (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En un entorno de la cuadrícula, este problema es aún más difícil, debido a la heterogeneidad de los recursos: los nodos de cómputo tienen varias velocidades y la calidad de las conexiones de red entre ellos varía de la \"red del área local de alta latencia y de alto ancho\" (LANS) a redes de alta latencia y posiblemente de bajo ancho de banda ancha (Wans).Red de área local de alto ancho de banda"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "lower-bandwidth wide-area network": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "network link": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded <br>network link</br> 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded <br>network link</br> duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded <br>network link</br> In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded <br>network link</br> In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Duraciones de iteración de Barnes-Hut con/sin adaptación, \"enlace de red\" sobrecargado 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (SECS.) Sin adaptación con adaptación Un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados2 Nodos ligeramente sobrecargados Figura 6. Enlace de red",
                "Las duraciones de la iteración de Barnes-Hut con/sin adaptación, CPU sobrecargadas y una duración de \"enlace de red\" sobrecargado aumentó en un factor de 2 a 3. Enlace de red",
                "Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: \"Enlace de red\" sobrecargado En este escenario, ejecutamos la aplicación en 36 nodos en 3 grupos.enlace de red",
                "El tiempo de ejecución total se redujo en un 60% (Figura 2).5.5 Escenario 4: procesadores sobrecargados y un \"enlace de red\" sobrecargado En este escenario, ejecutamos la aplicación en 36 nodos en 3 clústeres.enlace de red"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "communication time": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the <br>communication time</br>s and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Durante la ejecución de la aplicación, periódicamente recopilamos información sobre los \"tiempo de comunicación\" y los tiempos inactivos de los procesadores.Tiempo de comunicación"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "idle times of the processors": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and <br>idle times of the processors</br>.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Durante la ejecución de la aplicación, periódicamente recopilamos información sobre los tiempos de comunicación y los \"tiempos de inactividad de los procesadores\".tiempos inactivos de los procesadores"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "the processor idle time": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "degree of parallelism": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the <br>degree of parallelism</br> in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its <br>degree of parallelism</br> allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application <br>degree of parallelism</br> is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Maneja todos los siguientes casos: • Adaptando automáticamente el número de procesadores al \"grado de paralelismo\" en la aplicación, incluso cuando este grado cambia dinámicamente durante el cálculo • Migrando (parte de) un cálculo de recursos sobrecargados • Eliminar recursoscon malos enlaces de comunicación que ralentizan el cálculo • Agregar nuevos recursos para reemplazar los recursos que han bloqueado nuestro trabajo supone que la aplicación es maleable y puede ejecutarse (de manera eficiente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación (15)).grado de paralelismo",
                "Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas de la cuadrícula: • Si una aplicación se inicia en menos procesadores que su \"grado de paralelismo\", se expandirá automáticamente a más procesadores (tan pronto como hay más.recursos disponibles).grado de paralelismo",
                "Estrategia de adaptación • Si el \"grado de paralelismo\" de la aplicación está cambiando durante el cálculo, el número de nodos en los que se ejecuta la aplicación se ajustará automáticamente.grado de paralelismo"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "parallelism degree": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "overloaded resource": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from <br>overloaded resource</br>s • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the <br>overloaded resource</br>s will be removed.",
                "After removing the <br>overloaded resource</br>s, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from <br>overloaded resource</br>s. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Maneja todos los siguientes casos: • Adaptando automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante el cálculo • Migración (parte de) un cálculo lejos de \"recursos sobrecargados\" S • EliminaciónRecursos con malos enlaces de comunicación que ralentizan el cálculo • Agregar nuevos recursos para reemplazar los recursos que han bloqueado nuestro trabajo supone que la aplicación es maleable y puede ejecutarse (de manera eficiente) en múltiples sitios de una cuadrícula (es decir, utilizando la co-asignación (15)).recurso sobrecargado",
                "Por el contrario, si se inicia una aplicación en más procesadores de los que puede usar de manera eficiente, se lanzará una parte de los procesadores.• Si una aplicación se ejecuta en un conjunto apropiado de recursos, pero después de un tiempo, algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, se eliminarán los \"recursos sobrecargados\".recurso sobrecargado",
                "Después de eliminar los \"recursos sobrecargados\" s, la eficiencia promedio ponderada aumentará por encima del umbral EMAX y el Coordinador de adaptación intentará agregar nuevos recursos.recurso sobrecargado",
                "Por lo tanto, la aplicación se migrará de \"recursos sobrecargados\" s.• Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados se eliminarán.recurso sobrecargado"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "divide-and-conquer": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to <br>divide-and-conquer</br> applications, which satisfy these requirements.",
                "<br>divide-and-conquer</br> has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled <br>divide-and-conquer</br> applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by <br>divide-and-conquer</br> applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, <br>divide-and-conquer</br> applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled <br>divide-and-conquer</br> applications.",
                "With Satin, the programmer annotates the sequential code with <br>divide-and-conquer</br> primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin <br>divide-and-conquer</br> framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area <br>divide-and-conquer</br> applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Hemos aplicado nuestras ideas a aplicaciones de \"dividir y concertar\", que satisfacen estos requisitos.divide y conquistaras",
                "Se ha demostrado que \"dividir y consultar\" es un paradigma atractivo para la programación de aplicaciones de cuadrícula (4; 20).divide y conquistaras",
                "Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones \"divididas y conquistar\" habilitadas para la cuadrícula (20).divide y conquistaras",
                "Esto se puede lograr mediante el uso de una estrategia de equilibrio de carga dinámica, como el robo del trabajo utilizado por aplicaciones de \"dividir y concebir\" (19).divide y conquistaras",
                "Desafortunadamente, las aplicaciones de \"dividir y consultar\" generalmente exhiben una estructura muy irregular.divide y conquistaras",
                "Implementación Incorporamos nuestro mecanismo de adaptación en el satén, un marco Java para crear aplicaciones \"dividir y concluir\" habilitadas para la cuadrícula.divide y conquistaras",
                "Con satén, el programador anota el código secuencial con primitivas \"dividir y concluir\" y compila el código anotado con un compilador de satén especial que genera la comunicación necesaria y el código de equilibrio de carga.divide y conquistaras",
                "Implementamos nuestro enfoque en el marco satinado \"dividir y concebir\" y lo evaluamos en la supercomputadora distribuida DAS-2 y demostramos que nuestro enfoque puede producir mejoras de rendimiento significativas (hasta el 60% en nuestros experimentos).divide y conquistaras",
                "Equilibrio eficiente de carga para aplicaciones de \"división y conclusión\" de área ancha.divide y conquistaras"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "self-adaptivity": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Self-Adaptive Applications on the Grid Gosia Wrzesinska Jason Maassen Henri E. Bal Dept.",
                "of Computer Systems, Vrije Universiteit Amsterdam {gosia, jason, bal}@cs.vu.nl Abstract Grids are inherently heterogeneous and dynamic.",
                "One important problem in grid computing is resource selection, that is, finding an appropriate resource set for the application.",
                "Another problem is adaptation to the changing characteristics of the grid environment.",
                "Existing solutions to these two problems require that a performance model for an application is known.",
                "However, constructing such models is a complex task.",
                "In this paper, we investigate an approach that does not require performance models.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect the statistics about the application run and deduce application requirements from these statistics.",
                "Then, we adjust the resource set to better fit the application needs.",
                "This approach allows us to avoid performance bottlenecks, such as overloaded WAN links or very slow processors, and therefore can yield significant performance improvements.",
                "We evaluate our approach in a number of scenarios typical for the Grid.",
                "Categories and Subject Descriptors C.2.4 [COMPUTER COMMUNICATION NETWORKS]: Distributed Systems-Distributed applications ; C.4 [PERFORMANCE OF SYSTEMS]: Measurement techniques, Modelling techniques General Terms Algorithms, Measurement, Performance, Experimentation 1.",
                "Introduction In recent years, grid computing has become a real alternative to traditional parallel computing.",
                "A grid provides much computational power, and thus offers the possibility to solve very large problems, especially if applications can run on multiple sites at the same time (7; 15; 20).",
                "However, the complexity of Grid environments also is many times larger than that of traditional parallel machines like clusters and supercomputers.",
                "One important problem is resource selection - selecting a set of compute nodes such that the application achieves good performance.",
                "Even in traditional, homogeneous parallel environments, finding the optimal number of nodes is a hard problem and is often solved in a trial-and-error fashion.",
                "In a grid environment this problem is even more difficult, because of the heterogeneity of resources: the compute nodes have various speeds and the quality of network connections between them varies from low-latency and high-bandwidth local-area networks (LANs) to high-latency and possibly low-bandwidth wide-area networks (WANs).",
                "Another important problem is that the performance and availability of grid resources varies over time: the network links or compute nodes may become overloaded, or the compute nodes may become unavailable because of crashes or because they have been claimed by a higher priority application.",
                "Also, new, better resources may become available.",
                "To maintain a reasonable performance level, the application therefore needs to adapt to the changing conditions.",
                "The adaptation problem can be reduced to the resource selection problem: the resource selection phase can be repeated during application execution, either at regular intervals, or when a performance problem is detected, or when new resources become available.",
                "This approach has been adopted by a number of systems (5; 14; 18).",
                "For resource selection, the application runtime is estimated for some resource sets and the set that yields the shortest runtime is selected for execution.",
                "Predicting the application runtime on a given set of resources, however, requires knowledge about the application.",
                "Typically, an analytical performance model is used, but constructing such a model is inherently difficult and requires an expertise which application programmers may not have.",
                "In this paper, we introduce and evaluate an alternative approach to application adaptation and resource selection which does not need a performance model.",
                "We start an application on any set of resources.",
                "During the application run, we periodically collect information about the communication times and idle times of the processors.",
                "We use these statistics to automatically estimate the resource requirements of the application.",
                "Next, we adjust the resource set the application is running on by adding or removing compute nodes or even entire clusters.",
                "Our adaptation strategy uses the work by Eager et al. (10) to determine the efficiency and tries to keep the efficiency of the application between a lower and upper threshold derived from their theory.",
                "Processors are added or deleted to stay between the thresholds, thus adapting automatically to the changing environment.",
                "A major advantage of our approach is that it improves application performance in many different situations that are typical for grid computing.",
                "It handles all of the following cases: • automatically adapting the number of processors to the degree of parallelism in the application, even when this degree changes dynamically during the computation • migrating (part of) a computation away from overloaded resources • removing resources with poor communication links that slow down the computation • adding new resources to replace resources that have crashed Our work assumes the application is malleable and can run (efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).",
                "It should not use static load balancing or be very sensitive to wide121 area latencies.",
                "We have applied our ideas to divide-and-conquer applications, which satisfy these requirements.",
                "Divide-and-conquer has been shown to be an attractive paradigm for programming grid applications (4; 20).",
                "We believe that our approach can be extended to other classes of applications with the given assumptions.",
                "We implemented our strategy in Satin, which is a Java-centric framework for writing grid-enabled divide-and-conquer applications (20).",
                "We evaluate the performance of our approach on the DAS-2 wide-area system and we will show that our approach yields major performance improvements (roughly 10-60 %) in the above scenarios.",
                "The rest of this paper is structured as follows.",
                "In Section 2, we explain what assumptions we are making about the applications and grid resources.",
                "In Section 3, we present our resource selection and adaptation strategy.",
                "In Section 4, we describe its implementation in the Satin framework.",
                "In Section 5, we evaluate our approach in a number of grid scenarios.",
                "In Section 6, we compare our approach with the related work.",
                "Finally, in Section 7, we conclude and describe future work. 2.",
                "Background and assumptions In this section, we describe our assumptions about the applications and their resources.",
                "We assume the following resource model.",
                "The applications are running on multiple sites at the same time, where sites are clusters or supercomputers.",
                "We also assume that the processors of the sites are accessible using a grid scheduling system, such as Koala (15), Zorilla (9) or GRMS (3).",
                "Processors belonging to one site are connected by a fast LAN with a low latency and high bandwidth.",
                "The different sites are connected by a WAN.",
                "Communication between sites suffers from high latencies.",
                "We assume that the links connecting the sites with the Internet backbone might become bottlenecks causing the inter-site communication to suffer from low bandwidths.",
                "We studied the adaptation problem in the context of divide-andconquer applications.",
                "However, we believe that our methodology can be used for other types of applications as well.",
                "In this section we summarize the assumptions about applications that are important to our approach.",
                "The first assumption we make is that the application is malleable, i.e., it is able to handle processors joining and leaving the on-going computation.",
                "In (23), we showed how divide-andconquer applications can be made fault tolerant and malleable.",
                "Processors can be added or removed at any point in the computation with little overhead.",
                "The second assumption is that the application can efficiently run on processors with different speeds.",
                "This can be achieved by using a dynamic load balancing strategy, such as work stealing used by divide-and-conquer applications (19).",
                "Also, master-worker applications typically use dynamic load-balancing strategies (e.g., MW - a framework for writing gridenabled master-worker applications (12)).",
                "We find it a reasonable assumption for a grid application, since applications for which the slowest processor becomes a bottleneck will not be able to efficiently utilize grid resources.",
                "Finally, the application should be insensitive to wide-area latencies, so it can run efficiently on a widearea grid (16; 17). 3.",
                "Self-adaptation In this section we will explain how we use application malleability to find a suitable set of resources for a given application and to adapt to changing conditions in the grid environment.",
                "In order to monitor the application performance and guide the adaptation, we added an extra process to the computation which we call adaptation coordinator.",
                "The adaptation coordinator periodically collects performance statistics from the application processors.",
                "We introduce a new application performance metric: weighted average efficiency which describes the application performance on a heterogeneous set of resources.",
                "The coordinator uses statistics from application processors to compute the weighted average efficiency.",
                "If the efficiency falls above or below certain thresholds, the coordinator decides on adding or removing processors.",
                "A heuristic formula is used to decide which processors have to be removed.",
                "During this process the coordinator learns the application requirements by remembering the characteristics of the removed processors.",
                "These requirements are then used to guide the adding of new processors. 3.1 Weighted average efficiency In traditional parallel computing, a standard metric describing the performance of a parallel application is efficiency.",
                "Efficiency is defined as the average utilization of the processors, that is, the fraction of time the processors spend doing useful work rather than being idle or communicating with other processors (10). efficiency = 1 n ∗ n i=0 (1 − overheadi ) where n is the number of processors and overheadi is the fraction of time the ith processor spends being idle or communicating.",
                "Efficiency indicates the benefit of using multiple processors.",
                "Typically, the efficiency drops as new processors are added to the computation.",
                "Therefore, achieving a high speedup (and thus a low execution time) and achieving a high system utilization are conflicting goals (10).",
                "The optimal number of processors is the number for which the ratio of efficiency to execution time is maximized.",
                "Adding processors beyond this number yields little benefit.",
                "This number is typically hard to find, but in (10) it was theoretically proven that if the optimal number of processors is used, the efficiency is at least 50%.",
                "Therefore, adding processors when efficiency is smaller or equal to 50% will only decrease the system utilization without significant performance gains.",
                "For heterogeneous environments with different processor speeds, we extended the notion of efficiency and introduced weighted average efficiency. wa efficiency = 1 n ∗ n i=0 speedi ∗ (1 − overheadi ) The useful work done by a processor (1 − overheadi) is weighted by multiplying it by the speed of this processor relative to the fastest processor.",
                "The fastest processor has speed = 1, for others holds: 0 < speed ≤ 1.",
                "Therefore, slower processors are modeled as fast ones that spend a large fraction of the time being idle.",
                "Weighted average efficiency reflects the fact that adding slow processors yields less benefit than adding fast processors.",
                "In the heterogeneous world, it is hardly beneficial to add processors if the efficiency is lower than 50% unless the added processor is faster than some of the currently used processors.",
                "Adding faster processors might be beneficial regardless of the efficiency. 3.2 Application monitoring Each processor measures the time it spends communicating or being idle.",
                "The computation is divided into monitoring periods.",
                "After each monitoring period, the processors compute their overhead over this period as the percentage of the time they spent being idle or communicating in this period.",
                "Apart from total overhead, each processor also computes the overhead of inter-cluster and intracluster communication.",
                "To calculate weighted average efficiency, we need to know the relative speeds of the processors, which depend on the application and the problem size used.",
                "Since it is impractical to run the 122 whole application on each processor separately, we use applicationspecific benchmarks.",
                "Currently we use the same application with a small problem size as a benchmark and we require the application programmer to specify this problem size.",
                "This approach requires extra effort from the programmer to find the right problem size and possibly to produce input files for this problem size, which may be hard.",
                "In the future, we are planning to generate benchmarks automatically by choosing a random subset of the task graph of the original application.",
                "Benchmarks have to be re-run periodically because the speed of a processor might change if it becomes overloaded by another application (for time-shared machines).",
                "There is a trade-off between the accuracy of speed measurements and the overhead it incurs.",
                "The longer the benchmark, the greater the accuracy of the measurement.",
                "The more often it is run, the faster changes in processor speed are detected.",
                "In our current implementation, the application programmer specifies the length of the benchmark (by specifying its problem size) and the maximal overhead it is allowed to cause.",
                "Processors run the benchmark at such frequency so as not to exceed the specified overhead.",
                "In the future, we plan to combine benchmarking with monitoring the load of the processor which would allow us to avoid running the benchmark if no change in processor load is detected.",
                "This optimization will further reduce the benchmarking overhead.",
                "Note that the benchmarking overhead could be avoided completely for more regular applications, for example, for masterworker applications with tasks of equal or similar size.",
                "The processor speed could then be measured by counting the tasks processed by this processor within one monitoring period.",
                "Unfortunately, divide-and-conquer applications typically exhibit a very irregular structure.",
                "The sizes of tasks can vary by many orders of magnitude.",
                "At the end of each monitoring period, the processors send the overhead statistics and processor speeds to the coordinator.",
                "Periodically, the coordinator computes the weighted average efficiency and other statistics, such as average inter-cluster overhead or overheads in each cluster.",
                "The clocks of the processors are not synchronized with each other or with the clock of the coordinator.",
                "Each processor decides separately when it is time to send data.",
                "Occasionally, the coordinator may miss data at the end of a monitoring period, so it has to use data from the previous monitoring period for these processors.",
                "This causes small inaccuracies in the calculations of the coordinator, but does not influence the performance of adaptation. 3.3 Adaptation strategy The adaptation coordinator tries to keep the weighted average efficiency between Emin and Emax.",
                "When it exceeds Emax, the coordinator requests new processors from the scheduler.",
                "The number of requested processors depends on the current efficiency: the higher the efficiency, the more processors are requested.",
                "The coordinator starts removing processors when the weighted average efficiency drops below Emin.",
                "The number of nodes that are removed again depends on the weighted average efficiency.",
                "The lower the efficiency, the more nodes are removed.",
                "The thresholds we use are Emax = 50%, because we know that adding processors when efficiency is lower does not make sense, and Emin = 30%.",
                "Efficiency of 30% or lower might indicate performance problems such as low bandwidth or overloaded processors.",
                "In that case, removing bad processors will be beneficial for the application.",
                "Such low efficiency might also indicate that we simply have too many processors.",
                "In that case, removing some processors may not be beneficial but it will not harm the application.",
                "The coordinator always tries to remove the worst processors.",
                "The badness of a processor is determined by the following formula: proc badnessi = α ∗ 1 speedi + β ∗ ic overheadi + γ ∗ inW orstCluster(i) The processor is considered bad if it has low speed ( 1 speed is big) and high inter-cluster overhead (ic overhead).",
                "High intercluster overhead indicates that the bandwidth to this processors cluster is insufficient.",
                "Removing processors located in a single cluster is desirable since it decreases the amount of wide-area communication.",
                "Therefore, processors belonging to the worst cluster are preferred.",
                "Function inW orstCluster(i) returns 1 for processors belonging to the worst cluster and 0 otherwise.",
                "The badness of clusters is computed similarly to the badness of processors: cluster badnessi = α ∗ 1 speedi + β ∗ ic overheadi The speed of a cluster is the sum of processor speeds normalized to the speed of the fastest cluster.",
                "The ic overhead of a cluster is an average of processor inter-cluster overheads.",
                "The α, β and γ coefficients determine the relative importance of the terms.",
                "Those coefficients are established empirically.",
                "Currently we are using the following values: α = 1, β = 100 and γ = 10, based on the observation that ic overhead > 0.2 indicates bandwidth problems and processors with speed < 0.05 do not contribute to the computation.",
                "Additionally, when one of the clusters has an exceptionally high inter-cluster overhead (larger than 0.25), we conclude that the bandwidth on the link between this cluster and the Internet backbone is insufficient for the application.",
                "In that case, we simply remove the whole cluster instead of computing node badness and removing the worst nodes.",
                "After deciding which nodes are removed, the coordinator sends a message to these nodes and the nodes leave the computation.",
                "Figure 1 shows a schematic view of the adaptation strategy.",
                "Dashed lines indicate a part that is not supported yet, as will be explained below.",
                "This simple adaptation strategy allows us to improve application performance in several situations typical for the Grid: • If an application is started on fewer processors than its degree of parallelism allows, it will automatically expand to more processors (as soon as there are extra resources available).",
                "Conversely, if an application is started on more processors than it can efficiently use, a part of the processors will be released. • If an application is running on an appropriate set of resources but after a while some of the resources (processors and/or network links) become overloaded and slow down the computation, the overloaded resources will be removed.",
                "After removing the overloaded resources, the weighted average efficiency will increase to above the Emax threshold and the adaptation coordinator will try to add new resources.",
                "Therefore, the application will be migrated from overloaded resources. • If some of the original resources chosen by the user are inappropriate for the application, for example the bandwidth to one of the clusters is too small, the inappropriate resources will be removed.",
                "If necessary, the adaptation component will try to add other resources. • If during the computation a substantial part of the processors will crash, the adaptation component will try to add new resources to replace the crashed processors. 123 0 2000 4000 6000 runtime(secs.)",
                "Scenario 0 a b c Scenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5 without monitoring and adaptation (runtime 1) with monitoring and adaptation (runtime 2) with monitoring but no adaptation (runtime 3) Figure 2.",
                "The runtimes of the Barnes-Hut application, scenarios 0-5 add nodes faster nodes available if compute weighted average efficiency E wa wait & collect statistics rank nodes remove worst nodes waE Ewa Y N N Y above if below if Emin maxE Figure 1.",
                "Adaptation strategy • If the application degree of parallelism is changing during the computation, the number of nodes the application is running on will be automatically adjusted.",
                "Further improvements are possible, but require extra functionality from the grid scheduler and/or integration with monitoring services such as NWS (22).",
                "For example, adding nodes to a computation can be improved.",
                "Currently, we add any nodes the scheduler gives us.",
                "However, it would be more efficient to ask for the fastest processors among the available ones.",
                "This could be done, for example, by passing a benchmark to the grid scheduler, so that it can measure processor speeds in an application specific way.",
                "Typically, it would be enough to measure the speed of one processor per site, since clusters and supercomputers are usually homogeneous.",
                "An alternative approach would be ranking the processors based on parameters such as clock speed and cache size.",
                "This approach is sometimes used for resource selection for sequential applications (14).",
                "However, it is less accurate than using an application specific benchmark.",
                "Also, during application execution, we can learn some application requirements and pass them to the scheduler.",
                "One example is minimal bandwidth required by the application.",
                "The lower bound on minimal required bandwidth is tightened each time a cluster with high inter-cluster overhead is removed.",
                "The bandwidth between each pair of clusters is estimated during the computation by measuring data transfer times, and the bandwidth to the removed cluster is set as a minimum.",
                "Alternatively, information from a grid monitoring system can be used.",
                "Such bounds can be passed to the scheduler to avoid adding inappropriate resources.",
                "It is especially important when migrating from resources that cause performance problems: we have to be careful not to add the resources we have just removed.",
                "Currently we use blacklisting - we simply do not allow adding resources we removed before.",
                "This means, however, that we cannot use these resources even if the cause of the performance problem disappears, e.g. the bandwidth of a link might improve if the background traffic diminishes.",
                "We are currently not able to perform opportunistic migration - migrating to better resources when they are discovered.",
                "If an application runs with efficiency between Emin and Emax, the adaptation component will not undertake any action, even if better resources become available.",
                "Enabling opportunistic migration requires, again, the ability to specify to the scheduler what better resources are (faster, with a certain minimal bandwidth) and receiving notifications when such resources become available.",
                "Existing grid schedulers such as GRAM from the Globus Toolkit (11) do not support such functionality.",
                "The developers of the KOALA metascheduler (15) have recently started a project whose goal is to provide support for adaptive applications.",
                "We are currently discussing with them the possibility of providing the functionalities required by us, aiming to extend our adaptivity strat124 egy to support opportunistic migration and to improve the initial resource selection. 4.",
                "Implementation We incorporated our adaptation mechanism into Satin - a Java framework for creating grid-enabled divide-and-conquer applications.",
                "With Satin, the programmer annotates the sequential code with divide-and-conquer primitives and compiles the annotated code with a special Satin compiler that generates the necessary communication and load balancing code.",
                "Satin uses a very efficient, grid-aware load balancing algorithm - Cluster-aware Random Work Stealing (CRS) (19), which hides wide-area latencies by overlapping local and remote stealing.",
                "Satin also provides transparent fault tolerance and malleability (23).",
                "With Satin, removing and adding processors from/to an ongoing computation incurs little overhead.",
                "We instrumented the Satin runtime system to collect runtime statistics and send them to the adaptation coordinator.",
                "The coordinator is implemented as a separate process.",
                "Both coordinator and Satin are implemented entirely in Java on top of the Ibis communication library (21).",
                "The core of Ibis is also implemented in Java.",
                "The resulting system therefore is highly portable (due to Javas write once, run anywhere property) allowing the software to run unmodified on a heterogeneous grid.",
                "Ibis also provides the Ibis Registry.",
                "The Registry provides, among others, a membership service to the processors taking part in the computation.",
                "The adaptation coordinator uses the Registry to discover the application processes, and the application processes use this service to discover each other.",
                "The Registry also offers fault detection (additional to the fault detection provided by the communication channels).",
                "Finally, the Registry provides the possibility to send signals to application processes.",
                "The coordinator uses this functionality to notify the processors that they need to leave the computation.",
                "Currently the Registry is implemented as a centralized server.",
                "For requesting new nodes, the Zorilla (9) system is used - a peer-to-peer supercomputing middleware which allows straightforward allocation of processors in multiple clusters and/or supercomputers.",
                "Zorilla provides locality-aware scheduling, which tries to allocate processors that are located close to each other in terms of communication latency.",
                "In the future, Zorilla will also support bandwidth-aware scheduling, which tries to maximize the total bandwidth in the system.",
                "Zorilla can be easily replaced with another grid scheduler.",
                "In the future, we are planning to integrate our adaptation component with GAT (3) which is becoming a standard in the grid community and KOALA (15) a scheduler that provides co-allocation on top of standard grid middleware, such as the Globus Toolkit (11). 5.",
                "Performance evaluation In this section, we will evaluate our approach.",
                "We will demonstrate the performance of our mechanism in a few scenarios.",
                "The first scenario is an ideal situation: the application runs on a reasonable set of nodes (i.e., such that the efficiency is around 50%) and no problems such as overloaded networks and processors, crashing processors etc. occur.",
                "This scenario allows us to measure the overhead of the adaptation support.",
                "The remaining scenarios are typical for grid environments and demonstrate that with our adaptation support the application can avoid serious performance bottlenecks such as overloaded processors or network links.",
                "For each scenario, we compare the performance of an application with adaptation support to a non-adaptive version.",
                "In the non-adaptive version, the coordinator does not collect statistics and no benchmarking (for measuring processor speeds) is performed.",
                "In the ideal scenario, 0 5 10 15 iteration number 0 200 400 600 iterationduration(secs.) starting on 8 nodes starting on 16 nodes starting on 24 nodes starting on 8 nodes starting on 16 nodes starting on 24 nodes }no adaptation }with adaptation Figure 3.",
                "Barnes-Hut iteration durations with/without adaptation, too few processors 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation CPU load introduced overloaded nodes removed started adding nodes 36 nodes reached Figure 4.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs we additionally measure the performance of an application with collecting statistics and benchmarking turned on but without doing adaptation, that is, without allowing it to change the number of nodes.",
                "This allows us to measure the overhead of benchmarking and collecting statistics.",
                "In all experiments we used a monitoring period of 3 minutes for the adaptive versions of the applications.",
                "All the experiments were carried out on the DAS-2 wide-area system (8), which consists of five clusters located at five Dutch uni125 versities.",
                "One of the clusters consists of 72 nodes, the others of 32 nodes.",
                "Each node contains two 1 GHz Pentium processors.",
                "Within a cluster, the nodes are connected by Fast Ethernet.",
                "The clusters are connected by the Dutch university Internet backbone.",
                "In our experiments, we used the Barnes-Hut N-body simulation.",
                "BarnesHut simulates the evolution of a large set of bodies under influence of (gravitational or electrostatic) forces.",
                "The evolution of N bodies is simulated in iterations of discrete time steps. 5.1 Scenario 0: adaptivity overhead In this scenario, the application is started on 36 nodes.",
                "The nodes are equally divided over 3 clusters (12 nodes in each cluster).",
                "On this number of nodes, the application runs with 50% efficiency, so we consider it a reasonable number of nodes.",
                "As mentioned above, in this scenario we measured three runtimes: the runtime of the application without adaptation support (runtime 1), the runtime with adaptation support (runtime 2) and the runtime with monitoring (i.e., collection of statistics and benchmarking) turned on but without allowing it to change the number of nodes (runtime 3).",
                "Those runtimes are shown in Figure 2, first group of bars.",
                "The comparison between runtime 3 and 1 shows the overhead of adaptation support.",
                "In this experiment it is around 15%.",
                "Almost all overhead comes from benchmarking.",
                "The benchmark is run 1-2 times per monitoring period.",
                "This overhead can be made smaller by increasing the length of the monitoring period and decreasing the benchmarking frequency.",
                "The monitoring period we used (3 minutes) is relatively short, because the runtime of the application was also relatively short (30-60 minutes).",
                "Using longer running applications would not allow us to finish the experimentation in a reasonable time.",
                "However, real-world grid applications typically need hours, days or even weeks to complete.",
                "For such applications, a much longer monitoring period can be used and the adaptation overhead can be kept much lower.",
                "For example, with the Barnes-Hut application, if the monitoring period is extended to 10 minutes, the overhead drops to 6%.",
                "Note that combining benchmarking with monitoring processor load (as described in Section 3.2) would reduce the benchmarking overhead to almost zero: since the processor load is not changing, the benchmarks would only need to be run at the beginning of the computation. 5.2 Scenario 1: expanding to more nodes In this scenario, the application is started on fewer nodes than the application can efficiently use.",
                "This may happen because the user does not know the right number of nodes or because insufficient nodes were available at the moment the application was started.",
                "We tried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b) and 24 (Scenario 1c).",
                "The nodes were located in 1 or 2 clusters.",
                "In each of the three sub-scenarios, the application gradually expanded to 36-40 nodes located in 4 clusters.",
                "This allowed to reduce the application runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and 12% (Scenario 1c) with respect to the non-adaptive version.",
                "Those runtimes are shown in Figure 2.",
                "Since Barnes-Hut is an iterative application, we also measured the time of each iteration, as shown in Figure 3.",
                "Adaptation reduces the iteration time by a factor of 3 (Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows us to conclude that the gains in the total runtime would be even bigger if the application were run longer than for 15 iterations. 5.3 Scenario 2: overloaded processors In this scenario, we started the application on 36 nodes in 3 clusters.",
                "After 200 seconds, we introduced a heavy, artificial load on the processors in one of the clusters.",
                "Such a situation may happen when an application with a higher priority is started on some of the resources.",
                "Figure 4 shows the iteration durations of both the adaptive and non-adaptive versions.",
                "After introducing the load, the iteration 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected badly connected cluster removed started adding nodes 36 nodes reached Figure 5.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded network link 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation one cluster is badly connected 12 nodes lightly overloaded removed badly connected cluster removed 2 lightly overloaded nodes Figure 6.",
                "Barnes-Hut iteration durations with/without adaptation, overloaded CPUs and an overloaded network link duration increased by a factor of 2 to 3.",
                "Also, the iteration times became very variable.",
                "The adaptive version reacted by removing the overloaded nodes.",
                "After removing these nodes, the weighted average efficiency rose to around 35% which triggered adding new nodes and the application expanded back to 38 nodes.",
                "So, the overloaded nodes were replaced by better nodes, which brought the iteration duration back to the initial values.",
                "This reduced the total runtime by 14%.",
                "The runtimes are shown in Figure 2. 126 5.4 Scenario 3: overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "We simulated that the uplink to one of the clusters was overloaded and the bandwidth on this uplink was reduced to approximately 100 KB/s.",
                "To simulate low bandwidth we use the traffic-shaping techniques described in (6).",
                "The iteration durations in this experiment are shown in Figure 5.",
                "The iteration durations of the nonadaptive version exhibit enormous variation: from 170 to 890 seconds.",
                "The adaptive version removed the badly connected cluster after the first monitoring period.",
                "As a result, the weighted average efficiency rose to around 35% and new nodes were gradually added until their number reached 38.",
                "This brought the iteration times down to around 100 seconds.",
                "The total runtime was reduced by 60% (Figure 2). 5.5 Scenario 4: overloaded processors and an overloaded network link In this scenario, we ran the application on 36 nodes in 3 clusters.",
                "Again, we simulated an overloaded uplink to one of the clusters.",
                "Additionally, we simulated processors with heterogeneous speeds by inserting a relatively light artificial load on the processors in one of the remaining clusters.",
                "The iteration durations are shown in Figure 6.",
                "Again, the non-adaptive version exhibits a great variation in iteration durations: from 200 to 1150 seconds.",
                "The adaptive version removes the badly connected cluster after the first monitoring period which brings the iteration duration down to 210 seconds on average.",
                "After removing one of the clusters, since some of the processors are slower (approximately 5 times), the weighted average efficiency raises only to around 40%.",
                "Since this value lies between Emin and Emax, no nodes are added or removed.",
                "This example illustrates what the advantages of opportunistic migration would be.",
                "There were faster nodes available in the system.",
                "If these nodes were added to the application (which could trigger removing the slower nodes) the iteration duration could be reduced even further.",
                "Still, the adaptation reduced the total runtime by 30% (Figure 2). 5.6 Scenario 5: crashing nodes In the last scenario, we also run the application on 36 nodes in 3 clusters.",
                "After 500 seconds, 2 out of 3 clusters crash.",
                "The iteration durations are shown in Figure 7.",
                "After the crash, the iteration duration raised from 100 to 200 seconds.",
                "The weighted efficiency rose to around 30% which triggered adding new nodes in the adaptive version.",
                "The number of nodes gradually went back to 35 which brought the iteration duration back to around 100 seconds.",
                "The total runtime was reduced by 13% (Figure 2). 6.",
                "Related work A number of Grid projects address the question of resource selection and adaptation.",
                "In GrADS (18) and ASSIST (1), resource selection and adaptation requires a performance model that allows predicting application runtimes.",
                "In the resource selection phase, a number of possible resource sets is examined and the set of resources with the shortest predicted runtime is selected.",
                "If performance degradation is detected during the computation, the resource selection phase is repeated.",
                "GrADS uses the ratio of the predicted execution times (of certain application phases) to the real execution times as an indicator of application performance.",
                "ASSIST uses the number of iterations per time unit (for iterative applications) or the number of tasks per time unit (for regular master-worker applications) as a performance indicator.",
                "The main difference between these approaches and our approach is the use of performance models.",
                "The main advantage is that once the performance model is known, the system is able to take more accurate migration decisions than with our approach.",
                "However, even if the performance 0 5 10 15 iteration number 0 200 400 600 800 1000 iterationduration(secs.) no adaptation with adaptation 2 out of 3 clusters crash started adding nodes 36 nodes reached Figure 7.",
                "Barnes-Hut iteration durations with/without adaptation, crashing CPUs model is known, the problem of finding an optimal resource set (i.e. the resource set with the minimal execution time) is NP-complete.",
                "Currently, both GrADS and ASSIST examine only a subset of all possible resource sets and therefore there is no guarantee that the resulting resource set will be optimal.",
                "As the number of available grid resources increases, the accuracy of this approach diminishes, as the subset of possible resource sets that can be examined in a reasonable time becomes smaller.",
                "Another disadvantage of these systems is that the performance degradation detection is suitable only for iterative or regular applications.",
                "Cactus (2) and GridWay (14) do not use performance models.",
                "However, these frameworks are only suitable for sequential (GridWay) or single-site applications (Cactus).",
                "In that case, the resource selection problem boils down to selecting the fastest machine or cluster.",
                "Processor clock speed, average load and a number of processors in a cluster (Cactus) are used to rank resources and the resource with the highest rank is selected.",
                "The application is migrated if performance degradation is detected or better resources are discovered.",
                "Both Cactus and GridWay use the number of iterations per time unit as the performance indicator.",
                "The main limitation of this methodology is that it is suitable only for sequential or single-site applications.",
                "Moreover, resource selection based on clock speed is not always accurate.",
                "Finally, performance degradation detection is suitable only for iterative applications and cannot be used for irregular computations such as search and optimization problems.",
                "The resource selection problem was also studied by the AppLeS project (5).",
                "In the context of this project, a number of applications were studied and performance models for these applications were created.",
                "Based on such a model a scheduling agent is built that uses the performance model to select the best resource set and the best application schedule on this set.",
                "AppLeS scheduling agents are written on a case-by-case basis and cannot be reused for another application.",
                "Two reusable templates were also developed for specific classes of applications, namely master-worker (AMWAT template) and parameter sweep (APST template) applications.",
                "Migration is not supported by the AppLeS software. 127 In (13), the problem of scheduling master-worker applications is studied.",
                "The authors assume homogeneous processors (i.e., with the same speed) and do not take communication costs into account.",
                "Therefore, the problem is reduced to finding the right number of workers.",
                "The approach here is similar to ours in that no performance model is used.",
                "Instead, the system tries to deduce the application requirements at runtime and adjusts the number of workers to approach the ideal number. 7.",
                "Conclusions and future work In this paper, we investigated the problem of resource selection and adaptation in grid environments.",
                "Existing approaches to these problems typically assume the existence of a performance model that allows predicting application runtimes on various sets of resources.",
                "However, creating performance models is inherently difficult and requires knowledge about the application.",
                "We propose an approach that does not require in-depth knowledge about the application.",
                "We start the application on an arbitrary set of resources and monitor its performance.",
                "The performance monitoring allows us to learn certain application requirements such as the number of processors needed by the application or the applications bandwidth requirements.",
                "We use this knowledge to gradually refine the resource set by removing inadequate nodes or adding new nodes if necessary.",
                "This approach does not result in the optimal resource set, but in a reasonable resource set, i.e. a set free from various performance bottlenecks such as slow network connections or overloaded processors.",
                "Our approach also allows the application to adapt to the changing grid conditions.",
                "The adaptation decisions are based on the weighted average efficiency - an extension of the concept of parallel efficiency defined for traditional, homogeneous parallel machines.",
                "If the weighted average efficiency drops below a certain level, the adaptation coordinator starts removing worst nodes.",
                "The badness of the nodes is defined by a heuristic formula.",
                "If the weighted average efficiency raises above a certain level, new nodes are added.",
                "Our simple adaptation strategy allows us to handle multiple scenarios typical for grid environments: expand to more nodes or shrink to fewer nodes if the application was started on an inappropriate number of processors, remove inadequate nodes and replace them with better ones, replace crashed processors, etc.",
                "The application adapts fully automatically to changing conditions.",
                "We implemented our approach in the Satin divide-and-conquer framework and evaluated it on the DAS-2 distributed supercomputer and demonstrate that our approach can yield significant performance improvements (up to 60% in our experiments).",
                "Future work will involve extending our adaptation strategy to support opportunistic migration.",
                "This, however, requires grid schedulers with more sophisticated functionality than currently exists.",
                "Further research is also needed to decrease the benchmarking overhead.",
                "For example, the information about CPU load could be used to decrease the benchmarking frequency.",
                "Another line of research that we wish to investigate is using feedback control to refine the adaptation strategy during the application run.",
                "For example, the node badness formula could be refined at runtime based on the effectiveness of the previous adaptation decisions.",
                "Finally, the centralized implementation of the adaptation coordinator might become a bottleneck for applications which are running on very large numbers of nodes (hundreds or thousands).",
                "This problem can be solved by implementing a hierarchy of coordinators: one subcoordinator per cluster which collects and processes statistics from its cluster and one main coordinator which collects the information from the sub-coordinators.",
                "Acknowledgments This work was carried out in the context of Virtual Laboratory for e-Science project (ww.vl-e.nl).",
                "This project is supported by a BSIK grant from the Dutch Ministry of Education, Culture and Science (OC&W) and is part of the ICT innovation program of the Ministry of Economic Affairs (EZ).",
                "References [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto, and C. Zoccolo.",
                "Parallel program/component adaptivity management.",
                "In ParCo 2005, Sept. 2005. [2] G. Allen, D. Angulo, I.",
                "Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel, and J. Shalf.",
                "The cactus worm: Experiments with resource discovery and allocation in a grid environment.",
                "Intl Journal of High Performance Computing Applications, 15(4):345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf, and I. Taylor.",
                "Enabling applications on the grid - a gridlab overview.",
                "Intl Journal of High-Performance Computing Applications, 17(4):449-466, Aug. 2003. [4] J. E. Baldeschwieler, R. D. Blumofe, and E. A.",
                "Brewer.",
                "ATLAS: An Infrastructure for Global Computing.",
                "In 7th ACM SIGOPS European Workshop on System Support for Worldwide Applications, pages 165-172, Sept. 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su, and D. Zagorodnov.",
                "Adaptive Computing on the Grid Using AppLeS.",
                "IEEE Trans. on Parallel and Distributed Systems, 14(4):369-382, Apr. 2003. [6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley.",
                "Experiences in programming a traffic shaper.",
                "In 5th IEEE Symp. on Computers and Communications, pages 470-476, 2000. [7] W. Chrabakh and R. Wolski.",
                "GridSAT: A Chaff-based Distributed SAT Solver for the Grid.",
                "In 2003 ACM/IEEE conference on Supercomputing, page 37, 2003. [8] The Distributed ASCI Supercomputer (DAS). http://www.cs.vu.nl/das2/. [9] N. Drost, R. V. van Nieuwport, and H. E. Bal.",
                "Simple localityaware co-allocation in peer-to-peer supercomputing.",
                "In 6th Intl Workshop on Global Peer-2-Peer Computing, May 2005. [10] D. L. Eager, J. Zahorjan, and E. D. Lazowska.",
                "Speedup versus efficiency in parallel systems.",
                "IEEE Transactions on Computers, 38(3):408-423, Mar. 1989. [11] I.",
                "Foster.",
                "Globus toolkit version 4: Software for serviceoriented systems.",
                "In IFIP International Conference on Network and Parallel Computing, pages 2-13.",
                "Springer-Verlag LNCS 3779, 2005. [12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth.",
                "An Enabling Framework for Master-Worker Applications on the Computational Grid.",
                "In 9th IEEE Intl Symp. on High Performance Distributed Computing, pages 43-50, Aug. 2000. [13] E. Heymann, M. A. Senar, E. Luque, and M. Livny.",
                "Adaptive scheduling for master-worker applications on the computational grid.",
                "In 1st IEEE/ACM International Workshop on Grid Computing, pages 214-227.",
                "Springer Verlag LNCS 1971, 2000. 128 [14] E. Huedo, R. S. Montero, and I. M. Llorente.",
                "A framework for adaptive execution in grids.",
                "Software - Practice & Experience, 34(7):631-651, 2004. [15] H. H. Mohamed and D. H. Epema.",
                "Experiences with the KOALA Co-Allocating Scheduler in Multiclusters.",
                "In 5th IEEE/ACM Intl Symp. on Cluster Computing and the GRID, pages 640-650, May 2005. [16] A. Plaat, H. E. Bal, and R. F. H. Hofman.",
                "Sensitivity of parallel applications to large differences in bandwidth and latency in two-layer interconnects.",
                "In 5th Intl Symp.",
                "On High Performance Computer Architecture, pages 244-253, Jan. 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat.",
                "A performance analysis of transposition-table-driven work scheduling in distributed search.",
                "IEEE Trans. on Parallel and Distributed Systems, 13(5):447-459, May 2002. [18] S. S. Vadhiyar and J. J. Dongarra.",
                "Self adaptivity in Grid computing.",
                "Concurrency and Computation: Practice and Experience, 17(2-4):235-257, 2005. [19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal.",
                "Efficient load balancing for wide-area divide-and-conquer applications.",
                "In 8th ACM SIGPLAN Symp. on Principles and Practices of Parallel Programming, pages 34-43, 2001. [20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.",
                "Satin: Simple and Efficient Java-based Grid Programming.",
                "Scalable Computing: Practice and Experience, 6(3):19-32, Sept. 2004. [21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann, and H. E. Bal.",
                "Ibis: a Flexible and Efficient Java-based Grid Programming Environment.",
                "Concurrency & Computation: Practice & Experience, 17(78):1079-1107, 2005. [22] R. Wolski, N. Spring, and J. Hayes.",
                "The network weather service: A distributed resource performance forecasting service for metacomputing.",
                "Journal of Future Generation Computing Systems, 15(5-6):757-768, Oct. 1999. [23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E. Bal.",
                "Fault-tolerance, Malleability and Migration for Divideand-Conquer Applications on the Grid.",
                "In Intl Parallel and Distributed Processing Symposium, Apr. 2005. 129"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        }
    }
}