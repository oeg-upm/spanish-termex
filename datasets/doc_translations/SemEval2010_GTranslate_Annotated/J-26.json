{
    "id": "J-26",
    "original_text": "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal. The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings. This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties. Our model is a combinatorial variant of the classical principalagent problem from economic theory. In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him. Our focus is on cases where complex combinations of the efforts of the agents influence the outcome. The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game. We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open. Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1. INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations. The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants. Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey). A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another. In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants. This paper deals with the complementary lack of knowledge, that of hidden actions. In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly. Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract. An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information. While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort? Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory. How can we ensure that the right combination of allocations is actually made by the different servers? A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system. How can we ensure that the desired level of 18 collective security is obtained? Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal? The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible. This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14. The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort. In this paper we initiate a general study of handling combinations of agents rather than a single agent. While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions. In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal. The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility? In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent. This paper suggest models for and provides some interesting initial results about this combinatorial agency problem. We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research. We believe that this type of analysis may also find applications in regular economic activity. Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms). It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.) When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives. It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems. In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled. This calls for the study of the standard issues in economic theory in new complex settings. The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically. The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions. Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action. The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 . Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project. Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action. Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 . The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment. The main difficulty is that of determining the required Nash equilibrium point. In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure. It seems that this case already captures the main interesting ingredients3 . In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort. This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort. We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented. This subclass will provide many natural types of problem instances. In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort. The whole project succeeds as a deterministic Boolean function of the success of the subtasks. This Boolean function can now be represented in various ways. Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds. A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge. Effort by the edge increases this success probability. The complete project succeeds if there is a complete path of successful edges between a given source and sink. Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium. One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results. We believe that despite the large amount of work that appears here, we have only scratched the surface. In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results. In many cases, simulations reveal structure that we were not able to formally prove. We present here an informal overview of the issues that we studied, what we were able to do, and what we were not. The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper. Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance. Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success. For very low values, no agent will be contracted since even a single agents cost is higher than the principals value. For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment. What happens for intermediate principals values? We first observe that there is a finite number of transitions between different sets, as the principals project value increases. These transitions behave very differently for different functions. For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted. For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one. We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur. However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks. We do have several partial results, including a construction with an exponential number of transitions. During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal? We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity. More general analysis remains an open problem. Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems. In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function. We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model. We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard. The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks. In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one. We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free. Both phenomena can not occur in the non-strategic setting. 2. MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +). The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O). A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn). The principal has a certain value for each possible outcome, given by the function v : O → . As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value. Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome. Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O). Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai). The agents will be assumed to reach Nash equilibrium, if such equilibrium exists. The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium. In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium. A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists. Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12]. We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort). The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0). The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model. We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success). The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0). We assume that the principal can pay the agents but not fine them (known as the limited liability constraint). The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success. If the project fails, the agent gets 0. When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds. At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci. As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone. Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0). Definition 1. The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks. Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function. At this point we can already make some simple observations. The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi. Claim 1. Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.) As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case. This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium. Observation 1. The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1). In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk. The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) . We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A). The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium. Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}). We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A. A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs). In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci. The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability. Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases). Definition 2. The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare). When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c). Note that the POU is at least 1 for any technology. As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c). For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions. This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions. In a structured technology function, each individual succeeds or fails in his own task independently. The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks. Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents). Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort. In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 . Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ. We denote x = (x1, . . . , xn). The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit. An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player. The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 . A few simple examples should be in order here: 1. The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi). Thus the project succeeds only if all agents succeed in their tasks. This is shown graphically as a read-once network in Figure 1(a). If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m . E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2. The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi). Thus the project succeeds if at least one of the agents succeed in their tasks. This is shown graphically as a read-once network in Figure 1(b). If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3. The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions. In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k). Thus the project succeeds if in at least one clause all agents succeed in their tasks. This is shown graphically as a read-once network in Figure 2(a). If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents. Figure 1: Graphical representations of (a) AND and (b) OR technologies. Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4. The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions. In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k). Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks. This is shown graphically as a read-once network in Figure 2(b). If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5. The Majority technology: f(x) is 1 if a majority of the values xi are 1. Thus the project succeeds if most players succeed. The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz. In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3. ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players. I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort). A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents. Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA). As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ. OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1. Example 1. AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8. The principal has 3 possibilities: contracting with 0, 1, or 2 agents. Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3. Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal. The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6. This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally. In this case the principal will make both agents exert effort whenever v ≥ 4. Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3. It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below. Example 2. OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8. Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2. Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3. In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8. It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case. This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]). Lemma 1. For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases. Proof sketch: We look at all transition points in both cases. For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1. Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1. Thus, we can focus on the interval between the first and last transition points. Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment). We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point). As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted. Figure 3 shows the same phenomena for AND and OR technologies with 3 players. Theorem 1. For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents. Thus, the optimal contract corresponds to the maximum over a set of linear functions. Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents. In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}. As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal. This is true for both the agency and the non-strategic cases. As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below. For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case. The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case. Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )). Next we consider the OR technology and show that it exhibits all n transitions. Theorem 2. For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted). For v = vk, the principal is indifferent between contracting with k − 1 or k agents. Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents. We then show that for any k, vk < vk+1. As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case. This characterization is a direct corollary of a more general characterization given in [2]. While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze. Open Question 1. What is the POU for OR with n > 2 agents? Is it bounded by a constant for every n? We are only able to determine the POU of the OR technology for the case of two agents [2]. Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies. Observation 2. While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions? Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases. However, this is not true in general. In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions. We find that the conditions in the agency case are different than the ones in the non-strategic case. We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]). Lemma 2. For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case. Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case. Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively. By Lemma 1 the POU is obtained at a transition point. As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case. The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 . Substituting the transition point of the agency case into the POU expression yields the required expression. POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3). We are unable to characterize the transition behavior of the MAJORITY technology analytically. Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5. The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture. Conjecture 1. For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents. For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents. For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions. Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4. NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents. In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology. Definition 3. For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ). The korbit of t is the collection of sets of size exactly k in the orbit. Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit). Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1. We show that the picture in the agency case is very different. A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma. Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value. Proof. Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively. Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci). The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S). As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2). We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value. Next we show that the success probability is monotonic non-decreasing in the value. S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2). Finally we show that the expected payment is monotonic non-decreasing in the value. As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies. The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together. Theorem 3. Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs. Then for any value v, an optimal contract contracts with the same number of agents in each OR-component. Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section. We conjecture that a similar result holds for the OOA technology. Conjecture 2. In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths. Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted. We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents. If conjecture 2 is true, the same holds for the OOA technology. What can be said about the orbit size of a general non-anonymous technology? In case of identical costs, it is impossible for all subsets of agents to be on the orbit. This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1. Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least). Nevertheless, we next show that the orbit can have exponential size. A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be). Theorem 4. Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive. Let S be some admissible collection of k-size sets. For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj . We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j. For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version). This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S . We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal. This result is obtained by taking the derivative of u(S, v). Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t. S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof. We next show that there exist very large admissible collections. Lemma 4. For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ). Proof sketch: The proof is based on an error correcting code that corrects one bit. Such a code has a distance ≥ 3, thus admissible. It is known that there are such codes with Ω(2n /n) code words. To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible. Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n . Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit. Corollary 1. There exists a technology (t, c) with orbit of size Ω( 2n n √ n ). Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology. Open Question 2. Is there a Read Once network with exponential orbit? Is there a structured technology with exponential orbit? Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1. Open Question 3. How big can the orbit size of a seriesparallel network be? We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes. Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series). The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively. Lemma 5. Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T). Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well. Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R). Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6. The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)). Proof. Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1. By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2). By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2). As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma. For the full proof, see [2]. Lemma 7. Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series). Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1. By induction we get the following corollary. Corollary 2. Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj). Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents). In particular, this holds for AOO technology where each OR-component is anonymous. It would also be interesting to consider a disjunction of two Boolean functions. Open Question 4. Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)? We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well. If this is true, this will show that series-parallel networks have polynomial size orbit. 5. ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract. In this section we state these implications (for the proofs see [2]). We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ . In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that. In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract. Proposition 1. Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c). Proof. We prove the claims for the non-anonymous case, the proof for the anonymous case is similar. We first show how to construct the orbit of the technology (the same procedure apply in both cases). To construct the orbit we find all transition points and the sets that are in the orbit. The empty contract is always optimal for v = 0. Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability. We show how to calculate the next transition point and the next optimal contract. By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit). We calculate the next optimal contract by the following procedure. We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract. Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works. Clearly the above calculation is polynomial in the input size. Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated. We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point. Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time. By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio. A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5. Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof. Consider the following family of technologies. For some small > 0 and k = n/2 we define the success probability for a given set T as follows. If |T| < k, then t(T) = |T| · . If |T| > k, then t(T) = 1 − (n − |T|) · . For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative). If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one). We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function. Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract. Let t(E) denote the probability of success when each edge succeeds with probability δe. We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8]. Just a little effort will reveal that our problem is not easier: Theorem 6. The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions). Proof. We will show that an algorithm for this problem can be used to solve the network reliability problem. Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx. For the other edges, we let δe = ζe and γe = ζe/2. By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract. Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value). Let us denote βx = 1 − 2γx. The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value. Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}. Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E). In conclusion, computing the optimal contract in general is hard. These results suggest two natural research directions. The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time. The second avenue is to explore approximation algorithms for the optimal contract problem. A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial. Open Question 5. Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time? We can only handle the non-trivial level of AOO networks: Lemma 8. Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time. Acknowledgments. This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6. REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan. The Price of Purity and Free-Labor in Combinatorial Agency. In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan. Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker. Hidden-action in multi-hop routing. In EC05, pages 117-126, 2005. [4] B. Holmstrom. Moral Hazard in Teams. Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J. Green. Microeconomic Theory. Oxford University Press, 1995. [6] N. Nisan and A. Ronen. Algorithmic mechanism design. Games and Economic Behaviour, 35:166 - 196, 2001. A preliminary version appeared in STOC 1999. [7] C. Papadimitriou. Algorithms, Games, and the Internet. In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O. Ball. The complexity of counting cuts and of computing the probability that a graph is connected. SIAM J. Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann. Prediction Games. WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz. Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz. Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case. Forthcoming, GEB, 2005. [12] E. Winter. Incentives and Discrimination. American Economic Review, 94:764-773, 2004. 28",
    "original_translation": "Agencia Combinatorial [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión y Sistemas de la Información UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería y Ciencias de la Computación La Universidad Hebrea de Jerusalén Jerusalén, 91904 ISRAEL MFELDMAN@CS.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática La Universidad Hebrea de Jerusalén Jerusalén, 91904 israel noam@cs.huji.ac.il Abrazo de sistemas de investigación de investigación muy recientes, como los componentes, cuyos componentes son propiedad y operadospor diferentes partidos, cada uno con su propio objetivo egoísta. El campo del diseño del mecanismo algorítmico maneja el problema de la información privada en poder de las diferentes partes en tales configuraciones computacionales. Este documento se ocupa de un problema complementario en tales entornos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del problema clásico de principios de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos a ejercer un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque está en los casos en que las combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes al ofrecerles un conjunto de contratos, que juntos ponen a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este entorno, sugerimos y embarcamos en un análisis de algunos problemas básicos, pero dejamos abiertas muchas preguntas. Categorías y descriptores de sujetos J.4 [Ciencias sociales y conductuales]: Economía;K.4.4 [Comercio electrónico]: esquemas de pago;C.2.4 [Redes de Computercommunication]: Sistemas distribuidos Términos generales Diseño, Economía, Teoría 1. Introducción 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular en Internet, es que diferentes partes de ellas son propiedad y operadas por diferentes individuos, empresas y organizaciones. El análisis y el diseño de protocolos para este entorno, por lo tanto, naturalmente necesita tener en cuenta los diferentes intereses económicos egoístas de los diferentes participantes. De hecho, los últimos años han visto mucho trabajo abordar este problema utilizando nociones teóricas del juego (ver [7] para una encuesta influyente). Una parte importante de la dificultad proviene de las asimetrías subyacentes de información: un participante puede no saber todo lo que otro lo conoce o hace. En particular, el campo del diseño del mecanismo algorítmico [6] utiliza incentivos apropiados para extraer la información privada de los participantes. Este artículo trata de la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos a otros e solo influyen en el resultado final indirectamente. Hidden aquí cubre una amplia gama de situaciones que incluyen no precisamente medibles, costosos de determinar o incluso no contratibles, lo que significa que no se puede utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es la calidad del enrutamiento de servicio en una red: cada enlace o enrutador intermedio puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete alcanzó su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio: ¿cómo podemos asegurar que realmente ejercen la cantidad adecuada de esfuerzo? Muchos otros problemas de asignación de recursos complejos exhiben acciones ocultas similares, por ejemplo, una tarea que se ejecuta en una colección de servidores compartidos puede ser asignado, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de CPU o de la memoria física. ¿Cómo podemos asegurar que los diferentes servidores realicen la combinación correcta? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger algunas propiedades de seguridad deseadas del sistema. ¿Cómo podemos asegurar que se obtenga el nivel deseado de 18 de seguridad colectiva? Nuestro enfoque de este problema se basa en el problema de agente principal bien estudiado en la teoría económica: ¿cómo puede un principal motivar a un agente racional a ejercer un esfuerzo costoso hacia el bienestar del director? El quid del modelo es que la acción de los agentes (es decir, si ejerce el esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como [5] Capítulo 14. La solución se basa en la observación de que un contrato diseñado adecuadamente, en el que los pagos dependen del resultado final, puede influir en un agente racional para ejercer el esfuerzo requerido. En este artículo iniciamos un estudio general de manejo de combinaciones de agentes en lugar de un solo agente. Si bien ya se realizó mucho trabajo para motivar equipos de agentes [4], nuestro énfasis es lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por las N agentes diferentes puede dar como resultado una ganancia esperada diferente para el director. La pregunta general pregunta qué pagos condicionales debe la oferta principal a ¿Qué agentes para maximizar su utilidad neta? En nuestro entorno y, a diferencia de los trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este documento sugiere modelos para y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que solo hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas e instrucciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Considere, por ejemplo, una empresa que subcontrata a una familia de tareas relacionadas para muchas personas (u otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencias combinatorias pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general derivada del hecho de que todos los tipos de actividad económica se manejan cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en tales entornos computarizados, los escenarios complejos que involucran múltiples agentes y bienes pueden ocurrir naturalmente, y deben ser manejados algorítmicamente. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema de agente principal es un excelente ejemplo en el que tales configuraciones complejas introducen nuevos desafíos.1.2 Nuestros modelos comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones por parte de los jugadores da como resultado algún resultado, donde esto sucede probablemente. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de las acciones de los agentes. Además, el problema especifica la utilidad de los principales para cada resultado posible, y para cada agente, los agentes cuestan cada acción posible. El principal motiva a los agentes al ofrecer a cada uno de ellos un contrato que especifica un pago para cada resultado posible de todo el proyecto1. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos sean directamente dependientes de las acciones de los jugadores, sino solo en el resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se supone que alcanzan un equilibrio de Nash2. El problema de los principales, nuestro problema en este documento, es diseñar un conjunto óptimo de contratos: es decir, contratos que maximizan su utilidad esperada del resultado, menos su pago total esperado. La principal dificultad es determinar el punto de equilibrio NASH requerido. Para concentrarse en los problemas principales, el resto del documento se ocupa del caso binario básico: cada agente tiene solo dos posibles acciones ejercer esfuerzo y eludir y solo hay dos posibles resultados, el éxito y el fracaso. Parece que este caso ya captura los principales ingredientes interesantes3. En este caso, cada problema de los agentes se reduce al esfuerzo o no, y el problema de los principales se reduce a qué agentes deben ser contratados para ejercer el esfuerzo. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de los agentes que ejercen el esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias problemáticas en las que esta tabla de tamaño exponencial se representa sucintamente. Esta subclase proporcionará muchos tipos naturales de instancias problemáticas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no ejerce esfuerzo y con una mayor probabilidad Δ> γ, si el agente ejerce un esfuerzo. Todo el proyecto tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora se puede representar de varias maneras. Dos ejemplos básicos son la función y la función en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función OR que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un solo borde, y el éxito de la subtarea significa que ese borde reenvía un mensaje. El esfuerzo por el borde aumenta esta probabilidad de éxito. El proyecto completo tiene éxito si hay una ruta completa de bordes exitosos entre una fuente y sumidero determinado. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros resultados 1 Uno podría pensar en un modelo diferente en el que los agentes tienen una utilidad intrínseca del resultado y los pagos pueden no ser necesarios, como en [10, 11].2 En este artículo, nuestra filosofía es que el director puede sugerir un punto de equilibrio Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Alternativamente, se puede estudiar el peor de equilibrio de los casos como en [12], o alternativamente, intentar modelar algún tipo de juego extenso entre los agentes, como en [9, 10, 11].3 Sin embargo, algunas de las preguntas más avanzadas que hacemos para este caso pueden verse como instancias del modelo general.19 Abordamos una gran cantidad de preguntas y demostramos una gran cantidad de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, solo hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseamos y tuvimos que conformarnos con el análisis de casos especiales o probar resultados parciales. En muchos casos, las simulaciones revelan una estructura que no pudimos probar formalmente. Presentamos aquí una descripción informal de los problemas que estudiamos, lo que pudimos hacer y lo que no éramos. El tratamiento completo de la mayoría de nuestros resultados aparece solo en la versión extendida [2], y solo algunos se discuten, a menudo con resultados de simulación asociados, en el cuerpo del documento. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden contratarse para una instancia de problema determinado. Corrigamos una función dada que describe las probabilidades de éxito, solucionemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de los principales del éxito. Para valores muy bajos, no se contraerá ningún agente ya que incluso un costo de un solo agente es más alto que el valor de los principales. Para valores muy altos, todos los agentes siempre se contratarán ya que la contribución marginal de un agente multiplicado por el valor de los principales superará cualquier pago asociado. ¿Qué sucede para los valores de los principios intermedios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, mostramos que para la función y la función solo ocurre una sola transición: para valores lo suficientemente bajos, no se contraerá ningún agente, mientras que para valores más altos se contraerán todos los agentes, no existe un rango intermedio para el cual solo algunos de los agentes se contraen. Para la función OR, la situación es opuesta: a medida que aumenta el valor de los principios, el conjunto de agentes contratados aumenta uno por uno. Podemos caracterizar completamente los tipos de funciones para las cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función mayoritaria (el proyecto tiene éxito si la mayoría de las subtareas tienen éxito) o redes muy simples. Tenemos varios resultados parciales, incluida una construcción con un número exponencial de transiciones. Durante el análisis anterior, también estudiamos qué llamamos el precio de la falta de cuenta: cuánto se logra la utilidad social bajo los contratos óptimos peores de lo que podría lograrse en el caso no estratégico4, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Podemos analizar completamente este precio para la función y la función, donde se muestra que tiende al infinito ya que el número de agentes tiende al infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados naturales. En particular, observamos que el contrato óptimo se puede encontrar en el polinomio de tiempo en la representación explícita de la función de probabilidad. Probamos un límite inferior que muestra que el contrato óptimo no se puede encontrar en el número de consultas que es polinomial solo en el número de agentes, en un modelo general de caja negra. También mostramos que cuando la función de probabilidad se representa sucintamente como 4, el caso no estratégico a menudo se conoce como el caso con acciones contratibles o la primera solución de los principales.Una red de lectura, el problema se convierte en #P-Hard. El estado de algunas preguntas algorítmicas permanece abierta, en particular el de encontrar el contrato óptimo para las tecnologías definidas por redes paralelas en serie. En un documento de seguimiento [1] tratamos con los equilibrios en estrategias mixtas y mostramos que el director puede obtener al inducir un equilibrio de la red mixta entre los agentes en lugar de uno puro. También mostramos casos en los que el director puede obtener pidiendo a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este esfuerzo llega de forma gratuita. Ambos fenómenos no pueden ocurrir en el entorno no estratégico.2. Modelo y preliminares 2.1 El entorno general Un principal emplea un conjunto de agentes n de tamaño n.Cada agente i ∈ N tiene un posible conjunto de acciones ai, y un costo (esfuerzo) ci (ai) ≥ 0 para cada posible acción ai ∈ Ai (ci: ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contratible o ∈ O, de acuerdo con una función de éxito t: A1 × ,...× an → δ (O) (donde δ (O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t y funciones de costo, c = (c1, c2, ..., CN). El principal tiene un cierto valor para cada resultado posible, dada por la función V: O →. Como solo consideraremos jugadores neutrales en el riesgo en este documento5, también trataremos V como una función en δ (O), tomando un valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final O es visible para él y para otros (en particular en la corte), y puede diseñar contratos aplicables basados en el resultado final. Por lo tanto, el contrato para el Agente I es una función (pago) PI: O →;Nuevamente, también veremos Pi como una función en δ (O). Dada esta configuración, los agentes han sido colocados en un juego, donde la utilidad del agente I bajo el vector de acciones a = (a1, ..., an) está dada por ui (a) = pi (t (a))−ci (ai). Se supondrá que los agentes alcanzan el equilibrio de Nash, si existe dicho equilibrio. El problema de los principales (que es nuestro problema en este documento) es cómo diseñar los contratos PI para maximizar su propia utilidad esperada u (a) = v (t (a)) - p i pi (t (a)), dondeLas acciones a1 ,..., y están en Nash-Equilibrio. En el caso de los equilibrios de NASH múltiples, permitimos que el principal elija el equilibrio, centrándose así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a una fuerte implementación en el diseño del mecanismo, sería tomar el peor equilibrio de Nash, o incluso más fuerte, pero exigir que solo exista un solo equilibrio. Finalmente, el bienestar social para a ∈ A es u (a) + p i∈N ui (a) = v (t (a)) - p i∈N ci (ai).2.2 El modelo de acción binaria de salida binaria deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un entorno más simple que parece concentrarse más claramente en la estructura de t.Se usó un modelo similar en [12]. Primero restringimos los espacios de acción para tener solo dos estados (acción binaria): 0 (bajo esfuerzo) y 1 (alto esfuerzo). La función de costo del Agente I ahora es solo un Ci> 0 escalar que denota el costo de ejercer un alto esfuerzo (donde el bajo esfuerzo ha costado 0). El vector de los costos es C = (C1, C2, ..., CN), 5 El caso de aversión al riesgo obviamente sería un segundo paso natural en la investigación de este modelo, como lo ha sido para escenarios no combinatorios.20 Y usamos la notación (t, c) para denotar una tecnología en un modelo de salida binaria. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (falla del proyecto) y 1 (éxito del proyecto). El valor de los principales para un proyecto exitoso viene dado por un V> 0 escalar (donde el valor de la falla del proyecto es 0). Suponemos que el director puede pagar a los agentes pero no multarlos (conocidos como la restricción de responsabilidad limitada). Por lo tanto, el contrato al agente I ahora es dado por un valor escalar Pi ≥ 0 que denota el pago que obtiene en caso de éxito del proyecto. Si el proyecto falla, el agente obtiene 0. Cuando la acción de menor costo tiene cero costo (como suponemos), esto implica inmediatamente que la restricción de participación se mantiene. En este punto, la función de éxito t se convierte en una función t: {0, 1} n → [0, 1], donde t (a1, ..., an) denota la probabilidad de éxito del proyecto donde los jugadores con AI = 0 noejercer esfuerzo e incurrir en ningún costo, y los jugadores con AI = 1 ejercen esfuerzos e incurren en un costo de CI. Como deseamos concentrarnos en motivar a los agentes, en lugar de en la coordinación entre los agentes, suponemos que un mayor esfuerzo de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos a - i ∈ A - I el vector dimensional (n - 1) de las acciones de todos los agentes, excluyendo el agente i.es decir, a - i = (a1, ..., ai - 1, ai+1, ..., an), entonces una función de éxito debe satisfacer: ∀i ∈ N, ∀a - i ∈ A - i t (1, a - i)> t (0, a - i) Además, suponemos que t (a)> 0 para cualquier a ∈ A (o de manera equivalente, t (0, 0, ..., 0)> 0). Definición 1. La contribución marginal del agente I, denotada por ΔI, es la diferencia entre la probabilidad de éxito cuando ejecuta el esfuerzo y cuando evita. Δi (a - i) = t (1, a - i) - t (0, a - i) Tenga en cuenta que, dado que t es monótono, Δi es una función estrictamente positiva. En este punto, ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente ahora puedo determinar fácilmente en función de lo que hacen los otros, a - i ∈ A - I, y su contrato Pi. Reclamación 1. Dado un perfil de acciones a - I, el agente es la mejor estrategia es ai = 1 si pi ≥ ci Δi (a - i), y es ai = 0 si pi ≤ ci Δi (a - i).(En el caso de la igualdad, el agente es indiferente entre las dos alternativas). Como pi ≥ ci Δi (a - i) si y solo si ui (1, a - i) = pi · t (1, a - i) −ci ≥ pi · t (0, a - i) = ui (0, a - i), es la mejor estrategia es elegir AI = 1 en este caso. Esto nos permite especificar los contratos que son los principales óptimos, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a ∈ A como un equilibrio son pi = 0 para el agente I que no ejerce ningún esfuerzo (ai = 0), y pi = ci Δi (a - i) para el agente i que ejerce esfuerzo ((ai = 1). En este caso, la utilidad esperada del Agente I que ejerce el esfuerzo es CI · T (1, A - I) ΔI (A - I) - 1 y 0 para un agente que elude. La utilidad esperada de los directores viene dada por u (a, v) = (v - p) · t (a), donde p es el pago total en caso de éxito, dado por p = p i | ai = 1 ci Δi (a−i). Decimos que el principal contrata con el agente I si pi> 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo de los principales es maximizar su utilidad dado su valor V, es decir, determinar el perfil de las acciones a ∗ ∈ A, que da el valor más alto de U (A, V) en equilibrio. Elegir A ∈ A corresponde a elegir un conjunto de agentes que ejercen un esfuerzo (s = {i | ai = 1}). Llamamos al conjunto de agentes s ∗ que el principal contrata en a ∗ (s ∗ = {i | a ∗ i = 1}) Un contrato óptimo para el principal al valor v. A veces abusamos de notación y denotamos t (s)En lugar de t (a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en un ∈ A. Un criterio natural por el cual medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan ser motivados, sino que están controlados directamente por el director (que también tiene sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimiza el bienestar social (eficiencia global), t (a) · v - p i | ai = 1 ci. La peor relación entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede denominarse precio de la falta de contabilidad. Dada una tecnología (t, c), que s ∗ (v) denote el contrato óptimo en el caso de la agencia y permita que S ∗ ns (v) denote un contrato óptimo en el caso no estratégico, cuando el valor de los principales es v.El bienestar social para el valor V cuando se contrae el conjunto de agentes es t (s) · v-p i∈S Ci (tanto en los casos de agencia como no estratégicos). Definición 2. El precio de la falta de contabilidad POU (T, C) de una tecnología (t, c) se define como la peor relación (sobre V) entre el bienestar social total en el caso no estratégico y el caso de la agencia: POU (T, C)= Supv> 0 t (s ∗ ns (v)) · v - p i∈S ∗ ns (v) ci t (s ∗ (v)) · v - p i∈S ∗ (v) ci en casos en los casos en los casos en los casos en los casos en los casos en los casos dondeLos conjuntos son óptimos en el caso de la agencia, tomamos el peor conjunto (es decir, el conjunto que produce el bienestar social más bajo). Cuando la tecnología (T, C) sea clara en el contexto, utilizaremos POU para denotar el precio de la falta de contabilidad para la tecnología (T, C). Tenga en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento trataremos con el caso donde todos los agentes tienen un costo idéntico C, es decir, CI = C para todos los i ∈ N. DenotamosUna tecnología (T, C) con costos idénticos por (T, C). Para la simplicidad de la presentación, a veces utilizamos la función de tecnología término para referirnos a la función de éxito de la tecnología.2.3 Funciones de tecnología estructurada Para ser más concretas, nos centraremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes: llamamos a estas funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función tecnológica, y también proporcionará una forma sucinta y natural de representar las funciones tecnológicas. En una función tecnológica estructurada, cada individuo tiene éxito o falla en su propia tarea de forma independiente. El éxito o el fracaso de los proyectos dependen, posiblemente de una manera compleja, del conjunto de subestamales exitosas. Por lo tanto, asumiremos una función booleana monótona f: {0, 1} n → {0, 1} que denota 21 si el proyecto tiene éxito en función del éxito de las tareas de los agentes (y no está determinado por ningún conjunto de n−1 agentes). Además, hay constantes 0 <γi <Δi <1, donde γi denota la probabilidad de éxito para el agente I si no ejerce esfuerzo, y Δi (> γi) denota la probabilidad de éxito si hace un esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 =...= γn = γ y Δ1 =...= Δn = 1 - γ dejándonos con un solo parámetro γ S.T.0 <γ <1 2. Según esta estructura, la función tecnológica t se define por t (a1, ..., un) es la probabilidad de que F (x1, ..., xn) = 1 donde los bits x1 ,..., xn se eligen de acuerdo con la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 - γ;De lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 - γ y xi = 0 con probabilidad γ. Denotamos x = (x1, ..., xn). La cuestión de la representación de la función tecnológica ahora se reduce a la de representar la función booleana monótona subyacente f.En el caso más general, la función F puede ser dada por un circuito booleano monótono general. Una subclase especialmente natural de funciones en la configuración de tecnologías estructuradas serían funciones que pueden representarse como una red de lectura: un gráfico con una fuente y sumidero determinados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman una ruta entre la fuente y el fregadero6. Algunos ejemplos simples deben estar en orden aquí: 1. La tecnología y la tecnología: F (x1, ..., xn) es la conjunción lógica de xi (f (x) = v i∈N xi). Por lo tanto, el proyecto solo tiene éxito si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura en la Figura 1 (a). Si los agentes M ejercen el esfuerzo (p i ai = m), entonces t (a) = tm = γn - m (1 - γ) m. P.ej.Para dos jugadores, la función tecnológica t (a1a2) = ta1+a2 viene dada por t0 = t (00) = γ2, t1 = t (01) = t (10) = γ (1 - γ), y t2 = t = t ((11) = (1 - γ) 2.2. La tecnología OR: F (x1, ..., xn) es la disyunción lógica de xi (f (x) = w i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura en la Figura 1 (b). Si los agentes M ejercen el esfuerzo, entonces tm = 1 - γm (1 - γ) n - m .e.g.Para dos jugadores, la función tecnológica viene dada por t (00) = 1 - (1 - γ) 2, t (01) = t (10) = 1 - γ (1 - γ) y t (11) = 1- γ2.3. La tecnología OR-OF-yS (OOA): F (x) es la disyunción lógica de las conjunciones. En el caso más simple de cláusulas de igual longitud (denota por nc el número de cláusulas y por su longitud), f (x) = wnc j = 1 (vnl k = 1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura en la Figura 2 (a). Si los agentes de MI en la ruta I ejercen el esfuerzo, entonces t (m1, ..., mnc) = 1 - q i (1 - γnl - MI (1 - γ) mi). P.ej.Para cuatro jugadores, la función tecnológica T (A1 1 A1 2, A2 1 A2 2) viene dada por t (00, 00) = 1 - (1 - γ2) 2, t (01, 00) = t (10, 00) = t (00, 01) = t (00, 10) = 1 - (1 - γ (1 - γ)) (1 - γ2), y así sucesivamente.6 Uno puede ver esta representación como directamente correspondiente al proyecto de entregar un mensaje desde la fuente al sumidero en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de (a) y (b) o tecnologías. Figura 2: Representaciones gráficas de (a) tecnologías OOA y (b) AOO.4. La tecnología de And-Of-Sor (AOO): F (x) es la conjunción lógica de los disyunciones. En el caso más simple de cláusulas de igual longitud (denota por nl el número de cláusulas y por nc su longitud), f (x) = vnl j = 1 (wnc k = 1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula de forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura en la Figura 2 (b). Si los agentes de MI en la cláusula I ejercen el esfuerzo, entonces t (m1, ..., mnc) = q i (1 - γmi (1 - γ) nc -mi). P.ej.Para cuatro jugadores, la función tecnológica T (A1 1 A1 2, A2 1 A2 2) viene dada por t (00, 00) = (1 - (1 - γ) 2) 2, t (01, 00) = t (T (10, 00) = t (00, 01) = t (00, 10) = (1 - γ (1 - γ)) (1 - (1 - γ) 2), y así sucesivamente.5. La tecnología mayoritaria: F (x) es 1 si la mayoría de los valores XI son 1. Por lo tanto, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función mayoritaria, incluso en 3 entradas, no puede representarse mediante una red de lectura, pero se representa fácilmente por una fórmula booleana monótona maj (x, y, z) = xy+yz+xz. En este caso, la función tecnológica viene dada por t (000) = 3γ2 (1 - γ) +γ3, t (001) = t (010) = t (100) = γ3 +2 (1 - γ) 2 γ +γ2(1 - γ), etc. 3. Análisis de algunas tecnologías anónimas Una función de éxito t se llama anónimo si es simétrico con respecto a los jugadores. Es decir.t (a1, ..., an) depende solo de p i∈N ai (el número de agentes que ejercen el esfuerzo). Una tecnología (T, C) es anónima si T es anónimo y el costo C es idéntico a todos los agentes. De los ejemplos presentados anteriormente, las tecnologías y, o, y mayoritarias eran anónimas (pero no AOO y OOA). En cuanto a una t anónima solo el número de agentes que ejercen el esfuerzo es importante, podemos acortar las anotaciones y denotar tm = t (1m, 0n - m), Δm = tm+1 - tm, pm = c Δm - 1 y um= tm · (v - m · pm), para el caso de costo idéntico c.22 V 3 0 Gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 Gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de y (izquierda) y (izquierda) yO tecnologías (correctas) con 3 jugadores, en función de γ y v. Y tecnología: se contraen 0 o 3 agentes y el valor de transición es monotónico en γ. O tecnología: para cualquier γ podemos ver todas las transiciones.3.1 y y o las tecnologías comenzamos con un análisis directo y completo de las tecnologías y/////o las tecnologías para dos jugadores para el caso γ = 1/4 y C = 1. Ejemplo 1. Y tecnología con dos agentes, C = 1, γ = 1/4: tenemos T0 = γ2 = 1/16, T1 = γ (1 - γ) = 3/16 y T2 = (1 - γ) 2 = 9/16 Por lo tanto, Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Escriba las expresiones de su utilidad en estos 3 casos: • 0 Agentes: No se paga ningún agente y la utilidad de los principales es U0 = T0 · V = V/16.• 1 Agente: este agente se paga p1 = c/Δ0 = 8 en el éxito y la utilidad de los principales es u1 = t1 (v - p1) = 3V/16− 3/2.• 2 Agentes: cada agente se paga p2 = c/Δ1 = 8/3 en el éxito, y la utilidad de los principales es u2 = t2 (v - 2p2) = 9v/16 - 3. Observe que la opción de contratar con un agente siempre es inferior a contratar con ambos o con ninguno, y nunca será tomado por el director. El director se contraerá sin agente cuando V <6, con ambos agentes cada vez que v> 6, y con no o ambos para V = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y lleva sus costos) y, por lo tanto, simplemente optimiza a nivel mundial. En este caso, el director hará que ambos agentes ejerceran esfuerzo cuando v ≥ 4. Así, por ejemplo, para V = 6, la decisión globalmente óptima (caso no estratégico) daría una utilidad global de 6 · 9/16-2 = 11/8, mientras que la decisión de los directores (en el caso de la agencia) daría una utilidad globalde 3/8, dando una proporción del 11/3. Resulta que este es el peor precio de la innovabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. O tecnología con dos agentes, C = 1, γ = 1/4: tenemos T0 = 1 - (1 - γ) 2 = 7/16, T1 = 1 - γ (1 - γ) = 13/16 y T2= 1 - γ2 = 15/16 Por lo tanto, Δ0 = 3/8 y Δ1 = 1/8. Escribamos las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: no se paga ningún agente y la utilidad de los principales es U0 = T0 · V = 7V/16.• 1 Agente: este agente se paga p1 = c/Δ0 = 8/3 en el éxito y la utilidad de los principales es u1 = t1 (v - p1) = 13V/16 - 13/6.• 2 Agentes: cada agente se paga p2 = c/Δ1 = 8 en el éxito, y la utilidad de los principales es u2 = t2 (v - 2p2) = 15v/16 - 15/2. Ahora, contratar con un agente es mejor que contraer sin ninguno cada vez que v> 52/9 (y es equivalente para V = 52/9), y contratar con ambos agentes es mejor que contratar con un agente cuando V> 128/3 (y esequivalente para v = 128/3), por lo tanto, el principal se contraerá sin agente para 0 ≤ V ≤ 52/9, con un agente para 52/9 ≤ V ≤ 128/3, y con ambos agentes para V ≥ 128/3. En el caso no estratégico, en comparación, el director hará que un solo agente ejercerá un esfuerzo para V> 8/3, y el segundo ejercer esfuerzo también cuando v> 8. Resulta que el precio de la falta de cuenta aquí es 19/13, y se logra en V = 52/9, que es exactamente el punto de transición de agentes contratados de 0 a 1 en el caso de la agencia. Esta no es una coincidencia de que tanto en las tecnologías como en las tecnologías se obtenga el POU para V que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de contabilidad POU (T, C) se obtiene en algún valor V, que es un punto de transición, de la agencia o de los casos no estratégicos. Boceto de prueba: miramos todos los puntos de transición en ambos casos. Para cualquier valor inferior al primer punto de transición, se contratan 0 agentes en ambos casos, y la relación de bienestar social es 1. Del mismo modo, para cualquier valor superior al último punto de transición, los agentes N se contraen en ambos casos, y la relación de bienestar social es 1. Por lo tanto, podemos centrarnos en el intervalo entre los puntos de transición primero y último. Entre cualquier par de puntos consecutivos, la relación de bienestar social es entre dos funciones lineales de V (los contratos óptimos se fijan en dicho segmento). Luego mostramos que para cada segmento, la relación suprimum se obtiene en un punto final del segmento (un punto de transición). Como hay finamente muchos de estos puntos, el suprimum global se obtiene en el punto de transición con la relación de bienestar social máxima.2 Ya vemos una diferencia cualitativa entre las tecnologías y o / o (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para algún rango intermedio de valores V, exactamente un agente escontratado. La Figura 3 muestra los mismos fenómenos para y / o tecnologías con 3 jugadores. Teorema 1. Para cualquier anónimo y tecnología7: • Existe un valor8 V ∗ <∞ de tal manera que para cualquier v <v ∗ es óptimo contratar sin agente, para v> v ∗ es óptimo contratar con todos los agentes n, y para v= V ∗, ambos contratos (0, n) son óptimos.7 y tecnología con cualquier número de agentes n y cualquier γ, y cualquier costo idéntico c.8 V ∗ es una función de N, γ, c.23 • El precio de la falta de cuenta se obtiene en el punto de transición del caso de la agencia, y es POU = `1 γ - 1 ´N - 1 + (1 - γ 1 - γ) Sketch: para cualquier número fijo de agentes contratados,K, la utilidad de los principales es una función lineal en V, donde la pendiente es igual a la probabilidad de éxito bajo K agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Sea v ∗ denotar el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en V ∗, la utilidad de los principales de contratar con 0 (o n) agentes es más alto que su utilidad cuando se contrae con cualquier número de agentes k ∈ {1 ,..., n - 1}. Como el número de agentes contratados es monótono que no se puede tomar en el valor (debido a Lemma 3), para cualquier v <v ∗, contratar con 0 agentes es óptimo, y para cualquier v> v ∗, contratar con N agentes es óptimo. Esto es cierto tanto para la agencia como para los casos no estratégicos. Como en ambos casos hay un solo punto de transición, el reclamo sobre el precio de la innovación y la tecnología se demuestra como un caso especial de Lema 2 a continuación. Para y la tecnología TN - 1 T0 = (1 - γ) N - 1 · γ γn = 1 γ - 1 N - 1 y TN - 1 TN = (1 - γ) n - 1 · γ (1 - γ) n =γ 1 - γ, y las expresiones para el POU siguen.2 En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como caso especial. La propiedad de una sola transición ocurre tanto en la agencia como en los casos no estratégicos, donde la transición ocurre a un valor menor de V en el caso no estratégico. Observe que el POU no está limitado a través de la familia y la familia de tecnologías (para varias N, γ) como POU → ∞, ya sea γ → 0 (para cualquier n ≥ 2) o n → ∞ (para cualquier γ γ ∈ (0, 0, 0,1 2)). A continuación, consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier anónimo o tecnología, existen valores positivos finitos v1 <v2 <...<vn tal que para cualquier v s.t.VK <V <VK+1, contraer exactamente K agentes es óptimo (para V <v1, no se contrata ningún agente, y para V> VN, todos los agentes N están contratados). Para V = VK, el principal es indiferente entre contratar con agentes K - 1 o K. Boceto de prueba: para demostrar que la afirmación definimos a VK como el valor para el cual el principal es indiferente entre contratar con agentes K - 1 y contratar con los agentes K. Luego mostramos que para cualquier k, vk <vk+1. Como el número de agentes contratados es monótono que no se puede tomar en el valor (debido al Lemma 3), v1 <v2 <...<vn es una condición suficiente para que el teorema se mantenga.2 El mismo comportamiento ocurre tanto en la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología y pudimos determinar completamente el POU analíticamente, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Qué es el pou para o con n> 2 agentes? ¿Está limitado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes ya observamos una diferencia cualitativa entre el POU en las tecnologías y y y y / o. Observación 2. Mientras que en la tecnología y el POU para N = 2 no está limitado desde arriba (para γ → 0), el POU más alto o la tecnología con dos agentes es 2 (para γ → 0).3.2 ¿Qué determina las transiciones? Los teoremas 1 y 2 dicen que tanto las tecnologías como y / / / o exhiben el mismo comportamiento de transición (cambios del contrato óptimo) en la agencia y los casos no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las N transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las de las que no se estratégicas. Podemos determinar el POU para cualquier tecnología anónima que exhiba una sola transición tanto en la agencia como en los casos no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición tanto en la agencia como en los casos no estratégicos, el POU viene dado por: POU = 1 + TN-1 T0-TN-1 TN y se obtiene en el punto de transición de la agenciacaso. Boceto de prueba: dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre por un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que el número óptimo de agentes contratados en la agencia y los casos no estratégicos son 0 y N, respectivamente. Por Lemma 1, el POU se obtiene en un punto de transición. Como la relación de bienestar social está disminuyendo en V en esta región, el POU se obtiene al valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el que el principal es indiferente entre contratar con 0 y con n agentes, v ∗ = c · n tn - t0 · tn tn - tn - 1. Sustituir el punto de transición del caso de la agencia en la expresión de POU produce la expresión requerida. Pou = v ∗ · tn - c · n v ∗ · t0 = 1 + tn - 1 t0 - tn - 1 tn 2 3.3 La tecnología mayoritaria que el proyecto bajo la función mayoritaria tiene éxito si la mayoría de los agentes tiene éxito en sus tareas2.3). No podemos caracterizar el comportamiento de transición de la tecnología mayoritaria analíticamente. La Figura 4 presenta el número óptimo de agentes contratados en función de V y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y otros que miramos) nos lleva a la siguiente conjetura. Conjetura 1. Para cualquier tecnología mayoritaria (cualquiera de N, γ y C), existe L, 1 ≤ L ≤ N/2 de modo que la primera transición es de agentes de 0 a L, y luego existen todas las transiciones N - L restantes.24 4 5 3 1 0 2 400 0 0.3 100 Gamma 0.2 300 0.450.25 200 V 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología mayoritaria con 5 jugadores, en función de γ yv. A medida que γ, disminuye la primera transición está en un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles. Además, para cualquier C, N, L, L = 1 cuando γ está lo suficientemente cerca de 1 2, L es una función no divaz de γ (con la imagen {1, ..., n/2}) y L = n/2 Cuando γ está lo suficientemente cerca de 0. 4. Tecnologías no anónimas en tecnologías no anónimas (incluso con costos idénticos), debemos hablar sobre el conjunto contratado de agentes y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que se pueden obtener como el contrato óptimo para algunos v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología T, un conjunto de agentes s está en la órbita de T si para algún valor V, el contrato óptimo es exactamente con el conjunto de agentes (donde los lazos entre diferentes SS se rompen según un orden lexicográfico9). El Korbit de T es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la órbita K de cualquier tecnología con costo idéntico C es de tamaño como máximo 1 (ya que todos los conjuntos de tamaño K tienen el mismo costo, solo el que tiene la máxima probabilidad puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico es de tamaño como máximo n + 1. Mostramos que la imagen en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de monotonicidad) para cualquier tecnología (t, c), tanto en la agencia como en los casos no estratégicos, el 9 esto implica que no hay dos conjuntos con la misma probabilidad de éxito en la órbita.La utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, no son monotónicamente que no sean con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en V1 y V2 <V1, respectivamente. Que Q (s) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrata con el conjunto y el proyecto tenga éxito (para el caso de la agencia, Q (S) = t (S) · P i∈SCi t (s) −t (S \\ i), mientras que para el caso no estratégico q (s) = p i∈S Ci). La utilidad de los principales es una función lineal del valor, u (s, v) = t (s) · v - Q (s). Como S1 es óptimo en V1, U (S1, V1) ≥ U (S2, V1) y como T (S2) ≥ 0 y V1> V2, U (S2, V1) ≥ U (S2, V2). Concluimos que U (S1, V1) ≥ U (S2, V2), por lo tanto, la utilidad es monotónica no divaga en el valor. A continuación, mostramos que la probabilidad de éxito es la no daña monotónica en el valor. S1 es óptimo en V1, por lo tanto: T (S1) · V1 - Q (S1) ≥ T (S2) · V1 - Q (S2) S2 es óptimo en V2, por lo tanto: T (S2) · V2 - Q (S2)≥ t (s1) · v2 - q (s1) sumar estas dos ecuaciones, obtenemos que (t (s1) - t (s2)) · (v1 - v2) ≥ 0, lo que implica que si v1> v2 que t (S1) ≥ T (S2). Finalmente, mostramos que el pago esperado es monótono que no se da de alta en el valor. Como S2 es óptimo en V2 y T (S1) ≥ T (S2), observamos que: T (S2) · V2 - Q (S2) ≥ T (S1) · V2 - Q (S1) ≥ T (S2) · ·V2 - Q (S1) o de manera equivalente, Q (S2) ≤ Q (S1), que es lo que queríamos mostrar.4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión de tecnologías no anónimas con dos ejemplos;Las tecnologías de y de-órsis (AOO) y o de y de y ys (OOA). La tecnología AOO (ver Figura 2) está compuesta por múltiples o componentes que se y juntas. Teorema 3. Sea h un anónimo o tecnología, y F = Vnc J = 1 h sea la tecnología AOO que se obtiene por una conjunción de NC de estos o componentes en entradas disjuntas. Luego, para cualquier valor V, un contrato óptimo contrata con el mismo número de agentes en cada uno o componente. Por lo tanto, la órbita de F es de tamaño en la mayoría de NL + 1, donde NL es el número de agentes en H.Parte de la prueba del teorema (para la prueba completa ver [2]) se basa en que dicha tecnología AOO es un caso especial de una familia de tecnologías más general, en la que las tecnologías anónimas disjuntas son y se juntan, como se explican enla siguiente sección. Conjeturamos que un resultado similar es válido para la tecnología OOA. Conjetura 2. En una tecnología OOA, que es una disyunción de las mismas rutas anónimas (con el mismo número de agentes, γ y C, pero sobre las entradas de disjunto), para cualquier valor V, el contrato óptimo se construye a partir de una cantidad de rutas totalmente contratadas. Además, existe V1 <...<vnl de tal manera que para cualquier V, VI ≤ V ≤ Vi+1, se contraen exactamente las rutas I. No podemos demostrarlo en general, pero podemos probarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]).25 4.2 Caracterización de órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo es necesario para la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se mantiene mediante la observación de que el 1 órbita (un solo agente que ejerce el esfuerzo) es de tamaño como máximo 1. Solo el agente que da la mayor probabilidad de éxito (cuando solo él ejerce esfuerzo) puede estar en la órbita (ya que también necesita ser pagado menos). Sin embargo, luego mostramos que la órbita puede tener un tamaño exponencial. Se admisible una colección de conjuntos de elementos k (de n), si cada dos conjuntos en la colección difieren en al menos 2 elementos (por ejemplo, para k = 3, 123 y 234 no pueden estar juntos en la colección, sino 123 y 345puede ser). Teorema 4. Cada colección admisible se puede obtener como la órbita k de alguna t.Boceto de prueba: la prueba es constructiva. Sea s una colección admisible de conjuntos de tamaño K. Para cada conjunto s ∈ S en la colección, elegimos, de modo que para dos conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función tecnológica T de la siguiente manera: para cualquier s ∈ S, t (s) = 1/2 - sy ∀i ∈ S, t (s \\ i) = 1/2 - 2 S. Por lo tanto, el marginalLa contribución de cada i ∈ S es S. Tenga en cuenta que, dado que S es admisible, T está bien definido, como para dos conjuntos S, S ∈ S y dos agentes I, J, S \\ i = S \\ J. Para cualquier otro conjunto Z, definimos T (Z) de una manera que garantice que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t.Mostramos que cada conjunto admisible s ∈ S es óptimo en el valor vs = ck 2 2 s. Primero mostramos que es mejor que cualquier otro s ∈ S. al valor vs = ck 2 2 s, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de U (S, V). Por lo tanto, S produce una utilidad más alta que cualquier otra S ∈ S. También elegimos el rango de S para garantizar que en VS, S sea mejor que cualquier otro conjunto S \\ i S.T. S ∈ S. Ahora tenemos que mostrar que en VS, el conjunto S produce una utilidad más alta que cualquier otro conjunto Z ∈ S. La construcción de t (z) asegura esto ya que la contribución marginal de cada agente en z es talpequeño, que el pago es demasiado alto para que el set sea óptimo.2 en [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás reclamaciones presentadas en esta sección sin tal prueba. Luego mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño K de tamaño ω (1 n · `n k ´). Sketch de prueba: la prueba se basa en un código de corrección de errores que corrige un bit. Tal código tiene una distancia ≥ 3, así admisible. Se sabe que hay tales códigos con palabras de código Ω (2n /n). Para garantizar que una fracción apropiada de estas palabras de código tenga peso k, construimos un nuevo código Xor-cada palabra de código con una palabra aleatoria r.Las propiedades de XOR aseguran que el nuevo código permanezca admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo y, por lo tanto, su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de peso k palabras es Ω (`n k ´ /n), y para algunas r esta expectativa se logra o se excede.2 Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que por el Teorema 4 se puede utilizar para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño ω (2n n √ n). Por lo tanto, podemos construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Pregunta abierta 2. ¿Hay una red de lectura una vez con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes de seriesparallel cuyo tamaño de órbita es mayor que N + 1. Pregunta abierta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red paralela de serie? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomar las dos en una serie) es como máximo la suma de los tamaños de órbita de las dos redes. Deje que G y H sean dos funciones booleanas en las entradas disjuntas y deje F = G V H (es decir, tomen sus redes en serie). El contrato óptimo para F para algunos V, denotado por S, está compuesto por algunos agentes de la parte H y algunos de la G-Part, llámalas T y R respectivamente. Lema 5. Sea S un contrato óptimo para F = G V H en v. Entonces, T es un contrato óptimo para H en V · Tg (R), y R es un contrato óptimo para G en V · th (t). Boceto de prueba: Expresamos la utilidad de principios u (S, v) de contratar con el conjunto S cuando su valor es v. Abusamos de la notación y usamos la función para denotar la tecnología también. Deje que ΔF I (S \\ i) denote la contribución marginal del agente I ∈ S. Entonces, para cualquier I ∈ T, ΔF I (S \\ i) = G (R) · ΔH I (T \\ i), y para cualquierai ∈ R, ΔF I (S \\ i) = H (T) · ΔG I (R \\ I). Al sustituir estas expresiones y f (s) = h (t) · g (r), derivamos que u (s, v) = h (t) g (r) · v - p i∈T ci ΔH I (t\\ i) + g (r) · p i∈R ci Δ g i (r \\ i). El primer término se maximiza en un conjunto T que es óptimo para H en el valor G (R) · V, mientras que el segundo término es independiente de T y H.Por lo tanto, S es óptimo para F en V IF y solo si T es un contrato óptimo para H en V · Tg (R). Del mismo modo, mostramos que R es un contrato óptimo para G en V · th (t).2 Lema 6. La función real v → th (t), donde t es la parte h h-de un contrato óptimo para F en V, es monótono que no es decreciente (y de manera similar para la función V → Tg (R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para F en V1, y S2 = T2 ∪R2 sea el contrato óptimo para F en V2 <V1. Por Lemma 3 F (S1) ≥ F (S2), y desde F = G · H, F (S1) = H (T1) · G (R1) ≥ H (T2) · G (R2) = F (S2). Suponga en contradicción que H (T1) <H (T2), entonces, dado que H (T1) · G (R1) ≥ H (T2) · G (R2) esto implica que G (R1)> G (R2). Por Lemma 5, T1 es óptimo para H en V1 · G (R1), y T2 es óptimo para H en V2 · G (R2). Como V1> V2 y G (R1)> G (R2), T1 es óptimo para H en un valor mayor que T2, por lo tanto, por Lemma 3, H (T1) ≥ H (T2), una contradicción.26 Basado en Lemma 5 y Lemma 6, obtenemos el siguiente lema. Para la prueba completa, ver [2]. Lema 7. Deje que G y H sean dos funciones booleanas en las entradas disjuntas y deje F = G V H (es decir, tomen sus redes en serie). Supongamos que X e Y son los tamaños de órbita respectivos de G y H;Luego, el tamaño de la órbita de F es menor o igual a x + y - 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Suponga que {(GJ, CJ)} M J = 1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con costo de agente idéntico (todos los agentes de tecnología GJ tienen el mismo costo CJ). Entonces la órbita de F = VM J = 1 GJ es de tamaño como máximo (PM J = 1 NJ) - 1, donde NJ es el número de agentes en tecnología GJ (la órbita es lineal en el número de agentes). En particular, esto es válido para la tecnología AOO donde cada uno o componente es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Pregunta abierta 4. ¿Lemma 7 se mantiene también para la función booleana F = G W H (es decir, cuando las redes G, H se toman en paralelo)? Conjeturamos que este es de hecho el caso, y que los Lemmas 5 y 7 correspondientes también existen para el caso OR. Si esto es cierto, esto mostrará que las redes paralelas en serie tienen órbita de tamaño polinómico.5. Aspectos algorítmicos Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección declaramos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función tecnológica está dada por una función monótona arbitraria T (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente.5.1 Tecnologías de acción binaria de salida binaria Aquí suponemos que se nos da una tecnología y un valor V como entrada, y nuestra salida debe ser el contrato óptimo, es decir, el conjunto S ∗ de los agentes que se contraerán y el contrato PI para cada i∈ S ∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de las tecnologías anónimas, la descripción de t es solo los números n+1 t0 ,..., TN, y en este caso nuestro análisis en la Sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dada como entrada, la descripción completa de una tecnología (los valores t0, ..., TN y el costo idéntico para una tecnología anónima, o el valor t (s) para todos los 2n subconjuntos posibles de los jugadores, yUn vector de costos C para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinomial: • La órbita de la tecnología tanto en la agencia como en los casos no estratégicos.• Un contrato óptimo para cualquier valor V, tanto para la agencia como para los casos no estratégicos.• El precio de la falta de cuenta POU (T, C). Prueba. Probamos los reclamos para el caso no anónimo, la prueba del caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (se aplica el mismo procedimiento en ambos casos). Para construir la órbita encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para V = 0. Suponga que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición V para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el siguiente punto de transición y el siguiente contrato óptimo. Por Lemma 3, el siguiente contrato en la órbita (para valores más altos) tiene una mayor probabilidad de éxito (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos t de tal manera que t (t)> t (s), y calculamos el valor para el cual el principal es indiferente entre contratar con t y contratar con S. El valor de indiferencia mínimo es el siguiente punto de transición y el contrato quetiene el valor mínimo de indiferencia es el siguiente contrato óptimo. La linealidad de la utilidad en el valor y la monotonicidad de la probabilidad de éxito de los contratos óptimos garantiza que funcione lo anterior. Claramente, el cálculo anterior es polinomio en el tamaño de entrada. Una vez que tenemos la órbita, está claro que se puede calcular un contrato óptimo para cualquier valor dado V. Encontramos el punto de transición más grande que no es mayor que el valor V, y el contrato óptimo en V es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología tanto en la agencia como en los casos no estratégicos en tiempo polinomial, podemos encontrar el precio de la falta de contabilidad en el tiempo polinomial. Por el Lema 1, el precio de la falta de contabilidad POU (t) se obtiene en algún punto de transición, por lo que solo necesitamos repasar todos los puntos de transición y encontrar el que tiene la relación de bienestar social máxima. Una pregunta más interesante es si si se le da la función T como un cuadro negro, podemos calcular el contrato óptimo en el tiempo que es polinomio en n.Podemos mostrar que, en general, este no es el caso: Teorema 5. Dada como entrada, un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor V, el número de consultas que se necesitan, en el peor de los casos, para encontrar que el contrato óptimo es exponencial en n.Prueba. Considere la siguiente familia de tecnologías. Para algunos pequeños> 0 y k = n/2 definimos la probabilidad de éxito para un conjunto t dado de la siguiente manera. Si | t |<k, entonces t (t) = | t |·. Si | t |> k, entonces t (t) = 1 - (n - | t |) ·. Para cada conjunto de agentes ˆt de tamaño k, la tecnología t ˆt se define por t (ˆt) = 1 - (n - | ˆt |) · y t (t) = | t |· Para cualquier t = ˆt de tamaño k.Para el valor v = c · (k + 1/2), el contrato óptimo para t ˆt es ˆT (para el contrato ˆT la utilidad del principal se trata de v −c · k = 1/2 · c> 0, mientras quePara cualquier otro contrato, la utilidad es negativa). Si el algoritmo consulta sobre como máximo `n n/2 ´ - 2 conjuntos de tamaño K, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan consultas `n n/2 ´ - 1 para determinar el contrato óptimo, y esto es exponencial en n.27 5.2 Tecnologías estructuradas En esta sección consideraremos la representación natural de las redes de lectura para la función booleana subyacente. Por lo tanto, el problema que abordamos será: el problema del contrato óptimo para leer una vez redes: entrada: una red de lectura g = (v, e), con dos vértices específicos s, t;Valores racionales γe, ΔE para cada jugador e ∈ E (y Ce = 1), y un valor racional v. Salida: un conjunto de agentes que deben contratarse en un contrato óptimo. Deje t (e) denotar la probabilidad de éxito cuando cada borde tiene éxito con la probabilidad ΔE. Primero notamos que incluso calcular el valor t (e) es un problema difícil: se llama problema de confiabilidad de la red y se sabe que es #p - difícil [8]. Solo un pequeño esfuerzo revelará que nuestro problema no es más fácil: el teorema 6. El problema de contrato óptimo para leer una vez que Networks es #P-Hard (bajo Reducciones de Turing). Prueba. Mostraremos que se puede usar un algoritmo para este problema para resolver el problema de confiabilidad de la red. Dada una instancia de un problema de confiabilidad de red <g, {ζe} e∈E> (donde ζe denota la probabilidad de éxito), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definir un nuevo gráfico G que se obtiene porAnding G con un nuevo jugador X, con γx muy cerca de 1 2 y Δx = 1 - γx. Para los otros bordes, dejamos ΔE = ζe y γe = ζe/2. Al elegir γx lo suficientemente cerca de 1 2, podemos asegurarnos de que el jugador X ingrese el contrato óptimo solo para valores muy grandes de V, después de que se contraen todos los demás agentes (si podemos encontrar el contrato óptimo para cualquier valor, es fácilPara encontrar un valor para el cual en la red original, el contrato óptimo es e, sigue duplicando el valor y solicitando el contrato óptimo. Una vez que encontramos tal valor, elegimos γx S.T.C 1−2γX es mayor que ese valor). Denotemos βx = 1 - 2γx. El valor crítico de V donde el Jugador X ingresa al contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Tenga en cuenta que en este valor crítico V, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, cuando escribimos la expresión para esta indiferencia, en términos de t (e) y Δt I (e), observamos lo siguiente.t (e) · γx · v - x i∈E c γx · Δt I (e \\ i)!= t (e) (1 - γx) V - x i∈E C (1 - γx) · Δt I (E \\ i) - C t (E) · βx!si y solo si t (e) = (1 - γx) · c (βx) 2 · v Por lo tanto, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t (e). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones de investigación natural. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos se pueden calcular en tiempo polinomial. La segunda vía es explorar algoritmos de aproximación para el problema de contrato óptimo. Un posible candidato para la primera dirección es la familia de redes paralelas en serie, para las cuales el problema de confiabilidad de la red (calcular el valor de t) es polinomio. Pregunta abierta 5. ¿Puede el problema del contrato óptimo para leer una vez que las redes paralelas en serie se resolveran en tiempo polinomial? Solo podemos manejar el nivel no trivial de las redes AOO: Lemma 8. Dada una lectura una vez y una red de o de tal manera que cada o componente es una tecnología anónima, el problema del contrato óptimo puede resolverse en el tiempo polinomial. Expresiones de gratitud. Este trabajo es apoyado por la Israel Science Foundation, la Usa-Israel Binational Science Foundation, la Lady Davis Fellowship Trust, y por un número de subvención de la Fundación Nacional de Ciencias ANI-0331659.6. Referencias [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia Combinatorial, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf.[3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Peligro moral en equipos. Bell Journal of Economics, 13: 324-340, 1982. [5] A. Mass-Color, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño de mecanismo algorítmico. Juegos y comportamiento económico, 35: 166 - 196, 2001. Una versión preliminar apareció en Stoc 1999. [7] C. Papadimitriou. Algoritmos, juegos e Internet. En Actas del 33º STOC, páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de los recortes de contar y de calcular la probabilidad de que un gráfico esté conectado. Siam J. Comput., 12 (4): 777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. Vino, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Poner la obtención de información secuencial en sistemas de múltiples agentes.20ª Conferencia sobre Incertidumbre en AI, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superar el paseo libre en cálculos multipartidistas: el caso anónimo. Próximamente, Geb, 2005. [12] E. Winter. Incentivos y discriminación. American Economic Review, 94: 764-773, 2004. 28",
    "original_sentences": [
        "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
        "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
        "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
        "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
        "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
        "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
        "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
        "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
        "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
        "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
        "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
        "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
        "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
        "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
        "This paper deals with the complementary lack of knowledge, that of hidden actions.",
        "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
        "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
        "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
        "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
        "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
        "How can we ensure that the right combination of allocations is actually made by the different servers?",
        "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
        "How can we ensure that the desired level of 18 collective security is obtained?",
        "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
        "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
        "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
        "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
        "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
        "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
        "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
        "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
        "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
        "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
        "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
        "We believe that this type of analysis may also find applications in regular economic activity.",
        "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
        "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
        "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
        "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
        "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
        "This calls for the study of the standard issues in economic theory in new complex settings.",
        "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
        "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
        "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
        "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
        "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
        "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
        "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
        "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
        "The main difficulty is that of determining the required Nash equilibrium point.",
        "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
        "It seems that this case already captures the main interesting ingredients3 .",
        "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
        "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
        "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
        "This subclass will provide many natural types of problem instances.",
        "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
        "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
        "This Boolean function can now be represented in various ways.",
        "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
        "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
        "Effort by the edge increases this success probability.",
        "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
        "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
        "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
        "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
        "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
        "In many cases, simulations reveal structure that we were not able to formally prove.",
        "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
        "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
        "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
        "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
        "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
        "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
        "What happens for intermediate principals values?",
        "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
        "These transitions behave very differently for different functions.",
        "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
        "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
        "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
        "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
        "We do have several partial results, including a construction with an exponential number of transitions.",
        "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
        "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
        "More general analysis remains an open problem.",
        "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
        "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
        "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
        "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
        "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
        "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
        "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
        "Both phenomena can not occur in the non-strategic setting. 2.",
        "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
        "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
        "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
        "The principal has a certain value for each possible outcome, given by the function v : O → .",
        "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
        "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
        "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
        "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
        "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
        "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
        "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
        "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
        "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
        "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
        "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
        "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
        "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
        "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
        "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
        "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
        "If the project fails, the agent gets 0.",
        "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
        "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
        "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
        "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
        "Definition 1.",
        "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
        "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
        "At this point we can already make some simple observations.",
        "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
        "Claim 1.",
        "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
        "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
        "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
        "Observation 1.",
        "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
        "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
        "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
        "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
        "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
        "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
        "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
        "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
        "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
        "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
        "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
        "Definition 2.",
        "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
        "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
        "Note that the POU is at least 1 for any technology.",
        "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
        "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
        "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
        "In a structured technology function, each individual succeeds or fails in his own task independently.",
        "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
        "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
        "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
        "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
        "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
        "We denote x = (x1, . . . , xn).",
        "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
        "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
        "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
        "A few simple examples should be in order here: 1.",
        "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
        "Thus the project succeeds only if all agents succeed in their tasks.",
        "This is shown graphically as a read-once network in Figure 1(a).",
        "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
        "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
        "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
        "Thus the project succeeds if at least one of the agents succeed in their tasks.",
        "This is shown graphically as a read-once network in Figure 1(b).",
        "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
        "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
        "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
        "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
        "This is shown graphically as a read-once network in Figure 2(a).",
        "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
        "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
        "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
        "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
        "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
        "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
        "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
        "This is shown graphically as a read-once network in Figure 2(b).",
        "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
        "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
        "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
        "Thus the project succeeds if most players succeed.",
        "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
        "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
        "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
        "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
        "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
        "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
        "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
        "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
        "Example 1.",
        "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
        "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
        "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
        "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
        "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
        "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
        "In this case the principal will make both agents exert effort whenever v ≥ 4.",
        "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
        "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
        "Example 2.",
        "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
        "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
        "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
        "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
        "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
        "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
        "Lemma 1.",
        "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
        "Proof sketch: We look at all transition points in both cases.",
        "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
        "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
        "Thus, we can focus on the interval between the first and last transition points.",
        "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
        "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
        "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
        "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
        "Theorem 1.",
        "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
        "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
        "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
        "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
        "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
        "This is true for both the agency and the non-strategic cases.",
        "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
        "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
        "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
        "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
        "Next we consider the OR technology and show that it exhibits all n transitions.",
        "Theorem 2.",
        "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
        "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
        "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
        "We then show that for any k, vk < vk+1.",
        "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
        "This characterization is a direct corollary of a more general characterization given in [2].",
        "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
        "Open Question 1.",
        "What is the POU for OR with n > 2 agents?",
        "Is it bounded by a constant for every n?",
        "We are only able to determine the POU of the OR technology for the case of two agents [2].",
        "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
        "Observation 2.",
        "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
        "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
        "However, this is not true in general.",
        "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
        "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
        "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
        "Lemma 2.",
        "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
        "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
        "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
        "By Lemma 1 the POU is obtained at a transition point.",
        "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
        "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
        "Substituting the transition point of the agency case into the POU expression yields the required expression.",
        "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
        "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
        "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
        "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
        "Conjecture 1.",
        "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
        "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
        "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
        "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
        "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
        "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
        "Definition 3.",
        "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
        "The korbit of t is the collection of sets of size exactly k in the orbit.",
        "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
        "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
        "We show that the picture in the agency case is very different.",
        "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
        "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
        "Proof.",
        "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
        "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
        "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
        "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
        "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
        "Next we show that the success probability is monotonic non-decreasing in the value.",
        "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
        "Finally we show that the expected payment is monotonic non-decreasing in the value.",
        "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
        "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
        "Theorem 3.",
        "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
        "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
        "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
        "We conjecture that a similar result holds for the OOA technology.",
        "Conjecture 2.",
        "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
        "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
        "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
        "If conjecture 2 is true, the same holds for the OOA technology.",
        "What can be said about the orbit size of a general non-anonymous technology?",
        "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
        "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
        "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
        "Nevertheless, we next show that the orbit can have exponential size.",
        "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
        "Theorem 4.",
        "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
        "Let S be some admissible collection of k-size sets.",
        "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
        "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
        "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
        "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
        "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
        "This result is obtained by taking the derivative of u(S, v).",
        "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
        "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
        "We next show that there exist very large admissible collections.",
        "Lemma 4.",
        "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
        "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
        "Such a code has a distance ≥ 3, thus admissible.",
        "It is known that there are such codes with Ω(2n /n) code words.",
        "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
        "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
        "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
        "Corollary 1.",
        "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
        "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
        "Open Question 2.",
        "Is there a Read Once network with exponential orbit?",
        "Is there a structured technology with exponential orbit?",
        "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
        "Open Question 3.",
        "How big can the orbit size of a seriesparallel network be?",
        "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
        "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
        "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
        "Lemma 5.",
        "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
        "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
        "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
        "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
        "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
        "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
        "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
        "Proof.",
        "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
        "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
        "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
        "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
        "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
        "For the full proof, see [2].",
        "Lemma 7.",
        "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
        "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
        "By induction we get the following corollary.",
        "Corollary 2.",
        "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
        "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
        "In particular, this holds for AOO technology where each OR-component is anonymous.",
        "It would also be interesting to consider a disjunction of two Boolean functions.",
        "Open Question 4.",
        "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
        "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
        "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
        "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
        "In this section we state these implications (for the proofs see [2]).",
        "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
        "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
        "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
        "Proposition 1.",
        "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
        "Proof.",
        "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
        "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
        "To construct the orbit we find all transition points and the sets that are in the orbit.",
        "The empty contract is always optimal for v = 0.",
        "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
        "We show how to calculate the next transition point and the next optimal contract.",
        "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
        "We calculate the next optimal contract by the following procedure.",
        "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
        "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
        "Clearly the above calculation is polynomial in the input size.",
        "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
        "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
        "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
        "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
        "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
        "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
        "Consider the following family of technologies.",
        "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
        "If |T| < k, then t(T) = |T| · .",
        "If |T| > k, then t(T) = 1 − (n − |T|) · .",
        "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
        "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
        "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
        "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
        "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
        "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
        "Just a little effort will reveal that our problem is not easier: Theorem 6.",
        "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
        "Proof.",
        "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
        "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
        "For the other edges, we let δe = ζe and γe = ζe/2.",
        "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
        "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
        "Let us denote βx = 1 − 2γx.",
        "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
        "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
        "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
        "In conclusion, computing the optimal contract in general is hard.",
        "These results suggest two natural research directions.",
        "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
        "The second avenue is to explore approximation algorithms for the optimal contract problem.",
        "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
        "Open Question 5.",
        "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
        "We can only handle the non-trivial level of AOO networks: Lemma 8.",
        "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
        "Acknowledgments.",
        "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
        "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
        "The Price of Purity and Free-Labor in Combinatorial Agency.",
        "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
        "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
        "Hidden-action in multi-hop routing.",
        "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
        "Moral Hazard in Teams.",
        "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
        "Green.",
        "Microeconomic Theory.",
        "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
        "Algorithmic mechanism design.",
        "Games and Economic Behaviour, 35:166 - 196, 2001.",
        "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
        "Algorithms, Games, and the Internet.",
        "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
        "Ball.",
        "The complexity of counting cuts and of computing the probability that a graph is connected.",
        "SIAM J.",
        "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
        "Prediction Games.",
        "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
        "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
        "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
        "Forthcoming, GEB, 2005. [12] E. Winter.",
        "Incentives and Discrimination.",
        "American Economic Review, 94:764-773, 2004. 28"
    ],
    "error_count": 0,
    "keys": {
        "optimal set of contract": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an <br>optimal set of contract</br>s: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "El problema de los principales, nuestro problema en este documento, es diseñar un \"conjunto óptimo de contrato\" s: es decir, contratos que maximizan su utilidad esperada del resultado, menos su pago total esperado.conjunto óptimo de contrato"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "contract optimal set": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "classical principalagent": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the <br>classical principalagent</br> problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nuestro modelo es una variante combinatoria del problema de la teoría económica de \"principios clásicos\" de la teoría económica.principalgente clásico"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "quality of service": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is <br>quality of service</br> routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Un ejemplo que se discutió en [3] es el enrutamiento de \"calidad del servicio\" en una red: cada enlace o enrutador intermedio puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información.calidad de servicio"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "service quality": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "combinatorial agency": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>combinatorial agency</br> [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this <br>combinatorial agency</br> problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that <br>combinatorial agency</br> models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in <br>combinatorial agency</br>.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "<br>combinatorial agency</br>, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "\"Agencia Combinatorial\" [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión y Sistemas de Información UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 ISRAEL MFELDMAN@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática La Universidad Hebrea de Jerusalén Jerusalén, 91904 israel noam@cs.huji.ac.il Abraza los sistemas de investigación de investigación muy recientes, como Internet, cuyos componentes son propiedad dey operado por diferentes partidos, cada uno con su propio objetivo egoísta.agencia combinatoria",
                "Este documento sugiere modelos para y proporciona algunos resultados iniciales interesantes sobre este problema de \"agencia combinatoria\".agencia combinatoria",
                "Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de \"agencia combinatoria\" pueden ofrecer una base para el diseño de contratos con incentivos apropiados.agencia combinatoria",
                "El precio de la pureza y el trabajo libre en la \"agencia combinatoria\".agencia combinatoria",
                "\"Agencia Combinatorial\", 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf.[3] M. Feldman, J. Chuang, I. Stoica y S. Shenker.agencia combinatoria"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "nash equilibrium": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required <br>nash equilibrium</br> point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a <br>nash equilibrium</br> point to the agents, thus focusing on the best <br>nash equilibrium</br>.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-<br>nash equilibrium</br> between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach <br>nash equilibrium</br>, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best <br>nash equilibrium</br>.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst <br>nash equilibrium</br>, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "La principal dificultad es determinar el punto de \"equilibrio NASH\" requerido.equilibrio de Nash",
                "Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros resultados 1 Uno podría pensar en un modelo diferente en el que los agentes tienen una utilidad intrínseca del resultado y los pagos pueden no ser necesarios, como en [10, 11].2 En este documento, nuestra filosofía es que el director puede sugerir un punto de \"equilibrio de Nash\" a los agentes, centrándose así en el mejor \"equilibrio de Nash\".equilibrio de Nash",
                "En un documento de seguimiento [1] tratamos con los equilibrios en estrategias mixtas y mostramos que el director puede obtener al inducir un \"equilibrio de Nash\" mixto entre los agentes en lugar de uno puro.equilibrio de Nash",
                "Se supondrá que los agentes alcanzan el \"equilibrio de Nash\", si existe dicho equilibrio.equilibrio de Nash",
                "En el caso de los equilibrios de NASH múltiples, permitimos que el principal elija el equilibrio, centrándose así en el mejor \"equilibrio de Nash\".equilibrio de Nash",
                "Una variante, que es similar en espíritu a una fuerte implementación en el diseño del mecanismo, sería tomar el peor \"equilibrio de Nash\", o incluso más fuerte, pero exigir que solo exista un solo equilibrio.equilibrio de Nash"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "contractible action": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with <br>contractible action</br>s or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "También mostramos que cuando la función de probabilidad se representa sucintamente como 4, el caso no estratégico a menudo se conoce como el caso con la \"acción contratible\" o la primera mejor solución de los principales.Una red de lectura, el problema se convierte en #P-Hard.acción contratible"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "k-orbit": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the <br>k-orbit</br> of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Observe que en el caso no estratégico, la \"órbita K\" de cualquier tecnología con costo idéntico C es de tamaño como máximo 1 (ya que todos los conjuntos de tamaño K tienen el mismo costo, solo el que tiene la máxima probabilidad puede estar en elorbita).k-órbita"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "anonymous technology": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any <br>anonymous technology</br> that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any <br>anonymous technology</br> that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-<br>anonymous technology</br>?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an <br>anonymous technology</br>, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an <br>anonymous technology</br>, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Podemos determinar el POU para cualquier \"tecnología anónima\" que exhiba una sola transición tanto en la agencia como en los casos no estratégicos (ver prueba completa en [2]).tecnología anónima",
                "Para cualquier \"tecnología anónima\" que tenga una sola transición tanto en la agencia como en los casos no estratégicos, el POU viene dado por: POU = 1 + TN-1 T0-TN-1 TN y se obtiene en el punto de transición deEl caso de la agencia.tecnología anónima",
                "¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no \"anónima\"?tecnología anónima",
                "Dada como entrada, la descripción completa de una tecnología (los valores T0, ..., TN y el costo idéntico para una \"tecnología anónima\", o el valor t (s) para todos los 2n subconjuntos posibles de los jugadores de los jugadoresy un vector de costos C para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinomial: • La órbita de la tecnología tanto en la agencia como en los casos no estratégicos.• Un contrato óptimo para cualquier valor V, tanto para la agencia como para los casos no estratégicos.• El precio de la falta de cuenta POU (T, C).tecnología anónima",
                "Dada una lectura una vez y una red de o de tal manera que cada o componente es una \"tecnología anónima\", el problema del contrato óptimo puede resolverse en el tiempo polinomial.tecnología anónima"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "series-parallel network": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that <br>series-parallel network</br>s have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of <br>series-parallel network</br>s, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once <br>series-parallel network</br>s be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Si esto es cierto, esto mostrará que la \"red de paralelo en serie\" tiene órbita de tamaño polinomial.5. Red de series paralelas",
                "Un posible candidato para la primera dirección es la familia de la \"red paralela en serie\", para las cuales el problema de confiabilidad de la red (calculando el valor de t) es polinomio.red paralela en serie",
                "¿Se puede resolver el problema de contrato óptimo para leer una vez que la \"red de series paralelas\" en tiempo polinomial?red paralela en serie"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "price of unaccountability": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the <br>price of unaccountability</br>: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the <br>price of unaccountability</br>.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The <br>price of unaccountability</br> POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the <br>price of unaccountability</br> for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst <br>price of unaccountability</br> in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the <br>price of unaccountability</br> here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the <br>price of unaccountability</br> POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the <br>price of unaccountability</br> is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the <br>price of unaccountability</br> for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The <br>price of unaccountability</br> POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the <br>price of unaccountability</br> in polynomial time.",
                "By Lemma 1 the <br>price of unaccountability</br> POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Durante el análisis anterior, también estudiamos lo que llamamos el \"precio de la falta de cuenta\": cuánto se logra la utilidad social bajo los contratos óptimos peor de lo que se podría lograr en el caso no estratégico4, donde las acciones socialmente óptimas simplemente están dictadas por¿el director?Precio de la falta de cuenta",
                "La peor relación entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede denominarse \"precio de la falta de cuenta\".Precio de la falta de cuenta",
                "El \"precio de la falta de cuenta\" POU (T, C) de una tecnología (t, c) se define como la peor relación (sobre V) entre el bienestar social total en el caso no estratégico y el caso de la agencia: POU (T,c) = supv> 0 t (s ∗ ns (v)) · v - p i∈S ∗ ns (v) ci t (s ∗ (v)) · v - p i∈S ∗ (v) ci en casosCuando varios conjuntos son óptimos en el caso de la agencia, tomamos el peor conjunto (es decir, el conjunto que produce el bienestar social más bajo).Precio de la falta de cuenta",
                "Cuando la tecnología (T, C) sea clara en el contexto, utilizaremos POU para denotar el \"precio de la falta de cuenta\" para la tecnología (T, C).Precio de la falta de cuenta",
                "Resulta que este es el peor \"precio de innovabilidad\" en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación.Precio de la falta de cuenta",
                "Resulta que el \"precio de la falta de cuenta\" aquí es 19/13, y se logra en V = 52/9, que es exactamente el punto de transición de agentes contratados de 0 a 1 en el caso de la agencia.Precio de la falta de cuenta",
                "Para cualquier tecnología dada (t, c), el POU \"PRECIO DE LA INCOUNTABILIDAD\" se obtiene en algún valor V, que es un punto de transición, de la agencia o de los casos no estratégicos.Precio de la falta de cuenta",
                "Para cualquier anónimo y tecnología7: • Existe un valor8 V ∗ <∞ de tal manera que para cualquier v <v ∗ es óptimo contratar sin agente, para v> v ∗ es óptimo contratar con todos los agentes n, y para v= V ∗, ambos contratos (0, n) son óptimos.7 y tecnología con cualquier número de agentes n y cualquier γ, y cualquier costo idéntico c.8 V ∗ es una función de N, γ, c.23 • El \"precio de la falta de contabilidad\" se obtiene en el punto de transición del caso de la agencia, y es POU = `1 γ - 1 ´N - 1 + (1 - γ 1 - γ) Sketch: para cualquier número fijo de contratadoAgentes, K, la utilidad de los principales es una función lineal en V, donde la pendiente es igual a la probabilidad de éxito bajo K agentes contratados.Precio de la falta de cuenta",
                "Como en ambos casos, hay un solo punto de transición, el reclamo sobre el \"precio de la falta de cuenta\" y la tecnología se demuestra como un caso especial de Lemma 2 a continuación.Precio de la falta de cuenta",
                "Dada como entrada, la descripción completa de una tecnología (los valores t0, ..., TN y el costo idéntico para una tecnología anónima, o el valor t (s) para todos los 2n subconjuntos posibles de los jugadores, yUn vector de costos C para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinomial: • La órbita de la tecnología tanto en la agencia como en los casos no estratégicos.• Un contrato óptimo para cualquier valor V, tanto para la agencia como para los casos no estratégicos.• El \"precio de la innovabilidad\" POU (T, C).Precio de la falta de cuenta"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "unaccountability price": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "agency theory": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "principal-agent model": {
            "translated_key": "",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "incentive": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate <br>incentive</br>s to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate <br>incentive</br>s.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En particular, el campo del diseño del mecanismo algorítmico [6] utiliza \"incentivos\" apropiados para extraer la información privada de los participantes.incentivo",
                "Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencias combinatorias pueden ofrecer una base para el diseño de contratos con \"incentivos\" apropiados.incentivo"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "con": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research <br>con</br>cerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from e<br>con</br>omic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of <br>con</br>tracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: E<br>con</br>omics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, E<br>con</br>omics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish e<br>con</br>omic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-<br>con</br>tractible - meaning that it can not be formally used in a legal <br>con</br>tract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples <br>con</br>cerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in e<br>con</br>omic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many <br>con</br>texts in classical e<br>con</br>omic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed <br>con</br>tract, in which the payments are <br>con</br>tingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which <br>con</br>ditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, <br>con</br>jectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular e<br>con</br>omic activity.",
                "Consider for example a firm that sub-<br>con</br>tracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-<br>con</br>tractor (e.g., in cases of public-relations activities, <br>con</br>sulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of <br>con</br>tracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of e<br>con</br>omic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in e<br>con</br>omic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a <br>con</br>tract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the <br>con</br>tract cannot make the payments directly <br>con</br>tingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of <br>con</br>tracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of <br>con</br>tracts: i.e. <br>con</br>tracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be <br>con</br>tracted to exert effort.",
                "This model is still pretty abstract, and every problem description <br>con</br>tains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then <br>con</br>sider a more <br>con</br>crete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example <br>con</br>siders a communication network, where each agent <br>con</br>trols a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be <br>con</br>tracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us <br>con</br>sider the set of <br>con</br>tracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be <br>con</br>tracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be <br>con</br>tracted since the marginal <br>con</br>tribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be <br>con</br>tracted, while for higher values all agents will be <br>con</br>tracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of <br>con</br>tracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a <br>con</br>struction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal <br>con</br>tracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal <br>con</br>tract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal <br>con</br>tract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with <br>con</br>tractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal <br>con</br>tract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a <br>con</br>tractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only <br>con</br>sider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable <br>con</br>tracts based on the final outcome.",
                "Thus the <br>con</br>tract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the <br>con</br>tracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to <br>con</br>centrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural se<br>con</br>d step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability <br>con</br>straint).",
                "The <br>con</br>tract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation <br>con</br>straint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to <br>con</br>centrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal <br>con</br>tribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his <br>con</br>tract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the <br>con</br>tracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best <br>con</br>tracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal <br>con</br>tracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal <br>con</br>tracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal <br>con</br>tract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather <br>con</br>trolled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal <br>con</br>tract in the agency case and let S∗ ns(v) denote an optimal <br>con</br>tract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the <br>con</br>text we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more <br>con</br>crete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are <br>con</br>stants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical <br>con</br>junction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of <br>con</br>junctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being <br>con</br>trolled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical <br>con</br>junction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal <br>con</br>tract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are <br>con</br>tracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: <br>con</br>tracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of <br>con</br>tracting with one agent is always inferior to either <br>con</br>tracting with both or with none, and will never be taken by the principal.",
                "The principal will <br>con</br>tract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be <br>con</br>trasted with the non-strategic case in which the principal completely <br>con</br>trols the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now <br>con</br>tracting with one agent is better than <br>con</br>tracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the se<br>con</br>d one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 <br>con</br>tracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are <br>con</br>tracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are <br>con</br>tracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of <br>con</br>secutive points, the social welfare ratio is between two linear functions of v (the optimal <br>con</br>tracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are <br>con</br>tracted or none, while in the se<br>con</br>d case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to <br>con</br>tract with no agent, for v > v∗ it is optimal to <br>con</br>tract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal <br>con</br>tract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between <br>con</br>tracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from <br>con</br>tracting with 0 (or n) agents is higher than his utility when <br>con</br>tracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of <br>con</br>tracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, <br>con</br>tracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we <br>con</br>sider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, <br>con</br>tracting with exactly k agents is optimal (for v < v1, no agent is <br>con</br>tracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between <br>con</br>tracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between <br>con</br>tracting with k − 1 agents, and <br>con</br>tracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of <br>con</br>tracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient <br>con</br>dition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a <br>con</br>stant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal <br>con</br>tract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary <br>con</br>ditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the <br>con</br>ditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of <br>con</br>tracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between <br>con</br>tracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of <br>con</br>tracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following <br>con</br>jecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal <br>con</br>tract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the <br>con</br>tracted set of agents and not only about the number of <br>con</br>tracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal <br>con</br>tract for some v. These sets <br>con</br>struct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal <br>con</br>tract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal <br>con</br>tracts, the success probability of the optimal <br>con</br>tracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal <br>con</br>tracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We <br>con</br>clude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a <br>con</br>junction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal <br>con</br>tract <br>con</br>tracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We <br>con</br>jecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal <br>con</br>tract is <br>con</br>structed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are <br>con</br>tracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If <br>con</br>jecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is <br>con</br>structive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal <br>con</br>tribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal <br>con</br>tribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The <br>con</br>struction of t(Z) ensures this since the marginal <br>con</br>tribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we <br>con</br>struct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can <br>con</br>struct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to <br>con</br>struct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a <br>con</br>junction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal <br>con</br>tract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal <br>con</br>tract for f = g V h on v. Then, T is an optimal <br>con</br>tract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from <br>con</br>tracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal <br>con</br>tribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the se<br>con</br>d term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal <br>con</br>tract for h on v · tg(R).",
                "Similarly, we show that R is an optimal <br>con</br>tract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal <br>con</br>tract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal <br>con</br>tract for f on v1, and let S2 = T2 ∪R2 be the optimal <br>con</br>tract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in <br>con</br>tradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a <br>con</br>tradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to <br>con</br>sider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We <br>con</br>jecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best <br>con</br>tract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first <br>con</br>sider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then <br>con</br>sider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal <br>con</br>tract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal <br>con</br>tract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to <br>con</br>struct the orbit of the technology (the same procedure apply in both cases).",
                "To <br>con</br>struct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty <br>con</br>tract is always optimal for v = 0.",
                "Assume that we have calculated the optimal <br>con</br>tracts and the transition points up to some transition point v for which S is an optimal <br>con</br>tract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal <br>con</br>tract.",
                "By Lemma 3 the next <br>con</br>tract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal <br>con</br>tract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between <br>con</br>tracting with T and <br>con</br>tracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal <br>con</br>tracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal <br>con</br>tract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal <br>con</br>tract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal <br>con</br>tract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal <br>con</br>tract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal <br>con</br>tract for t ˆT is ˆT (for the <br>con</br>tract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal <br>con</br>tract (as any of the sets that it has not queried about might be the optimal one).",
                "We <br>con</br>clude that ` n n/2 ´ − 1 queries are needed to determine the optimal <br>con</br>tract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be <br>con</br>tracted in an optimal <br>con</br>tract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal <br>con</br>tract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal <br>con</br>tract only for very large values of v, after all other agents are <br>con</br>tracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal <br>con</br>tract of G , can be found using binary search over the algorithm that supposedly finds the optimal <br>con</br>tract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal <br>con</br>tract we are also able to compute the value of t(E).",
                "In <br>con</br>clusion, computing the optimal <br>con</br>tract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal <br>con</br>tracts can be computed in polynomial time.",
                "The se<br>con</br>d avenue is to explore approximation algorithms for the optimal <br>con</br>tract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal <br>con</br>tract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal <br>con</br>tract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of E<br>con</br>omics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microe<br>con</br>omic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and E<br>con</br>omic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is <br>con</br>nected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American E<br>con</br>omic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Agencia Combinatorial [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión y Sistemas de la Información UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería y Ciencias de la Computación La Universidad Hebrea de Jerusalén Jerusalén, 91904 ISRAEL MFELDMAN@CS.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática La Universidad Hebrea de Jerusalén Jerusalén, 91904 israel noam@cs.huji.ac.il Resumen Investigación muy reciente \"Con\" sistemas de corerns, como Internet, cuyos componentes sonPropiedad y operado por diferentes partidos, cada uno con su propio objetivo egoísta.estafa",
                "Nuestro modelo es una variante combinatoria del problema clásico de principios de edad de E \"Con\" teoría ómica.estafa",
                "El principal motiva a los agentes al ofrecerles un conjunto de tratados \"con\", que juntos ponen a los agentes en un punto de equilibrio del juego inducido.estafa",
                "Categorías y descriptores de sujetos J.4 [Ciencias sociales y conductuales]: E \"Con\" ómics;K.4.4 [Comercio electrónico]: esquemas de pago;C.2.4 [Redes de Computercommunication]: Diseño de términos generales de sistemas distribuidos, E \"Con\" ómica, teoría 1. Con",
                "El análisis y el diseño de protocolos para este entorno, por lo tanto, naturalmente necesita tener en cuenta los diferentes intereses ómicos egoístas de los diferentes participantes.estafa",
                "Hidden aquí cubre una amplia gama de situaciones que incluyen no precisamente medibles, costosos de determinar o incluso un tractible \"con\", lo que significa que no puede usarse formalmente en un tracto legal \"Con\".estafa",
                "Una clase relacionada de ejemplos \"Con\" cuestiones de seguridad de los centros: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger algunas propiedades de seguridad deseadas del sistema.estafa",
                "Nuestro enfoque de este problema se basa en el problema de agente principal bien estudiado en la \"teoría ómica\": ¿cómo puede un principal motivar a un agente racional a ejercer un esfuerzo costoso hacia el bienestar del director?estafa",
                "Este problema está bien estudiado en muchos textos \"con\" en la teoría clásica de E \"Con\" y remitimos a los lectores a textos introductorios sobre teoría económica como [5] Capítulo 14. Con",
                "La solución se basa en la observación de que un tracto \"Con\" diseñado adecuadamente, en el que los pagos son \"contingentes\" sobre el resultado final, puede influir en un agente racional para ejercer el esfuerzo requerido.estafa"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        }
    }
}