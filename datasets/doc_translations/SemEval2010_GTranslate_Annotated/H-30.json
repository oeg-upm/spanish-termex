{
    "id": "H-30",
    "original_text": "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness. Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies. In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval. The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion. Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques. We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique. Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets. We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation. Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1. INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative. A great deal of information is lost during the process of translating from the information need to the actual query. For this reason, there has been a strong interest in query expansion techniques. Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need. Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29]. Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22]. The MRF model generalizes the unigram, bigram, and other various dependence models [14]. Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8]. The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6]. Until now, the model has been solely used for ranking documents in response to a given query. In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE). There are three primary contributions of our work. First, LCE provides a mechanism for combining term dependence with query expansion. Previous query expansion techniques are based on bag of words models. Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion. Next, as we will show, the MRF model allows arbitrary features to be used within the model. Query expansion techniques in the past have implicitly only made use of term occurrence features. By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better. Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts. Most previous techniques, by default, generate terms independently. There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28]. Our approach is both formally motivated and a natural extension of the underlying model. The remainder of this paper is laid out as follows. In Section 2 we describe related query expansion approaches. Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique. In Section 4 we evaluate our proposed model and analyze the results. Finally, Section 5 concludes the paper and summarizes the major results. 2. RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21]. Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents. Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval. A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29]. Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model. Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration. This separates the content model from the background model. The content model is then interpolated with the original query model to form the expanded query. The other technique, relevance models, is more closely related to our work. Therefore, we go into the details of the model. Much like model-based feedback, relevance models estimate an improved query model. The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents. Instead, they model a more generalized notion of relevance, as we now show. Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence. It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q. In the pseudo-relevant case, these are the top ranked documents for query Q. Furthermore, it is assumed that P(D) is uniform over this set. These mild assumptions make computing the Bayesian posterior more practical. After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q). This clipped distribution is then interpolated with with the original, maximum likelihood query model [1]. This can be thought of as expanding the original query by k weighted terms. Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3. There has been relatively little work done in the area of query expansion in the context of dependence models [9]. However, there have been several attempts to expand using multi-term concepts. Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28]. Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics. However, it is not clear based on the analysis done how much the phrases helped over the single terms alone. Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19]. The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other. Results showed that combining single term and large window multi-term concepts significantly improved effectiveness. However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3. MODEL This section details our proposed latent concept expansion technique. As mentioned previously, the technique is an extension of the MRF model for information retrieval [14]. Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution. Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution. That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query. A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution. A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors. Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant. We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways. However, following previous work, we consider three simple variants [14]. These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs. We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable. Therefore, we allow cliques to share feature functions and parameters based on clique sets. That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter. This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets. We propose seven clique sets for use with information retrieval. The first three clique sets consist of cliques that contain one or more query terms and the document node. Features over these cliques should encode how well the terms in the clique configuration describe the document. These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query. Note that UD is a superset of OD. By tying the parameters among the cliques within each set we can control how much influence each type gets. This also avoids the problem of trying to determine how to estimate weights for each clique within the sets. Instead, we now must only estimate a single parameter per set. Next, we consider cliques that only contain query term nodes. These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node. Feature functions over these cliques should capture how compatible query terms are to one another. These clique features may take on the form of language models that impose well-formedness of the terms. Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query. Finally, there is the clique that only contains the document node. Features over this node can be used as a type of document prior, encoding document-centric properties. This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets. After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively. These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model. The correct choice of features depends largely on the retrieval task and the evaluation metric. Therefore, there is likely not to be a single, universally applicable set of features. To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used. Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few. Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others. Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14]. See Table 1 for a list of features used. These features attempt to capture term occurrence and term proximity. Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q). After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters. Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model. Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level. Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17]. That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric. For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25]. Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query. As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations. We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query. We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts. These latent concepts can consist of a single term, multiple terms, or some combination of the two. It is, therefore, our goal to recover these latent concepts given some original query. This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating. We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts. Similarly, the graph on the right illustrates an expanded graph that generates two term concepts. Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure. After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms. Since it is not practical to compute this summation, we must approximate it. We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q. Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q. This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score. Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents. For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using. We then select the k latent concepts with the highest likelihood given by Equation 3. A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek. Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models. Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner. It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models. There are important differences between MRFs/LCE and unigram language models/relevance models. See Figure 1 for graphical model representations of both models. Unigram language models and relevance models are based on the multinomial distribution. This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features. However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used. Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4. EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets. Table 2 provides a summary of the TREC data sets considered. The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections. For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes. All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23]. All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer. In all cases, only the title portion of the TREC topics are used to construct queries. We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting. We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets. For the unigram language model, the smoothing parameter was trained. For the MRF model, we train the model parameters (i.e. Λ) and model hyperparameters (i.e. α, β). For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms. Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set). The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q. This equation clearly shows how LCE differs from relevance models. When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework. Therefore, LCE adds two very important factors to the equation. First, it adds the ordered and unordered window features that are applied to the original query. Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets. The results, evaluated using mean average precision, are given in Table 3. As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model. In addition, LCE shows significant improvements over relevance models across all data sets. The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2. Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20. However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model. Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets. In fact, the MRF model outperforms relevance models on the WT10g data set. This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16]. Although our model has more free parameters than relevance models, there is surprisingly little overfitting. Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts. For each query, we expanded using a set of single term concepts and a set of two term concepts. The sets were chosen independently. Unfortunately, only negligible increases in mean average precision were observed. This result may be due to the fact that strong correlations exist between the single term expansion concepts. We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts. For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen. Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query. This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account. Another potential issue is the feature set used. Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts. Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts. Instead, the results introduce interesting open questions and directions for future exploration. LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE). The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model. In this section we analyze the robustness of these two methods. Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods. A highly robust expansion technique will significantly improve many queries and only minimally hurt a few. Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets. The analysis for the two data sets not shown is similar. The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline. As the results show, LCE exhibits strong robustness for each data set. For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14. Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger. For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22. Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14. As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets. In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection. Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set. When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining. For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations. Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model. In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection. It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies. This is not the case when generating multi-term concepts using our model. Instead, a majority of the concepts generated are well-formed and meaningful. There are several cases where the concepts are less coherent, such as mirror mirror mirror. In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood. Such examples are in the minority, however. Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query. As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope. It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query. Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept. One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model. For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood. However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model. Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence. In information retrieval, there has been a long-term interest in understanding the role of term dependence. Out of this research, two broad types of dependencies have been identified. The first type of dependence is syntactic dependence. This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26]. These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies. The second type is semantic dependence. Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3]. These techniques have been explored on both the query and document side. On the query side, this is typically done using some form of query expansion, such as relevance models or LCE. On the document side, this is done as document expansion or document smoothing [11, 13, 24]. Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal. Our model uses both types of dependencies. The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence. This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion. If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models. Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect. An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model. Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5. CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion. The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models. LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features. We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts. The concepts generated can be used in an alternative query suggestion module. We also showed that the model is highly effective. In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets. It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets. This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones. Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies. Future work will look at incorporating document-side dependencies, as well. Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6. REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade. UMass at TREC 2004: Novelty and HARD. In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack. Shortest-substring retrieval and ranking. ACM Trans. Inf. Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan. Query expansion using random walk models. In Proc. 14th Intl. Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft. Boolean queries and term dependencies in probabilistic retrieval models. Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis. The use of phrases and structured queries in information retrieval. In Proc. 14th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi. NTCIR-5 query expansion experiments using term dependence models. In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan. Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods. In Proc. tenth Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao. Dependence language model for information retrieval. In Proc. 27th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen. An evaluation of feedback in document retrieval using co-occurrence data. Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims. A support vector method for multivariate performance measures. In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee. Corpus structure, language models, and ad-hoc information retrieval. In Proc. 27th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft. Relevance-based language models. In Proc. 24th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft. Cluster-based retrieval using language models. In Proc. 27th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft. A Markov random field model for term dependencies. In Proc. 28th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft. Linear feature based models for information retrieval. Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft. Indri at terabyte track 2005. In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson. Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach. Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan. Experiments using the lemur toolkit. In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan. Why bigger windows are better than smaller ones. Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford. Okapi at trec-3. In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio. Relevance Feedback in Information Retrieval, pages 313-323. Prentice-Hall, 1971. [22] F. Song and W. B. Croft. A general language model for information retrieval. In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft. Indri: A language model-based serach engine for complex queries. In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai. Language model information retrieval with document expansion. In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen. A theoretical basis for the use of cooccurrence data in information retrieval. Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft. LDA-based document models for ad-hoc retrieval. In Proc. 29th Ann. Intl. ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft. Improving the effectiveness of information retrieval with local context analysis. ACM Trans. Inf. Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty. Model-based feedback in the language modeling approach to information retrieval. In Proc. 10th Intl. Conf. on Information and Knowledge Management, pages 403-410, 2001.",
    "original_translation": "Expansión del concepto latente utilizando los campos aleatorios de Markov Donald Metzler metzler@cs.umass.edu W. Bruce croft croft@cs.umass.edu Centro para la información inteligente Departamento de Recuperación de la Información Universidad de Massachusetts Amherst, MA 01003 Expansión de consultas abstractas, en forma de formaciónDe la retroalimentación de pseudo-relevancia o la retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de los enfoques anteriores han ignorado temas importantes, como el papel de las características y la importancia de modelar dependencias de términos. En este documento, proponemos una técnica de expansión de consulta robusta basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión del concepto latente, proporciona un mecanismo para modelar dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las características de ocurrencia de términos simples que son implícitamente utilizadas por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica contra los modelos de relevancia, una técnica de expansión de consulta de modelado de idiomas de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de la recuperación en varios conjuntos de datos TREC. También describimos cómo nuestra técnica se puede utilizar para generar conceptos significativos de múltiples medios para tareas como la sugerencia de consulta/reformulación. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información Términos generales Algoritmos, Experimentación, Teoría 1. Introducción Los usuarios de los sistemas de recuperación de información son necesarios para expresar necesidades complejas de información en términos de expresiones booleanas, una breve lista de palabras clave, una oración, una pregunta o posiblemente una narración más larga. Se pierde una gran cantidad de información durante el proceso de traducción de la necesidad de información a la consulta real. Por esta razón, ha habido un gran interés en las técnicas de expansión de consultas. Dichas técnicas se utilizan para aumentar la consulta original para producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de la consulta se han estudiado bien para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la configuración de retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la bolsa simplista de palabras que subyace en el enfoque de modelado de idiomas BM25 y (unigram) para la recuperación de información [20, 22]. El modelo MRF generaliza el Unigram, BigRam y otros modelos de dependencia diversos [14]. La mayoría de los modelos de dependencia del término pasado no han podido mostrar mejoras consistentes y significativas sobre las líneas de base unigram, con pocas excepciones [8]. Sin embargo, se ha demostrado que el modelo MRF es altamente efectivo en una serie de tareas, incluida la recuperación ad hoc [14, 16], la búsqueda de PAGE con nombre [16] y la búsqueda web de idioma japonés [6]. Hasta ahora, el modelo se ha utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo se puede extender y usar para la expansión de consultas utilizando una técnica que llamamos expansión de concepto latente (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia del término con la expansión de la consulta. Las técnicas de expansión de consultas anteriores se basan en la bolsa de modelos de palabras. Por lo tanto, al realizar la expansión de la consulta utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia del término y la expansión de la consulta. A continuación, como mostraremos, el modelo MRF permite utilizar características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han utilizado implícitamente las características de ocurrencia del término. Al usar conjuntos de características más sólidos, es posible producir mejores términos de expansión que discriminen mejor los documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona a la perfección un mecanismo para generar conceptos individuales y múltiples. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que utilizan conceptos generalizados, sin embargo, tales enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está formalmente motivado y una extensión natural del modelo subyacente. El resto de este documento se presenta de la siguiente manera. En la Sección 2 describimos enfoques de expansión de consultas relacionadas. La Sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica de expansión de concepto latente propuesta. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el documento y resume los principales resultados.2. Trabajo relacionado Uno de los enfoques clásicos y más utilizados para la expansión de la consulta es el algoritmo Rocchio [21]. El enfoque de Rocchios, que se desarrolló dentro del modelo espacial vectorial, vuelve a sweswing el vector de consulta original al mover los pesos hacia el conjunto de documentos relevantes o pseudo relevantes y lejos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchios a un modelo de recuperación estadística, como el modelado de idiomas para la recuperación de información. Se han desarrollado una serie de técnicas de expansión de consultas formalizadas para el marco de modelado de idiomas, incluidos los modelos de relevancia de Lavrenko y Crofts de Zhai y Laffertys y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan usar documentos pseudo-relevantes o relevantes para estimar un mejor modelo de consulta. La retroalimentación basada en modelos encuentra el modelo que mejor describe los documentos relevantes al tener en cuenta un modelo de antecedentes (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, los modelos de relevancia, está más estrechamente relacionado con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que la retroalimentación basada en el modelo, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, modelan una noción más generalizada de relevancia, como ahora mostramos. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, p (· | q), que codifica la probabilidad de cada término dada la consulta como evidencia. Se calcula como: p (w | q) = d p (w | d) p (d | q) ≈ d∈Rq p (w | d) p (q | d) p (d) w d∈Rq p (w | d) p (q | d) p (d) (1) donde rq es el conjunto de documentos que son relevantes o pseudorelevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se supone que P (d) es uniforme sobre este conjunto. Estos suaves supuestos hacen que la calculación del posterior bayesiano sea más práctico. Después de estimar el modelo, los documentos se clasifican recortando el modelo de relevancia eligiendo los términos K más probables de P (· | Q). Esta distribución recortada se interpola con el modelo original de consulta de máxima probabilidad [1]. Esto puede considerarse expandiendo la consulta original por K ponderados. A lo largo del resto de este trabajo, nos referimos a esta instanciación de modelos de relevancia como RM3. Se ha realizado relativamente poco trabajo en el área de expansión de la consulta en el contexto de los modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandirse utilizando conceptos de múltiples medios. El método de análisis de contexto local de Xu y Crofts (LCA) combinó la recuperación a nivel de paso con la expansión del concepto, donde los conceptos fueron términos y frases individuales [28]. Los conceptos de expansión se eligieron y se ponderaron utilizando una métrica basada en estadísticas de concurrencia. Sin embargo, no está claro en base al análisis realizado cuánto ayudaron solo a los términos únicos. Papka y Allan investigan utilizando comentarios de relevancia para realizar una expansión de conceptos de múltiples medios para el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en LCA, e incluyen estructuras de lenguaje de consulta de consulta, como #UW50 (Casa Blanca), que corresponde al concepto que ocurren los términos blancos y la casa, en cualquier orden, dentro de 50 términosel uno del otro. Los resultados mostraron que la combinación de conceptos de un solo término y ventana múltiple de ventana mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas.3. Modele esta sección detalla nuestra técnica de expansión de concepto latente propuesta. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas.3.1 MRFS para IR 3.1.1 Conceptos básicos Markov Los campos aleatorios, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí, estamos interesados en modelar la distribución conjunta a través de una consulta Q = Q1 ,..., Qn y un documento D. Se supone que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, el muestreo de la distribución ofrece pares de documentos y consultas, de modo que el documento es relevante para la consulta. Un MRF se define mediante un gráfico G y un conjunto de funciones potenciales no negativas sobre las camarillas en G. Los nodos en el gráfico representan las variables aleatorias y los bordes definen la semántica de independencia de la distribución. Un MRF satisface la propiedad de Markov, que establece que un nodo es independiente de todos sus nodos que no son de vecinos dados valores observados para sus vecinos. Dado un gráfico G, un conjunto de potenciales ψi y un vector de parámetro λ, la distribución de la junta sobre Q y D viene dada por: PG, λ (Q, D) = 1 zλ c∈C (g) ψ (c; λ) donde z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi (c; λ) = exp [λifi (c)], donde fi (c) es una función de características de valor real.3.1.2 Construcción de G Dada una consulta q, el gráfico G se puede construir de varias maneras. Sin embargo, después del trabajo anterior, consideramos tres variantes simples [14]. Estas variantes son la independencia total, donde cada término de consulta es independiente entre sí dado un documento, dependencia secuencial, lo que supone que existe una dependencia entre los términos de consulta adyacentes y la plena dependencia, lo que no hace supuestos de independencia.3.1.3 Parametrización Los MRF se parametrizan comúnmente en función de las camarillas máximas de G. Sin embargo, dicha parametrización es demasiado grosera para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con camarillas en un nivel de grano más fino, al tiempo que mantiene el número de características y, por lo tanto, el número de parámetros, razonable. Por lo tanto, permitimos que las camarillas compartan funciones y parámetros de características basados en conjuntos de camarillas. Es decir, todas las camarillas dentro de un conjunto de camarillas están asociadas con la misma función de características y comparten un solo parámetro. Esto une efectivamente los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros al tiempo que proporciona un mecanismo para ajustar en el nivel de conjuntos de camarillas. Proponemos siete conjuntos de camarillas para su uso con recuperación de información. Los primeros tres conjuntos de camarillas consisten en camarillas que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estas camarillas deben codificar qué tan bien los términos en la configuración de la camarilla describen el documento. Estos conjuntos son: • TD - Conjunto de camarillas que contienen el nodo del documento y exactamente un término de consulta.• OD: conjunto de camarillas que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta.• UD: conjunto de camarillas que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Tenga en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre las camarillas dentro de cada conjunto, podemos controlar cuánta influencia tiene cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada camarilla dentro de los conjuntos. En cambio, ahora solo debemos estimar un solo parámetro por conjunto. A continuación, consideramos camarillas que solo contienen nodos de término de consulta. Estas camarillas, que no se consideraron en [14], se definen de manera análoga a las que se acaban de definir, excepto que las camarillas solo se componen de nodos de término de consulta y no contienen el nodo del documento. Las funciones de características sobre estas camarillas deben capturar cuán compatibles son los términos de consulta entre sí. Estas características de la camarilla pueden asumir la forma de modelos de lenguaje que imponen la bien formación de los términos. Por lo tanto, definimos los siguientes conjuntos de camarillas dependientes de la consulta: • TQ - conjunto de camarillas que contienen exactamente un término de consulta.• OQ: conjunto de camarillas que contienen dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta.• UQ: conjunto de camarillas que contienen dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la camarilla que solo contiene el nodo del documento. Las características sobre este nodo se pueden usar como un tipo de documento anterior, codificando propiedades centradas en el documento. Este conjunto de camarillas trivial es: • D - El conjunto de camarilla que contiene solo el nodo Singleton D, observamos que nuestros conjuntos de camarones forman una cubierta establecida sobre las camarillas de G, pero no son una partición, ya que algunas camarillas aparecen en múltiples conjuntos de camarillas. Después de unir los parámetros en nuestra camarilla se establece y usar la forma de función de potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log pg, λ (q, d) = λtd c∈Td ftd (c) + λodc∈D fod (c) + λud c∈Ud Fud (c) fdq (d, q) - documento y consulta dependiente + λtq c∈Tq ftq (c) + λoq c∈Oq foq (c) + λuq c∈Uqfuq (c) fq (q) - consulta dependiente de la consulta + λdfd (d) fd (d) - Documento dependiente del documento - log Zλ Documento + consulta independiente donde FDQ, FQ y FD son funciones de conveniencia definidas por el documento y la consulta dependiente de la consulta, la consulta dependiente de la consultay componentes dependientes del documento de la distribución articular, respectivamente. Estos se utilizarán para simplificar y aclarar expresiones derivadas en todo el resto del documento.3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de camarilla se puede usar en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no haya un conjunto único de características universalmente aplicables. Para proporcionar una idea de la gama de características que se pueden usar, ahora describimos brevemente los posibles tipos de características que podrían usarse. Las posibles características dependientes del término de consulta incluyen TF, IDF, entidades nombradas, proximidad de término y estilo de texto, por nombrar algunos. También se pueden utilizar muchos tipos de características dependientes de documentos, incluida la longitud de los documentos, el PageRank, la legibilidad y el género, entre otros. Dado que no es nuestro objetivo aquí encontrar características óptimas, utilizamos un conjunto simple y fijo de características que se ha demostrado que son efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para obtener una lista de características utilizadas. Estas características intentan capturar la ocurrencia del término y la proximidad del término. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad.3.1.5 Ranking Dada una consulta q, deseamos clasificar los documentos en orden descendente de acuerdo con PG, λ (d | Q). Después de soltar expresiones independientes del documento de log PG, λ (q, d), derivamos la siguiente función de clasificación: PG, λ (d | q) rango = fdq (d, q) + fd (d) (2) que es unCombinación lineal ponderada simple de funciones de características que se pueden calcular de manera eficiente para gráficos razonables.3.1.6 Estimación de parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, es inapropiado entrenarlos utilizando el valor de características FTD (Qi, D) log (1 - α) TFQI, D | D |+ α cfqi | c |FOD (Qi, Qi+1 ..., Qi+K, D) log (1 - β) TF#1 (Qi ... Qi+K), D | D |+ β cf#1 (qi ... qi+ k) | c |FUD (Qi, ..., QJ, D) log (1 - β) tf#uw (qi ... qj), d | d |+ β cf#uw (qi ... qj) | c |ftq (qi) - log cfqi | c |foq (qi, qi+1 ..., qi+k) - log cf#1 (qi ... qi+k) | c |fuq (qi, ..., qj) - log cf#uw (qi ... qj) | c |FD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, TFW, D es el número de veces que el término W ocurre en el documento D, TF#1 (Qi ... Qi+K), D denota el número de veces la frase exacta Qi...Qi+K ocurre en el documento d, tf#uw (qi ... qj), d es el número de veces los términos qi ,...QJ aparece ordenado o desordenado dentro de una ventana de n Términos, y | D |es la longitud del documento D. el CF y | C |Los valores se definen análogos en el nivel de colección. Finalmente, α y β son hiperparámetros modelo que controlan el suavizado para las características de un solo término y frase, respectivamente.Enfoques convencionales basados en la probabilidad debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima probabilidad sea la estimación que maximice nuestra métrica de evaluación. Por esta razón, capacitamos discriminativamente nuestro modelo para maximizar directamente la métrica de evaluación bajo consideración [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, utilizamos una estrategia de escalada simple, aunque son posibles otros enfoques más sofisticados [10].3.2 Expansión del concepto latente En esta sección describimos cómo este modelo MRF extendido puede usarse de una manera novedosa para generar conceptos individuales y multitermos que están relacionados tópicamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica se pueden utilizar para la expansión de consultas u otras tareas, como sugerir formulaciones de consultas alternativas. Suponemos que cuando un usuario formula su consulta original, tiene algún conjunto de conceptos en mente, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, múltiples términos o alguna combinación de los dos. Es, por lo tanto, nuestro objetivo recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco expandiendo primero el gráfico original G para incluir el tipo de concepto que estamos interesados en generar. Llamamos a este gráfico ampliado H. En la Figura 1, el gráfico intermedio proporciona un ejemplo de cómo construir un gráfico ampliado que pueda generar conceptos de un solo término. Del mismo modo, el gráfico de la derecha ilustra un gráfico ampliado que genera conceptos de dos términos. Aunque estos dos ejemplos utilizan la suposición de dependencia secuencial (es decir, dependencias entre los términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden usar cualquier estructura de independencia. Después de construir h, calculamos pH, λ (e | q), una distribución de probabilidad sobre conceptos latentes, según: pH, λ (e | q) = d∈R pH, λ (q, e, d) d∈R e ph, λ (q, e, d) donde r es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Como no es práctico calcular esta suma, debemos aproximarlo. Notamos que el pH, λ (Q, E, D) es probable que alcance su punto máximo alrededor de los documentos d que están altamente clasificados de acuerdo con la consulta Q. Por lo tanto, aproximamos el pH, λ (e | q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: pH, λ (e | q) ≈ d∈Rq pH, λ (q, e, d) d∈Rq e pH, λ (q, e, d) (3) ∝ d∈Rq exppFqd (q, d) + fd (d) + fqd (e, d) + fq (e) donde rq es un conjunto de documentos relevantes o pseudo relevantes para la consulta Q y todos los conjuntos de camarillas se construyen usando H., la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación de consultas original para el documento (ver Ecuación 2), puntaje de concepto para el documento y el puntaje independiente del documento ES. Por lo tanto, esta ecuación puede interpretarse como midiendo qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para obtener la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD (Q, D) y FQD (E, D), que nos permite ponderar el término, ordenado y las características de la ventana desordenada de manera diferente para la consulta original y el concepto de expansión del candidato.3.2.1 Expansión de consulta Para usar este marco para la expansión de la consulta, primero elegimos un gráfico de expansión que codifica la estructura de concepto latente que estamos interesados en expandir la consulta utilizando. Luego seleccionamos los conceptos latentes K con la mayor probabilidad dada por la ecuación 3. Se construye un nuevo gráfico G aumentando el gráfico original G con los conceptos de expansión K E1 ,..., Ek. Finalmente, los documentos se clasifican de acuerdo con PG, λ (D | Q, E1, ..., Ek) utilizando la ecuación 2. 3.2.2 Comparación con los modelos de relevancia Las ecuaciones 1 y 3 revela la conexión estrecha que existe entre los modelos de LCE y relevancia. Ambas Figura 1: Representaciones gráficas del modelo de modelado de relevancia (izquierda), expansión del concepto latente utilizando conceptos de un solo término (medio) y expansión de conceptos latentes utilizando conceptos de dos términos (derecho) para una consulta de tres términos.Los modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede verse como una generalización del modelado de idiomas, también se puede ver como una generalización de los modelos de relevancia. Existen diferencias importantes entre MRF/LCE y modelos de lenguaje unigram/modelos de relevancia. Consulte la Figura 1 para las representaciones de modelos gráficos de ambos modelos. Los modelos de lenguaje unigram y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución bloquea el modelo en la representación de la bolsa de las palabras y el uso implícito de las características de ocurrencia del término. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambos supuestos, modelando ambas dependencias entre los términos de consulta y permitiendo que las características arbitrarias se usen explícitamente. Mover más allá de la bolsa simplista de la suposición de palabras de esta manera da como resultado un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de la recuperación.4. Resultados experimentales Para comprender mejor las fortalezas y debilidades de nuestra técnica, lo evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos TREC considerados. Las colecciones WSJ, AP y robustas son más pequeñas y consisten completamente en artículos de Newswire, mientras que WT10G y Gov2 son grandes colecciones web. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de capacitación y prueba, donde el conjunto de capacitación se usa únicamente para la estimación de parámetros y el conjunto de pruebas se usa para fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del kit de herramientas Lemur [18, 23]. Todas las colecciones se dejaron de usar una lista estándar de 418 términos comunes y se encuentran con un Porter Stemmer. En todos los casos, solo la parte del título de los temas de TREC se utiliza para construir consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14].4.1 Resultados de recuperación ad-hoc ahora investigamos qué tan bien funciona nuestro modelo en la práctica en una configuración de retroalimentación de pseudo-relevancia. Comparamos el modelado de lenguaje unigram (con suavizado de Dirichlet), el modelo MRF (sin expansión), modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diversos conjuntos de datos. Para el modelo de idioma unigram, el parámetro de suavizado fue entrenado. Para el modelo MRF, capacitamos los parámetros del modelo (es decir, Λ) y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de Pseudoname Descripción # Docs Temas de prueba Temas de prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 robustos sólidos 2004 datos 528,155 301-450 601-700 WT10g TREC Web Collection 1,692,096 451-500 501-550 Gov2 2004 Crawl de .govomán 25,205,179 701-750 751-800 Tabla 2:Descripción general de las colecciones y temas de TREC.Documentos de retroalimentación relevantes utilizados y el número de términos de expansión.4.1.1 Expansión con conceptos de un solo término Comenzamos evaluando qué tan bien funciona nuestro modelo cuando se expande usando solo términos individuales. Antes de describir y analizar los resultados, establecemos explícitamente cómo se calculan las probabilidades del término de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiéndose con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades del término de expansión se calculan de la siguiente manera: pH, λ (e | q) ∝ d∈Rq exp λtd w∈Q log (1 - α) tfw, d | d |+ α CFW | C |+ λod b∈Q log (1 - β) tf#1 (b), d | d |+ β cf#1 (b) | c |+ λud b∈Q log (1 - β) tf#uw (b), d | d |+ β cf#uw (b) | c |+ log (1 - α) tfe, d | d |+ α cfe | c |λtd cfe | c |λtq (4) donde b ∈ Q denota el conjunto de bigrams en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λtd = λt, d = 1 y todos los demás parámetros a 0, obtenemos la fórmula exacta que se usa para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE agrega dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y desordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva de TF.IDF al término de expansión del candidato w.El factor de las FDI, que no está presente en los modelos de relevancia, juega un papel importante en la selección de términos de expansión.<= −100%(−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%RM3 LCE 05101520 AP <= −100%(−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%RM3 LCE 05101520253035 robusto<= −100%(−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%RM3 LCE 0510152025 WT10G Figura 2: Histopramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión del concepto latente (LCE) con respecto aal modelo de probabilidad de consulta (QL) para conjuntos de datos AP, robustos y WT10G. Los resultados, evaluados usando precisión promedio media, se dan en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y la LCE siempre superan significativamente el modelo de idioma unigram. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son 6.9% para AP, 12.9% para WSJ, 6.5% para robusto, 16.7% para WT10G y 7.3% para GOV2. Además, el LCE muestra mejoras pequeñas, pero no significativas, sobre el modelado de relevancia para métricas como la precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en tales métricas sobre el modelo de idioma unigram. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10G. Esto reitera la importancia de las características no unigramas basadas en la proximidad para la búsqueda web basada en el contenido observadas anteriormente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que modelos de relevancia, sorprendentemente hay poco acogedora. En cambio, el modelo exhibe buenas propiedades de generalización.4.1.2 Expansión con conceptos de múltiples plazos También investigamos la expansión utilizando conceptos de palabras individuales y dos. Para cada consulta, nos expandimos usando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio media. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de un solo término. Descubrimos que los conceptos de dos palabras elegidos a menudo consistían en dos términos altamente correlacionados que también se eligen como conceptos de un solo término. Por ejemplo, se eligió el mercado de valores conceptual de dos términos, mientras que también se eligieron las acciones y el mercado de conceptos de un solo término. Por lo tanto, es poco probable que muchos conceptos de dos palabras aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben elegirse de acuerdo con algunos criterios que también tienen en cuenta las correlaciones de novedad, diversidad o término. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden generar resultados diferentes, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no producen resultados concluyentes con respecto a la expansión utilizando conceptos de múltiples medios. En cambio, los resultados introducen preguntas e instrucciones abiertas interesantes para la exploración futura. LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ robusto .2920 .3096α .3382αβ .3601αβγ γ WT10G .1861 .205533334x. .3520α .3656α .3924αβγ tabla3: Prueba de prueba Precisión promedio media para el modelado de lenguaje (LM), el campo aleatorio de Markov (MRF), los modelos de relevancia (RM3) y la expansión del concepto latente (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (P <0.05) sobre LM, MRF y RM3, respectivamente.4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión del concepto latente pueden mejorar significativamente la efectividad de la recuperación en el modelo de probabilidad de consulta basal. En esta sección analizamos la robustez de estos dos métodos. Aquí, definimos la robustez como las consultas numéricas cuya efectividad se mejoran/duele (y por cuánto) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo dañó unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión del concepto latente para los conjuntos de datos AP, robustos y WT10G. El análisis para los dos conjuntos de datos que no se muestran es similar. Los histogramas proporcionan, para diversos rangos de disminuciones relativas/aumentos en la precisión promedio media, el número de consultas que se dolieron/mejoraron con respecto a la línea de base de la probabilidad de consulta. Como muestran los resultados, LCE exhibe una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y duelen 11, mientras que LCE mejora 35 y duele 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos robusto, los modelos de relevancia mejoran 67 consultas y duelen 32, y LCE mejora 77 y duele 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y lastimadas 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por los modelos de LCE versus relevancia es significativamente mayor para los conjuntos de datos robustos y WT10G. Además, cuando LCE perjudica el rendimiento, es menos probable que lastime tanto como el modelado de relevancia, que es una propiedad deseable.1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescopemirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table4: Quince más probables Conceptos de uno, dos y tres palabras construidos utilizando los 25 principales documentos recuperados para los logros del telescopio de la consulta en la colección robusta. En general, LCE mejora la efectividad para 65% -80% de las consultas, según el conjunto de datos. Cuando se usa en combinación con un sistema de predicción de rendimiento de consultas altamente preciso, puede ser posible expandir selectivamente consultas y minimizar la pérdida asociada con el rendimiento de la subcuina.4.3 Generación de conceptos multi-plazo Aunque encontramos que la expansión que usa conceptos de múltiples medios no pudo producir mejoras concluyentes en la efectividad, existen otras tareas potenciales para las que estos conceptos pueden ser útiles, como la sugerencia de consulta/reformulación, resumen y minería conceptual. Por ejemplo, para una tarea de sugerencia de consulta, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones de consultas alternativas. Aunque evaluar nuestro modelo en estas tareas está más allá del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos más probables de uno, dos y tres términos generados utilizando LCE para los logros del telescopio del Hubble de consulta utilizando los 25 documentos clasificados principales de la colección robusta. Es bien sabido que la generación de conceptos multimotruales utilizando un modelo basado en unigram produce resultados insatisfactorios, ya que no considera las dependencias de términos. Este no es el caso al generar conceptos multimotrientes que usan nuestro modelo. En cambio, la mayoría de los conceptos generados están bien formados y significativos. Hay varios casos en los que los conceptos son menos coherentes, como el espejo espejo espejo. En este caso, la probabilidad de que el término espejo aparezca en un documento pseudo-relevante supera las características de modelado de idiomas (por ejemplo, FOQ), lo que hace que este concepto no coherente tenga una gran probabilidad. Sin embargo, tales ejemplos están en minoría. Los conceptos generados no solo son bien formados y significativos, sino que también son tópicamente relevantes para la consulta original. Como vemos, todos los conceptos generados están sobre el tema y de alguna manera relacionados con el telescopio Hubble. Es interesante ver que la falla del telescopio conceptual Hubble es uno de los conceptos de tres términos más probables, dado que es algo contradictorio para la consulta original. A pesar de esta contradicción, también es probable que los documentos que discutan los fallas del telescopio describan los éxitos, y por lo tanto, este es un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos que genera LCE son de una naturaleza diferente a las que se generarían utilizando un modelo de relevancia BigRam. Por ejemplo, es poco probable que un modelo BigRam genere la NASA del espacio del telescopio conceptual, ya que ninguno de los BigRams que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en varias características diferentes sobre varios tipos de camarillas, es más general y robusto que un modelo BigRam. Aunque solo proporcionamos los conceptos generados para una sola consulta, observamos que el mismo análisis y conclusiones se generalizan en otros conjuntos de datos, con conceptos coherentes y tópicos que se generan constantemente utilizando LCE.4.4 Discusión Nuestra técnica de expansión del concepto latente captura dos tipos de dependencia semiNthoGonal. En la recuperación de la información, ha habido un interés a largo plazo en comprender el papel de la dependencia del término. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia cubre frases, proximidad del término y coincidencia de término [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, los sinónimos y, en cierta medida, la derivación [3]. Estas técnicas se han explorado tanto en la consulta como en el lado del documento. En el lado de la consulta, esto generalmente se hace utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se realiza como expansión del documento o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frases y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura la dependencia semántica del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda mediante el uso del modelo MRF no se pierde después de la expansión de la consulta. Si los mismos tipos de dependencias fueran capturados por dependencias sintácticas y semánticas, se esperaría que LCE funcione por igual como modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias vemos un efecto aditivo, en lugar de un efecto absorbente. Un área interesante del trabajo futuro es determinar si modelar dependencias semánticas del lado del documento puede agregar algo al modelo. Los resultados anteriores que tienen dependencias semánticas combinadas de consultas y documentos han mostrado resultados mixtos [13, 27].5. Conclusiones En este documento propusimos una sólida técnica de expansión de consultas llamada expansión de concepto latente. Se demostró que la técnica es una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso porque realiza una expansión simple o múltiple dentro de un marco que permite el modelado de dependencias de términos y el uso de características arbitrarias, mientras que el trabajo previo se ha basado en la bolsa de palabras y las características de ocurrencia de términos. Demostramos que la técnica se puede utilizar para producir conceptos de expansión multiclipmonte de alta calidad, bien formados y tópicamente relevantes. Los conceptos generados se pueden usar en un módulo de sugerencia de consulta alternativa. También mostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en los modelos de precisión promedio media sobre la relevancia en una selección de conjuntos de datos TREC. También se mostró que el modelo MRF en sí, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reconfirma las observaciones anteriores de que el modelado de dependencias mediante el uso de características de proximidad dentro del MRF tiene un mayor impacto en las colecciones más grandes y ruidosas que las más pequeñas y bien emprendidas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes y mostramos cómo LCE captura dependencias semánticas sintácticas y de consulta. El trabajo futuro también analizará la incorporación de dependencias del lado del documento. Agradecimientos Este trabajo fue apoyado en parte por el Centro para la Recuperación de Información Inteligente, en parte por NSF Grant #CNS-0454018, en parte por Arda y NSF Grant #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgos y conclusiones o recomendaciones expresadas en este material son las del autor (s) y no reflejan necesariamente las del patrocinador.6. Referencias [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Díaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en Trec 2004: Novedad y duro. En los procedimientos en línea de la conf. De recuperación de texto de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de substrato más corto. ACM Trans. Inf. Syst., 18 (1): 44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consulta utilizando modelos de caminata aleatorias. En Proc.14th intl. Conf.Sobre la gestión de información y conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Journal of the American Society for Information Science, 37 (4): 71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc.14th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de la consulta NTCIR-5 utilizando modelos de dependencia de términos. En Proc.de la quinta reunión del taller de NTCIR sobre la evaluación de tecnologías de acceso a la información, páginas 494-501, 2005. [7] J. Fagan. Indexación de frases automáticas para la recuperación de documentos: un examen de los métodos sintácticos y no sintácticos. En Proc.Décima Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para la recuperación de información. En Proc.27th Ann. Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, páginas 170-177, 2004. [9] D. Harper y C. J. Van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de concurrencia. Journal of Documation, 34 (3): 189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc.de la Conf. Internacional.En el aprendizaje automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de idiomas y recuperación de información ad-hoc. En Proc.27th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de idiomas basados en relevancia. En Proc.24th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clúster utilizando modelos de lenguaje. En Proc.27th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias de términos. En Proc.28 Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para recuperación de información. Recuperación de información, para aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en Terabyte Track 2005. En las actas en línea de la conf. De recuperación de texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante la escalada con una comparación con un enfoque de entropía máxima. Informe técnico, Miter, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas Lemur. En Proc.del texto Conf., 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en TREC-3. En Actas en línea de la tercera conf. De recuperación de texto, páginas 109-126, 1995. [21] J. J. Rocchio. Comentarios de relevancia en la recuperación de la información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de idioma general para la recuperación de información. En Proc.Octava Conferencia Internacional sobre Gestión de Información y Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: un motor Serach basado en modelos de idiomas para consultas complejas. En Proc.de la Conf. Internacional.en análisis de inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de idioma con expansión de documentos. En Proc.de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. GuestRin y D. Koller. Redes de Margin Margin Max. En Proc.de avances en sistemas de procesamiento de información neural (NIPS 2003), 2003. [26] C. J. Van Rijsbergen. Una base teórica para el uso de datos de coincurrencia en la recuperación de información. Journal of Documation, 33 (2): 106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc.29th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejora de la efectividad de la recuperación de información con el análisis de contexto local. ACM Trans. Inf. Syst., 18 (1): 79-112, 2000. [29] C. Zhai y J. Lafferty. Comentarios basados en modelos en el enfoque de modelado de idiomas para la recuperación de información. En Proc.10º intl. Conf.Sobre la gestión de información y conocimiento, páginas 403-410, 2001.",
    "original_sentences": [
        "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
        "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
        "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
        "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
        "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
        "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
        "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
        "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
        "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
        "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
        "A great deal of information is lost during the process of translating from the information need to the actual query.",
        "For this reason, there has been a strong interest in query expansion techniques.",
        "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
        "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
        "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
        "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
        "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
        "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
        "Until now, the model has been solely used for ranking documents in response to a given query.",
        "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
        "There are three primary contributions of our work.",
        "First, LCE provides a mechanism for combining term dependence with query expansion.",
        "Previous query expansion techniques are based on bag of words models.",
        "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
        "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
        "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
        "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
        "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
        "Most previous techniques, by default, generate terms independently.",
        "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
        "Our approach is both formally motivated and a natural extension of the underlying model.",
        "The remainder of this paper is laid out as follows.",
        "In Section 2 we describe related query expansion approaches.",
        "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
        "In Section 4 we evaluate our proposed model and analyze the results.",
        "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
        "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
        "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
        "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
        "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
        "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
        "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
        "This separates the content model from the background model.",
        "The content model is then interpolated with the original query model to form the expanded query.",
        "The other technique, relevance models, is more closely related to our work.",
        "Therefore, we go into the details of the model.",
        "Much like model-based feedback, relevance models estimate an improved query model.",
        "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
        "Instead, they model a more generalized notion of relevance, as we now show.",
        "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
        "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
        "In the pseudo-relevant case, these are the top ranked documents for query Q.",
        "Furthermore, it is assumed that P(D) is uniform over this set.",
        "These mild assumptions make computing the Bayesian posterior more practical.",
        "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
        "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
        "This can be thought of as expanding the original query by k weighted terms.",
        "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
        "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
        "However, there have been several attempts to expand using multi-term concepts.",
        "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
        "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
        "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
        "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
        "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
        "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
        "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
        "MODEL This section details our proposed latent concept expansion technique.",
        "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
        "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
        "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
        "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
        "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
        "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
        "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
        "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
        "However, following previous work, we consider three simple variants [14].",
        "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
        "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
        "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
        "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
        "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
        "We propose seven clique sets for use with information retrieval.",
        "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
        "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
        "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
        "Note that UD is a superset of OD.",
        "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
        "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
        "Instead, we now must only estimate a single parameter per set.",
        "Next, we consider cliques that only contain query term nodes.",
        "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
        "Feature functions over these cliques should capture how compatible query terms are to one another.",
        "These clique features may take on the form of language models that impose well-formedness of the terms.",
        "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
        "Finally, there is the clique that only contains the document node.",
        "Features over this node can be used as a type of document prior, encoding document-centric properties.",
        "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
        "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
        "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
        "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
        "Therefore, there is likely not to be a single, universally applicable set of features.",
        "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
        "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
        "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
        "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
        "See Table 1 for a list of features used.",
        "These features attempt to capture term occurrence and term proximity.",
        "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
        "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
        "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
        "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
        "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
        "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
        "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
        "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
        "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
        "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
        "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
        "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
        "It is, therefore, our goal to recover these latent concepts given some original query.",
        "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
        "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
        "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
        "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
        "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
        "Since it is not practical to compute this summation, we must approximate it.",
        "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
        "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
        "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
        "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
        "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
        "We then select the k latent concepts with the highest likelihood given by Equation 3.",
        "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
        "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
        "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
        "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
        "There are important differences between MRFs/LCE and unigram language models/relevance models.",
        "See Figure 1 for graphical model representations of both models.",
        "Unigram language models and relevance models are based on the multinomial distribution.",
        "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
        "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
        "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
        "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
        "Table 2 provides a summary of the TREC data sets considered.",
        "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
        "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
        "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
        "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
        "In all cases, only the title portion of the TREC topics are used to construct queries.",
        "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
        "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
        "For the unigram language model, the smoothing parameter was trained.",
        "For the MRF model, we train the model parameters (i.e.",
        "Λ) and model hyperparameters (i.e. α, β).",
        "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
        "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
        "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
        "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
        "This equation clearly shows how LCE differs from relevance models.",
        "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
        "Therefore, LCE adds two very important factors to the equation.",
        "First, it adds the ordered and unordered window features that are applied to the original query.",
        "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
        "The results, evaluated using mean average precision, are given in Table 3.",
        "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
        "In addition, LCE shows significant improvements over relevance models across all data sets.",
        "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
        "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
        "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
        "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
        "In fact, the MRF model outperforms relevance models on the WT10g data set.",
        "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
        "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
        "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
        "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
        "The sets were chosen independently.",
        "Unfortunately, only negligible increases in mean average precision were observed.",
        "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
        "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
        "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
        "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
        "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
        "Another potential issue is the feature set used.",
        "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
        "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
        "Instead, the results introduce interesting open questions and directions for future exploration.",
        "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
        "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
        "In this section we analyze the robustness of these two methods.",
        "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
        "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
        "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
        "The analysis for the two data sets not shown is similar.",
        "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
        "As the results show, LCE exhibits strong robustness for each data set.",
        "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
        "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
        "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
        "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
        "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
        "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
        "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
        "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
        "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
        "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
        "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
        "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
        "This is not the case when generating multi-term concepts using our model.",
        "Instead, a majority of the concepts generated are well-formed and meaningful.",
        "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
        "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
        "Such examples are in the minority, however.",
        "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
        "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
        "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
        "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
        "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
        "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
        "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
        "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
        "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
        "Out of this research, two broad types of dependencies have been identified.",
        "The first type of dependence is syntactic dependence.",
        "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
        "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
        "The second type is semantic dependence.",
        "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
        "These techniques have been explored on both the query and document side.",
        "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
        "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
        "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
        "Our model uses both types of dependencies.",
        "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
        "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
        "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
        "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
        "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
        "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
        "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
        "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
        "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
        "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
        "The concepts generated can be used in an alternative query suggestion module.",
        "We also showed that the model is highly effective.",
        "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
        "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
        "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
        "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
        "Future work will look at incorporating document-side dependencies, as well.",
        "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
        "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
        "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
        "UMass at TREC 2004: Novelty and HARD.",
        "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
        "Shortest-substring retrieval and ranking.",
        "ACM Trans.",
        "Inf.",
        "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
        "Query expansion using random walk models.",
        "In Proc. 14th Intl.",
        "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
        "Boolean queries and term dependencies in probabilistic retrieval models.",
        "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
        "The use of phrases and structured queries in information retrieval.",
        "In Proc. 14th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
        "NTCIR-5 query expansion experiments using term dependence models.",
        "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
        "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
        "In Proc. tenth Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
        "Dependence language model for information retrieval.",
        "In Proc. 27th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
        "An evaluation of feedback in document retrieval using co-occurrence data.",
        "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
        "A support vector method for multivariate performance measures.",
        "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
        "Corpus structure, language models, and ad-hoc information retrieval.",
        "In Proc. 27th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
        "Relevance-based language models.",
        "In Proc. 24th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
        "Cluster-based retrieval using language models.",
        "In Proc. 27th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
        "A Markov random field model for term dependencies.",
        "In Proc. 28th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
        "Linear feature based models for information retrieval.",
        "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
        "Indri at terabyte track 2005.",
        "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
        "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
        "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
        "Experiments using the lemur toolkit.",
        "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
        "Why bigger windows are better than smaller ones.",
        "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
        "Okapi at trec-3.",
        "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
        "Relevance Feedback in Information Retrieval, pages 313-323.",
        "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
        "A general language model for information retrieval.",
        "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
        "Indri: A language model-based serach engine for complex queries.",
        "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
        "Language model information retrieval with document expansion.",
        "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
        "Max-margin markov networks.",
        "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
        "A theoretical basis for the use of cooccurrence data in information retrieval.",
        "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
        "LDA-based document models for ad-hoc retrieval.",
        "In Proc. 29th Ann.",
        "Intl.",
        "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
        "Improving the effectiveness of information retrieval with local context analysis.",
        "ACM Trans.",
        "Inf.",
        "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
        "Model-based feedback in the language modeling approach to information retrieval.",
        "In Proc. 10th Intl.",
        "Conf. on Information and Knowledge Management, pages 403-410, 2001."
    ],
    "error_count": 0,
    "keys": {
        "robust query expansion technique": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a <br>robust query expansion technique</br> based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a <br>robust query expansion technique</br> called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En este documento, proponemos una \"técnica de expansión de consulta robusta\" basada en el modelo de campo aleatorio de Markov para la recuperación de información.Técnica de expansión de consulta robusta",
                "Conclusiones En este artículo propusimos una \"técnica de expansión de consultas robusta\" llamada expansión de concepto latente.Técnica de expansión de consulta robusta"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "language modeling query expansion technique": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art <br>language modeling query expansion technique</br>.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Evaluamos nuestra técnica contra modelos de relevancia, una \"técnica de expansión de consulta de modelado de idiomas\" de última generación.Técnica de expansión de consultas de modelado de idiomas"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "relevance feedback": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-<br>relevance feedback</br> or <br>relevance feedback</br>, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the <br>relevance feedback</br> and pseudo-<br>relevance feedback</br> setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using <br>relevance feedback</br> to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-<br>relevance feedback</br> setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are <br>relevance feedback</br>, pseudo-<br>relevance feedback</br>, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "<br>relevance feedback</br> in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Expansión del concepto latente utilizando los campos aleatorios de Markov Donald Metzler metzler@cs.umass.edu W. Bruce croft croft@cs.umass.edu Centro para la información inteligente Departamento de Recuperación de la Informática Universidad de Massachusetts Amherst, MA 01003 Expansión de consultas abstractas, en forma de formaciónde pseudo- \"retroalimentación de relevancia\" o \"retroalimentación de relevancia\" es una técnica común utilizada para mejorar la efectividad de la recuperación.Comentarios de relevancia",
                "Las técnicas de expansión de la consulta se han estudiado bien para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la \"retroalimentación de relevancia\" como en el entorno de pseudo- \"retroalimentación de relevancia\" [12, 21, 28, 29].Comentarios de relevancia",
                "Papka y Allan investigan el uso de \"retroalimentación de relevancia\" para realizar una expansión de conceptos de múltiples medios para el enrutamiento de documentos [19].Comentarios de relevancia",
                "Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14].4.1 Resultados de recuperación ad-hoc ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en un entorno de \"retroalimentación de relevancia\".Comentarios de relevancia",
                "Ejemplos de dependencia semántica son la \"retroalimentación de relevancia\", pseudo- \"retroalimentación de relevancia\", sinónimos y, en cierta medida, derivados [3].Comentarios de relevancia",
                "\"Comentarios de relevancia\" en la recuperación de la información, páginas 313-323.Comentarios de relevancia"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "pseudo-relevance feedback": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of <br>pseudo-relevance feedback</br> or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and <br>pseudo-relevance feedback</br> setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a <br>pseudo-relevance feedback</br> setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, <br>pseudo-relevance feedback</br>, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Expansión del concepto latente utilizando los campos aleatorios de Markov Donald Metzler metzler@cs.umass.edu W. Bruce croft croft@cs.umass.edu Centro para la información inteligente Departamento de Recuperación de la Información Universidad de Massachusetts Amherst, MA 01003 Expansión de consultas abstractas, en forma de formaciónde \"retroalimentación de pseudo-relevancia\" o retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación.Comentarios de pseudo-relevancia",
                "Las técnicas de expansión de la consulta se han estudiado bien para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la configuración de \"retroalimentación de pseudo-relevancia\" [12, 21, 28, 29].Comentarios de pseudo-relevancia",
                "Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14].4.1 Resultados de recuperación ad-hoc ahora investigamos qué tan bien se desempeña nuestro modelo en la práctica en una configuración de \"retroalimentación de pseudo-relevancia\".Comentarios de pseudo-relevancia",
                "Ejemplos de dependencia semántica son la retroalimentación de relevancia, \"retroalimentación de pseudo-relevancia\", sinónimos y, en cierta medida, detrás [3].Comentarios de pseudo-relevancia"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "information retrieval": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent <br>information retrieval</br> Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for <br>information retrieval</br>.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of <br>information retrieval</br> systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for <br>information retrieval</br> was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to <br>information retrieval</br> [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for <br>information retrieval</br>.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for <br>information retrieval</br> [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with <br>information retrieval</br>.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In <br>information retrieval</br>, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for <br>information retrieval</br> and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent <br>information retrieval</br>, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in <br>information retrieval</br>.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for <br>information retrieval</br>.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc <br>information retrieval</br>.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for <br>information retrieval</br>.",
                "<br>information retrieval</br>, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in <br>information retrieval</br>, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for <br>information retrieval</br>.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model <br>information retrieval</br> with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in <br>information retrieval</br>.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in <br>information retrieval</br>, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of <br>information retrieval</br> with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to <br>information retrieval</br>.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Expansión del concepto latente utilizando los campos aleatorios de Markov Donald Metzler metzler@cs.umass.edu W. Bruce croft croft@cs.umass.edu Centro para la \"recuperación de información\" inteligente de la Universidad de Massachusetts Amherst, MA 01003 Expansión de consultas abstractas, enLa forma de retroalimentación de pseudo-relevancia o retroalimentación de relevancia es una técnica común utilizada para mejorar la efectividad de la recuperación.recuperación de información",
                "En este artículo, proponemos una técnica de expansión de consulta robusta basada en el modelo de campo aleatorio de Markov para la \"recuperación de información\".recuperación de información",
                "Introducción Los usuarios de los sistemas de \"recuperación de información\" son necesarios para expresar necesidades de información complejas en términos de expresiones booleanas, una breve lista de palabras clave, una oración, una pregunta o posiblemente una narrativa más larga.recuperación de información",
                "Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la \"recuperación de la información\" que va más allá de la bolsa simplista de palabras que subyace en el enfoque de modelado de idiomas (unigram) para la \"recuperación de información\" [20, 22].recuperación de información",
                "Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchios a un modelo de recuperación estadística, como el modelado de idiomas para la \"recuperación de información\".recuperación de información",
                "Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la \"recuperación de información\" [14].recuperación de información",
                "Proponemos siete conjuntos de camarillas para su uso con \"recuperación de información\".recuperación de información",
                "En la \"recuperación de la información\", ha habido un interés a largo plazo en comprender el papel de la dependencia del término.recuperación de información",
                "Se demostró que la técnica es una extensión natural del modelo de campo aleatorio de Markov para la \"recuperación de la información\" y una generalización de los modelos de relevancia.recuperación de información",
                "Agradecimientos Este trabajo fue apoyado en parte por el Centro para la \"Recuperación de información\" inteligente, en parte por NSF Grant #CNS-0454018, en parte por Arda y NSF Grant #CCF-0205575, y en parte por Microsoft Live Labs.recuperación de información"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "language modeling approach": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) <br>language modeling approach</br> to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the <br>language modeling approach</br> to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la bolsa simplista de palabras que subyace en BM25 y el \"enfoque de modelado de idiomas\" (unigram) para la recuperación de información [20, 22].Enfoque de modelado de idiomas",
                "Comentarios basados en modelos en el \"Enfoque de modelado de idiomas\" para la recuperación de la información.Enfoque de modelado de idiomas"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "web search": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language <br>web search</br> [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based <br>web search</br> observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Sin embargo, se ha demostrado que el modelo MRF es altamente efectivo en una serie de tareas, incluida la recuperación ad hoc [14, 16], la búsqueda de PAGE nombrada [16] y la \"búsqueda web\" del idioma japonés [6].búsqueda Web",
                "Esto reitera la importancia de las características no unigramas basadas en la proximidad para la \"búsqueda web\" basada en el contenido observadas anteriormente [14, 16].búsqueda Web"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "query expansion": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT <br>query expansion</br>, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust <br>query expansion</br> technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling <br>query expansion</br> technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in <br>query expansion</br> techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "<br>query expansion</br> techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for <br>query expansion</br> using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with <br>query expansion</br>.",
                "Previous <br>query expansion</br> techniques are based on bag of words models.",
                "Therefore, by performing <br>query expansion</br> using the MRF model, we are able to study the dynamics between term dependence and <br>query expansion</br>.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "<br>query expansion</br> techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related <br>query expansion</br> approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to <br>query expansion</br> is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized <br>query expansion</br> techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of <br>query expansion</br> in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for <br>query expansion</br> or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 <br>query expansion</br> To use this framework for <br>query expansion</br>, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of <br>query expansion</br>, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after <br>query expansion</br>.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust <br>query expansion</br> technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any <br>query expansion</br>, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "<br>query expansion</br> using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 <br>query expansion</br> experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Expansión del concepto latente utilizando los campos aleatorios de Markov Donald Metzler metzler@cs.umass.edu W. Bruce croft croft@cs.umass.edu Centro para la información inteligente Departamento de Recuperación de la Informática Universidad de Massachusetts Amherst, MA 01003 Resumen \"Expansión de consultoría\", In In, In InLa forma de retroalimentación de pseudo-relevancia o retroalimentación de relevancia es una técnica común utilizada para mejorar la efectividad de la recuperación.expansión de la consulta",
                "En este artículo, proponemos una sólida técnica de \"expansión de consultas\" basada en el modelo de campo aleatorio de Markov para la recuperación de información.expansión de la consulta",
                "Evaluamos nuestra técnica contra los modelos de relevancia, una técnica de \"expansión de consultas\" de última generación.expansión de la consulta",
                "Por esta razón, ha habido un gran interés en las técnicas de \"expansión de la consulta\".expansión de la consulta",
                "Las técnicas de \"expansión de la consulta\" se han estudiado bien para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la configuración de retroalimentación de pseudo-relevancia [12, 21, 28, 29].expansión de la consulta",
                "En este trabajo, mostramos cómo el modelo se puede extender y usar para la \"expansión de consultas\" utilizando una técnica que llamamos expansión de concepto latente (LCE).expansión de la consulta",
                "Primero, LCE proporciona un mecanismo para combinar la dependencia del término con la \"expansión de la consulta\".expansión de la consulta",
                "Las técnicas anteriores de \"expansión de la consulta\" se basan en modelos de bolsa de palabras.expansión de la consulta",
                "Por lo tanto, al realizar la \"expansión de la consulta\" utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia del término y la \"expansión de la consulta\".expansión de la consulta",
                "Las técnicas de \"expansión de la consulta\" en el pasado solo han utilizado implícitamente las características de ocurrencia.expansión de la consulta"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "mrf": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (<br>mrf</br>) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The <br>mrf</br> model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The <br>mrf</br> model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the <br>mrf</br> model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the <br>mrf</br> model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the <br>mrf</br> model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the <br>mrf</br> model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the <br>mrf</br> model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A <br>mrf</br> is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A <br>mrf</br> satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended <br>mrf</br> model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the <br>mrf</br> model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the <br>mrf</br> model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the <br>mrf</br> model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the <br>mrf</br> model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the <br>mrf</br> model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the <br>mrf</br> model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the <br>mrf</br> model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM <br>mrf</br> RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (<br>mrf</br>), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, <br>mrf</br>, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the <br>mrf</br> model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the <br>mrf</br> model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the <br>mrf</br> has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Recientemente, se propuso un modelo de campo aleatorio de Markov (\"MRF\") para la recuperación de información que va más allá de la bolsa simplista de palabras que subyace en BM25 y el enfoque de modelado de idiomas (unigram) para la recuperación de información [20, 22].MRF",
                "El modelo \"MRF\" generaliza el Unigram, BigRam y otros modelos de dependencia diversos [14].MRF",
                "Sin embargo, se ha demostrado que el modelo \"MRF\" es altamente efectivo en una serie de tareas, incluida la recuperación ad hoc [14, 16], la búsqueda de PAGE [16] y la búsqueda web de idioma japonés [6].MRF",
                "Por lo tanto, al realizar la expansión de la consulta utilizando el modelo \"MRF\", podemos estudiar la dinámica entre la dependencia del término y la expansión de la consulta.MRF",
                "A continuación, como mostraremos, el modelo \"MRF\" permite que las características arbitrarias se usen dentro del modelo.MRF",
                "La Sección 3 proporciona una visión general del modelo \"MRF\" y detalla nuestra técnica de expansión de concepto latente propuesta.MRF",
                "Como se mencionó anteriormente, la técnica es una extensión del modelo \"MRF\" para la recuperación de información [14].MRF",
                "Por lo tanto, comenzamos proporcionando una visión general del modelo \"MRF\" y nuestras extensiones propuestas.3.1 MRFS para IR 3.1.1 Conceptos básicos Markov Los campos aleatorios, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta.MRF",
                "Un \"MRF\" se define por un gráfico G y un conjunto de funciones potenciales no negativas sobre las camarillas en G. Los nodos en el gráfico representan las variables aleatorias y los bordes definen la semántica de independencia de la distribución.MRF",
                "Un \"MRF\" satisface la propiedad de Markov, que establece que un nodo es independiente de todos sus nodos no vecinos que se les dan valores observados para sus vecinos.MRF"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "rocchio algorithm": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the <br>rocchio algorithm</br> [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Trabajo relacionado Uno de los enfoques clásicos y más utilizados para la expansión de la consulta es el \"Algoritmo Rocchio\" [21].algoritmo rocio"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "language modeling framework": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the <br>language modeling framework</br>, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Se han desarrollado una serie de técnicas formalizadas de expansión de consultas para el \"marco de modelado de idiomas\", incluidos los modelos de relevancia de Lavrenko y Crofts de Zhai y Laffertys [12, 29].Marco de modelado de idiomas"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "rm3": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as <br>rm3</br>.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For <br>rm3</br> and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>rm3</br> LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% <br>rm3</br> LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF <br>rm3</br> LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (<br>rm3</br>), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and <br>rm3</br>, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "A lo largo del resto de este trabajo, nos referimos a esta instanciación de modelos de relevancia como \"RM3\".RM3",
                "Para \"RM3\" y LCE, también entrenamos el número de Pseudoname Descripción # Docs Temas de prueba Temas de prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.RM3",
                "En segundo lugar, aplica una forma intuitiva de TF.IDF al término de expansión del candidato w.El factor de las FDI, que no está presente en los modelos de relevancia, juega un papel importante en la selección de términos de expansión.<= −100%(−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%\"RM3\" LCE 05101520 AP <= −100%(−100%, −75%] (−75%, −50%](−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%\"RM3\"LCE 05101520253035 robusto <= −100%(−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%RM3 LCE 0510152025 WT10g Figura 2: Histopramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión del concepto latente (LCE) con respecto al modelo de probabilidad de consulta (QL) para conjuntos de datos AP, robustos y WT10G. RM3",
                "LM MRF \"RM3\" LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ sólido .2920 .3096α .3382αβ .3601αβγ γ γ .1861 .2053330. 34 .3520α .3656α.3924ααβγ Tabla 3: Prueba de prueba Precisión promedio media para el modelado del lenguaje (LM), el campo aleatorio de Markov (MRF), los modelos de relevancia (\"RM3\") y la expansión del concepto latente (LCE).RM3",
                "Los superíndices α, β y γ indican mejoras estadísticamente significativas (P <0.05) sobre LM, MRF y \"RM3\", respectivamente.4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión del concepto latente pueden mejorar significativamente la efectividad de la recuperación en el modelo de probabilidad de consulta basal.RM3"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "document routing": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for <br>document routing</br> [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Papka y Allan investigan utilizando comentarios de relevancia para realizar una expansión de conceptos de múltiples medios para \"enrutamiento de documentos\" [19].enrutamiento de documentos"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "ad-hoc retrieval": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 <br>ad-hoc retrieval</br> Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for <br>ad-hoc retrieval</br>.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14].4.1 Resultados de \"recuperación ad-hoc\" Ahora investigamos qué tan bien funciona nuestro modelo en la práctica en una configuración de retroalimentación de pseudo-relevancia.recuperación ad-hoc",
                "Modelos de documentos basados en LDA para \"recuperación ad-hoc\".recuperación ad-hoc"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "mrf model": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The <br>mrf model</br> generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The <br>mrf model</br>, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the <br>mrf model</br>, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the <br>mrf model</br> allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the <br>mrf model</br> and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the <br>mrf model</br> for information retrieval [14].",
                "Therefore, we begin by providing an overview of the <br>mrf model</br> and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended <br>mrf model</br> can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the <br>mrf model</br> can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the <br>mrf model</br> allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the <br>mrf model</br> (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the <br>mrf model</br>, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the <br>mrf model</br>, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the <br>mrf model</br> is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the <br>mrf model</br> outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the <br>mrf model</br> is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the <br>mrf model</br> itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "El \"modelo MRF\" generaliza el Unigram, BigRam y otros modelos de dependencia diversos [14].modelo MRF",
                "Sin embargo, se ha demostrado que el \"modelo MRF\" es altamente efectivo en una serie de tareas, incluida la recuperación ad hoc [14, 16], la búsqueda de PAGE [16] y la búsqueda web de idioma japonés [6].modelo MRF",
                "Por lo tanto, al realizar la expansión de la consulta utilizando el \"modelo MRF\", podemos estudiar la dinámica entre la dependencia del término y la expansión de la consulta.modelo MRF",
                "A continuación, como mostraremos, el \"Modelo MRF\" permite que las características arbitrarias se usen dentro del modelo.modelo MRF",
                "La Sección 3 proporciona una visión general del \"Modelo MRF\" y detalla nuestra técnica de expansión de concepto latente propuesta.modelo MRF",
                "Como se mencionó anteriormente, la técnica es una extensión del \"modelo MRF\" para la recuperación de información [14].modelo MRF",
                "Por lo tanto, comenzamos proporcionando una visión general del \"Modelo MRF\" y nuestras extensiones propuestas.3.1 MRFS para IR 3.1.1 Conceptos básicos Markov Los campos aleatorios, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta.modelo MRF",
                "Dado que nuestro espacio de parámetros es pequeño, utilizamos una estrategia de escalada simple, aunque son posibles otros enfoques más sofisticados [10].3.2 Expansión del concepto latente En esta sección describimos cómo este \"modelo MRF\" extendido puede usarse de una manera novedosa para generar conceptos individuales y multitermos que están relacionados tópicamente con alguna consulta original.modelo MRF",
                "Es fácil ver que al igual que el \"modelo MRF\" puede verse como una generalización del modelado de idiomas, también se puede ver como una generalización de los modelos de relevancia.modelo MRF",
                "Sin embargo, la distribución subyacente al \"modelo MRF\" nos permite ir más allá de ambos supuestos, modelando ambas dependencias entre los términos de consulta y permitiendo que las características arbitrarias se usen explícitamente.modelo MRF"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "relevance distribution": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the Markov random field model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a Markov random field (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a <br>relevance distribution</br>.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in Markov random field model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), Markov random field (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the Markov random field model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A Markov random field model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Aquí, estamos interesados en modelar la distribución conjunta a través de una consulta Q = Q1 ,..., Qn y un documento D. Se supone que la distribución subyacente sobre pares de documentos y consultas es una \"distribución de relevancia\".distribución de relevancia"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "markov random field": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Latent Concept Expansion Using Markov Random Fields Donald Metzler metzler@cs.umass.edu W. Bruce Croft croft@cs.umass.edu Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 ABSTRACT Query expansion, in the form of pseudo-relevance feedback or relevance feedback, is a common technique used to improve retrieval effectiveness.",
                "Most previous approaches have ignored important issues, such as the role of features and the importance of modeling term dependencies.",
                "In this paper, we propose a robust query expansion technique based on the <br>markov random field</br> model for information retrieval.",
                "The technique, called latent concept expansion, provides a mechanism for modeling term dependencies during expansion.",
                "Furthermore, the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques.",
                "We evaluate our technique against relevance models, a state-of-the-art language modeling query expansion technique.",
                "Our model demonstrates consistent and significant improvements in retrieval effectiveness across several TREC data sets.",
                "We also describe how our technique can be used to generate meaningful multi-term concepts for tasks such as query suggestion/reformulation.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Experimentation, Theory 1.",
                "INTRODUCTION Users of information retrieval systems are required to express complex information needs in terms of Boolean expressions, a short list of keywords, a sentence, a question, or possibly a longer narrative.",
                "A great deal of information is lost during the process of translating from the information need to the actual query.",
                "For this reason, there has been a strong interest in query expansion techniques.",
                "Such techniques are used to augment the original query to produce a representation that better reflects the underlying information need.",
                "Query expansion techniques have been well studied for various models in the past and have shown to significantly improve effectiveness in both the relevance feedback and pseudo-relevance feedback setting [12, 21, 28, 29].",
                "Recently, a <br>markov random field</br> (MRF) model for information retrieval was proposed that goes beyond the simplistic bag of words assumption that underlies BM25 and the (unigram) language modeling approach to information retrieval [20, 22].",
                "The MRF model generalizes the unigram, bigram, and other various dependence models [14].",
                "Most past term dependence models have failed to show consistent, significant improvements over unigram baselines, with few exceptions [8].",
                "The MRF model, however, has been shown to be highly effective across a number of tasks, including ad hoc retrieval [14, 16], named-page finding [16], and Japanese language web search [6].",
                "Until now, the model has been solely used for ranking documents in response to a given query.",
                "In this work, we show how the model can be extended and used for query expansion using a technique that we call latent concept expansion (LCE).",
                "There are three primary contributions of our work.",
                "First, LCE provides a mechanism for combining term dependence with query expansion.",
                "Previous query expansion techniques are based on bag of words models.",
                "Therefore, by performing query expansion using the MRF model, we are able to study the dynamics between term dependence and query expansion.",
                "Next, as we will show, the MRF model allows arbitrary features to be used within the model.",
                "Query expansion techniques in the past have implicitly only made use of term occurrence features.",
                "By using more robust feature sets, it is possible to produce better expansion terms that discriminate between relevant and non-relevant documents better.",
                "Finally, our proposed approach seamlessly provides a mechanism for generating both single and multi-term concepts.",
                "Most previous techniques, by default, generate terms independently.",
                "There have been several approaches that make use of generalized concepts, however such approaches were somewhat heuristic and done outside of the model [19, 28].",
                "Our approach is both formally motivated and a natural extension of the underlying model.",
                "The remainder of this paper is laid out as follows.",
                "In Section 2 we describe related query expansion approaches.",
                "Section 3 provides an overview of the MRF model and details our proposed latent concept expansion technique.",
                "In Section 4 we evaluate our proposed model and analyze the results.",
                "Finally, Section 5 concludes the paper and summarizes the major results. 2.",
                "RELATED WORK One of the classic and most widely used approaches to query expansion is the Rocchio algorithm [21].",
                "Rocchios approach, which was developed within the vector space model, reweights the original query vector by moving the weights towards the set of relevant or pseudo-relevant documents and away from the non-relevant documents.",
                "Unfortunately, it is not possible to formally apply Rocchios approach to a statistical retrieval model, such as language modeling for information retrieval.",
                "A number of formalized query expansion techniques have been developed for the language modeling framework, including Zhai and Laffertys model-based feedback and Lavrenko and Crofts relevance models [12, 29].",
                "Both approaches attempt to use pseudo-relevant or relevant documents to estimate a better query model.",
                "Model-based feedback finds the model that best describes the relevant documents while taking a background (noise) model into consideration.",
                "This separates the content model from the background model.",
                "The content model is then interpolated with the original query model to form the expanded query.",
                "The other technique, relevance models, is more closely related to our work.",
                "Therefore, we go into the details of the model.",
                "Much like model-based feedback, relevance models estimate an improved query model.",
                "The only difference between the two approaches is that relevance models do not explicitly model the relevant or pseudo-relevant documents.",
                "Instead, they model a more generalized notion of relevance, as we now show.",
                "Given a query Q, a relevance model is a multinomial distribution, P(·|Q), that encodes the likelihood of each term given the query as evidence.",
                "It is computed as: P(w|Q) = D P(w|D)P(D|Q) ≈ D∈RQ P(w|D)P(Q|D)P(D) w D∈RQ P(w|D)P(Q|D)P(D) (1) where RQ is the set of documents that are relevant or pseudorelevant to query Q.",
                "In the pseudo-relevant case, these are the top ranked documents for query Q.",
                "Furthermore, it is assumed that P(D) is uniform over this set.",
                "These mild assumptions make computing the Bayesian posterior more practical.",
                "After the model is estimated, documents are ranked by clipping the relevance model by choosing the k most likely terms from P(·|Q).",
                "This clipped distribution is then interpolated with with the original, maximum likelihood query model [1].",
                "This can be thought of as expanding the original query by k weighted terms.",
                "Throughout the remainder of this work, we refer to this instantiation of relevance models as RM3.",
                "There has been relatively little work done in the area of query expansion in the context of dependence models [9].",
                "However, there have been several attempts to expand using multi-term concepts.",
                "Xu and Crofts local context analysis (LCA) method combined passage-level retrieval with concept expansion, where concepts were single terms and phrases [28].",
                "Expansion concepts were chosen and weighted using a metric based on co-occurrence statistics.",
                "However, it is not clear based on the analysis done how much the phrases helped over the single terms alone.",
                "Papka and Allan investigate using relevance feedback to perform multi-term concept expansion for document routing [19].",
                "The concepts used in their work are more general than those used in LCA, and include InQuery query language structures, such as #UW50(white house), which corresponds to the concept the terms white and house occur, in any order, within 50 terms of each other.",
                "Results showed that combining single term and large window multi-term concepts significantly improved effectiveness.",
                "However, it is unclear whether the same approach is also effective for ad hoc retrieval, due to the differences in the tasks. 3.",
                "MODEL This section details our proposed latent concept expansion technique.",
                "As mentioned previously, the technique is an extension of the MRF model for information retrieval [14].",
                "Therefore, we begin by providing an overview of the MRF model and our proposed extensions. 3.1 MRFs for IR 3.1.1 Basics Markov random fields, which are undirected graphical models, provide a compact, robust way of modeling a joint distribution.",
                "Here, we are interested in modeling the joint distribution over a query Q = q1, . . . , qn and a document D. It is assumed the underlying distribution over pairs of documents and queries is a relevance distribution.",
                "That is, sampling from the distribution gives pairs of documents and queries, such that the document is relevant to the query.",
                "A MRF is defined by a graph G and a set of non-negative potential functions over the cliques in G. The nodes in the graph represent the random variables and the edges define the independence semantics of the distribution.",
                "A MRF satisfies the Markov property, which states that a node is independent of all of its non-neighboring nodes given observed values for its neighbors.",
                "Given a graph G, a set of potentials ψi, and a parameter vector Λ, the joint distribution over Q and D is given by: PG,Λ(Q, D) = 1 ZΛ c∈C(G) ψ(c; Λ) where Z is a normalizing constant.",
                "We follow common convention and parameterize the potentials as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valued feature function. 3.1.2 Constructing G Given a query Q, the graph G can be constructed in a number of ways.",
                "However, following previous work, we consider three simple variants [14].",
                "These variants are full independence, where each query term is independent of each other given a document, sequential dependence, which assumes a dependence exists between adjacent query terms, and full dependence, which makes no independence assumptions. 3.1.3 Parameterization MRFs are commonly parameterized based on the maximal cliques of G. However, such a parameterization is too coarse for our needs.",
                "We need a parameterization that allows us to associate feature functions with cliques on a more fine grained level, while keeping the number of features, and thus the number of parameters, reasonable.",
                "Therefore, we allow cliques to share feature functions and parameters based on clique sets.",
                "That is, all of the cliques within a clique set are associated with the same feature function and share a single parameter.",
                "This effectively ties together the parameters of the features associated with each set, which significantly reduces the number of parameters while still providing a mechanism for fine-tuning on the level of clique sets.",
                "We propose seven clique sets for use with information retrieval.",
                "The first three clique sets consist of cliques that contain one or more query terms and the document node.",
                "Features over these cliques should encode how well the terms in the clique configuration describe the document.",
                "These sets are: • TD - set of cliques containing the document node and exactly one query term. • OD - set of cliques containing the document node and two or more query terms that appear in sequential order within the query. • UD - set of cliques containing the document node and two or more query terms that appear in any order within the query.",
                "Note that UD is a superset of OD.",
                "By tying the parameters among the cliques within each set we can control how much influence each type gets.",
                "This also avoids the problem of trying to determine how to estimate weights for each clique within the sets.",
                "Instead, we now must only estimate a single parameter per set.",
                "Next, we consider cliques that only contain query term nodes.",
                "These cliques, which were not considered in [14], are defined in an analogous way to those just defined, except the the cliques are only made up of query term nodes and do not contain the document node.",
                "Feature functions over these cliques should capture how compatible query terms are to one another.",
                "These clique features may take on the form of language models that impose well-formedness of the terms.",
                "Therefore, we define following query-dependent clique sets: • TQ - set of cliques containing exactly one query term. • OQ - set of cliques containing two or more query terms that appear in sequential order within the query. • UQ - set of cliques containing two or more query terms that appear in any order within the query.",
                "Finally, there is the clique that only contains the document node.",
                "Features over this node can be used as a type of document prior, encoding document-centric properties.",
                "This trivial clique set is then: • D - clique set containing only the singleton node D We note that our clique sets form a set cover over the cliques of G, but are not a partition, since some cliques appear in multiple clique sets.",
                "After tying the parameters in our clique sets together and using the exponential potential function form, we end up with the following simplified form of the joint distribution: log PG,Λ(Q, D) = λTD c∈TD fTD (c) + λOD c∈OD fOD (c) + λUD c∈UD fUD (c) FDQ(D,Q) - document and query dependent + λTQ c∈TQ fTQ (c) + λOQ c∈OQ fOQ (c) + λUQ c∈UQ fUQ (c) FQ(Q) - query dependent + λDfD(D) FD(D) - document dependent − log ZΛ document + query independent where FDQ, FQ, and FD are convenience functions defined by the document and query dependent, query dependent, and document dependent components of the joint distribution, respectively.",
                "These will be used to simplify and clarify expressions derived throughout the remainder of the paper. 3.1.4 Features Any arbitrary feature function over clique configurations can be used in the model.",
                "The correct choice of features depends largely on the retrieval task and the evaluation metric.",
                "Therefore, there is likely not to be a single, universally applicable set of features.",
                "To provide an idea of the range of features that can be used, we now briefly describe possible types of features that could be used.",
                "Possible query term dependent features include tf, idf, named entities, term proximity, and text style to name a few.",
                "Many types of document dependent features can be used, as well, including document length, PageRank, readability, and genre, among others.",
                "Since it is not our goal here to find optimal features, we use a simple, fixed set of features that have been shown to be effective in previous work [14].",
                "See Table 1 for a list of features used.",
                "These features attempt to capture term occurrence and term proximity.",
                "Better feature selection in the future will likely lead to improved effectiveness. 3.1.5 Ranking Given a query Q, we wish to rank documents in descending order according to PG,Λ(D|Q).",
                "After dropping document independent expressions from log PG,Λ(Q, D), we derive the following ranking function: PG,Λ(D|Q) rank = FDQ(D, Q) + FD(D) (2) which is a simple weighted linear combination of feature functions that can be computed efficiently for reasonable graphs. 3.1.6 Parameter Estimation Now that the model has been fully specified, the final step is to estimate the model parameters.",
                "Although MRFs are generative models, it is inappropriate to train them using Feature Value fTD (qi, D) log (1 − α) tfqi,D |D| + α cfqi |C| fOD (qi, qi+1 . . . , qi+k, D) log (1 − β) tf#1(qi...qi+k),D |D| + β cf#1(qi...qi+k) |C| fUD (qi, ..., qj, D) log (1 − β) tf#uw(qi...qj ),D |D| + β cf#uw(qi...qj ) |C| fTQ (qi) − log cfqi |C| fOQ (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |C| fUQ (qi, ..., qj) − log cf#uw(qi...qj ) |C| fD 0 Table 1: Feature functions used in <br>markov random field</br> model.",
                "Here, tfw,D is the number of times term w occurs in document D, tf#1(qi...qi+k),D denotes the number of times the exact phrase qi . . . qi+k occurs in document D, tf#uw(qi...qj ),D is the number of times the terms qi, . . . qj appear ordered or unordered within a window of N terms, and |D| is the length of document D. The cf and |C| values are analogously defined on the collection level.",
                "Finally, α and β are model hyperparameters that control smoothing for single term and phrase features, respectively. conventional likelihood-based approaches because of metric divergence [17].",
                "That is, the maximum likelihood estimate is unlikely to be the estimate that maximizes our evaluation metric.",
                "For this reason, we discriminatively train our model to directly maximize the evaluation metric under consideration [14, 15, 25].",
                "Since our parameter space is small, we make use of a simple hill climbing strategy, although other more sophisticated approaches are possible [10]. 3.2 Latent Concept Expansion In this section we describe how this extended MRF model can be used in a novel way to generate single and multiterm concepts that are topically related to some original query.",
                "As we will show, the concepts generated using our technique can be used for query expansion or other tasks, such as suggesting alternative query formulations.",
                "We assume that when a user formulates their original query, they have some set of concepts in mind, but are only able to express a small number of them in the form of a query.",
                "We treat the concepts that the user has in mind, but did not explicitly express in the query, as latent concepts.",
                "These latent concepts can consist of a single term, multiple terms, or some combination of the two.",
                "It is, therefore, our goal to recover these latent concepts given some original query.",
                "This can be accomplished within our framework by first expanding the original graph G to include the type of concept we are interested in generating.",
                "We call this expanded graph H. In Figure 1, the middle graph provides an example of how to construct an expanded graph that can generate single term concepts.",
                "Similarly, the graph on the right illustrates an expanded graph that generates two term concepts.",
                "Although these two examples make use of the sequential dependence assumption (i.e. dependencies between adjacent query terms), it is important to note that both the original query and the expansion concepts can use any independence structure.",
                "After H is constructed, we compute PH,Λ(E|Q), a probability distribution over latent concepts, according to: PH,Λ(E|Q) = D∈R PH,Λ(Q, E, D) D∈R E PH,Λ(Q, E, D) where R is the universe of all possible documents and E is some latent concept that may consist of one or more terms.",
                "Since it is not practical to compute this summation, we must approximate it.",
                "We notice that PH,Λ(Q, E, D) is likely to be peaked around those documents D that are highly ranked according to query Q.",
                "Therefore, we approximate PH,Λ(E|Q) by only summing over a small subset of relevant or pseudo-relevant documents for query Q.",
                "This is computed as follows: PH,Λ(E|Q) ≈ D∈RQ PH,Λ(Q, E, D) D∈RQ E PH,Λ(Q, E, D) (3) ∝ D∈RQ exp FQD(Q, D) + FD(D) + FQD(E, D) + FQ(E) where RQ is a set of relevant or pseudo-relevant documents for query Q and all clique sets are constructed using H. As we see, the likelihood contribution for each document in RQ is a combination of the original querys score for the document (see Equation 2), concept Es score for the document, and Es document-independent score.",
                "Therefore, this equation can be interpreted as measuring how well Q and E account for the top ranked documents and the goodness of E, independent of the documents.",
                "For maximum robustness, we use a different set of parameters for FQD(Q, D) and FQD(E, D), which allows us to weight the term, ordered, and unordered window features differently for the original query and the candidate expansion concept. 3.2.1 Query Expansion To use this framework for query expansion, we first choose an expansion graph H that encodes the latent concept structure we are interested in expanding the query using.",
                "We then select the k latent concepts with the highest likelihood given by Equation 3.",
                "A new graph G is constructed by augmenting the original graph G with the k expansion concepts E1, . . . , Ek.",
                "Finally, documents are ranked according to PG ,Λ(D|Q, E1, . . . , Ek) using Equation 2. 3.2.2 Comparison to Relevance Models Inspecting Equations 1 and 3 reveals the close connection that exists between LCE and relevance models.",
                "Both Figure 1: Graphical model representations of relevance modeling (left), latent concept expansion using single term concepts (middle), and latent concept expansion using two term concepts (right) for a three term query. models essentially compute the likelihood of a term (or concept) in the same manner.",
                "It is easy to see that just as the MRF model can be viewed as a generalization of language modeling, so too can LCE be viewed as a generalization of relevance models.",
                "There are important differences between MRFs/LCE and unigram language models/relevance models.",
                "See Figure 1 for graphical model representations of both models.",
                "Unigram language models and relevance models are based on the multinomial distribution.",
                "This distributional assumption locks the model into the bag of words representation and the implicit use of term occurrence features.",
                "However, the distribution underlying the MRF model allows us to move beyond both of these assumptions, by modeling both dependencies between query terms and allowing arbitrary features to be explicitly used.",
                "Moving beyond the simplistic bag of words assumption in this way results in a general, robust model and, as we show in the next section, translates into significant improvements in retrieval effectiveness. 4.",
                "EXPERIMENTAL RESULTS In order to better understand the strengths and weaknesses of our technique, we evaluate it on a wide range of data sets.",
                "Table 2 provides a summary of the TREC data sets considered.",
                "The WSJ, AP, and ROBUST collections are smaller and consist entirely of newswire articles, whereas WT10g and GOV2 are large web collections.",
                "For each data set, we split the available topics into a training and test set, where the training set is used solely for parameter estimation and the test set is used for evaluation purposes.",
                "All experiments were carried out using a modified version of Indri, which is part of the Lemur Toolkit [18, 23].",
                "All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer.",
                "In all cases, only the title portion of the TREC topics are used to construct queries.",
                "We construct G using the sequential dependence assumption for all data sets [14]. 4.1 ad-hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo-relevance feedback setting.",
                "We compare unigram language modeling (with Dirichlet smoothing), the MRF model (without expansion), relevance models, and LCE to better understand how each model performs across the various data sets.",
                "For the unigram language model, the smoothing parameter was trained.",
                "For the MRF model, we train the model parameters (i.e.",
                "Λ) and model hyperparameters (i.e. α, β).",
                "For RM3 and LCE, we also train the number of pseudoName Description # Docs Train Topics Test Topics WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc.",
                "Press 88-90 242,918 51-150 151-200 ROBUST Robust 2004 data 528,155 301-450 601-700 WT10g TREC Web collection 1,692,096 451-500 501-550 GOV2 2004 crawl of .gov domain 25,205,179 701-750 751-800 Table 2: Overview of TREC collections and topics. relevant feedback documents used and the number of expansion terms. 4.1.1 Expansion with Single Term Concepts We begin by evaluating how well our model performs when expanding using only single terms.",
                "Before we describe and analyze the results, we explicitly state how expansion term likelihoods are computed under this setup (i.e. using the sequential dependence assumption, expanding with single term concepts, and using our feature set).",
                "The expansion term likelihoods are computed as follows: PH,Λ(e|Q) ∝ D∈RQ exp λTD w∈Q log (1 − α) tfw,D |D| + α cfw |C| + λOD b∈Q log (1 − β) tf#1(b),D |D| + β cf#1(b) |C| + λUD b∈Q log (1 − β) tf#uw(b),D |D| + β cf#uw(b) |C| + log (1 − α) tfe,D |D| + α cfe |C| λTD cfe |C| λTQ (4) where b ∈ Q denotes the set of bigrams in Q.",
                "This equation clearly shows how LCE differs from relevance models.",
                "When we set λTD = λT,D = 1 and all other parameters to 0, we obtain the exact formula that is used to compute term likelihoods in the relevance modeling framework.",
                "Therefore, LCE adds two very important factors to the equation.",
                "First, it adds the ordered and unordered window features that are applied to the original query.",
                "Second, it applies an intuitive tf.idf-like form to the candidate expansion term w. The idf factor, which is not present in relevance models, plays an important role in expansion term selection. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520 AP <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 05101520253035 ROBUST <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% RM3 LCE 0510152025 WT10G Figure 2: Histograms that demonstrate and compare the robustness of relevance models (RM3) and latent concept expansion (LCE) with respect to the query likelihood model (QL) for the AP, ROBUST, and WT10G data sets.",
                "The results, evaluated using mean average precision, are given in Table 3.",
                "As we see, the MRF model, relevance models, and LCE always significantly outperform the unigram language model.",
                "In addition, LCE shows significant improvements over relevance models across all data sets.",
                "The relative improvements over relevance models is 6.9% for AP, 12.9% for WSJ, 6.5% for ROBUST, 16.7% for WT10G, and 7.3% for GOV2.",
                "Furthermore, LCE shows small, but not significant, improvements over relevance modeling for metrics such as precision at 5, 10, and 20.",
                "However, both relevance modeling and LCE show statistically significant improvements in such metrics over the unigram language model.",
                "Another interesting result is that the MRF model is statistically equivalent to relevance models on the two web data sets.",
                "In fact, the MRF model outperforms relevance models on the WT10g data set.",
                "This reiterates the importance of non-unigram, proximity-based features for content-based web search observed previously [14, 16].",
                "Although our model has more free parameters than relevance models, there is surprisingly little overfitting.",
                "Instead, the model exhibits good generalization properties. 4.1.2 Expansion with Multi-Term Concepts We also investigated expanding using both single and two word concepts.",
                "For each query, we expanded using a set of single term concepts and a set of two term concepts.",
                "The sets were chosen independently.",
                "Unfortunately, only negligible increases in mean average precision were observed.",
                "This result may be due to the fact that strong correlations exist between the single term expansion concepts.",
                "We found that the two word concepts chosen often consisted of two highly correlated terms that are also chosen as single term concepts.",
                "For example, the two term concept stock market was chosen while the single term concepts stock and market were also chosen.",
                "Therefore, many two word concepts are unlikely to increase the discriminative power of the expanded query.",
                "This result suggests that concepts should be chosen according to some criteria that also takes novelty, diversity, or term correlations into account.",
                "Another potential issue is the feature set used.",
                "Other feature sets may ultimately yield different results, especially if they reduce the correlation among the expansion concepts.",
                "Therefore, our experiments yield no conclusive results with regard to expansion using multi-term concepts.",
                "Instead, the results introduce interesting open questions and directions for future exploration.",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ ROBUST .2920 .3096α .3382αβ .3601αβγ WT10g .1861 .2053α .1944α .2269αβγ GOV2 .3234 .3520α .3656α .3924αβγ Table 3: Test set mean average precision for language modeling (LM), <br>markov random field</br> (MRF), relevance models (RM3), and latent concept expansion (LCE).",
                "The superscripts α, β, and γ indicate statistically significant improvements (p < 0.05) over LM, MRF, and RM3, respectively. 4.2 Robustness As we have shown, relevance models and latent concept expansion can significantly improve retrieval effectiveness over the baseline query likelihood model.",
                "In this section we analyze the robustness of these two methods.",
                "Here, we define robustness as the number queries whose effectiveness are improved/hurt (and by how much) as the result of applying these methods.",
                "A highly robust expansion technique will significantly improve many queries and only minimally hurt a few.",
                "Figure 2 provides an analysis of the robustness of relevance modeling and latent concept expansion for the AP, ROBUST, and WT10G data sets.",
                "The analysis for the two data sets not shown is similar.",
                "The histograms provide, for various ranges of relative decreases/increases in mean average precision, the number of queries that were hurt/improved with respect to the query likelihood baseline.",
                "As the results show, LCE exhibits strong robustness for each data set.",
                "For AP, relevance models improve 38 queries and hurt 11, whereas LCE improves 35 and hurts 14.",
                "Although relevance models improve the effectiveness of 3 more queries than LCE, the relative improvement exhibited by LCE is significantly larger.",
                "For the ROBUST data set, relevance models improve 67 queries and hurt 32, and LCE improves 77 and hurts 22.",
                "Finally, for the WT10G collection, relevance models improve 32 queries and hurt 16, and LCE improves 35 and hurts 14.",
                "As with AP, the amount of improvement exhibited by the LCE versus relevance models is significantly larger for both the ROBUST and WT10G data sets.",
                "In addition, when LCE does hurt performance, it is less likely to hurt as much as relevance modeling, which is a desirable property. 1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescope mirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table 4: Fifteen most likely one, two, and three word concepts constructed using the top 25 documents retrieved for the query hubble telescope achievements on the ROBUST collection.",
                "Overall, LCE improves effectiveness for 65%-80% of queries, depending on the data set.",
                "When used in combination with a highly accurate query performance prediction system, it may be possible to selectively expand queries and minimize the loss associated with sub-baseline performance. 4.3 Multi-Term Concept Generation Although we found that expansion using multi-term concepts failed to produce conclusive improvements in effectiveness, there are other potential tasks that these concepts may be useful for, such as query suggestion/reformulation, summarization, and concept mining.",
                "For example, for a query suggestion task, the original query could be used to generate a set of latent concepts which correspond to alternative query formulations.",
                "Although evaluating our model on these tasks is beyond the scope of this work, we wish to show an illustrative example of the types of concepts generated using our model.",
                "In Table 4, we present the most likely one, two, and three term concepts generated using LCE for the query hubble telescope achievements using the top 25 ranked documents from the ROBUST collection.",
                "It is well known that generating multi-term concepts using a unigram-based model produces unsatisfactory results, since it fails to consider term dependencies.",
                "This is not the case when generating multi-term concepts using our model.",
                "Instead, a majority of the concepts generated are well-formed and meaningful.",
                "There are several cases where the concepts are less coherent, such as mirror mirror mirror.",
                "In this case, the likelihood of the term mirror appearing in a pseudo-relevant document outweighs the language modeling features (e.g. fOQ ), which causes this non-coherent concept to have a high likelihood.",
                "Such examples are in the minority, however.",
                "Not only are the concepts generated well-formed and meaningful, but they are also topically relevant to the original query.",
                "As we see, all of the concepts generated are on topic and in some way related to the Hubble telescope.",
                "It is interesting to see that the concept hubble telescope flaw is one of the most likely three term concepts, given that it is somewhat contradictory to the original query.",
                "Despite this contradiction, documents that discuss the telescope flaws are also likely to describe the successes, as well, and therefore this is likely to be a meaningful concept.",
                "One important thing to note is that the concepts LCE generates are of a different nature than those that would be generated using a bigram relevance model.",
                "For example, a bigram model would be unlikely to generate the concept telescope space NASA, since none of the bigrams that make up the concept have high likelihood.",
                "However, since our model is based on a number of different features over various types of cliques, it is more general and robust than a bigram model.",
                "Although we only provided the concepts generated for a single query, we note that the same analysis and conclusions generalize across other data sets, with coherent, topically related concepts being consistently generated using LCE. 4.4 Discussion Our latent concept expansion technique captures two semiorthogonal types of dependence.",
                "In information retrieval, there has been a long-term interest in understanding the role of term dependence.",
                "Out of this research, two broad types of dependencies have been identified.",
                "The first type of dependence is syntactic dependence.",
                "This type of dependence covers phrases, term proximity, and term co-occurrence [2, 4, 5, 7, 26].",
                "These methods capture the fact that queries implicitly or explicitly impose a certain set of positional dependencies.",
                "The second type is semantic dependence.",
                "Examples of semantic dependence are relevance feedback, pseudo-relevance feedback, synonyms, and to some extent stemming [3].",
                "These techniques have been explored on both the query and document side.",
                "On the query side, this is typically done using some form of query expansion, such as relevance models or LCE.",
                "On the document side, this is done as document expansion or document smoothing [11, 13, 24].",
                "Although there may be some overlap between syntactic and semantic dependencies, they are mostly orthogonal.",
                "Our model uses both types of dependencies.",
                "The use of phrase and proximity features within the model captures syntactic dependencies, whereas LCE captures query-side semantic dependence.",
                "This explains why the initial improvement in effectiveness achieved by using the MRF model is not lost after query expansion.",
                "If the same types of dependencies were capture by both syntactic and semantic dependencies, LCE would be expected to perform about equally as well as relevance models.",
                "Therefore, by modeling both types of dependencies we see an additive effect, rather than an absorbing effect.",
                "An interesting area of future work is to determine whether or not modeling document-side semantic dependencies can add anything to the model.",
                "Previous results that have combined query- and document-side semantic dependencies have shown mixed results [13, 27]. 5.",
                "CONCLUSIONS In this paper we proposed a robust query expansion technique called latent concept expansion.",
                "The technique was shown to be a natural extension of the <br>markov random field</br> model for information retrieval and a generalization of relevance models.",
                "LCE is novel in that it performs single or multi-term expansion within a framework that allows the modeling of term dependencies and the use of arbitrary features, whereas previous work has been based on the bag of words assumption and term occurrence features.",
                "We showed that the technique can be used to produce high quality, well formed, topically relevant multi-term expansion concepts.",
                "The concepts generated can be used in an alternative query suggestion module.",
                "We also showed that the model is highly effective.",
                "In fact, it achieves significant improvements in mean average precision over relevance models across a selection of TREC data sets.",
                "It was also shown the MRF model itself, without any query expansion, outperforms relevance models on large web data sets.",
                "This reconfirms previous observations that modeling dependencies via the use of proximity features within the MRF has more of an impact on larger, noisier collections than smaller, well-behaved ones.",
                "Finally, we reiterated the importance of choosing expansion terms that model relevance, rather than the relevant documents and showed how LCE captures both syntactic and query-side semantic dependencies.",
                "Future work will look at incorporating document-side dependencies, as well.",
                "Acknowledgments This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF grant #CNS-0454018, in part by ARDA and NSF grant #CCF-0205575, and in part by Microsoft Live Labs.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the sponsor. 6.",
                "REFERENCES [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Diaz, L. Larkey, X. Li, M. D. Smucker, and C. Wade.",
                "UMass at TREC 2004: Novelty and HARD.",
                "In Online proceedings of the 2004 Text Retrieval Conf., 2004. [2] C. L. A. Clarke and G. V. Cormack.",
                "Shortest-substring retrieval and ranking.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):44-78, 2000. [3] K. Collins-Thompson and J. Callan.",
                "Query expansion using random walk models.",
                "In Proc. 14th Intl.",
                "Conf. on Information and Knowledge Management, pages 704-711, 2005. [4] W. B. Croft.",
                "Boolean queries and term dependencies in probabilistic retrieval models.",
                "Journal of the American Society for Information Science, 37(4):71-77, 1986. [5] W. B. Croft, H. Turtle, and D. Lewis.",
                "The use of phrases and structured queries in information retrieval.",
                "In Proc. 14th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 32-45, 1991. [6] K. Eguchi.",
                "NTCIR-5 query expansion experiments using term dependence models.",
                "In Proc. of the Fifth NTCIR Workshop Meeting on Evaluation of Information Access Technologies, pages 494-501, 2005. [7] J. Fagan.",
                "Automatic phrase indexing for document retrieval: An examination of syntactic and non-syntactic methods.",
                "In Proc. tenth Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 91-101, 1987. [8] J. Gao, J. Nie, G. Wu, and G. Cao.",
                "Dependence language model for information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 170-177, 2004. [9] D. Harper and C. J. van Rijsbergen.",
                "An evaluation of feedback in document retrieval using co-occurrence data.",
                "Journal of Documentation, 34(3):189-216, 1978. [10] T. Joachims.",
                "A support vector method for multivariate performance measures.",
                "In Proc. of the International Conf. on Machine Learning, pages 377-384, 2005. [11] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 194-201, 2004. [12] V. Lavrenko and W. B. Croft.",
                "Relevance-based language models.",
                "In Proc. 24th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 120-127, 2001. [13] X. Liu and W. B. Croft.",
                "Cluster-based retrieval using language models.",
                "In Proc. 27th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 186-193, 2004. [14] D. Metzler and W. B. Croft.",
                "A <br>markov random field</br> model for term dependencies.",
                "In Proc. 28th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 472-479, 2005. [15] D. Metzler and W. B. Croft.",
                "Linear feature based models for information retrieval.",
                "Information Retrieval, to appear, 2006. [16] D. Metzler, T. Strohman, Y. Zhou, and W. B. Croft.",
                "Indri at terabyte track 2005.",
                "In Online proceedings of the 2005 Text Retrieval Conf., 2005. [17] W. Morgan, W. Greiff, and J. Henderson.",
                "Direct maximization of average precision by hill-climbing with a comparison to a maximum entropy approach.",
                "Technical report, MITRE, 2004. [18] P. Ogilvie and J. P. Callan.",
                "Experiments using the lemur toolkit.",
                "In Proc. of the Text REtrieval Conf., 2001. [19] R. Papka and J. Allan.",
                "Why bigger windows are better than smaller ones.",
                "Technical report, University of Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford.",
                "Okapi at trec-3.",
                "In Online proceedings of the Third Text Retrieval Conf., pages 109-126, 1995. [21] J. J. Rocchio.",
                "Relevance Feedback in Information Retrieval, pages 313-323.",
                "Prentice-Hall, 1971. [22] F. Song and W. B. Croft.",
                "A general language model for information retrieval.",
                "In Proc. eighth international conference on Information and knowledge management (CIKM 99), pages 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft.",
                "Indri: A language model-based serach engine for complex queries.",
                "In Proc. of the International Conf. on Intelligence Analysis, 2004. [24] T. Tao, X. Wang, Q. Mei, and C. Zhai.",
                "Language model information retrieval with document expansion.",
                "In Proc. of HLT/NAACL, pages 407-414, 2006. [25] B. Taskar, C. Guestrin, and D. Koller.",
                "Max-margin markov networks.",
                "In Proc. of Advances in Neural Information Processing Systems (NIPS 2003), 2003. [26] C. J. van Rijsbergen.",
                "A theoretical basis for the use of cooccurrence data in information retrieval.",
                "Journal of Documentation, 33(2):106-119, 1977. [27] X. Wei and W. B. Croft.",
                "LDA-based document models for ad-hoc retrieval.",
                "In Proc. 29th Ann.",
                "Intl.",
                "ACM SIGIR Conf. on Research and Development in Information Retrieval, pages 178-185, 2006. [28] J. Xu and W. B. Croft.",
                "Improving the effectiveness of information retrieval with local context analysis.",
                "ACM Trans.",
                "Inf.",
                "Syst., 18(1):79-112, 2000. [29] C. Zhai and J. Lafferty.",
                "Model-based feedback in the language modeling approach to information retrieval.",
                "In Proc. 10th Intl.",
                "Conf. on Information and Knowledge Management, pages 403-410, 2001."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En este artículo, proponemos una técnica de expansión de consulta robusta basada en el modelo \"Campo aleatorio de Markov\" para la recuperación de información.Campo aleatorio de Markov",
                "Recientemente, se propuso un modelo de \"campo aleatorio de Markov\" (MRF) para la recuperación de información que va más allá de la bolsa simplista de palabras que subyace en BM25 y el enfoque de modelado de idiomas (unigram) para la recuperación de información [20, 22].Campo aleatorio de Markov",
                "Aunque los MRF son modelos generativos, es inapropiado entrenarlos utilizando el valor de características FTD (Qi, D) log (1 - α) TFQI, D | D |+ α cfqi | c |FOD (Qi, Qi+1 ..., Qi+K, D) log (1 - β) TF#1 (Qi ... Qi+K), D | D |+ β cf#1 (qi ... qi+ k) | c |FUD (Qi, ..., QJ, D) log (1 - β) tf#uw (qi ... qj), d | d |+ β cf#uw (qi ... qj) | c |ftq (qi) - log cfqi | c |foq (qi, qi+1 ..., qi+k) - log cf#1 (qi ... qi+k) | c |fuq (qi, ..., qj) - log cf#uw (qi ... qj) | c |FD 0 Tabla 1: Funciones de características utilizadas en el modelo \"Campo aleatorio de Markov\".Campo aleatorio de Markov",
                "LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ robusto .2920 .3096α .3382αβ .3601αβγ γ WT10G .1861 .205533334x. .3520α .3656α .3924αβγ tabla3: Prueba de prueba Precisión promedio media para el modelado de lenguaje (LM), \"Campo aleatorio de Markov\" (MRF), modelos de relevancia (RM3) y expansión de concepto latente (LCE).Campo aleatorio de Markov",
                "Se demostró que la técnica es una extensión natural del modelo de \"campo aleatorio de Markov\" para la recuperación de la información y una generalización de los modelos de relevancia.Campo aleatorio de Markov",
                "Un modelo de \"campo aleatorio de Markov\" para dependencias de términos.Campo aleatorio de Markov"
            ],
            "translated_text": "",
            "candidates": [],
            "error": []
        }
    }
}