{
    "id": "I-56",
    "original_text": "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation. The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment. By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies. A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP. To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed. Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles. Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1. INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment. Important application examples include distributed resource allocation [1] and distributed scheduling [2]. Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications. Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents. While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed. As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible. In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9]. Negotiation is viewed as a process of several agents searching for a solution called an agreement. The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step. Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies. The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP. To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed. Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6]. The rest of this paper is organized as follows. In Section 2, we provide a formal overview of DCSP. Section 3 presents a BDI negotiation model by which a DCSP agent reasons. Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol. A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones. Section 6 concludes the paper and points to some future work. 2. DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively. We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!. The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied. In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl. The DCSP may be formally stated as follows. Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied. A constraint may consist of different variables belonging to different agents. An agent cannot change or modify the assignment values of other agents variables. Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations. If the agents succeed in their resolution, a solution is found. In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list. Each variable assumes a range of values called a domain. A domain value, which usually abstracts an action, is a possible option that an agent may take. Each agent has an assigned priority. These priority values help decide the order in which they revise or modify their variable assignments. An agents priority may be fixed (static) or changing (dynamic) when searching for a solution. If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first. An agent which shares the same constraint with another agent is called the latters neighbor. Each agent needs to refer to its list of neighbors during the search process. This list may also be kept unchanged or updated accordingly in runtime. Similarly, each agent maintains a constraint list. The agent needs to ensure that there is no violation of the constraints in this list. Constraints can be added or removed from an agents constraint list in runtime. As with an agent, a constraint can also be associated with a priority value. Constraints with a high priority are said to be more important than constraints with a lower priority. To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3. THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11]. According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals. Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints. In automated negotiation [9], such a solution is called an agreement among the agents. Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI. Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol. The solid line indicates the common component or transition which always exists regardless of the strategy used. The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy. Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message. An info message perceived is a message sent by another agent. The message will contain the current selected values and priorities of the variables of that sending agent. The main purpose of this message is to update the agent about the current environment. Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round. A negotiation message is a message which may be sent within a round. This message is for mediation purposes. The agent may put different contents into this type of message as long as it is agreed among the group. The format of the negotiation message and when it is to be sent out are subject to the strategy. A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step. Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous. In synchronous mechanism, mediation is required in every negotiation round. In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message. A more in-depth view of this mediation step is provided later in this section. The BDI protocol prescribes the skeletal structure for DCSP negotiation. We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model. The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent. For a conceptually clearer description, we assume that there is only one variable per agent. • Percept. In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list. The image P will drive the agents actions in subsequent steps. The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief. Using the image P and constraint list C, the agent will check if there is any violated constraint. If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action. The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints. When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found. In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy. If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option. However it does not always happen that an agent can successfully find such an option. If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments. To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied. Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire. If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set. If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments. How this sublist is created depends on the strategy devised for the agent. In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy. If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention. The agent will select a value from its desire set as its intention. An intention is the best desired option that the agent assigns to its variable. The criteria for selecting a desire as the agents intention depend on the strategy used. Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation. Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation. This is an important function of the agent. Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved. Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3). Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them. There are two types of mediation: local mediation and group mediation. In the former, the agents exchange their intentions. When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention. In the latter, there is an agent which acts as a group mediator. This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed. The result of this mediation is passed back to the agents in the group. Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution. This is the last step of a negotiation round. The agent will execute by updating its variable assignment if the intention obtained at this step is its own. Following execution, the agent will inform its neighbors about its new variable assignment and updated priority. To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process. Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs. The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property. In other words, these dimensions provide technical considerations for a strategy design. 4. DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO. All these algorithms assume that there is only one variable per agent. Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively. To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy. As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message. For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows. Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi). Update Ci to be the list of 526 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent. Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list. Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list. Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅. Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof). Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round. The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi. Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists. The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi. The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent. Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy. The model is similar to that of incorporating the ABT strategy (see Figure 2). This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps. The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi). For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows. Step 1 - Percept: This step is identical to the Percept step of ABT. Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list. Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅. Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}. Step 4 - Intention: This step is similar to the Intention step of ABT. However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki. This list of assignment is considered as a nogood. If the same negotiation message had been sent out before, agent i will have nil intention. Otherwise, the agent will send the message and save the nogood in the nogood list. Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi. Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy. Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints. The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum. For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows. Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi). Update Ci to be the list of its relevant constraints. Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0. Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅. Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention. Following, agent i will send its intention to all its neighbors. In return, it will receive intentions from these agents before proceeding to Mediation step. Mediation: Agent i receives all the intentions from its neighbors. If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention. Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value. Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5. THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy. Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step. The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors. In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention. For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows. Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi). Update Ci to be the list of constraints relevant to agent i. Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0. Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list. In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations. It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list. In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅. Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors. This message is called a voluntary advice. If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i. Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step. Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention. This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention. This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention. Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors. If agent i has a reluctant intention, it will also send this intention to all its neighbors. In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention. In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step. Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step. Otherwise, agent i will select the best intention among all the intentions received, including its own (if any). The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected. If the selected intention is not agent is intention, it will cancel its intention. Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value. Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state. Hence an observer is needed that will keep track of the negotiation messages communicated in the environment. Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6. In this example, each agent has a color variable representing a node. There are 10 color variables sharing the same domain {Black, White}. The following records the outcome of each step in every negotiation round executed. Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors. Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black). In this negotiation round, the improvements achieved by these agents are 1. Agents which do not have any improvements are agents 4, 5 and 8. Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied. Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10). These agents will send the voluntary advices to all their neighbors. Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8). Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it. Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively. Agents 3, 6 and 9 do not have any desire to update their color assignments. Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively. They form their voluntary intentions. Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention. Agents 3, 6 and 9 do not have any intention. Following, the intention from the agents will be sent to all their neighbors. Mediation: Agent 1 finds that the intention from agent 2 is better than its intention. This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any. Hence agent 1 cancels its intention. Agent 2 will keep its intention. Agents 7 and 10 keep their intentions since none of their neighbors has an intention. The rest of the agents do nothing in this step as they do not have any intention. Step 5 - Execution: Agent 2 changes its color to White. Agents 7 and 10 change their colors to Black. The new state after round 1 is shown in Figure 7. Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors. Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1. It believes it should change its The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black. Agent 2 does not have any positive improvement. The rest of the agents need not make any change as all their relevant constraints are satisfied. They will have no desire, and hence no intention. Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2. Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state. Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3. Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3. Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention. Step 5 - Execution: Agent 3 changes its color to Black. The new state after round 2 is shown in Figure 8. Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment. Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC. The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1. The network delay is neglected. • Each agent has it own clock. The initial clocks value is 0. Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value. Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs. For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems. The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then. In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}. Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4). For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high. This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9). The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve. In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type. The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem. UMA outperforms AWC in solving the critical problem as shown in Figure 11. It was observed that the latter strategy failed in some test cases. However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance. The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies. The worst case occurs when all the possible global states of the search are reached. Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced. As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices. Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update. Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6. CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture. Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol. Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies. Towards the latter, we have proposed and formulated a new strategy - the UMA strategy. Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects. It was observed from our simulations that UMA possesses the completeness property. Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5]. The idea of DCSP agents using different strategies in the same environment will also be investigated. 7. REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems. Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction. Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter. The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason. Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence. The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A. B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531",
    "original_translation": "Algoritmos de restricción distribuidos unificadoras en un marco de negociación de BDI Bao Chau le Dinh y Kiam Tian SEOW Escuela de Ingeniería Informática Nanyang Universidad Tecnológica República de Singapur {LEDI0002, AsktSeow}@ntu.edu.sg Resumen Este documento presenta una novela, un marco de satisfacción distribuida de distribución unificada.Basado en la negociación automatizada. El problema de satisfacción de restricción distribuido (DCSP) es uno que implica varios agentes para buscar un acuerdo, que es una combinación consistente de acciones que satisface sus limitaciones mutuas en un entorno compartido. Al anclar la búsqueda de DCSP en la negociación automatizada, mostramos que varios algoritmos DCSP conocidos son en realidad mecanismos que pueden llegar a acuerdos a través de un protocolo común de intención de creencias (BDI), pero utilizando diferentes estrategias. Una motivación importante para este marco BDI es que no solo proporciona una comprensión conceptualmente más clara de los algoritmos DCSP existentes desde una perspectiva del modelo de agente, sino que también abre las oportunidades para extender y desarrollar nuevas estrategias para DCSP. Con este fin, se propone una nueva estrategia llamada asesoramiento mutuo no solicitado (UMA). La evaluación del rendimiento muestra que la estrategia UMA puede superar a algunos mecanismos existentes en términos de ciclos computacionales. Categorías y descriptores de sujetos I.2.11 [Inteligencia artificial distribuida]: Agentes inteligentes, Sistemas Multiagentes Algoritmos de términos generales, Diseño, Experimentación 1. La introducción en el núcleo de muchas aplicaciones distribuidas emergentes es el problema de satisfacción de restricciones distribuidas (DCSP), uno que implica encontrar una combinación consistente de acciones (abstraída como valores de dominio) para satisfacer las restricciones entre múltiples agentes en un entorno compartido. Los ejemplos de aplicaciones importantes incluyen asignación de recursos distribuidos [1] y programación distribuida [2]. Se han desarrollado muchos algoritmos importantes, como la ruptura distribuida (DBO) [3], el retroceso asíncrono (ABT) [4], la superposición parcial asincrónica (APO) [5] y el compromiso débil asincrónico (AWC) [4] [4], para abordarel DCSP y proporcionar la base de la solución del agente para sus aplicaciones. En términos generales, estos algoritmos se basan en dos enfoques diferentes, ya sea que se extienden desde los algoritmos de retroceso clásico [6] o introducen mediación entre los agentes. Si bien no ha habido falta de esfuerzos en este campo de investigación prometedor, especialmente en el tratamiento de problemas pendientes como restricciones de recursos (por ejemplo, límites en el tiempo y la comunicación) [7] y los requisitos de privacidad [8], desafortunadamente no hay un tratamiento conceptualmente claroPara abrir el funcionamiento teórico modelo de los diversos algoritmos de agentes que se han desarrollado. Como resultado, por ejemplo, una comprensión intelectual más profunda sobre por qué un algoritmo es mejor que el otro, más allá de los problemas computacionales, no es posible. En este documento, presentamos un marco de satisfacción de restricciones distribuidas unificadas novedosas basado en la negociación automatizada [9]. La negociación se considera un proceso de varios agentes que buscan una solución llamada acuerdo. La búsqueda se puede realizar a través de un mecanismo de negociación (o algoritmo) por el cual los agentes siguen un protocolo de alto nivel que prescribe las reglas de interacciones, utilizando un conjunto de estrategias ideadas para seleccionar sus propias preferencias en cada paso de negociación. Anclar la búsqueda DCSP en la negociación automatizada, mostramos en este documento que varios algoritmos DCSP bien conocidos [3] son en realidad mecanismos que comparten el mismo protocolo de interacción de la intención de creencias (BDI) para alcanzar acuerdos, pero usan diferentes estrategias de selección de acción o valor.. El marco propuesto proporciona no solo una comprensión más clara de los algoritmos DCSP existentes desde una perspectiva de agente BDI unificado, sino que también abre las oportunidades para extender y desarrollar nuevas estrategias para DCSP. Con este fin, se propone una nueva estrategia llamada asesoramiento mutuo no solicitado (UMA). Nuestra evaluación de rendimiento muestra que UMA puede superar a ABT y AWC en términos del número promedio de ciclos computacionales para los problemas de coloración escasos y críticos [6]. El resto de este documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una descripción formal de DCSP. La Sección 3 presenta un modelo de negociación BDI por el cual razona un agente DCSP. La Sección 4 presenta los algoritmos existentes ABT, AWC y DBO como diferentes estrategias formalizadas en un protocolo común. En la Sección 5 se propone una nueva estrategia llamada asesoramiento mutuo no solicitado;Nuestros resultados empíricos y discusión intentan resaltar los méritos de la nueva estrategia sobre las existentes. La Sección 6 concluye el documento y señala algún trabajo futuro.2. DCSP: Formalización del problema El DCSP [4] considera el siguiente entorno.• Hay N agentes con variables K x0, x1, · · ·, xk - 1, n ≤ k, que tienen valores en los dominios D1, D2, · · ·, DK, respectivamente. Definimos una función parcial B sobre el ProductRange {0, 1 ,..., (n - 1)} × {0, 1 ,..., (k −1)} tal que esa variable XJ pertenece al agente I es denotada por B (i, j)!. ¡La marca de exclamación!se define los medios.• Existen m restricciones C0, C1, · · · cm - 1 para satisfacer conjuntamente. De manera similar, como se define para B (I, J), usamos E (L, J)!, (0 ≤ L <M, 0 ≤ J <K), para denotar que XJ es relevante para la restricción Cl. El DCSP puede establecerse formalmente de la siguiente manera. Declaración del problema: ∀i, j (0 ≤ i <n) (0 ≤ j <k) donde b (i, j)!, Encuentre la tarea xj = dj ∈ Dj tal que ∀l (0 ≤ l <m) dondeE (L, J)!, Cl está satisfecho. Una restricción puede consistir en diferentes variables pertenecientes a diferentes agentes. Un agente no puede cambiar o modificar los valores de asignación de las variables de otros agentes. Por lo tanto, al buscar cooperativamente una solución DCSP, los agentes necesitarían comunicarse entre sí y ajustar y volver a ajustar sus propias tareas variables en el proceso.2.1 Modelo de agente DCSP En general, todos los agentes DCSP deben interactuar cooperativamente, y esencialmente realizar la asignación y reasignación de valores de dominio a variables para resolver todas las violaciones de restricciones. Si los agentes tienen éxito en su resolución, se encuentra una solución. Para participar en el comportamiento cooperativo, un agente DCSP necesita cinco parámetros fundamentales, a saber, (i) una variable [4] o un conjunto variable [10], (ii) dominios, (iii) prioridad, (iv) una lista de vecinosy (v) una lista de restricciones. Cada variable asume un rango de valores llamado dominio. Un valor de dominio, que generalmente abstrae una acción, es una posible opción que un agente puede tomar. Cada agente tiene una prioridad asignada. Estos valores prioritarios ayudan a decidir el orden en que revisan o modifican sus asignaciones de variables. La prioridad de los agentes puede ser fijada (estática) o cambiando (dinámica) al buscar una solución. Si un agente tiene más de una variable, a cada variable se le puede asignar una prioridad diferente, para ayudar a determinar qué asignación de variable debe modificar primero. Un agente que comparte la misma restricción con otro agente se llama vecino de los últimos. Cada agente debe consultar su lista de vecinos durante el proceso de búsqueda. Esta lista también puede mantenerse sin cambios o actualizarse en consecuencia en tiempo de ejecución. Del mismo modo, cada agente mantiene una lista de restricciones. El agente debe asegurarse de que no haya violación de las limitaciones en esta lista. Las restricciones se pueden agregar o eliminar de una lista de restricciones de agentes en tiempo de ejecución. Al igual que con un agente, una restricción también puede asociarse con un valor de prioridad. Se dice que las restricciones con una alta prioridad son más importantes que las restricciones con una prioridad menor. Para distinguirlo de la prioridad de un agente, la prioridad de una restricción se llama peso.3. El modelo de negociación BDI El modelo BDI se origina con el trabajo de M. Bratman [11]. Según [12, Ch.1], la arquitectura BDI se basa en un modelo filosófico de razonamiento práctico humano, y extrae el proceso de razonamiento por el cual un agente decide qué acciones realizar en momentos consecutivos cuando persiguen ciertos objetivos. Con una base del marco DCSP, el objetivo común de todos los agentes es encontrar una combinación de valores de dominio para satisfacer un conjunto de restricciones predefinidas. En la negociación automatizada [9], dicha solución se denomina acuerdo entre los agentes. Dentro de este alcance, descubrimos que pudimos descubrir el comportamiento genérico de un agente DCSP y formularlo en un protocolo de negociación, prescrito utilizando los poderosos conceptos de BDI. Por lo tanto, se puede decir que nuestro modelo de negociación propuesto combina los conceptos BDI con una negociación automatizada en un marco multiagente, lo que nos permite separar los mecanismos DCSP conceptualmente en un protocolo de interacción BDI común y las estrategias adoptadas.3.1 El protocolo genérico Figura 1 muestra los pasos de razonamiento básicos en una ronda arbitraria de negociación que constituye el nuevo protocolo. La línea continua indica el componente o transición común que siempre existe independientemente de la estrategia utilizada. La línea punteada indica la percepción del deseo de deseo de la mediación de la intención P B D I I I Info Mensaje Información Mensaje Negociación Negociación Mensaje de negociación Mensaje Negociación Mensaje de negociación Mensaje de negociación Mensaje de negociación Figura 1: El componente o transición del protocolo de interacción BDI que puede o no aparecer dependiendo de la adopción de la adopción de la adopción de la adopción de la Figura 1:estrategia. Se intercambian dos tipos de mensajes a través de este protocolo, a saber, el mensaje de información y el mensaje de negociación. Un mensaje de información percibido es un mensaje enviado por otro agente. El mensaje contendrá los valores y prioridades seleccionados actuales de las variables de ese agente de envío. El objetivo principal de este mensaje es actualizar al agente sobre el entorno actual. El mensaje de información se envía al final de una ronda de negociación (también llamada ciclo de negociación) y se recibe al comienzo de la próxima ronda. Un mensaje de negociación es un mensaje que puede enviarse dentro de una ronda. Este mensaje es para fines de mediación. El agente puede poner diferentes contenidos en este tipo de mensaje siempre que se acuerde entre el grupo. El formato del mensaje de negociación y cuándo se enviará está sujeto a la estrategia. Se puede enviar un mensaje de negociación al final de un paso de razonamiento y recibir al comienzo del siguiente paso. La mediación es un paso del protocolo que depende de si la interacción de los agentes con otros es sincrónica o asincrónica. En el mecanismo sincrónico, se requiere mediación en cada ronda de negociación. En una asíncrona, la mediación solo se necesita en una ronda de negociación cuando el agente recibe un mensaje de negociación. Una visión más profunda de este paso de mediación se proporciona más adelante en esta sección. El protocolo BDI prescribe la estructura esquelética para la negociación DCSP. Mostraremos en la Sección 4 que varios mecanismos DCSP conocidos heredan este modelo genérico. Los detalles de los seis pasos de razonamiento principales para el protocolo (ver Figura 1) se describen de la siguiente manera para un agente DCSP. Para una descripción conceptualmente más clara, suponemos que solo hay una variable por agente.• percepción. En este paso, el agente recibe mensajes de información de sus vecinos en el entorno, y utilizando su función de percepción, devuelve una imagen P. Esta imagen contiene los valores actuales asignados a las variables de todos los agentes en su lista de vecinos. La imagen P impulsará las acciones de los agentes en pasos posteriores. El agente también actualiza su lista de restricciones C utilizando algunos criterios de la estrategia adoptada.• Creencia. Usando la imagen P y la lista de restricciones C, el agente verificará si hay alguna restricción violada. Si no hay violación, el agente creerá que está eligiendo una opción correcta y, por lo tanto, no tomará medidas. El agente no hará nada si está en un estado estable local, una instantánea de las asignaciones de variables del agente y todos sus vecinos por los cuales satisfacen sus limitaciones compartidas. Cuando todos los agentes se encuentran en sus estados estables locales, se dice que todo el entorno está en un estado estable global y un acuerdo sexto INTL. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) se encuentra 525 mentes. En caso de que el agente encuentre su valor en conflicto con algunos de sus vecinos, es decir, la combinación de valores asignados a las variables conduce a una violación de restricción, el agente primero intentará reasignar su propia variable utilizando una estrategia específica. Si encuentra una opción adecuada que cumple con algunos criterios de la estrategia adoptada, el agente creerá que debería cambiar a la nueva opción. Sin embargo, no siempre sucede que un agente pueda encontrar con éxito tal opción. Si no se puede encontrar ninguna opción, el agente creerá que no tiene opción y, por lo tanto, solicitará a sus vecinos que reconsideren sus tareas variables. Para resumir, hay tres tipos de creencias que un agente DCSP puede formarse: (i) puede cambiar su asignación variable para mejorar la situación actual, (ii) no puede cambiar su asignación variable y algunas violaciones de restricciones no se pueden resolver y (iii) No necesita cambiar su asignación variable ya que todas las restricciones están satisfechas. Una vez que se forman las creencias, el agente determinará sus deseos, que son las opciones que intentan resolver las violaciones de restricción actuales.• Deseo. Si el agente toma creencia (i), generará una lista de sus propios valores de dominio adecuados como su conjunto de deseo. Si el agente toma creencia (ii), no puede determinar su set de deseo, pero generará un sublista de agentes de su lista de vecinos, a quien solicitará reconsiderar sus tareas variables. La forma en que se crea este sublista depende de la estrategia ideada para el agente. En esta situación, el agente utilizará un conjunto de deseo virtual que determina en función de su estrategia adoptada. Si el agente toma creencia (iii), no tendrá ganas de revisar su valor de dominio y, por lo tanto, no hay intención.• Intención. El agente seleccionará un valor de su deseo establecido como su intención. Una intención es la mejor opción deseada que el agente asigna a su variable. Los criterios para seleccionar un deseo, ya que la intención de los agentes depende de la estrategia utilizada. Una vez que se forma la intención, el agente puede proceder al paso de ejecución o someterse a una mediación. Nuevamente, la decisión de hacerlo está determinada por algunos criterios de la estrategia adoptada.• Mediación. Esta es una función importante del agente. Dado que, si el agente ejecuta su intención sin realizar una mediación de intención con sus vecinos, la violación de la restricción entre los agentes no puede resolverse. Tomemos, por ejemplo, suponga que dos agentes tienen variables, x1 y x2, asociadas con el mismo dominio {1, 2}, y su restricción compartida es (x1 + x2 = 3). Entonces, si ambas variables se inicializan con el valor 1, cambiarán simultáneamente entre los valores 2 y 1 en ausencia de mediación entre ellas. Hay dos tipos de mediación: mediación local y mediación grupal. En el primero, los agentes intercambian sus intenciones. Cuando un agente recibe la intención de Another que entra en conflicto con la suya, el agente debe mediar entre las intenciones, ya sea cambiando su propia intención o informando al otro agente que cambie su intención. En este último, hay un agente que actúa como mediador grupal. Este mediador recopilará las intenciones del grupo, una unión del agente y sus vecinos, y determinará qué intención se ejecutará. El resultado de esta mediación se transfiere a los agentes del grupo. Después de la mediación, el agente puede proceder al siguiente paso de razonamiento para ejecutar su intención o comenzar una nueva ronda de negociación.• Ejecución. Este es el último paso de una ronda de negociación. El agente se ejecutará actualizando su asignación variable si la intención obtenida en este paso es suya. Después de la ejecución, el agente informará a sus vecinos sobre su nueva asignación de variable y su prioridad actualizada. Para hacerlo, el agente enviará un mensaje de información.3.2 La estrategia Una estrategia juega un papel importante en el proceso de negociación. Dentro del protocolo, a menudo determinará la eficiencia de la percepción de la ejecución de la mediación de la intención del deseo P B D I Información Mensaje Información Mensaje de negociación Mensaje de negociación Mensaje de negociación Figura 2: Protocolo BDI Con proceso de búsqueda de estrategia de retroceso asíncrono en términos de ciclos computacionales y costos de comunicación de mensajes. El espacio de diseño al diseñar una estrategia está influenciado por las siguientes dimensiones: (i) asíncrono o sincrónico, (ii) prioridad dinámica o estática, (iii) peso dinámico o de restricción estática, (iv) Número de mensajes de negociación que se comunicarán ((v) el formato del mensaje de negociación y (vi) la propiedad de integridad. En otras palabras, estas dimensiones proporcionan consideraciones técnicas para un diseño de estrategia.4. Algoritmos DCSP: Protocolo BDI + Estrategias En esta sección, aplicamos el modelo de negociación BDI propuesto presentado en la Sección 3 para exponer el protocolo BDI y las diferentes estrategias utilizadas para tres algoritmos bien conocidos, ABT, AWC y DBO. Todos estos algoritmos suponen que solo hay una variable por agente. Bajo nuestro marco, llamamos a las estrategias aplicadas las estrategias ABT, AWC y DBO, respectivamente. Para describir cada estrategia formalmente, se utilizan las siguientes anotaciones matemáticas: • n es el número de agentes, M es el número de restricciones;• Xi denota la variable sostenida por el agente I, (0 ≤ i <n);• Di denota el dominio de la variable Xi;Fi denota la lista vecina del Agente I;CI denota su lista de restricciones;• Pi denota la prioridad del agente I;y pi = {(xj = vj, pj = k) |agente j ∈ Fi, vj ∈ Dj es el valor actual asignado a XJ y el valor de prioridad k es un entero positivo} es la percepción del agente I;• WL denota el peso de la restricción l, (0 ≤ l <m);• Si (V) es el peso total de las restricciones violadas en CI cuando su variable tiene el valor v ∈ Di.4.1 El retroceso asíncrono Figura 2 presenta el modelo de negociación BDI que incorpora la estrategia de retroceso asíncrono (ABT). Como se menciona en la Sección 3, para un mecanismo asincrónico que es ABT, el paso de mediación solo se necesita en una ronda de negociación cuando un agente recibe un mensaje de negociación. Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m); pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su BDI impulsadoLa estrategia ABT se describe de la siguiente manera. Paso 1 - Percepción: Actualice PI al recibir los mensajes de información de los vecinos (en FI). Actualice CI para ser la lista de 526 el sexto intl. Conf.en agentes autónomos y restricciones de sistemas de múltiples agentes (AAMAS 07) que solo consisten en agentes en FI que tienen la misma o mayor prioridad que este agente. Paso 2 - Creencia: la función de creencia GB (PI, CI) devolverá un valor bi ∈ {0, 1, 2}, decidió lo siguiente: • Bi = 0 Cuando agente puedo encontrar una opción óptima, es decir, if (Si (Si(vi) = 0 o VI está en la lista de valores malos) y (∃a ∈ Di) (si (a) = 0) y A no está en una lista de valores de dominio llamado Lista de valores malos. Inicialmente, esta lista está vacía y se borrará cuando un vecino de mayor prioridad cambie su asignación variable.• Bi = 1 Cuando no puede encontrar una opción óptima, es decir, if (∀a ∈ Di) (Si (a) = 0) o A está en la lista de valores malos.• BI = 2 Cuando su asignación de variable actual es una opción óptima, es decir, si SI (VI) = 0 y VI no está en la lista de valor malo. Paso 3 - Deseo: la función de deseo GD (BI) devolverá un deseo establecido denotado por DS, decidido de la siguiente manera: • Si bi = 0, entonces ds = {a |(a = vi), (si (a) = 0) y a no está en la lista de valor incorrecto}.• Si bi = 1, entonces ds = ∅, el agente también encuentra el agente k que está determinado por {k |Pk = min (PJ) con agente J ∈ Fi y Pk> Pi}.• Si bi = 2, entonces ds = ∅. Paso 4 - Intención: la función de intención GI (DS) devolverá una intención, decidida de la siguiente manera: • Si ds = ∅, luego seleccione un valor arbitrario (digamos, vi) de DS como la intención.• Si ds = ∅, asigne nil como intención (para denotar su falta de ella). Paso 5 - Ejecución: • Si el agente I tiene un valor de dominio como intención, el agente actualizará su asignación variable con este valor.• Si bi = 1, agente enviaré un mensaje de negociación al Agente K, luego elimine K de FI y comenzará su próxima ronda de negociación. El mensaje de negociación contendrá la lista de asignaciones variables de esos agentes en su lista de vecinos FI que tienen una prioridad más alta que el Agente I en la imagen actual PI. Mediación: cuando el agente I recibe un mensaje de negociación, se llevan a cabo varios subpasos, de la siguiente manera: • Si la lista de agentes asociados con el mensaje de negociación contiene agentes que no están en FI, agregará estos agentes a FI y solicitaráEstos agentes se suman a sus listas de vecinos. La solicitud se considera como un tipo de mensaje de negociación.• Agente Primero verificaré si el agente del remitente se actualiza con su valor actual VI. El agente agregará VI a su lista de valores malos si es así, o enviará su valor actual al agente del remitente. Después de este paso, el agente I procede a la próxima ronda de negociación.4.2 Búsqueda de compromiso débil asincrónico La Figura 3 presenta el modelo de negociación BDI que incorpora la estrategia de compromiso débil asincrónico (AWC). El modelo es similar al de incorporar la estrategia ABT (ver Figura 2). Esto no es sorprendente;AWC y ABT son estratégicamente similares, que difieren solo en los detalles de algunos pasos de razonamiento. El punto distintivo de AWC es que cuando el agente no puede encontrar una asignación de variable adecuada, cambiará su prioridad a los más altos entre los miembros de su grupo ({I} ∪ Fi). Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m); pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su bdi impulsadoLa estrategia AWC se describe de la siguiente manera. Paso 1 - Percepción: este paso es idéntico al paso de percepción de ABT. Paso 2 - Creencia: la función de creencia GB (PI, CI) devolverá un valor bi ∈ ∈ {0, 1, 2}, decidido de la siguiente manera: Percept BRISTA DESEMIENTO MEDIACIÓN Ejecución de mediación P B D I Información Información Información Mensaje Mensaje Mensaje Mensaje Figura de mensajes de negociación3: Protocolo BDI con estrategia de comisión débil asincrónica • Bi = 0 Cuando el agente puede encontrar una opción óptima, es decir, IF (Si (VI) = 0 o la asignación xi = VI y las asignaciones de variables actuales de los vecinos en FiFORMA A NOGOOD [4]) almacenado en una lista llamada Nogood List y ∃a ∈ Di, Si (a) = 0 (inicialmente la lista está vacía).• bi = 1 Cuando el agente no puede encontrar ninguna opción óptima, es decir, si ∀a ∈ Di, si (a) = 0. • bi = 2 cuando la asignación actual es una opción óptima, es decir, si si (vi) = 0 y elEl estado actual no es un nogood en la lista de Nogood. Paso 3 - Deseo: la función de deseo GD (BI) devolverá un desire establecido DS, decidido de la siguiente manera: • Si bi = 0, entonces ds = {a |(a = vi), (si (a) = 0) y el número de violaciones de restricción con agentes de menor prioridad se minimiza}.• Si bi = 1, entonces ds = {a |a ∈ Di y el número de violaciones de todas las restricciones relevantes se minimiza}.• Si bi = 2, entonces ds = ∅. A continuación, si Bi = 1, agente encontraré una lista Ki de vecinos de mayor prioridad, definido por ki = {k |agente k ∈ Fi y Pk> pi}. Paso 4 - Intención: este paso es similar al paso de intención de ABT. Sin embargo, para esta estrategia, el mensaje de negociación contendrá las asignaciones de variables (de la imagen actual PI) para todos los agentes en KI. Esta lista de asignación se considera un nogood. Si el mismo mensaje de negociación se había enviado antes, agente, tendré una intención nula. De lo contrario, el agente enviará el mensaje y guardará el Nogood en la lista de Nogood. Paso 5 - Ejecución: • Si el agente I tiene un valor de dominio como intención, el agente actualizará su asignación variable con este valor.• Si bi = 1, enviará el mensaje de negociación a sus vecinos en ki, y establecerá pi = max {pj} + 1, con agente j ∈ Fi. Mediación: Este paso es idéntico al paso de mediación de ABT, excepto que el agente ahora agregaré el Nogood contenido en el mensaje de negociación recibido a su propia lista de Nogood.4.3 Breakout distribuido La Figura 4 presenta el modelo de negociación BDI que incorpora la estrategia de ruptura distribuida (DBO). Esencialmente, según esta estrategia sincrónica, cada agente buscará iterativamente la mejora al reducir el peso total de las restricciones violadas. La iteración continuará hasta que ningún agente pueda mejorar aún más, momento en el que se persiguen algunas limitaciones, los pesos del sexto INTL. Conf.Sobre agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 527 Percept Believe Desprecio Mediación Mediación Ejecución P B D I A Información Mensaje Información Mensaje de negociación Mensaje de negociación Figura 4: Protocolo BDI Con estrategia de ruptura distribuida Estas limitaciones aumentarán en 1 para ayudar a Breakout de un local de un local de un Local Local.mínimo. Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m), pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su BDI impulsadoLa estrategia DBO se describe de la siguiente manera. Paso 1 - Percepción: Actualice PI al recibir los mensajes de información de los vecinos (en FI). Actualice CI para que sea la lista de sus restricciones relevantes. Paso 2 - Creencia: la función de creencia GB (PI, CI) devolverá un valor bi ∈ {0, 1, 2}, decidió lo siguiente: • Bi = 0 Cuando agente puedo encontrar una opción para reducir las violaciones numéricas de larestricciones en CI, es decir, si ∃a ∈ Di, si (a) <si (vi).• Bi = 1 Cuando no puede encontrar ninguna opción para mejorar la situación, es decir, si ∀a ∈ Di, a = vi, si (a) ≥ Si (vi).• Bi = 2 Cuando su asignación actual es una opción óptima, es decir, si SI (VI) = 0. Paso 3 - Deseo: la función de deseo GD (BI) devolverá un desire establecido DS, decidido de la siguiente manera: • Si bi = 0, entonces ds = {a |a = vi, si (a) <si (vi) y (si (vi) −si (a)) se maximiza}.(Max {(Si (VI) −si (a))} será referenciado por Hmax I en pasos posteriores, y define la reducción máxima en las violaciones de restricciones).• De lo contrario, ds = ∅. Paso 4 - Intención: la función de intención GI (DS) devolverá una intención, decidida de la siguiente manera: • Si ds = ∅, luego seleccione un valor arbitrario (digamos, vi) de DS como la intención.• Si ds = ∅, entonces asigne nil como intención. Siguiendo, agente, enviaré su intención a todos sus vecinos. A cambio, recibirá intenciones de estos agentes antes de proceder al paso de mediación. Mediación: el agente I recibe todas las intenciones de sus vecinos. Si encuentra que la intención recibida de un agente vecino J está asociada con Hmax J> Hmax I, el agente cancelará automáticamente su intención actual. Paso 5 - Ejecución: • Si el agente no cancelé su intención, actualizará su asignación variable con el valor previsto. Percepta creencia Deseo de la intención de ejecución de mediación P B D I I A Información Información Información Mensaje Mensaje Negociación Mensaje de negociación Mensaje Mensaje de negociación Figura 5: Protocolo BDI Con estrategia de asesoramiento mutuo no solicitado • Si todas las intenciones recibidas y su propia son intención, el agente aumentará el peso de cada unoRestricción violada actualmente por 1. 5. La Figura 5 de la Estrategia UMA presenta el modelo de negociación BDI que incorpora la estrategia de asesoramiento mutuo no solicitado (UMA). A diferencia de cuando se usa las estrategias de la sección anterior, un agente DCSP que usa UMA no solo enviará un mensaje de negociación al concluir su paso de intención, sino también al concluir su paso de deseo. El mensaje de negociación que envía para concluir el paso del deseo constituye un consejo no solicitado para todos sus vecinos. A su vez, el agente esperará para recibir consejos no solicitados de todos sus vecinos, antes de continuar para determinar su intención. Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m), pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su BDI impulsadoLa estrategia de UMA se describe de la siguiente manera. Paso 1 - Percepción: Actualice PI al recibir los mensajes de información de los vecinos (en FI). Actualizar CI para que sea la lista de restricciones relevantes para el agente i. Paso 2 - Creencia: la función de creencia GB (PI, CI) devolverá un valor bi ∈ {0, 1, 2}, decidió lo siguiente: • Bi = 0 Cuando agente puedo encontrar una opción para reducir las violaciones numéricas de larestricciones en CI, es decir, si ∃a ∈ Di, Si (a) <Si (vi) y la asignación xi = a y las asignaciones variables actuales de sus vecinos no forman un estado local almacenado en una lista llamada lista de estados malos (Inicialmente, esta lista está vacía).• bi = 1 cuando no puede encontrar un valor a tal como a ∈ Di, si (a) <si (vi), y la asignación xi = a y las asignaciones variables actuales de sus vecinos no forman un estado local almacenado en elLista de estados malos.• Bi = 2 Cuando su asignación actual es una opción óptima, es decir, si SI (VI) = 0. Paso 3 - Deseo: la función de deseo GD (BI) devolverá un desire establecido DS, decidido de la siguiente manera: • Si bi = 0, entonces ds = {a |a = vi, si (a) <si (vi) y (si (vi) - si (a)) se maximiza} y la asignación xi = a y las asignaciones variables actuales del agente no forman un estado en el estado en el estado en el estado en el estadoLista de estados malos. En este caso, DS se llama un conjunto de deseos voluntarios.Max {(Si (VI) −si (a))} será referenciado por Hmax I en pasos posteriores, y define 528 el sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) la reducción máxima en las violaciones de restricciones. También se conoce como una mejora).• Si bi = 1, entonces ds = {a |a = vi, Si (a) se minimiza} y la asignación xi = a y las asignaciones variables actuales del agente son vecinos no forman un estado en la lista de estados malos. En este caso, DS se llama un conjunto de deseos reacios • Si Bi = 2, entonces ds = ∅. A continuación, si Bi = 0, agente enviaré un mensaje de negociación que contenga Hmax I a todos sus vecinos. Este mensaje se llama consejo voluntario. Si bi = 1, agente, enviaré un mensaje de negociación llamado consejo de cambio a los vecinos en FI que comparten las limitaciones violadas con el agente i. Agente recibí consejos de todos sus vecinos y los almacena en una lista llamada A, antes de continuar con el siguiente paso. Paso 4 - Intención: la función de intención GI (DS, A) devolverá una intención, decidida de la siguiente manera: • Si hay un consejo voluntario de un agente J asociado con Hmax J> Hmax I, asigne nil como intención.• Si DS = ∅, DS es un conjunto de deseos voluntarios y Hmax I es la mayor mejora entre los asociados con los consejos voluntarios recibidos, seleccione un valor arbitrario (digamos, vi) de DS como la intención. Esta intención se llama intención voluntaria.• Si ds = ∅, ds es un conjunto de deseos reacios y agente I recibe algunos consejos de cambio, seleccione un valor arbitrario (digamos, vi) de DS como intención. Esta intención se llama intención reacia.• Si ds = ∅, entonces asigne nil como intención. A continuación, si la mejora Hmax I es la mayor mejora y es igual a algunas mejoras asociadas con los consejos voluntarios recibidos, el agente enviaré su intención calculada a todos sus vecinos. Si el agente I tiene una intención reacia, también enviará esta intención a todos sus vecinos. En ambos casos, el agente I adjuntará el número de consejos de cambio recibidos en la ronda de negociación actual con su intención. A cambio, agente, recibiré las intenciones de sus vecinos antes de proceder al paso de mediación. Mediación: si el agente I no envía su intención antes de este paso, es decir, el agente tiene una intención nula o una intención voluntaria con la mayor mejora, procederá al siguiente paso. De lo contrario, agente, seleccionaré la mejor intención entre todas las intenciones recibidas, incluidas las suyas (si corresponde). Los criterios para seleccionar la mejor intención se enumeran, se aplican en orden descendente de importancia de la siguiente manera.• Se prefiere una intención voluntaria sobre una intención reacia.• Se selecciona una intención voluntaria (si la hay) con mayor mejora.• Si no hay intención voluntaria, se selecciona la intención reacia con el menor número de violaciones de restricciones.• Se selecciona la intención de un agente que ha recibido un mayor número de consejos de cambio en la ronda de negociación actual.• Se selecciona la intención de un agente con la más alta prioridad. Si la intención seleccionada no es el agente es intención, cancelará su intención. Paso 5 - Ejecución: si el Agente I no cancela su intención, actualizará su asignación variable con el valor previsto. Condición de terminación: dado que cada agente no tiene información completa sobre el estado global, puede no saber cuándo ha alcanzado una solución, es decir, cuándo todos los agentes están en un estado estable global. Por lo tanto, se necesita un observador que realizará un seguimiento de los mensajes de negociación comunicados en el entorno. Después de un cierto período de tiempo cuando no hay más comunicación de mensajes (y esto sucede cuando todos los agentes no tienen más intención de actualizar sus tareas variables), el observador informará a los agentes en el entorno que se ha encontrado una solución.1 2 3 4 5 6 7 8 9 10 Figura 6: Problema de ejemplo 5.1 Un ejemplo para ilustrar cómo funciona UMA, considere un problema de gráfico de 2 colores [6] como se muestra en la Figura 6. En este ejemplo, cada agente tiene una variable de color que representa un nodo. Hay 10 variables de color que comparten el mismo dominio {negro, blanco}. El siguiente registra el resultado de cada paso en cada ronda de negociación ejecutada. Ronda 1: Paso 1 - Percepción: cada agente obtiene las asignaciones de color actuales de esos nodos (agentes) adyacentes a él, es decir, sus vecinos. Paso 2 - Creencia: los agentes que tienen mejoras positivas son el Agente 1 (este agente cree que debería cambiar su color a blanco), Agente 2 (esto cree que debería cambiar su color a blanco), Agente 7 (este agente cree que debería cambiar su colora negro) y agente 10 (este agente cree que debería cambiar su valor a negro). En esta ronda de negociación, las mejoras logradas por estos agentes son 1. Los agentes que no tienen mejoras son los Agentes 4, 5 y 8. Los agentes 3, 6 y 9 no necesitan cambiar ya que todas sus limitaciones relevantes se cumplen. Paso 3 - Deseo: los agentes 1, 2, 7 y 10 tienen el deseo voluntario (color blanco para los agentes 1, 2 y el color negro para los agentes 7, 10). Estos agentes enviarán los consejos voluntarios a todos sus vecinos. Mientras tanto, los agentes 4, 5 y 8 tienen los deseos reacios (color blanco para el agente 4 y el color negro para los agentes 5, 8). El Agente 4 enviará un consejo de cambio al Agente 2, ya que el Agente 2 comparte la restricción violada con él. Del mismo modo, los agentes 5 y 8 enviarán consejos de cambio a los agentes 7 y 10 respectivamente. Los agentes 3, 6 y 9 no tienen ningún deseo de actualizar sus tareas de color. Paso 4 - Intención: los agentes 2, 7 y 10 reciben los consejos de cambio de los agentes 4, 5 y 8, respectivamente. Forman sus intenciones voluntarias. Los agentes 4, 5 y 8 reciben los consejos voluntarios de los Agentes 2, 7 y 10, por lo tanto, no tendrán ninguna intención. Los agentes 3, 6 y 9 no tienen ninguna intención. A continuación, la intención de los agentes se enviará a todos sus vecinos. Mediación: el Agente 1 encuentra que la intención del Agente 2 es mejor que su intención. Esto se debe a que, aunque ambos agentes tienen intenciones voluntarias con una mejora de 1, el Agente 2 ha recibido un consejo de cambio del Agente 4, mientras que el Agente 1 no ha recibido ninguno. Por lo tanto, el Agente 1 cancela su intención. El agente 2 mantendrá su intención. Los agentes 7 y 10 mantienen sus intenciones ya que ninguno de sus vecinos tiene una intención. El resto de los agentes no hacen nada en este paso, ya que no tienen ninguna intención. Paso 5 - Ejecución: el agente 2 cambia su color a blanco. Los agentes 7 y 10 cambian sus colores a negro. El nuevo estado después de la Ronda 1 se muestra en la Figura 7. Ronda 2: Paso 1 - Percepción: los agentes obtienen las asignaciones de color actuales de sus vecinos. Paso 2 - Creencia: el Agente 3 es el único agente que tiene una mejora positiva que es 1. Cree que debería cambiar su sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figura 7: El gráfico después de la ronda 1 color a negro. El agente 2 no tiene ninguna mejora positiva. El resto de los agentes no necesitan hacer ningún cambio ya que todas sus limitaciones relevantes se cumplen. No tendrán ningún deseo y, por lo tanto, no hay intención. Paso 3 - Deseo: el Agente 3 desea cambiar su color a negro voluntariamente, por lo tanto, envía un consejo voluntario a su vecino, es decir, el Agente 2. El agente 2 no tiene ningún valor para su deseo reacio establecido como la única opción, Black Color, traerá el Agente 2 y sus vecinos al estado anterior, que se sabe que es un mal estado. Dado que el Agente 2 comparte la violación de la restricción con el Agente 3, envía un consejo de cambio al Agente 3. Paso 4 - Intención: el Agente 3 tendrá una intención voluntaria, mientras que el Agente 2 no tendrá ninguna intención, ya que recibe el consejo voluntario del Agente 3. Mediación: el Agente 3 mantendrá su intención como su único vecino, el Agente 2, no tiene ninguna intención. Paso 5 - Ejecución: el agente 3 cambia su color a negro. El nuevo estado después de la ronda 2 se muestra en la Figura 8. Ronda 3: En esta ronda, cada agente encuentra que no tiene deseo y, por lo tanto, no tiene intención de revisar su asignación variable. A continuación, sin más comunicación de mensajes de negociación en el entorno, el observador informará a todos los agentes que se ha encontrado una solución.2 3 4 5 6 7 8 91 10 Figura 8: La solución obtuvo una evaluación de rendimiento 5.2 para facilitar las comparaciones creíbles con las estrategias existentes, medimos el tiempo de ejecución en términos de ciclos computacionales como se define en [4], y construimos un simulador que podría reproducirLos resultados publicados para ABT y AWC. La definición de un ciclo computacional es la siguiente.• En un ciclo, cada agente recibe todos los mensajes entrantes, realiza el cálculo local y envía una respuesta.• Un mensaje que se envía en el momento t se recibirá en el momento t + 1. El retraso de la red se descuida.• Cada agente tiene su propio reloj. El valor inicial de los relojes es 0. Los agentes adjuntan su valor de reloj como una tabla de tiempo en el mensaje saliente y usan la tabla de tiempo en el mensaje entrante para actualizar el valor de sus propios relojes. Se consideraron cuatro problemas de referencia [6], a saber, colorante N-coles y nodo para gráficos escasos, densos y críticos. Para cada problema, se generó un número finito de casos de prueba para varios tamaños de problemas n.El tiempo de ejecución máximo se estableció en 0 200 400 600 800 1000 10 50 100 Número de ciclos de reinas de reinas retroceso asíncrono Compromiso débil asincrónico Asesoramiento mutuo no solicitado Figura 9: Relación entre el tiempo de ejecución y el tamaño del problema 10000 ciclos para el color de nodos para gráficos críticos y 1000 ciclos paraotros problemas. El programa del simulador se terminó después de este período y se consideró que el algoritmo falla un caso de prueba si no encontraba una solución para entonces. En tal caso, el tiempo de ejecución para la prueba se contó como 1000 ciclos.5.2.1 Evaluación con el problema de N-Queens El problema N-Queens es un problema tradicional de satisfacción de restricción.Se generaron 10 casos de prueba para cada tamaño de problema n ∈ {10, 50 y 100}. La Figura 9 muestra el tiempo de ejecución para diferentes tamaños de problemas cuando se ejecutaron ABT, AWC y UMA.5.2.2 Evaluación con problema de coloración de gráficos El problema de coloración del gráfico puede caracterizarse por tres parámetros: (i) el número de colores k, el número de nodos/agentes n y el número de enlaces m.Según la relación m/n, el problema se puede clasificar en tres tipos [3]: (i) escaso (con m/n = 2), (ii) crítico (con m/n = 2.7 o 4.7) y (iii) denso (con m/n = (n - 1)/4). Para este problema, no incluimos ABT en nuestros resultados empíricos, ya que se encontró que su tasa de falla era muy alta. Se esperaba este bajo rendimiento de ABT, ya que el problema de coloración del gráfico es más difícil que el problema de N-Queens, en el que ABT ya no funcionó bien (ver Figura 9). Los tipos de problemas escasos y densos (colorantes) son relativamente fáciles, mientras que el tipo crítico es difícil de resolver. En los experimentos, corrigimos k = 3. 10 casos de prueba se crearon utilizando el método descrito en [13] para cada valor de n ∈ {60, 90, 120}, para cada tipo de problema. Los resultados de la simulación para cada tipo de problema se muestran en las Figuras 10 - 12. 0 40 80 120 160 200 60 90 120 150 Número de nodos Ciclos Asincrónicos Compromiso débil de asesoramiento mutuo no solicitado Figura 10: Comparación entre AWC y UMA (coloración de gráficos dispersos) 5.3Discusión 5.3.1 Comparación con ABT y AWC 530 El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Número de nodos ciclos de compromiso débil asincrónico Asesoramiento mutuo no solicitado Figura 11: Comparación entre AWC y UMA (color gráfico crítico) 0 20 30 40 40 40 40 40 40 4050 60 90 120 Número de nodos Ciclos de compromiso débil asincrónico Consejo mutuo no solicitado Figura 12: Comparación entre AWC y UMA (coloración densa gráfica) La Figura 10 muestra que el rendimiento promedio de UMA es ligeramente mejor que AWC para el problema escaso. UMA supera a AWC para resolver el problema crítico como se muestra en la Figura 11. Se observó que la última estrategia falló en algunos casos de prueba. Sin embargo, como se ve en la Figura 12, ambas estrategias son muy eficientes al resolver el problema denso, y AWC muestra un rendimiento ligeramente mejor. El rendimiento de UMA, en el peor caso (complejidad del tiempo), es similar al de todas las estrategias evaluadas. El peor de los casos ocurre cuando se alcanzan todos los posibles estados globales de la búsqueda. Dado que solo unos pocos agentes tienen derecho a cambiar sus tareas variables en una ronda de negociación, se reduce el número de ciclos computacionales redundantes y mensajes de información. Como observamos del retroceso en ABT y AWC, la diferencia en el orden de los mensajes entrantes puede dar lugar a un número diferente de ciclos computacionales para ser ejecutados por los agentes.5.3.2 Comparación con DBO El rendimiento computacional de UMA es posiblemente mejor que DBO por las siguientes razones: • Uma puede garantizar que habrá una reasignación variable después de cada ronda de negociación, mientras que DBO no puede.• Uma presenta un viaje de ida y vuelta de comunicación más (el de enviar un mensaje y esperar una respuesta) que DBO, que ocurre debido a la necesidad de comunicar consejos no solicitados. Aunque esto aumenta el costo de comunicación por ronda de negociación, observamos a partir de nuestras simulaciones que el costo general de comunicación incurrido por UMA es menor debido al número significativamente menor de rondas de negociación.• Usando UMA, en el peor de los casos, un agente solo tomará 2 o 3 viajes de la ronda de comunicación por ronda de negociación, después de lo cual el agente o su vecino hará una actualización de asignación variable. Usando DBO, este número de viajes redondos es incierto ya que cada agente podría tener que aumentar los pesos de las restricciones violadas hasta que un agente tenga una mejora positiva;Esto podría dar lugar a un bucle infinito [3].6. Conclusión Aplicación de negociación automatizada a DCSP, este documento ha propuesto un protocolo que prescribe el razonamiento genérico de un agente DCSP en una arquitectura BDI. Nuestro trabajo muestra que varios algoritmos DCSP conocidos, a saber, ABT, AWC y DBO, pueden describirse como mecanismos que comparten el mismo protocolo propuesto, y solo difieren en las estrategias empleadas para los pasos de razonamiento por ronda de negociación como se rige por el protocolo. Es importante destacar que esto significa que podría proporcionar un marco unificado para DCSP que no solo proporciona una visión teórica teórica de agente BDI más clara de los enfoques DCSP existentes, sino que también abre las oportunidades para mejorar o desarrollar nuevas estrategias. Hacia este último, hemos propuesto y formulado una nueva estrategia: la estrategia de UMA. Los resultados empíricos y nuestra discusión sugieren que UMA es superior a ABT, AWC y DBO en algunos aspectos específicos. De nuestras simulaciones se observó que Uma posee la propiedad de integridad. El trabajo futuro intentará establecer formalmente esta propiedad, así como formalizar otros algoritmos DSCP existentes como mecanismos de negociación BDI, incluido el reciente esfuerzo que emplea a un mediador grupal [5]. También se investigará la idea de que los agentes DCSP que usen diferentes estrategias en el mismo entorno.7. Referencias [1] P. J. Modi, H. Jung, M. Tambe, W.-M.Shen y S. Kulkarni, Asignación dinámica de recursos distribuidos: un enfoque de satisfacción de restricciones distribuidas, en Notas de conferencias en Ciencias de la Computación, 2001, p.264. [2] H. Schlenker y U. Geske, simulando grandes redes ferroviarias utilizando la satisfacción de restricciones distribuidas, en la segunda conferencia internacional IEEE sobre informática industrial (Indin-04), 2004, pp. 441-446. [3] M. Yokoo, Satisfacción de restricción distribuida: fundamentos de cooperación en sistemas de agentes múltiples. Springer Verlag, 2000, Serie Springer sobre tecnología de agentes.[4] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara, El problema de satisfacción de restricciones distribuidas: formalización y algoritmos, transacciones IEEE sobre conocimiento e ingeniería de datos, vol.10, no.5, pp. 673-685, septiembre/octubre de 1998. [5] R. Mailler y V. Lesser, utilizando mediación cooperativa para resolver problemas distribuidos de satisfacción de restricciones, en los procedimientos de la tercera conferencia conjunta internacional sobre agentes autónomos y sistemas multiagentes (AAMAS (AAMAS-04), 2004, pp. 446-453.[6] E. Tsang, Fundación de satisfacción de restricción. Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop y J. Shen, en tiempo real suave, negociación cooperativa para la asignación de recursos distribuidos, Simposio AAAI Fall sobre métodos de negociación autónomos para la cooperativa autónomaSystems, noviembre de 2001. [8] M. Yokoo, K. Suzuki y K. Hirayama, Satisfacción de restricción distribuida segura: llegar a un acuerdo sin revelar información privada, Inteligencia Artificial, vol.161, no.1-2, pp. 229-246, 2005. [9] J. S. Rosenschein y G. Zlotkin, Reglas de encuentro. The MIT Press, 1994. [10] M. Yokoo y K. Hirayama, Algoritmo distribuido de satisfacción de restricciones para problemas locales complejos, en las actas de la tercera conferencia internacional sobre sistemas multiagentes (ICMAS-98), 1998, pp. 372-379.[11] M. E. Bratman, Intenciones, planes y razones prácticas. Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, ed., Sistema multiagente: un enfoque moderno para la inteligencia artificial distribuida. The MIT Press, Londres, Reino Unido, 1999. [13] S. Minton, M. D. Johnson, A. B. Philips y P. Laird, Minimización de conflictos: un método de reparación heurística para la satisfacción de la restricción y los problemas de programación, Inteligencia Artificial, vol.E58, no.1-3, pp. 161-205, 1992. El sexto intl. Conf.Sobre agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 531",
    "original_sentences": [
        "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
        "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
        "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
        "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
        "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
        "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
        "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
        "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
        "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
        "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
        "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
        "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
        "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
        "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
        "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
        "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
        "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
        "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
        "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
        "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
        "The rest of this paper is organized as follows.",
        "In Section 2, we provide a formal overview of DCSP.",
        "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
        "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
        "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
        "Section 6 concludes the paper and points to some future work. 2.",
        "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
        "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
        "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
        "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
        "The DCSP may be formally stated as follows.",
        "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
        "A constraint may consist of different variables belonging to different agents.",
        "An agent cannot change or modify the assignment values of other agents variables.",
        "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
        "If the agents succeed in their resolution, a solution is found.",
        "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
        "Each variable assumes a range of values called a domain.",
        "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
        "Each agent has an assigned priority.",
        "These priority values help decide the order in which they revise or modify their variable assignments.",
        "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
        "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
        "An agent which shares the same constraint with another agent is called the latters neighbor.",
        "Each agent needs to refer to its list of neighbors during the search process.",
        "This list may also be kept unchanged or updated accordingly in runtime.",
        "Similarly, each agent maintains a constraint list.",
        "The agent needs to ensure that there is no violation of the constraints in this list.",
        "Constraints can be added or removed from an agents constraint list in runtime.",
        "As with an agent, a constraint can also be associated with a priority value.",
        "Constraints with a high priority are said to be more important than constraints with a lower priority.",
        "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
        "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
        "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
        "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
        "In automated negotiation [9], such a solution is called an agreement among the agents.",
        "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
        "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
        "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
        "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
        "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
        "An info message perceived is a message sent by another agent.",
        "The message will contain the current selected values and priorities of the variables of that sending agent.",
        "The main purpose of this message is to update the agent about the current environment.",
        "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
        "A negotiation message is a message which may be sent within a round.",
        "This message is for mediation purposes.",
        "The agent may put different contents into this type of message as long as it is agreed among the group.",
        "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
        "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
        "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
        "In synchronous mechanism, mediation is required in every negotiation round.",
        "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
        "A more in-depth view of this mediation step is provided later in this section.",
        "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
        "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
        "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
        "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
        "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
        "The image P will drive the agents actions in subsequent steps.",
        "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
        "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
        "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
        "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
        "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
        "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
        "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
        "However it does not always happen that an agent can successfully find such an option.",
        "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
        "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
        "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
        "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
        "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
        "How this sublist is created depends on the strategy devised for the agent.",
        "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
        "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
        "The agent will select a value from its desire set as its intention.",
        "An intention is the best desired option that the agent assigns to its variable.",
        "The criteria for selecting a desire as the agents intention depend on the strategy used.",
        "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
        "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
        "This is an important function of the agent.",
        "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
        "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
        "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
        "There are two types of mediation: local mediation and group mediation.",
        "In the former, the agents exchange their intentions.",
        "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
        "In the latter, there is an agent which acts as a group mediator.",
        "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
        "The result of this mediation is passed back to the agents in the group.",
        "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
        "This is the last step of a negotiation round.",
        "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
        "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
        "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
        "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
        "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
        "In other words, these dimensions provide technical considerations for a strategy design. 4.",
        "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
        "All these algorithms assume that there is only one variable per agent.",
        "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
        "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
        "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
        "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
        "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
        "Update Ci to be the list of 526 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
        "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
        "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
        "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
        "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
        "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
        "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
        "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
        "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
        "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
        "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
        "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
        "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
        "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
        "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
        "Step 1 - Percept: This step is identical to the Percept step of ABT.",
        "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
        "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
        "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
        "Step 4 - Intention: This step is similar to the Intention step of ABT.",
        "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
        "This list of assignment is considered as a nogood.",
        "If the same negotiation message had been sent out before, agent i will have nil intention.",
        "Otherwise, the agent will send the message and save the nogood in the nogood list.",
        "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
        "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
        "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
        "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
        "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
        "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
        "Update Ci to be the list of its relevant constraints.",
        "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
        "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
        "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
        "Following, agent i will send its intention to all its neighbors.",
        "In return, it will receive intentions from these agents before proceeding to Mediation step.",
        "Mediation: Agent i receives all the intentions from its neighbors.",
        "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
        "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
        "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
        "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
        "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
        "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
        "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
        "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
        "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
        "Update Ci to be the list of constraints relevant to agent i.",
        "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
        "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
        "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
        "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
        "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
        "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
        "This message is called a voluntary advice.",
        "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
        "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
        "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
        "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
        "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
        "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
        "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
        "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
        "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
        "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
        "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
        "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
        "If the selected intention is not agent is intention, it will cancel its intention.",
        "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
        "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
        "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
        "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
        "In this example, each agent has a color variable representing a node.",
        "There are 10 color variables sharing the same domain {Black, White}.",
        "The following records the outcome of each step in every negotiation round executed.",
        "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
        "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
        "In this negotiation round, the improvements achieved by these agents are 1.",
        "Agents which do not have any improvements are agents 4, 5 and 8.",
        "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
        "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
        "These agents will send the voluntary advices to all their neighbors.",
        "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
        "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
        "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
        "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
        "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
        "They form their voluntary intentions.",
        "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
        "Agents 3, 6 and 9 do not have any intention.",
        "Following, the intention from the agents will be sent to all their neighbors.",
        "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
        "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
        "Hence agent 1 cancels its intention.",
        "Agent 2 will keep its intention.",
        "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
        "The rest of the agents do nothing in this step as they do not have any intention.",
        "Step 5 - Execution: Agent 2 changes its color to White.",
        "Agents 7 and 10 change their colors to Black.",
        "The new state after round 1 is shown in Figure 7.",
        "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
        "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
        "It believes it should change its The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
        "Agent 2 does not have any positive improvement.",
        "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
        "They will have no desire, and hence no intention.",
        "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
        "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
        "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
        "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
        "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
        "Step 5 - Execution: Agent 3 changes its color to Black.",
        "The new state after round 2 is shown in Figure 8.",
        "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
        "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
        "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
        "The network delay is neglected. • Each agent has it own clock.",
        "The initial clocks value is 0.",
        "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
        "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
        "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
        "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
        "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
        "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
        "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
        "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
        "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
        "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
        "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
        "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
        "It was observed that the latter strategy failed in some test cases.",
        "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
        "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
        "The worst case occurs when all the possible global states of the search are reached.",
        "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
        "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
        "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
        "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
        "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
        "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
        "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
        "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
        "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
        "It was observed from our simulations that UMA possesses the completeness property.",
        "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
        "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
        "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
        "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
        "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
        "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
        "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
        "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
        "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
    ],
    "error_count": 0,
    "keys": {
        "dcsp": {
            "translated_key": "DCSP",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (<br>dcsp</br>) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the <br>dcsp</br> search on automated negotiation, we show that several well-known <br>dcsp</br> algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing <br>dcsp</br> algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for <br>dcsp</br>.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (<br>dcsp</br>) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the <br>dcsp</br> and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the <br>dcsp</br> search on automated negotiation, we show in this paper that several well-known <br>dcsp</br> algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing <br>dcsp</br> algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for <br>dcsp</br>.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of <br>dcsp</br>.",
                "Section 3 presents a BDI negotiation model by which a <br>dcsp</br> agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "<br>dcsp</br>: PROBLEM FORMALIZATION The <br>dcsp</br> [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The <br>dcsp</br> may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a <br>dcsp</br> solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 <br>dcsp</br> Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a <br>dcsp</br> agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the <br>dcsp</br> framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a <br>dcsp</br> agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate <br>dcsp</br> mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for <br>dcsp</br> negotiation.",
                "We will show in Section 4 that several well-known <br>dcsp</br> mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a <br>dcsp</br> agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a <br>dcsp</br> agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "<br>dcsp</br> ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a <br>dcsp</br> agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to <br>dcsp</br>, this paper has proposed a protocol that prescribes the generic reasoning of a <br>dcsp</br> agent in a BDI architecture.",
                "Our work shows that several wellknown <br>dcsp</br> algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for <br>dcsp</br> that not only provides a clearer BDI agent-theoretic view of existing <br>dcsp</br> approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of <br>dcsp</br> agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "El problema de satisfacción de restricción distribuido (\"DCSP\") es uno que implica varios agentes para buscar un acuerdo, que es una combinación consistente de acciones que satisface sus limitaciones mutuas en un entorno compartido.",
                "Al anclar la búsqueda \"DCSP\" en la negociación automatizada, mostramos que varios algoritmos \"DCSP\" conocidos son en realidad mecanismos que pueden alcanzar acuerdos a través de un protocolo común de intención de creencia (BDI), pero utilizando diferentes estrategias.",
                "Una motivación importante para este marco BDI es que no solo proporciona una comprensión conceptualmente más clara de los algoritmos existentes de \"DCSP\" desde una perspectiva del modelo de agente, sino que también abre las oportunidades para extender y desarrollar nuevas estrategias para \"DCSP\".",
                "La introducción en el núcleo de muchas aplicaciones distribuidas emergentes es el problema de satisfacción de restricciones distribuidas (\"DCSP\"), uno que implica encontrar una combinación consistente de acciones (abstraída como valores de dominio) para satisfacer las restricciones entre múltiples agentes en un entorno compartido.",
                "Se han desarrollado muchos algoritmos importantes, como la ruptura distribuida (DBO) [3], el retroceso asíncrono (ABT) [4], la superposición parcial asincrónica (APO) [5] y el compromiso débil asincrónico (AWC) [4] [4], para abordarel \"DCSP\" y proporcionar la base de la solución del agente para sus aplicaciones.",
                "Anclado de la búsqueda \"DCSP\" en la negociación automatizada, mostramos en este documento que varios algoritmos \"DCSP\" conocidos [3] son en realidad mecanismos que comparten el mismo protocolo de interacción de la intención de creencias (BDI) para alcanzar acuerdos, pero usan diferentes acciones.o estrategias de selección de valor.",
                "El marco propuesto proporciona no solo una comprensión más clara de los algoritmos \"DCSP\" existentes desde una perspectiva de agente BDI unificado, sino que también abre las oportunidades para extender y desarrollar nuevas estrategias para \"DCSP\".",
                "En la Sección 2, proporcionamos una descripción formal de \"DCSP\".",
                "La Sección 3 presenta un modelo de negociación BDI por el cual razona un agente \"DCSP\".",
                "\"DCSP\": Formalización del problema El \"DCSP\" [4] considera el siguiente entorno.• Hay N agentes con variables K x0, x1, · · ·, xk - 1, n ≤ k, que tienen valores en los dominios D1, D2, · · ·, DK, respectivamente.",
                "El \"DCSP\" puede establecerse formalmente de la siguiente manera.",
                "Por lo tanto, al buscar cooperativamente una solución \"DCSP\", los agentes necesitarían comunicarse entre sí y ajustar y volver a ajustar sus propias tareas variables en el proceso.2.1 Modelo de agente \"DCSP\" En general, todos los agentes DCSP deben interactuar cooperativamente, y esencialmente realizar la asignación y reasignación de valores de dominio a variables para resolver todas las violaciones de restricciones.",
                "Para participar en el comportamiento cooperativo, un agente \"DCSP\" necesita cinco parámetros fundamentales, a saber, (i) una variable [4] o un conjunto variable [10], (ii) dominios, (iii) prioridad, (iv) ALista de vecinos y (v) una lista de restricciones.",
                "Con base en el alcance del marco \"DCSP\", el objetivo común de todos los agentes es encontrar una combinación de valores de dominio para satisfacer un conjunto de restricciones predefinidas.",
                "Dentro de este alcance, descubrimos que pudimos descubrir el comportamiento genérico de un agente \"DCSP\" y formularlo en un protocolo de negociación, prescrito utilizando los poderosos conceptos de BDI.",
                "Por lo tanto, se puede decir que nuestro modelo de negociación propuesto combina los conceptos BDI con una negociación automatizada en un marco multiagente, lo que nos permite separar los mecanismos conceptualmente \"DCSP\" en un protocolo de interacción BDI común y las estrategias adoptadas.3.1 El protocolo genérico Figura 1 muestra los pasos de razonamiento básicos en una ronda arbitraria de negociación que constituye el nuevo protocolo.",
                "El protocolo BDI prescribe la estructura esquelética para la negociación \"DCSP\".",
                "Mostraremos en la Sección 4 que varios mecanismos \"DCSP\" conocidos heredan este modelo genérico.",
                "Los detalles de los seis pasos de razonamiento principales para el protocolo (ver Figura 1) se describen de la siguiente manera para un agente \"DCSP\".",
                "Para resumir, hay tres tipos de creencias que un agente \"DCSP\" puede formarse: (i) puede cambiar su asignación variable para mejorar la situación actual, (ii) no puede cambiar su asignación variable y algunas violaciones de restricciones no pueden resolverse y(iii) No necesita cambiar su asignación variable ya que todas las restricciones están satisfechas.",
                "Algoritmos \"DCSP\": Protocolo BDI + Estrategias En esta sección, aplicamos el modelo de negociación BDI propuesto presentado en la Sección 3 para exponer el protocolo BDI y las diferentes estrategias utilizadas para tres algoritmos conocidos, ABT, AWC y DBO.",
                "A diferencia de cuando se usa las estrategias de la sección anterior, un agente \"DCSP\" que usa UMA no solo enviará un mensaje de negociación al concluir su paso de intención, sino también al concluir su paso de deseo.",
                "Conclusión Aplicando la negociación automatizada a \"DCSP\", este documento ha propuesto un protocolo que prescribe el razonamiento genérico de un agente \"DCSP\" en una arquitectura BDI.",
                "Nuestro trabajo muestra que varios algoritmos \"DCSP\" conocidos, a saber, ABT, AWC y DBO, pueden describirse como mecanismos que comparten el mismo protocolo propuesto, y solo difieren en las estrategias empleadas para los pasos de razonamiento por ronda de negociación como se rige por el protocolo.",
                "Es importante destacar que esto significa que podría proporcionar un marco unificado para \"DCSP\" que no solo proporciona una visión teórica teórica de agente de BDI de los enfoques \"DCSP\" existentes, sino que también abre las oportunidades para mejorar o desarrollar nuevas estrategias.",
                "También se investigará la idea de los agentes \"DCSP\" que utilizan diferentes estrategias en el mismo entorno.7."
            ],
            "translated_text": "",
            "candidates": [
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP",
                "DCSP"
            ],
            "error": []
        },
        "constraint": {
            "translated_key": "restricción",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed <br>constraint</br> Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed <br>constraint</br> satisfaction framework based on automated negotiation.",
                "The Distributed <br>constraint</br> Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed <br>constraint</br> satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed <br>constraint</br> satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the <br>constraint</br> cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A <br>constraint</br> may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all <br>constraint</br> violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a <br>constraint</br> list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same <br>constraint</br> with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a <br>constraint</br> list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents <br>constraint</br> list in runtime.",
                "As with an agent, a <br>constraint</br> can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a <br>constraint</br> is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its <br>constraint</br> list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and <br>constraint</br> list C, the agent will check if there is any violated <br>constraint</br>.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a <br>constraint</br> violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current <br>constraint</br> violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the <br>constraint</br> violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared <br>constraint</br> is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static <br>constraint</br> weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its <br>constraint</br> list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of <br>constraint</br> l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of <br>constraint</br> violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in <br>constraint</br> violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated <br>constraint</br> by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in <br>constraint</br> violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of <br>constraint</br> violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated <br>constraint</br> with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the <br>constraint</br> violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of <br>constraint</br> satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed <br>constraint</br> satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed <br>constraint</br> satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed <br>constraint</br> satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed <br>constraint</br> satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed <br>constraint</br> satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed <br>constraint</br> satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for <br>constraint</br> satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Algoritmos de \"restricción\" distribuidos unificadores en un marco de negociación de BDI Bao Chau Le Dinh y Kiam Tian SEOW Escuela de Ingeniería Informática Nanyang Universidad Tecnológica República de Singapur {LEDI0002, AsktSeow}@ntu.edu.sg Resumen Este documento presenta una novela, distribuida y distribuida \"\"Restricción \"Marco de satisfacción basado en la negociación automatizada.",
                "El problema distribuido de satisfacción de \"restricción\" (DCSP) es uno que implica varios agentes para buscar un acuerdo, que es una combinación consistente de acciones que satisface sus restricciones mutuas en un entorno compartido.",
                "La introducción en el núcleo de muchas aplicaciones distribuidas emergentes es el problema de satisfacción de \"restricción\" distribuido (DCSP), uno que implica encontrar una combinación consistente de acciones (abstraída como valores de dominio) para satisfacer las restricciones entre múltiples agentes en un entorno compartido.",
                "En este documento, presentamos un marco de satisfacción de \"restricción\" distribuido unificado y unificado basado en la negociación automatizada [9].",
                "De manera similar, como se define para B (i, j), usamos E (L, J)!, (0 ≤ L <m, 0 ≤ J <k), para denotar que XJ es relevante para la \"restricción\" CL.",
                "Una \"restricción\" puede consistir en diferentes variables pertenecientes a diferentes agentes.",
                "Por lo tanto, al buscar cooperativamente una solución DCSP, los agentes necesitarían comunicarse entre sí y ajustar y volver a ajustar sus propias tareas variables en el proceso.2.1 Modelo de agente DCSP En general, todos los agentes DCSP deben interactuar cooperativamente, y esencialmente realizar la asignación y reasignación de valores de dominio a variables para resolver todas las violaciones de \"restricción\".",
                "Para participar en el comportamiento cooperativo, un agente DCSP necesita cinco parámetros fundamentales, a saber, (i) una variable [4] o un conjunto variable [10], (ii) dominios, (iii) prioridad, (iv) una lista de vecinosy (v) una lista de \"restricción\".",
                "Un agente que comparte la misma \"restricción\" con otro agente se llama vecino de los últimos.",
                "Del mismo modo, cada agente mantiene una lista de \"restricción\".",
                "Las restricciones se pueden agregar o eliminar de una lista de \"restricción\" de agentes en tiempo de ejecución.",
                "Al igual que con un agente, una \"restricción\" también puede asociarse con un valor de prioridad.",
                "Para distinguirlo de la prioridad de un agente, la prioridad de una \"restricción\" se llama peso.3.",
                "El agente también actualiza su lista C de \"restricción\" utilizando algunos criterios de la estrategia adoptada.• Creencia.",
                "Usando la imagen P y la lista de \"restricción\" C, el agente verificará si hay alguna \"restricción\" violada.",
                "En caso de que el agente encuentre su valor en conflicto con algunos de sus vecinos, es decir, la combinación de valores asignados a las variables conduce a una violación de \"restricción\", el agente primero intentará reasignar su propia variable utilizando una estrategia específica.",
                "Una vez que se forman las creencias, el agente determinará sus deseos, que son las opciones que intentan resolver las violaciones actuales de \"restricción\".• Deseo.",
                "Dado que si el agente ejecuta su intención sin realizar una mediación de intención con sus vecinos, la violación de la \"restricción\" entre los agentes no puede resolverse.",
                "Tomemos, por ejemplo, suponga que dos agentes tienen variables, x1 y x2, asociadas con el mismo dominio {1, 2}, y su \"restricción\" compartida es (x1 + x2 = 3).",
                "El espacio de diseño al diseñar una estrategia está influenciado por las siguientes dimensiones: (i) asíncrono o sincrónico, (ii) prioridad dinámica o estática, (iii) peso dinámico o estático de \"restricción\", (iv) Número de mensajes de negociación que se comunicarán, (v) El formato del mensaje de negociación y (vi) la propiedad de integridad.",
                "Para describir cada estrategia formalmente, se utilizan las siguientes anotaciones matemáticas: • n es el número de agentes, M es el número de restricciones;• Xi denota la variable sostenida por el agente I, (0 ≤ i <n);• Di denota el dominio de la variable Xi;Fi denota la lista vecina del Agente I;CI denota su lista de \"restricción\";• Pi denota la prioridad del agente I;y pi = {(xj = vj, pj = k) |agente j ∈ Fi, vj ∈ Dj es el valor actual asignado a XJ y el valor de prioridad k es un entero positivo} es la percepción del agente I;• WL denota el peso de \"restricción\" l, (0 ≤ l <m);• Si (V) es el peso total de las restricciones violadas en CI cuando su variable tiene el valor v ∈ Di.4.1 El retroceso asíncrono Figura 2 presenta el modelo de negociación BDI que incorpora la estrategia de retroceso asíncrono (ABT).",
                "Paso 3 - Deseo: la función de deseo GD (BI) devolverá un desire establecido DS, decidido de la siguiente manera: • Si bi = 0, entonces ds = {a |(a = vi), (si (a) = 0) y el número de violaciones de \"restricción\" con agentes de menor prioridad se minimiza}.• Si bi = 1, entonces ds = {a |a ∈ Di y el número de violaciones de todas las restricciones relevantes se minimiza}.• Si bi = 2, entonces ds = ∅.",
                "Paso 3 - Deseo: la función de deseo GD (BI) devolverá un desire establecido DS, decidido de la siguiente manera: • Si bi = 0, entonces ds = {a |a = vi, si (a) <si (vi) y (si (vi) −si (a)) se maximiza}.(Max {(si (vi) −si (a))} será referenciado por Hmax I en pasos posteriores, y define la reducción máxima en las violaciones de \"restricción\").• De lo contrario, ds = ∅.",
                "Percepta creencia Deseo de la intención de ejecución de mediación P B D I I A Información Información Información Mensaje Mensaje Negociación Mensaje de negociación Mensaje Mensaje de negociación Figura 5: Protocolo BDI Con estrategia de asesoramiento mutuo no solicitado • Si todas las intenciones recibidas y su propia son intención, el agente aumentará el peso de cada unoactualmente violó \"restricción\" por 1. 5.",
                "Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) la reducción máxima en las violaciones de \"restricción\".",
                "Los criterios para seleccionar la mejor intención se enumeran, se aplican en orden descendente de importancia de la siguiente manera.• Se prefiere una intención voluntaria sobre una intención reacia.• Se selecciona una intención voluntaria (si la hay) con mayor mejora.• Si no hay intención voluntaria, se selecciona la intención reacia con el menor número de violaciones de \"restricción\".• Se selecciona la intención de un agente que ha recibido un mayor número de consejos de cambio en la ronda de negociación actual.• Se selecciona la intención de un agente con la más alta prioridad.",
                "El Agente 4 enviará un consejo de cambio al Agente 2, ya que el Agente 2 comparte la \"restricción\" violada con él.",
                "Dado que el Agente 2 comparte la violación de la \"restricción\" con el Agente 3, envía un consejo de cambio al Agente 3.",
                "En tal caso, el tiempo de ejecución para la prueba se contó como 1000 ciclos.5.2.1 Evaluación con el problema de N-Ceaens El problema de N-Queens es un problema tradicional de satisfacción de \"restricción\".Se generaron 10 casos de prueba para cada tamaño de problema n ∈ {10, 50 y 100}.",
                "Referencias [1] P. J. Modi, H. Jung, M. Tambe, W.-M.Shen y S. Kulkarni, Asignación dinámica de recursos distribuidos: un enfoque de satisfacción de \"restricción\" distribuido, en Notas de conferencias en informática, 2001, p.264. [2] H. Schlenker y U. Geske, simulando grandes redes ferroviarias utilizando satisfacción de \"restricción\" distribuida, en la segunda conferencia internacional IEEE sobre informática industrial (Indin-04), 2004, pp. 441-446. [3] M. Yokoo, Satisfacción de restricción distribuida: fundamentos de cooperación en sistemas de múltiples agentes.",
                "Springer Verlag, 2000, Serie Springer sobre tecnología de agentes.[4] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara, El problema distribuido de satisfacción de \"restricción\": formalización y algoritmos, transacciones IEEE sobre conocimiento e ingeniería de datos, vol.10, no.5, pp. 673-685, septiembre/octubre de 1998. [5] R. Mailler y V. Lesser, utilizando mediación cooperativa para resolver problemas de satisfacción de \"restricción\" distribuidos, en los procedimientos de la tercera conferencia conjunta internacional sobre agentes autónomos y sistemas multiagentes(AAMAS-04), 2004, pp. 446-453.[6] E. Tsang, Fundación de satisfacción de restricción.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop y J. Shen, en tiempo real suave, negociación cooperativa para la asignación de recursos distribuidos, Simposio AAAI Fall sobre métodos de negociación autónomos para la cooperativa autónomaSystems, noviembre de 2001. [8] M. Yokoo, K. Suzuki y K. Hirayama, Satisfacción de \"restricción\" distribuida segura: llegar a un acuerdo sin revelar información privada, inteligencia artificial, vol.161, no.1-2, pp. 229-246, 2005. [9] J. S. Rosenschein y G. Zlotkin, Reglas de encuentro.",
                "The MIT Press, 1994. [10] M. Yokoo y K. Hirayama, Algoritmo de satisfacción de \"restricción\" distribuido para problemas locales complejos, en las actas de la tercera conferencia internacional sobre sistemas multiagentes (ICMAS-98), 1998, pp. 372-379.[11] M. E. Bratman, Intenciones, planes y razones prácticas.",
                "B. Philips y P. Laird, Minimización de conflictos: un método de reparación heurística para problemas de satisfacción y programación de \"restricción\", Inteligencia Artificial, vol.E58, no.1-3, pp. 161-205, 1992."
            ],
            "translated_text": "",
            "candidates": [
                "restricción",
                "restricción",
                "Restricción ",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "Restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "restricción",
                "Restricción",
                "restricción"
            ],
            "error": []
        },
        "shared environment": {
            "translated_key": "entorno compartido",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a <br>shared environment</br>.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a <br>shared environment</br>.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "El problema de satisfacción de restricción distribuido (DCSP) es uno que implica varios agentes para buscar un acuerdo, que es una combinación consistente de acciones que satisface sus limitaciones mutuas en un \"entorno compartido\".",
                "La introducción en el núcleo de muchas aplicaciones distribuidas emergentes es el problema de satisfacción de restricciones distribuidas (DCSP), uno que implica encontrar una combinación consistente de acciones (abstraída como valores de dominio) para satisfacer las restricciones entre múltiples agentes en un \"entorno compartido\"."
            ],
            "translated_text": "",
            "candidates": [
                "entorno compartido",
                "entorno compartido",
                "entorno compartido",
                "entorno compartido"
            ],
            "error": []
        },
        "algorithm": {
            "translated_key": "algoritmo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one <br>algorithm</br> is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or <br>algorithm</br>) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the <br>algorithm</br> was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction <br>algorithm</br> for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Como resultado, por ejemplo, una comprensión intelectual más profunda sobre por qué un \"algoritmo\" es mejor que el otro, más allá de los problemas computacionales, no es posible.",
                "La búsqueda se puede realizar a través de un mecanismo de negociación (o \"algoritmo\") mediante el cual los agentes siguen un protocolo de alto nivel que prescribe las reglas de interacciones, utilizando un conjunto de estrategias ideadas para seleccionar sus propias preferencias en cada paso de negociación.",
                "El programa del simulador se terminó después de este período y se consideró que el \"algoritmo\" falla un caso de prueba si no encontraba una solución para entonces.",
                "The MIT Press, 1994. [10] M. Yokoo y K. Hirayama, Satisfacción de restricción distribuida \"Algoritmo\" para problemas locales complejos, en las actas de la Tercera Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-98), 1998, pp. 372-379.[11] M. E. Bratman, Intenciones, planes y razones prácticas."
            ],
            "translated_text": "",
            "candidates": [
                "algoritmo",
                "algoritmo",
                "algoritmo",
                "algoritmo",
                "algoritmo",
                "algoritmo",
                "algoritmo",
                "Algoritmo"
            ],
            "error": []
        },
        "backtracking": {
            "translated_key": "retroceso",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous <br>backtracking</br> (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical <br>backtracking</br> algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous <br>backtracking</br> strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous <br>backtracking</br> Figure 2 presents the BDI negotiation model incorporating the Asynchronous <br>backtracking</br> (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous <br>backtracking</br> Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the <br>backtracking</br> in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Se han desarrollado muchos algoritmos importantes, como la ruptura distribuida (DBO) [3], el \"retroceso\" asincrónico (ABT) [4], la superposición parcial asincrónica (APO) [5] y el compromiso débil asincrónico (AWC) [4] [4]Para abordar el DCSP y proporcionar la base de la solución del agente para sus aplicaciones.",
                "En términos generales, estos algoritmos se basan en dos enfoques diferentes, ya sea que se extienden desde los algoritmos clásicos de \"retroceso\" [6] o que introducen mediación entre los agentes.",
                "Dentro del protocolo, a menudo determinará la eficiencia de la percepción del deseo de la intención de la ejecución de la mediación P B D I Información Información Información Mensaje de negociación Mensaje de negociación Mensaje Mensaje Figura 2: Protocolo BDI Con proceso de búsqueda de estrategia de \"retroceso\" asíncrono en términos de ciclos computacionales y comunicación de mensajescostos.",
                "Para describir cada estrategia formalmente, se utilizan las siguientes anotaciones matemáticas: • n es el número de agentes, M es el número de restricciones;• Xi denota la variable sostenida por el agente I, (0 ≤ i <n);• Di denota el dominio de la variable Xi;Fi denota la lista vecina del Agente I;CI denota su lista de restricciones;• Pi denota la prioridad del agente I;y pi = {(xj = vj, pj = k) |agente j ∈ Fi, vj ∈ Dj es el valor actual asignado a XJ y el valor de prioridad k es un entero positivo} es la percepción del agente I;• WL denota el peso de la restricción l, (0 ≤ l <m);• Si (V) es el peso total de las restricciones violadas en CI cuando su variable tiene el valor v ∈ Di.4.1 La Figura 2 de \"retroceso\" asíncrono presenta el modelo de negociación BDI que incorpora la estrategia asincrónica de \"retroceso\" (ABT).",
                "Para cada problema, se generó un número finito de casos de prueba para varios tamaños de problemas n.El tiempo de ejecución máxima se estableció en 0 200 400 600 800 1000 10 50 100 Número de ciclos de reinas \"retroceso\" asíncrono \"compromiso débil asíncrono Asesoramiento mutuo no solicitado Figura 9: Relación entre el tiempo de ejecución y el tamaño del problema 10000 ciclos para el color de nodos para gráficos críticos y 1000 1000ciclos para otros problemas.",
                "Como observamos del \"retroceso\" en ABT y AWC, la diferencia en el orden de los mensajes entrantes puede dar como resultado un número diferente de ciclos computacionales para ser ejecutados por los agentes.5.3.2 Comparación con DBO El rendimiento computacional de UMA es posiblemente mejor que DBO por las siguientes razones: • Uma puede garantizar que habrá una reasignación variable después de cada ronda de negociación, mientras que DBO no puede.• Uma presenta un viaje de ida y vuelta de comunicación más (el de enviar un mensaje y esperar una respuesta) que DBO, que ocurre debido a la necesidad de comunicar consejos no solicitados."
            ],
            "translated_text": "",
            "candidates": [
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso",
                "retroceso"
            ],
            "error": []
        },
        "mediation": {
            "translated_key": "mediación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing <br>mediation</br> among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention <br>mediation</br> Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for <br>mediation</br> purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "<br>mediation</br> is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, <br>mediation</br> is required in every negotiation round.",
                "In an asynchronous one, <br>mediation</br> is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this <br>mediation</br> step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo <br>mediation</br>.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • <br>mediation</br>.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention <br>mediation</br> with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of <br>mediation</br> between them.",
                "There are two types of <br>mediation</br>: local <br>mediation</br> and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this <br>mediation</br> is passed back to the agents in the group.",
                "Following <br>mediation</br>, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention <br>mediation</br> Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the <br>mediation</br> step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "<br>mediation</br>: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention <br>mediation</br> Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "<br>mediation</br>: This step is identical to the <br>mediation</br> step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention <br>mediation</br> Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to <br>mediation</br> step.",
                "<br>mediation</br>: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention <br>mediation</br> Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to <br>mediation</br> step.",
                "<br>mediation</br>: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "<br>mediation</br>: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "<br>mediation</br>: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative <br>mediation</br> to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En términos generales, estos algoritmos se basan en dos enfoques diferentes, ya sea que se extienden desde los algoritmos de retroceso clásico [6] o introducen \"mediación\" entre los agentes.",
                "La línea punteada indica la intención de la creencia de percepción intención de \"mediación\" Ejecución P B D I I I Info Mensaje Información Mensaje Negociación Mensaje Negociación Mensaje de negociación Mensaje de negociación Mensaje de negociación Mensaje de negociación Mensaje Figura 1: El componente de protocolo de interacción BDI o transición que puede o no aparecer dependiendo de depender de de depender de de ser dependiendo de lala estrategia adoptada.",
                "Este mensaje es para fines de \"mediación\".",
                "La \"mediación\" es un paso del protocolo que depende de si la interacción de los agentes con otros es sincrónica o asíncrona.",
                "En el mecanismo sincrónico, se requiere \"mediación\" en cada ronda de negociación.",
                "En una asíncrona, se necesita \"mediación\" solo en una ronda de negociación cuando el agente recibe un mensaje de negociación.",
                "Una visión más profunda de este paso de \"mediación\" se proporciona más adelante en esta sección.",
                "Una vez que se forma la intención, el agente puede proceder al paso de ejecución o someterse a \"mediación\".",
                "Nuevamente, la decisión de hacerlo está determinada por algunos criterios de la estrategia adoptada.• \"Mediación\".",
                "Dado que si el agente ejecuta su intención sin realizar la \"mediación\" de la intención con sus vecinos, la violación de la restricción entre los agentes no puede resolverse.",
                "Luego, si ambas variables se inicializan con el valor 1, cambiarán simultáneamente entre los valores 2 y 1 en ausencia de \"mediación\" entre ellas.",
                "Hay dos tipos de \"mediación\": \"mediación\" local y mediación grupal.",
                "El resultado de esta \"mediación\" se transfiere a los agentes del grupo.",
                "Después de la \"mediación\", el agente puede proceder al siguiente paso de razonamiento para ejecutar su intención o comenzar una nueva ronda de negociación.• Ejecución.",
                "Dentro del protocolo, a menudo determinará la eficiencia de la percepción de la creencia de la creencia, la intención de \"mediación\" P B D I Info Mensaje Información Mensaje de negociación Mensaje de negociación Mensaje de negociación Figura 2: Protocolo BDI Con proceso de búsqueda de estrategia de retroceso asíncrono en términos de ciclos computacionales y mensajes Comunicación de mensajescostos.",
                "Como se menciona en la Sección 3, para un mecanismo asincrónico que ABT es, el paso de \"mediación\" solo se necesita en una ronda de negociación cuando un agente recibe un mensaje de negociación.",
                "\"Mediación\": cuando el agente I recibe un mensaje de negociación, se llevan a cabo varios subpasos, de la siguiente manera: • Si la lista de agentes asociados con el mensaje de negociación contiene agentes que no están en FI, agregará estos agentes a FI,y solicite a estos agentes que se agregen a sus listas de vecinos.",
                "Paso 2 - Creencia: la función de creencia GB (PI, CI) devolverá un valor bi ∈ ∈ {0, 1, 2}, decidido de la siguiente manera: Percept BRISTA DESEMIENTO INTENCIÓN \"Mediación\" P B D I Información Información Información Mensaje Negociación Mensaje Negociación NegociaciónMensaje Figura 3: Protocolo BDI con estrategia asincrónica de compromiso débil • bi = 0 Cuando el agente puede encontrar una opción óptima, es decir, if (si (vi) = 0 o la asignación xi = vi y las asignaciones de variables actuales de los vecinos en FiForma de mayor prioridad A Nogood [4]) almacenado en una lista llamada Lista de Nogood y ∃a ∈ Di, Si (a) = 0 (inicialmente la lista está vacía).• bi = 1 Cuando el agente no puede encontrar ninguna opción óptima, es decir, si ∀a ∈ Di, si (a) = 0. • bi = 2 cuando la asignación actual es una opción óptima, es decir, si si (vi) = 0 y elEl estado actual no es un nogood en la lista de Nogood.",
                "\"Mediación\": este paso es idéntico al paso de \"mediación\" de ABT, excepto que el agente ahora agregaré el nogood contenido en el mensaje de negociación recibido a su propia lista de Nogood.4.3 Breakout distribuido La Figura 4 presenta el modelo de negociación BDI que incorpora la estrategia de ruptura distribuida (DBO).",
                "Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 527 Perceptel creencia Deseo de la intención \"Mediación\" Ejecución P B D I I Información Mensaje Información Mensaje de negociación Mensaje de negociación Figura 4: Protocolo BDI con estrategia de ruptura distribuida Estas restricciones se incrementarán en 1 para ayudar a la ruptura desdeun mínimo local.",
                "A cambio, recibirá intenciones de estos agentes antes de proceder al paso de \"mediación\".",
                "\"Mediación\": el agente I recibe todas las intenciones de sus vecinos.",
                "Percept Believe Deseo intención \"Mediación\" Ejecución P B D I I A Información Mensaje Información Negociación Mensaje Negociación Mensaje de negociación Mensaje de negociación Mensaje Figura 5: Protocolo BDI Con Strategia de asesoramiento mutuo no solicitado • Si todas las intenciones recibidas y su propia son intención, el agente aumentará el peso del pesode cada restricción violada actualmente por 1. 5.",
                "A cambio, agente, recibiré las intenciones de sus vecinos antes de proceder al paso de \"mediación\".",
                "\"Mediación\": si el agente I no envía su intención antes de este paso, es decir, el agente tiene una intención nula o una intención voluntaria con la mayor mejora, procederá al siguiente paso.",
                "\"Mediación\": el Agente 1 encuentra que la intención del Agente 2 es mejor que su intención.",
                "\"Mediación\": el Agente 3 mantendrá su intención como su único vecino, el Agente 2, no tiene ninguna intención.",
                "Springer Verlag, 2000, Serie Springer sobre tecnología de agentes.[4] M. Yokoo, E. H. Durfee, T. Ishida y K. Kuwabara, El problema de satisfacción de restricciones distribuidas: formalización y algoritmos, transacciones IEEE sobre conocimiento e ingeniería de datos, vol.10, no.5, pp. 673-685, septiembre/octubre de 1998. [5] R. Mailler y V. Lesser, utilizando la \"mediación\" cooperativa para resolver problemas distribuidos de satisfacción de restricciones, en los procedimientos de la tercera conferencia conjunta internacional sobre agentes autónomos y sistemas multiagentes.(AAMAS-04), 2004, pp. 446-453.[6] E. Tsang, Fundación de satisfacción de restricción."
            ],
            "translated_text": "",
            "candidates": [
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "Mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "mediación",
                "Mediación",
                "mediación",
                "Mediación",
                "mediación",
                "Mediación",
                "mediación",
                "mediación",
                "Mediación",
                "mediación",
                "mediación",
                "mediación",
                "Mediación",
                "Mediación",
                "Mediación",
                "mediación",
                "mediación",
                "mediación",
                "Mediación",
                "mediación",
                "Mediación",
                "mediación",
                "Mediación",
                "mediación",
                "mediación"
            ],
            "error": []
        },
        "resource restriction": {
            "translated_key": "restricción de recursos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as <br>resource restriction</br>s (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Si bien no ha habido falta de esfuerzos en este campo de investigación prometedor, especialmente en el manejo de problemas pendientes como \"restricción de recursos\" s (por ejemplo, límites en el tiempo y la comunicación) [7] y los requisitos de privacidad [8], desafortunadamente no hayTratamiento conceptualmente claro para abrir el funcionamiento teórico modelo de los diversos algoritmos de agentes que se han desarrollado."
            ],
            "translated_text": "",
            "candidates": [
                "restricción de recursos",
                "restricción de recursos"
            ],
            "error": []
        },
        "privacy requirement": {
            "translated_key": "requisito de privacidad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and <br>privacy requirement</br>s [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Si bien no ha habido falta de esfuerzos en este campo de investigación prometedor, especialmente en el tratamiento de problemas pendientes, como restricciones de recursos (por ejemplo, límites en el tiempo y la comunicación) [7] y el \"requisito de privacidad\" s [8], desafortunadamente no hayTratamiento conceptualmente claro para abrir el funcionamiento teórico modelo de los diversos algoritmos de agentes que se han desarrollado."
            ],
            "translated_text": "",
            "candidates": [
                "requisito de privacidad",
                "requisito de privacidad"
            ],
            "error": []
        },
        "negotiation": {
            "translated_key": "negociación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI <br>negotiation</br> Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated <br>negotiation</br>.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated <br>negotiation</br>, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated <br>negotiation</br> [9].",
                "<br>negotiation</br> is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a <br>negotiation</br> mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each <br>negotiation</br> step.",
                "Anchoring the DCSP search on automated <br>negotiation</br>, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI <br>negotiation</br> model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI <br>negotiation</br> MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated <br>negotiation</br> [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a <br>negotiation</br> protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed <br>negotiation</br> model can be said to combine the BDI concepts with automated <br>negotiation</br> in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message <br>negotiation</br> Message <br>negotiation</br> Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the <br>negotiation</br> message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one <br>negotiation</br> round (also called a <br>negotiation</br> cycle), and received at the beginning of next round.",
                "A <br>negotiation</br> message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the <br>negotiation</br> message and when it is to be sent out are subject to the strategy.",
                "A <br>negotiation</br> message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every <br>negotiation</br> round.",
                "In an asynchronous one, mediation is needed only in a <br>negotiation</br> round when the agent receives a <br>negotiation</br> message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP <br>negotiation</br>.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new <br>negotiation</br> round. • Execution.",
                "This is the last step of a <br>negotiation</br> round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the <br>negotiation</br> process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message <br>negotiation</br> Message <br>negotiation</br> Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of <br>negotiation</br> messages to be communicated, (v) the <br>negotiation</br> message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI <br>negotiation</br> model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI <br>negotiation</br> model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a <br>negotiation</br> round when an agent receives a <br>negotiation</br> message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a <br>negotiation</br> message to agent k, then remove k from Fi and begin its next <br>negotiation</br> round.",
                "The <br>negotiation</br> message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a <br>negotiation</br> message, several sub-steps are carried out, as follows: • If the list of agents associated with the <br>negotiation</br> message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of <br>negotiation</br> message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next <br>negotiation</br> round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI <br>negotiation</br> model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message <br>negotiation</br> Message <br>negotiation</br> Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the <br>negotiation</br> message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same <br>negotiation</br> message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the <br>negotiation</br> message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the <br>negotiation</br> message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI <br>negotiation</br> model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message <br>negotiation</br> Message <br>negotiation</br> Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message <br>negotiation</br> Message <br>negotiation</br> Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI <br>negotiation</br> model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a <br>negotiation</br> message when concluding its Intention step, but also when concluding its Desire step.",
                "The <br>negotiation</br> message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a <br>negotiation</br> message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a <br>negotiation</br> message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current <br>negotiation</br> round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current <br>negotiation</br> round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the <br>negotiation</br> messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every <br>negotiation</br> round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this <br>negotiation</br> round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more <br>negotiation</br> message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a <br>negotiation</br> round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every <br>negotiation</br> round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per <br>negotiation</br> round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of <br>negotiation</br> rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated <br>negotiation</br> to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per <br>negotiation</br> round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI <br>negotiation</br> mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative <br>negotiation</br> for Distributed Resource Allocation, AAAI Fall Symposium on <br>negotiation</br> Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Unifying Distributed Constraint Algorithms in a BDI \"negotiation\" Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraintMarco de satisfacción basado en la \"negociación\" automatizada.",
                "Al anclar la búsqueda DCSP en la \"negociación\" automatizada, mostramos que varios algoritmos DCSP bien conocidos son en realidad mecanismos que pueden llegar a acuerdos a través de un protocolo común de intención de creencia (BDI), pero utilizando diferentes estrategias.",
                "En este artículo, presentamos un marco de satisfacción de restricción distribuido unificado y novedoso basado en la \"negociación\" automatizada [9].",
                "La \"negociación\" se considera un proceso de varios agentes que buscan una solución llamada acuerdo.",
                "La búsqueda se puede realizar a través de un mecanismo de \"negociación\" (o algoritmo) mediante el cual los agentes siguen un protocolo de alto nivel que prescribe las reglas de interacciones, utilizando un conjunto de estrategias ideadas para seleccionar sus propias preferencias en cada paso de \"negociación\".",
                "Anclar la búsqueda DCSP en la \"negociación\" automatizada, mostramos en este documento que varios algoritmos DCSP bien conocidos [3] son en realidad mecanismos que comparten el mismo protocolo de interacción de la intención de creencia (BDI) para alcanzar acuerdos, pero usan diferentes acciones o valor de valor.Estrategias de selección.",
                "La Sección 3 presenta un modelo de \"negociación\" BDI mediante el cual un agente DCSP razona.",
                "El modelo de \"negociación\" BDI El modelo BDI se origina con el trabajo de M. Bratman [11].",
                "En la \"negociación\" automatizada [9], dicha solución se denomina acuerdo entre los agentes.",
                "Dentro de este alcance, descubrimos que pudimos descubrir el comportamiento genérico de un agente DCSP y formularlo en un protocolo de \"negociación\", prescrito utilizando los poderosos conceptos de BDI.",
                "Por lo tanto, se puede decir que nuestro modelo de \"negociación\" propuesto combina los conceptos BDI con la \"negociación\" automatizada en un marco multiagente, lo que nos permite separar los mecanismos DCSP conceptualmente en un protocolo de interacción BDI común y las estrategias adoptadas.3.1 El protocolo genérico Figura 1 muestra los pasos de razonamiento básicos en una ronda arbitraria de negociación que constituye el nuevo protocolo.",
                "La línea punteada indica la percepción de la creencia del deseo de ejecución de mediación de intención P B D I I I Info Mensaje Mensaje Información \"Mensaje\" Mensaje \"Negociación\" Mensaje de negociación Mensaje de negociación Mensaje de negociación Mensaje de negociación Mensaje Figura 1: El componente de protocolo de interacción BDI o transición que puede o no puede aparecerdependiendo de la estrategia adoptada.",
                "Se intercambian dos tipos de mensajes a través de este protocolo, a saber, el mensaje de información y el mensaje de \"negociación\".",
                "El mensaje de información se envía al final de una ronda de \"negociación\" (también llamada ciclo de \"negociación\"), y se recibe al comienzo de la próxima ronda.",
                "Un mensaje de \"negociación\" es un mensaje que puede enviarse dentro de una ronda.",
                "El formato del mensaje de \"negociación\" y cuándo se enviará está sujeto a la estrategia.",
                "Se puede enviar un mensaje de \"negociación\" al final de un paso de razonamiento y recibir al comienzo del siguiente paso.",
                "En el mecanismo sincrónico, se requiere mediación en cada ronda de \"negociación\".",
                "En una asíncrona, la mediación solo se necesita en una ronda de \"negociación\" cuando el agente recibe un mensaje de \"negociación\".",
                "El protocolo BDI prescribe la estructura esquelética para la \"negociación\" de DCSP.",
                "Después de la mediación, el agente puede proceder al siguiente paso de razonamiento para ejecutar su intención o comenzar una nueva ronda de \"negociación\".• Ejecución.",
                "Este es el último paso de una ronda de \"negociación\".",
                "Para hacerlo, el agente enviará un mensaje de información.3.2 La estrategia Una estrategia juega un papel importante en el proceso de \"negociación\".",
                "Dentro del protocolo, a menudo determinará la eficiencia de la percepción de la creencia del deseo de ejecución de la mediación de la intención P B D I Información Mensaje Mensaje de información \"Negociación\" Mensaje \"Negociación\" Mensaje de negociación Figura 2: Protocolo BDI con el proceso de búsqueda de estrategia de retroceso asíncrono en términos de ciclos de computación y computación.Costos de comunicación de mensajes.",
                "El espacio de diseño al diseñar una estrategia está influenciado por las siguientes dimensiones: (i) asíncrono o sincrónico, (ii) prioridad dinámica o estática, (iii) peso dinámico o de restricción estática, (iv) Mensajes de \"negociación\" que se comunicarán, (v) El formato de mensaje de \"negociación\" y (vi) la propiedad de integridad.",
                "Algoritmos DCSP: estrategias BDI Protocolo + En esta sección, aplicamos el modelo de \"negociación\" BDI propuesto presentado en la Sección 3 para exponer el protocolo BDI y las diferentes estrategias utilizadas para tres algoritmos conocidos, ABT, AWC y DBO.",
                "Para describir cada estrategia formalmente, se utilizan las siguientes anotaciones matemáticas: • n es el número de agentes, M es el número de restricciones;• Xi denota la variable sostenida por el agente I, (0 ≤ i <n);• Di denota el dominio de la variable Xi;Fi denota la lista vecina del Agente I;CI denota su lista de restricciones;• Pi denota la prioridad del agente I;y pi = {(xj = vj, pj = k) |agente j ∈ Fi, vj ∈ Dj es el valor actual asignado a XJ y el valor de prioridad k es un entero positivo} es la percepción del agente I;• WL denota el peso de la restricción l, (0 ≤ l <m);• Si (V) es el peso total de las restricciones violadas en CI cuando su variable tiene el valor v ∈ Di.4.1 retroceso asíncrono La Figura 2 presenta el modelo de \"negociación\" BDI que incorpora la estrategia de retroceso asíncrono (ABT).",
                "Como se menciona en la Sección 3, para un mecanismo asincrónico que es ABT, el paso de mediación solo se necesita en una ronda de \"negociación\" cuando un agente recibe un mensaje de \"negociación\".",
                "Paso 5 - Ejecución: • Si el agente I tiene un valor de dominio como intención, el agente actualizará su asignación variable con este valor.• Si bi = 1, agente enviaré un mensaje de \"negociación\" al Agente K, luego eliminará K de FI y comenzará su próxima ronda de \"negociación\".",
                "El mensaje de \"negociación\" contendrá la lista de asignaciones variables de esos agentes en su lista de vecinos FI que tienen una prioridad más alta que el agente I en la imagen actual Pi.",
                "Mediación: cuando el agente I recibe un mensaje de \"negociación\", se llevan a cabo varios subpasos, de la siguiente manera: • Si la lista de agentes asociados con el mensaje de \"negociación\" contiene agentes que no están en FI, agregará estos agentes aFI, y solicite a estos agentes que se agregen a sus listas de vecinos.",
                "La solicitud se considera como un tipo de mensaje de \"negociación\".• Agente Primero verificaré si el agente del remitente se actualiza con su valor actual VI.",
                "Después de este paso, el agente I procede a la próxima ronda de \"negociación\".4.2 Búsqueda de compromiso débil asincrónico La Figura 3 presenta el modelo de \"negociación\" BDI que incorpora la estrategia de compromiso débil asincrónico (AWC).",
                "Paso 2 - Creencia: la función de creencia GB (PI, CI) devolverá un valor bi ∈ ∈ {0, 1, 2}, decidido de la siguiente manera: Percept CREVERSE Ejecución de mediación de la intención P B D I Información Mensaje Mensaje \"Negociación\" Mensaje \"Negociación\"Mensaje de negociación de mensajes Figura 3: Protocolo BDI con estrategia de comisión débil asincrónica • Bi = 0 Cuando el agente puede encontrar una opción óptima, es decir, if (Si (VI) = 0 o la asignación xi = VI y las asignaciones de variables actuales de los vecinos en FIquienes tienen una forma de mayor prioridad un nogood [4]) almacenado en una lista llamada nogood lista y ∃a ∈ Di, si (a) = 0 (inicialmente la lista está vacía).• bi = 1 Cuando el agente no puede encontrar ninguna opción óptima, es decir, si ∀a ∈ Di, si (a) = 0. • bi = 2 cuando la asignación actual es una opción óptima, es decir, si si (vi) = 0 y elEl estado actual no es un nogood en la lista de Nogood.",
                "Sin embargo, para esta estrategia, el mensaje de \"negociación\" contendrá las asignaciones de variables (de la imagen actual Pi) para todos los agentes en KI.",
                "Si el mismo mensaje de \"negociación\" se había enviado antes, agente, tendré intención nula.",
                "Paso 5 - Ejecución: • Si el agente I tiene un valor de dominio como intención, el agente actualizará su asignación variable con este valor.• Si bi = 1, enviará el mensaje de \"negociación\" a sus vecinos en ki, y establecerá pi = max {pj} + 1, con agente j ∈ Fi.",
                "Mediación: Este paso es idéntico al paso de mediación de ABT, excepto que el agente ahora agregaré el Nogood contenido en el mensaje de \"negociación\" recibido a su propia lista de Nogood.4.3 Breakout distribuido La Figura 4 presenta el modelo de \"negociación\" BDI que incorpora la estrategia de ruptura distribuida (DBO).",
                "Conf.Sobre agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 527 Percept Believe Deseo intención Ejecución de mediación P B D I I A Información Mensaje Información Mensaje \"Negociación\" Mensaje \"Negociación\" Mensaje Figura 4: Protocolo BDI con estrategia de ruptura distribuida Estas restricciones se incrementarán en 1 para ayudar a ayudar a 1Breakout desde un mínimo local.",
                "Percept Believe Deseo Intención Mediación Ejecución P B D I I A Información Mensaje Información Mensaje \"Negociación\" Mensaje \"Negociación\" Mensaje Mensaje de negociación Mensaje de negociación Figura 5: Protocolo BDI Con estrategia de asesoramiento mutuo no solicitado • Si todas las intenciones recibidas y su propia son intención, el agente aumentaráEl peso de cada restricción violada actualmente por 1. 5.",
                "La Estrategia UMA Figura 5 presenta el modelo de \"negociación\" BDI que incorpora la estrategia de asesoramiento mutuo no solicitado (UMA).",
                "A diferencia del uso de las estrategias de la sección anterior, un agente DCSP que usa UMA no solo enviará un mensaje de \"negociación\" al concluir su paso de intención, sino también al concluir su paso de deseo.",
                "El mensaje de \"negociación\" que envía para concluir el paso del deseo constituye un consejo no solicitado para todos sus vecinos.",
                "Siguiendo, si Bi = 0, agente enviaré un mensaje de \"negociación\" que contenga Hmax I a todos sus vecinos.",
                "Si bi = 1, agente enviaré un mensaje de \"negociación\" llamado consejo de cambio a los vecinos en FI que comparten las limitaciones violadas con el agente i.",
                "En ambos casos, el agente I adjuntará el número de consejos de cambio recibidos en la ronda de \"negociación\" actual con su intención.",
                "Los criterios para seleccionar la mejor intención se enumeran, se aplican en orden descendente de importancia de la siguiente manera.• Se prefiere una intención voluntaria sobre una intención reacia.• Se selecciona una intención voluntaria (si la hay) con mayor mejora.• Si no hay intención voluntaria, se selecciona la intención reacia con el menor número de violaciones de restricciones.• Se selecciona la intención de un agente que ha recibido un mayor número de consejos de cambio en la ronda actual de \"negociación\".• Se selecciona la intención de un agente con la más alta prioridad.",
                "Por lo tanto, se necesita un observador que realizará un seguimiento de los mensajes de \"negociación\" comunicados en el entorno.",
                "El siguiente registra el resultado de cada paso en cada ronda de \"negociación\" ejecutada.",
                "En esta ronda de \"negociación\", las mejoras logradas por estos agentes son 1.",
                "A continuación, sin más comunicación de mensajes de \"negociación\" en el entorno, el observador informará a todos los agentes que se ha encontrado una solución.2 3 4 5 6 7 8 91 10 Figura 8: La solución obtuvo una evaluación de rendimiento 5.2 para facilitar las comparaciones creíbles con las estrategias existentes, medimos el tiempo de ejecución en términos de ciclos computacionales como se define en [4], y construimos un simulador que podría reproducirLos resultados publicados para ABT y AWC.",
                "Dado que solo unos pocos agentes tienen derecho a cambiar sus asignaciones variables en una ronda de \"negociación\", se reduce el número de ciclos computacionales redundantes y mensajes de información.",
                "Como observamos del retroceso en ABT y AWC, la diferencia en el orden de los mensajes entrantes puede dar lugar a un número diferente de ciclos computacionales para ser ejecutados por los agentes.5.3.2 Comparación con DBO El rendimiento computacional de UMA es posiblemente mejor que DBO por las siguientes razones: • Uma puede garantizar que habrá una reasignación variable después de cada ronda de \"negociación\", mientras que DBO no puede.• Uma presenta un viaje de ida y vuelta de comunicación más (el de enviar un mensaje y esperar una respuesta) que DBO, que ocurre debido a la necesidad de comunicar consejos no solicitados.",
                "Aunque esto aumenta el costo de comunicación por ronda de \"negociación\", observamos a partir de nuestras simulaciones que el costo general de comunicación incurrido por UMA es menor debido al número significativamente menor de rondas de \"negociación\".• Usando UMA, en el peor de los casos, un agente solo tomará 2 o 3 viajes de la ronda de comunicación por ronda de negociación, después de lo cual el agente o su vecino hará una actualización de asignación variable.",
                "Conclusión Aplicación de \"negociación\" automatizada a DCSP, este documento ha propuesto un protocolo que prescribe el razonamiento genérico de un agente DCSP en una arquitectura BDI.",
                "Nuestro trabajo muestra que varios algoritmos DCSP bien conocidos, a saber, ABT, AWC y DBO, pueden describirse como mecanismos que comparten el mismo protocolo propuesto, y solo difieren en las estrategias empleadas para los pasos de razonamiento por \"negociación\" ronda como se rige por el protocolo.",
                "El trabajo futuro intentará establecer formalmente esta propiedad, así como formalizar otros algoritmos DSCP existentes como mecanismos de \"negociación\" de BDI, incluido el reciente esfuerzo que emplea a un mediador grupal [5].",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop y J. Shen, en tiempo real suave, \"negociación\" cooperativa para la asignación de recursos distribuidos, el simposio de caída de AAAI sobre \"negociación\"Métodos para sistemas cooperativos autónomos, noviembre de 2001. [8] M. Yokoo, K. Suzuki y K. Hirayama, Satisfacción de restricción distribuida segura: llegar a un acuerdo sin revelar información privada, inteligencia artificial, vol.161, no.1-2, pp. 229-246, 2005. [9] J. S. Rosenschein y G. Zlotkin, Reglas de encuentro."
            ],
            "translated_text": "",
            "candidates": [
                "negociación",
                "negotiation",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "Mensaje",
                "Negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "Negociación",
                "Negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "Negociación",
                "Negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "Negociación",
                "Negociación",
                "Negociación",
                "Negociación",
                "Negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "Negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación",
                "negociación"
            ],
            "error": []
        },
        "bdi": {
            "translated_key": "bdi",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a <br>bdi</br> Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (<br>bdi</br>) protocol, but using different strategies.",
                "A major motivation for this <br>bdi</br> framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (<br>bdi</br>) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified <br>bdi</br> agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a <br>bdi</br> negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE <br>bdi</br> NEGOTIATION MODEL The <br>bdi</br> model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the <br>bdi</br> architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of <br>bdi</br>.",
                "Thus, our proposed negotiation model can be said to combine the <br>bdi</br> concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common <br>bdi</br> interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The <br>bdi</br> interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The <br>bdi</br> protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: <br>bdi</br> protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: <br>bdi</br> PROTOCOL + STRATEGIES In this section, we apply the proposed <br>bdi</br> negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the <br>bdi</br> negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its <br>bdi</br>-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the <br>bdi</br> negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its <br>bdi</br>-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: <br>bdi</br> protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the <br>bdi</br> negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: <br>bdi</br> protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its <br>bdi</br>-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: <br>bdi</br> protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the <br>bdi</br> negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its <br>bdi</br>-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a <br>bdi</br> architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer <br>bdi</br> agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as <br>bdi</br> negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Unifying Distributed Constraint Algorithms in a \"bdi\" Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraintMarco de satisfacción basado en la negociación automatizada.",
                "Al anclar la búsqueda de DCSP en la negociación automatizada, mostramos que varios algoritmos DCSP bien conocidos son en realidad mecanismos que pueden llegar a acuerdos a través de un protocolo común de intención de creencia (\"BDI\"), pero utilizando diferentes estrategias.",
                "Una motivación importante para este marco \"BDI\" es que no solo proporciona una comprensión conceptualmente más clara de los algoritmos DCSP existentes desde una perspectiva del modelo de agente, sino que también abre las oportunidades para extender y desarrollar nuevas estrategias para DCSP.",
                "Anclar la búsqueda DCSP en la negociación automatizada, mostramos en este documento que varios algoritmos DCSP bien conocidos [3] son en realidad mecanismos que comparten el mismo protocolo de interacción (\"BDI\") para alcanzar acuerdos, pero utilizan diferentes acciones o valor de valor.Estrategias de selección.",
                "El marco propuesto proporciona no solo una comprensión más clara de los algoritmos DCSP existentes desde una perspectiva de agente \"BDI\" unificado, sino que también abre las oportunidades para extender y desarrollar nuevas estrategias para DCSP.",
                "La Sección 3 presenta un modelo de negociación \"BDI\" mediante el cual razona un agente DCSP.",
                "El modelo de negociación \"BDI\" El modelo \"BDI\" se origina con el trabajo de M. Bratman [11].",
                "Según [12, Ch.1], la arquitectura \"BDI\" se basa en un modelo filosófico de razonamiento práctico humano, y extrae el proceso de razonamiento por el cual un agente decide qué acciones realizar en momentos consecutivos cuando persiguen ciertas metas.",
                "Dentro de este alcance, descubrimos que pudimos descubrir el comportamiento genérico de un agente DCSP y formularlo en un protocolo de negociación, prescrito utilizando los poderosos conceptos de \"BDI\".",
                "Por lo tanto, se puede decir que nuestro modelo de negociación propuesto combina los conceptos \"BDI\" con una negociación automatizada en un marco multiagente, lo que nos permite separar los mecanismos DCSP conceptualmente en un protocolo de interacción \"BDI\" común y las estrategias adoptadas.3.1 El protocolo genérico Figura 1 muestra los pasos de razonamiento básicos en una ronda arbitraria de negociación que constituye el nuevo protocolo.",
                "La línea punteada indica la percepción del deseo de deseo de la mediación de la intención P B D I I I Info Mensaje Información Mensaje Negociación Mensaje de negociación Mensaje de negociación Mensaje de negociación Mensaje de negociación Mensaje de negociación Figura 1: El componente de protocolo de interacción \"BDI\" o la transición que puede o no aparecer dependiendo de depender de de depender de de depender de de depender de lala estrategia adoptada.",
                "El protocolo \"BDI\" prescribe la estructura esquelética para la negociación DCSP.",
                "Dentro del protocolo, a menudo determinará la eficiencia de la percepción de la ejecución de la intención de la mediación P B D I Info Mensaje Información Mensaje Negociación Mensaje de negociación Mensaje de negociación Figura 2: Protocolo \"BDI\" con Proceso de búsqueda de estrategia de retroceso asíncrono en términos de ciclos computacionales y comunicación de mensajes Comunicación de mensajescostos.",
                "Algoritmos DCSP: estrategias \"BDI\" + estrategias En esta sección, aplicamos el modelo de negociación \"BDI\" propuesto presentado en la Sección 3 para exponer el protocolo BDI y las diferentes estrategias utilizadas para tres algoritmos conocidos, ABT, AWC y DBO.",
                "Para describir cada estrategia formalmente, se utilizan las siguientes anotaciones matemáticas: • n es el número de agentes, M es el número de restricciones;• Xi denota la variable sostenida por el agente I, (0 ≤ i <n);• Di denota el dominio de la variable Xi;Fi denota la lista vecina del Agente I;CI denota su lista de restricciones;• Pi denota la prioridad del agente I;y pi = {(xj = vj, pj = k) |agente j ∈ Fi, vj ∈ Dj es el valor actual asignado a XJ y el valor de prioridad k es un entero positivo} es la percepción del agente I;• WL denota el peso de la restricción l, (0 ≤ l <m);• Si (V) es el peso total de las restricciones violadas en CI cuando su variable tiene el valor v ∈ Di.4.1 retroceso asíncrono La Figura 2 presenta el modelo de negociación \"BDI\" que incorpora la estrategia de retroceso asíncrono (ABT).",
                "Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m); pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su \"bdi\"-La estrategia ABT impulsada se describe de la siguiente manera.",
                "Después de este paso, el agente I procede a la próxima ronda de negociación.4.2 Búsqueda de compromiso débil asincrónico La Figura 3 presenta el modelo de negociación \"BDI\" que incorpora la estrategia de compromiso débil asincrónico (AWC).",
                "Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m); pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su \"bdi\"-La estrategia de AWC impulsada se describe de la siguiente manera.",
                "Paso 2 - Creencia: la función de creencia GB (PI, CI) devolverá un valor bi ∈ ∈ {0, 1, 2}, decidido de la siguiente manera: Percept BRISTA DESEMIENTO MEDIACIÓN Ejecución de mediación P B D I Información Información Información Mensaje Mensaje Mensaje Mensaje Figura de mensajes de negociación3: Protocolo \"BDI\" con estrategia asincrónica de compromiso débil • bi = 0 Cuando el agente puede encontrar una opción óptima, es decir, if (si (vi) = 0 o la asignación xi = vi y las asignaciones de variables actuales de los vecinos en FiForma de mayor prioridad A Nogood [4]) almacenado en una lista llamada Lista de Nogood y ∃a ∈ Di, Si (a) = 0 (inicialmente la lista está vacía).• bi = 1 Cuando el agente no puede encontrar ninguna opción óptima, es decir, si ∀a ∈ Di, si (a) = 0. • bi = 2 cuando la asignación actual es una opción óptima, es decir, si si (vi) = 0 y elEl estado actual no es un nogood en la lista de Nogood.",
                "Mediación: este paso es idéntico al paso de mediación de ABT, excepto que el agente ahora agregaré el Nogood contenido en el mensaje de negociación recibido a su propia lista de Nogood.4.3 Breakout distribuido La Figura 4 presenta el modelo de negociación \"BDI\" que incorpora la estrategia de ruptura distribuida (DBO).",
                "Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 527 Percept Believe Desprecia intención de ejecución de mediación P B D I I A Info Mensaje Información Mensaje de negociación Mensaje de negociación Figura 4: Protocolo \"BDI\" con estrategia de ruptura distribuida Estas restricciones aumentarán en 1 para ayudar a la ruptura de Breakout de Breakout de desdeun mínimo local.",
                "Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m), pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su \"bdi\"-La estrategia DBO impulsada se describe de la siguiente manera.",
                "Percept Believe Deseo de la intención Mediación Ejecución P B D I I A Información Información Información Mensaje Mensaje Negociación Mensaje de negociación Mensaje Mensaje de negociación Figura 5de cada restricción violada actualmente por 1. 5.",
                "La Figura 5 de la Estrategia UMA presenta el modelo de negociación \"BDI\" que incorpora la estrategia de asesoramiento mutuo no solicitado (UMA).",
                "Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m), pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su \"bdi\"-La estrategia UMA impulsada se describe de la siguiente manera.",
                "Conclusión Aplicación de negociación automatizada a DCSP, este documento ha propuesto un protocolo que prescribe el razonamiento genérico de un agente DCSP en una arquitectura \"BDI\".",
                "Es importante destacar que esto significa que podría proporcionar un marco unificado para DCSP que no solo proporciona una visión teórica teórica de agente \"BDI\" más clara de los enfoques DCSP existentes, sino que también abre las oportunidades para mejorar o desarrollar nuevas estrategias.",
                "El trabajo futuro intentará establecer formalmente esta propiedad, así como formalizar otros algoritmos DSCP existentes como mecanismos de negociación \"BDI\", incluido el reciente esfuerzo que emplea a un mediador grupal [5]."
            ],
            "translated_text": "",
            "candidates": [
                "bdi",
                "bdi",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "bdi",
                "bdi",
                "BDI",
                "bdi",
                "bdi",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "bdi",
                "bdi",
                "BDI",
                "bdi",
                "BDI",
                "bdi",
                "BDI"
            ],
            "error": []
        },
        "uma": {
            "translated_key": "Uma",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (<br>uma</br>) is proposed.",
                "Performance evaluation shows that the <br>uma</br> strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (<br>uma</br>) is proposed.",
                "Our performance evaluation shows that <br>uma</br> can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE <br>uma</br> STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(<br>uma</br>) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using <br>uma</br> will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven <br>uma</br> strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how <br>uma</br> works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and <br>uma</br> were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and <br>uma</br> (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and <br>uma</br> (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and <br>uma</br> (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "<br>uma</br> outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of <br>uma</br>, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of <br>uma</br> is arguably better than DBO for the following reasons: • <br>uma</br> can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by <br>uma</br> is lower due to the significantly lower number of negotiation rounds. • Using <br>uma</br>, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the <br>uma</br> strategy.",
                "Empirical results and our discussion suggest that <br>uma</br> is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that <br>uma</br> possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Con este fin, se propone una nueva estrategia llamada asesoramiento mutuo no solicitado (\"UMA\").",
                "La evaluación del rendimiento muestra que la estrategia \"UMA\" puede superar a algunos mecanismos existentes en términos de ciclos computacionales.",
                "Con este fin, se propone una nueva estrategia llamada asesoramiento mutuo no solicitado (\"UMA\").",
                "Nuestra evaluación de rendimiento muestra que \"UMA\" puede superar a ABT y AWC en términos del número promedio de ciclos computacionales para los problemas de coloración escasos y críticos [6].",
                "La Figura 5 de la Estrategia \"Uma\" presenta el modelo de negociación BDI que incorpora la estrategia de asesoramiento mutuo no solicitado (\"UMA\").",
                "A diferencia de cuando se usa las estrategias de la sección anterior, un agente DCSP que usa \"UMA\" no solo enviará un mensaje de negociación al concluir su paso de intención, sino también al concluir su paso de deseo.",
                "Para el agente I, comenzando inicialmente con (wl = 1, (0 ≤ l <m), pi = i, (0 ≤ i <n)) y Fi contiene todos los agentes que comparten las limitaciones con el agente I, su BDI impulsadoLa estrategia \"Uma\" se describe de la siguiente manera.",
                "Después de un cierto período de tiempo cuando no hay más comunicación de mensajes (y esto sucede cuando todos los agentes no tienen más intención de actualizar sus tareas variables), el observador informará a los agentes en el entorno que se ha encontrado una solución.1 2 3 4 5 6 7 8 9 10 Figura 6: Problema de ejemplo 5.1 Un ejemplo para ilustrar cómo funciona \"Uma\", considere un problema de gráfico de 2 colores [6] como se muestra en la Figura 6.",
                "La Figura 9 muestra el tiempo de ejecución para diferentes tamaños de problemas cuando se ejecutaron ABT, AWC y \"UMA\".5.2.2 Evaluación con problema de coloración de gráficos El problema de coloración del gráfico puede caracterizarse por tres parámetros: (i) el número de colores k, el número de nodos/agentes n y el número de enlaces m.Según la relación m/n, el problema se puede clasificar en tres tipos [3]: (i) escaso (con m/n = 2), (ii) crítico (con m/n = 2.7 o 4.7) y (iii) denso (con m/n = (n - 1)/4).",
                "Los resultados de la simulación para cada tipo de problema se muestran en las Figuras 10 - 12. 0 40 80 120 160 200 60 90 120 150 Número de nodos Ciclos Asíncrono Compromiso débil Débil Asesoramiento mutuo no solicitado Figura 10: Comparación entre AWC y \"UMA\" (gráfico escaso colorante) 5.3 Discusión 5.3.1 Comparación con ABT y AWC 530 El sexto intl.",
                "Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Número de nodos ciclos de compromiso débil asincrónico Asesoramiento mutuo no solicitado Figura 11: Comparación entre AWC y \"UMA\" (color de gráfico crítico) 0 10 20 20 20 20 2030 40 50 60 90 120 Número de nodos Ciclos Asíncrono Débil Compromiso Asesoramiento mutuo no solicitado Figura 12: Comparación entre AWC y \"UMA\" (coloración densa gráfica) La Figura 10 muestra que el rendimiento promedio de UMA es ligeramente mejor que AWC para el problema escaso.",
                "\"Uma\" supera a AWC para resolver el problema crítico como se muestra en la Figura 11.",
                "El rendimiento de \"UMA\", en el peor caso (complejidad del tiempo), es similar al de todas las estrategias evaluadas.",
                "Como observamos del retroceso en ABT y AWC, la diferencia en el orden de los mensajes entrantes puede dar lugar a un número diferente de ciclos computacionales para ser ejecutados por los agentes.5.3.2 Comparación con DBO El rendimiento computacional de \"UMA\" es posiblemente mejor que DBO por las siguientes razones: • \"Uma\" puede garantizar que habrá una reasignación variable después de cada ronda de negociación, mientras que DBO no puede.• Uma presenta un viaje de ida y vuelta de comunicación más (el de enviar un mensaje y esperar una respuesta) que DBO, que ocurre debido a la necesidad de comunicar consejos no solicitados.",
                "Aunque esto aumenta el costo de comunicación por ronda de negociación, observamos a partir de nuestras simulaciones que el costo general de comunicación incurrido por \"UMA\" es menor debido al número significativamente menor de rondas de negociación.• Usando \"UMA\", en el peor de los casos, un agente solo tomará 2 o 3 viajes de la ronda de comunicación por ronda de negociación, después de lo cual el agente o su vecino hará una actualización de asignación variable.",
                "Hacia este último, hemos propuesto y formulado una nueva estrategia: la estrategia \"UMA\".",
                "Los resultados empíricos y nuestra discusión sugieren que \"UMA\" es superior a ABT, AWC y DBO en algunos aspectos específicos.",
                "De nuestras simulaciones se observó que \"Uma\" posee la propiedad de integridad."
            ],
            "translated_text": "",
            "candidates": [
                "Uma",
                "UMA",
                "Uma",
                "UMA",
                "Uma",
                "UMA",
                "Uma",
                "UMA",
                "Uma",
                "Uma",
                "UMA",
                "Uma",
                "UMA",
                "Uma",
                "Uma",
                "Uma",
                "Uma",
                "Uma",
                "UMA",
                "Uma",
                "UMA",
                "Uma",
                "UMA",
                "UMA",
                "Uma",
                "Uma",
                "Uma",
                "UMA",
                "Uma",
                "UMA",
                "Uma",
                "Uma",
                "UMA",
                "UMA",
                "Uma",
                "UMA",
                "Uma",
                "UMA",
                "Uma",
                "Uma"
            ],
            "error": []
        },
        "distribute constraint satisfaction problem": {
            "translated_key": "Distribuir el problema de satisfacción de restricciones",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "belief-desireintention model": {
            "translated_key": "modelo de intención de desire de la creencia",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "agent negotiation": {
            "translated_key": "negociación de agentes",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Unifying Distributed Constraint Algorithms in a BDI Negotiation Framework Bao Chau Le Dinh and Kiam Tian Seow School of Computer Engineering Nanyang Technological University Republic of Singapore {ledi0002,asktseow}@ntu.edu.sg ABSTRACT This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation.",
                "The Distributed Constraint Satisfaction Problem (DCSP) is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment.",
                "By anchoring the DCSP search on automated negotiation, we show that several well-known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief-Desire-Intention (BDI) protocol, but using different strategies.",
                "A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles.",
                "Categories and Subject Descriptors I.2.11 [Distributed Artificial Intelligence]: Intelligent Agents, Multiagent Systems General Terms Algorithms, Design, Experimentation 1.",
                "INTRODUCTION At the core of many emerging distributed applications is the distributed constraint satisfaction problem (DCSP) - one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment.",
                "Important application examples include distributed resource allocation [1] and distributed scheduling [2].",
                "Many important algorithms, such as distributed breakout (DBO) [3], asynchronous backtracking (ABT) [4], asynchronous partial overlay (APO) [5] and asynchronous weak-commitment (AWC) [4], have been developed to address the DCSP and provide the agent solution basis for its applications.",
                "Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents.",
                "While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model-theoretic workings of the various agent algorithms that have been developed.",
                "As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible.",
                "In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9].",
                "Negotiation is viewed as a process of several agents searching for a solution called an agreement.",
                "The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step.",
                "Anchoring the DCSP search on automated negotiation, we show in this paper that several well-known DCSP algorithms [3] are actually mechanisms that share the same Belief-DesireIntention (BDI) interaction protocol to reach agreements, but use different action or value selection strategies.",
                "The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP.",
                "To this end, a new strategy called Unsolicited Mutual Advice (UMA) is proposed.",
                "Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6].",
                "The rest of this paper is organized as follows.",
                "In Section 2, we provide a formal overview of DCSP.",
                "Section 3 presents a BDI negotiation model by which a DCSP agent reasons.",
                "Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol.",
                "A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones.",
                "Section 6 concludes the paper and points to some future work. 2.",
                "DCSP: PROBLEM FORMALIZATION The DCSP [4] considers the following environment. • There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively.",
                "We define a partial function B over the productrange {0, 1, . . . , (n−1)}×{0, 1, . . . , (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)!.",
                "The exclamation mark ! means is defined. • There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied.",
                "In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl.",
                "The DCSP may be formally stated as follows.",
                "Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied.",
                "A constraint may consist of different variables belonging to different agents.",
                "An agent cannot change or modify the assignment values of other agents variables.",
                "Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re-adjust their own variable assignments in the process. 2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations.",
                "If the agents succeed in their resolution, a solution is found.",
                "In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list.",
                "Each variable assumes a range of values called a domain.",
                "A domain value, which usually abstracts an action, is a possible option that an agent may take.",
                "Each agent has an assigned priority.",
                "These priority values help decide the order in which they revise or modify their variable assignments.",
                "An agents priority may be fixed (static) or changing (dynamic) when searching for a solution.",
                "If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first.",
                "An agent which shares the same constraint with another agent is called the latters neighbor.",
                "Each agent needs to refer to its list of neighbors during the search process.",
                "This list may also be kept unchanged or updated accordingly in runtime.",
                "Similarly, each agent maintains a constraint list.",
                "The agent needs to ensure that there is no violation of the constraints in this list.",
                "Constraints can be added or removed from an agents constraint list in runtime.",
                "As with an agent, a constraint can also be associated with a priority value.",
                "Constraints with a high priority are said to be more important than constraints with a lower priority.",
                "To distinguish it from the priority of an agent, the priority of a constraint is called its weight. 3.",
                "THE BDI NEGOTIATION MODEL The BDI model originates with the work of M. Bratman [11].",
                "According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals.",
                "Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints.",
                "In automated negotiation [9], such a solution is called an agreement among the agents.",
                "Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI.",
                "Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies. 3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol.",
                "The solid line indicates the common component or transition which always exists regardless of the strategy used.",
                "The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy.",
                "Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message.",
                "An info message perceived is a message sent by another agent.",
                "The message will contain the current selected values and priorities of the variables of that sending agent.",
                "The main purpose of this message is to update the agent about the current environment.",
                "Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round.",
                "A negotiation message is a message which may be sent within a round.",
                "This message is for mediation purposes.",
                "The agent may put different contents into this type of message as long as it is agreed among the group.",
                "The format of the negotiation message and when it is to be sent out are subject to the strategy.",
                "A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step.",
                "Mediation is a step of the protocol that depends on whether the agents interaction with others is synchronous or asynchronous.",
                "In synchronous mechanism, mediation is required in every negotiation round.",
                "In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message.",
                "A more in-depth view of this mediation step is provided later in this section.",
                "The BDI protocol prescribes the skeletal structure for DCSP negotiation.",
                "We will show in Section 4 that several well-known DCSP mechanisms all inherit this generic model.",
                "The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent.",
                "For a conceptually clearer description, we assume that there is only one variable per agent. • Percept.",
                "In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P. This image contains the current values assigned to the variables of all agents in its neighbor list.",
                "The image P will drive the agents actions in subsequent steps.",
                "The agent also updates its constraint list C using some criteria of the adopted strategy. • Belief.",
                "Using the image P and constraint list C, the agent will check if there is any violated constraint.",
                "If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action.",
                "The agent will do nothing if it is in a local stable state - a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints.",
                "When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 525 ment is found.",
                "In case the agent finds its value in conflict with some of its neighbors, i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy.",
                "If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option.",
                "However it does not always happen that an agent can successfully find such an option.",
                "If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments.",
                "To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied.",
                "Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations. • Desire.",
                "If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set.",
                "If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments.",
                "How this sublist is created depends on the strategy devised for the agent.",
                "In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy.",
                "If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention. • Intention.",
                "The agent will select a value from its desire set as its intention.",
                "An intention is the best desired option that the agent assigns to its variable.",
                "The criteria for selecting a desire as the agents intention depend on the strategy used.",
                "Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation.",
                "Again, the decision to do so is determined by some criteria of the adopted strategy. • Mediation.",
                "This is an important function of the agent.",
                "Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved.",
                "Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3).",
                "Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them.",
                "There are two types of mediation: local mediation and group mediation.",
                "In the former, the agents exchange their intentions.",
                "When an agent receives anothers intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention.",
                "In the latter, there is an agent which acts as a group mediator.",
                "This mediator will collect the intentions from the group - a union of the agent and its neighbors - and determine which intention is to be executed.",
                "The result of this mediation is passed back to the agents in the group.",
                "Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round. • Execution.",
                "This is the last step of a negotiation round.",
                "The agent will execute by updating its variable assignment if the intention obtained at this step is its own.",
                "Following execution, the agent will inform its neighbors about its new variable assignment and updated priority.",
                "To do so, the agent will send out an info message. 3.2 The strategy A strategy plays an important role in the negotiation process.",
                "Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs.",
                "The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property.",
                "In other words, these dimensions provide technical considerations for a strategy design. 4.",
                "DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well-known algorithms, ABT, AWC and DBO.",
                "All these algorithms assume that there is only one variable per agent.",
                "Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively.",
                "To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di. 4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking (ABT) strategy.",
                "As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven ABT strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of 526 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list.",
                "Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment. • bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list. • bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list }. • If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi }. • If bi = 2, then DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention (to denote its lack thereof).",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round.",
                "The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi.",
                "Mediation: When agent i receives a negotiation message, several sub-steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists.",
                "The request is considered as a type of negotiation message. • Agent i will first check if the sender agent is updated with its current value vi.",
                "The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent.",
                "Following this step, agent i proceeds to the next negotiation round. 4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment (AWC) strategy.",
                "The model is similar to that of incorporating the ABT strategy (see Figure 2).",
                "This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps.",
                "The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi).",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven AWC strategy is described as follows.",
                "Step 1 - Percept: This step is identical to the Percept step of ABT.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty). • bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0. • bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized }. • If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized }. • If bi = 2, then DS = ∅.",
                "Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi}.",
                "Step 4 - Intention: This step is similar to the Intention step of ABT.",
                "However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki.",
                "This list of assignment is considered as a nogood.",
                "If the same negotiation message had been sent out before, agent i will have nil intention.",
                "Otherwise, the agent will send the message and save the nogood in the nogood list.",
                "Step 5 - Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value. • If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi.",
                "Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list. 4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout (DBO) strategy.",
                "Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints.",
                "The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help breakout from a local minimum.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven DBO strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of its relevant constraints.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi). • bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi). • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized }. (max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations). • Otherwise, DS = ∅.",
                "Step 4 - Intention: The intention function GI (DS) will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention. • If DS = ∅, then assign nil as the intention.",
                "Following, agent i will send its intention to all its neighbors.",
                "In return, it will receive intentions from these agents before proceeding to Mediation step.",
                "Mediation: Agent i receives all the intentions from its neighbors.",
                "If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention.",
                "Step 5 - Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value.",
                "Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. 5.",
                "THE UMA STRATEGY Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy.",
                "Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step.",
                "The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors.",
                "In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention.",
                "For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI-driven UMA strategy is described as follows.",
                "Step 1 - Percept: Update Pi upon receiving the info messages from the neighbors (in Fi).",
                "Update Ci to be the list of constraints relevant to agent i.",
                "Step 2 - Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty). • bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list. • bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0.",
                "Step 3 - Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of voluntary desires. max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) the maximal reduction in constraint violations.",
                "It is also referred to as an improvement). • If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent is neighbors do not form a state in the bad states list.",
                "In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅.",
                "Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors.",
                "This message is called a voluntary advice.",
                "If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i.",
                "Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step.",
                "Step 4 - Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention. • If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called a voluntary intention. • If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention.",
                "This intention is called reluctant intention. • If DS = ∅, then assign nil as the intention.",
                "Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors.",
                "If agent i has a reluctant intention, it will also send this intention to all its neighbors.",
                "In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention.",
                "In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step.",
                "Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step.",
                "Otherwise, agent i will select the best intention among all the intentions received, including its own (if any).",
                "The criteria to select the best intention are listed, applied in descending order of importance as follows. • A voluntary intention is preferred over a reluctant intention. • A voluntary intention (if any) with biggest improvement is selected. • If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected. • The intention from an agent who has received a higher number of change advices in the current negotiation round is selected. • Intention from an agent with highest priority is selected.",
                "If the selected intention is not agent is intention, it will cancel its intention.",
                "Step 5 - Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value.",
                "Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state.",
                "Hence an observer is needed that will keep track of the negotiation messages communicated in the environment.",
                "Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found. 1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2-color graph problem [6] as shown in Figure 6.",
                "In this example, each agent has a color variable representing a node.",
                "There are 10 color variables sharing the same domain {Black, White}.",
                "The following records the outcome of each step in every negotiation round executed.",
                "Round 1: Step 1 - Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors.",
                "Step 2 - Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black).",
                "In this negotiation round, the improvements achieved by these agents are 1.",
                "Agents which do not have any improvements are agents 4, 5 and 8.",
                "Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied.",
                "Step 3 - Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10).",
                "These agents will send the voluntary advices to all their neighbors.",
                "Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8).",
                "Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it.",
                "Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively.",
                "Agents 3, 6 and 9 do not have any desire to update their color assignments.",
                "Step 4 - Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively.",
                "They form their voluntary intentions.",
                "Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention.",
                "Agents 3, 6 and 9 do not have any intention.",
                "Following, the intention from the agents will be sent to all their neighbors.",
                "Mediation: Agent 1 finds that the intention from agent 2 is better than its intention.",
                "This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any.",
                "Hence agent 1 cancels its intention.",
                "Agent 2 will keep its intention.",
                "Agents 7 and 10 keep their intentions since none of their neighbors has an intention.",
                "The rest of the agents do nothing in this step as they do not have any intention.",
                "Step 5 - Execution: Agent 2 changes its color to White.",
                "Agents 7 and 10 change their colors to Black.",
                "The new state after round 1 is shown in Figure 7.",
                "Round 2: Step 1 - Percept: The agents obtain the current color assignments of their neighbors.",
                "Step 2 - Belief: Agent 3 is the only agent who has a positive improvement which is 1.",
                "It believes it should change its The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black.",
                "Agent 2 does not have any positive improvement.",
                "The rest of the agents need not make any change as all their relevant constraints are satisfied.",
                "They will have no desire, and hence no intention.",
                "Step 3 - Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2.",
                "Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state.",
                "Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3.",
                "Step 4 - Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3.",
                "Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention.",
                "Step 5 - Execution: Agent 3 changes its color to Black.",
                "The new state after round 2 is shown in Figure 8.",
                "Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment.",
                "Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found. 2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC.",
                "The definition of a computational cycle is as follows. • In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply. • A message which is sent at time t will be received at time t + 1.",
                "The network delay is neglected. • Each agent has it own clock.",
                "The initial clocks value is 0.",
                "Agents attach their clock value as a time-stamp in the outgoing message and use the time-stamp in the incoming message to update their own clocks value.",
                "Four benchmark problems [6] were considered, namely, n-queens and node coloring for sparse, dense and critical graphs.",
                "For each problem, a finite number of test cases were generated for various problem sizes n. The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems.",
                "The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then.",
                "In such a case, the execution time for the test was counted as 1000 cycles. 5.2.1 Evaluation with n-queens problem The n-queens problem is a traditional problem of constraint satisfaction. 10 test cases were generated for each problem size n ∈ {10, 50 and 100}.",
                "Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run. 5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes/agents n and the number of links m. Based on the ratio m/n, the problem can be classified into three types [3]: (i) sparse (with m/n = 2), (ii) critical (with m/n = 2.7 or 4.7) and (iii) dense (with m/n = (n − 1)/4).",
                "For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high.",
                "This poor performance of ABT was expected since the graph coloring problem is more difficult than the n-queens problem, on which ABT already did not perform well (see Figure 9).",
                "The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve.",
                "In the experiments, we fix k = 3. 10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type.",
                "The simulation results for each type of problem are shown in Figures 10 - 12. 0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem.",
                "UMA outperforms AWC in solving the critical problem as shown in Figure 11.",
                "It was observed that the latter strategy failed in some test cases.",
                "However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance.",
                "The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies.",
                "The worst case occurs when all the possible global states of the search are reached.",
                "Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced.",
                "As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents. 5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot. • UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices.",
                "Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds. • Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update.",
                "Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. 6.",
                "CONCLUSION Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture.",
                "Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol.",
                "Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent-theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies.",
                "Towards the latter, we have proposed and formulated a new strategy - the UMA strategy.",
                "Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects.",
                "It was observed from our simulations that UMA possesses the completeness property.",
                "Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5].",
                "The idea of DCSP agents using different strategies in the same environment will also be investigated. 7.",
                "REFERENCES [1] P. J. Modi, H. Jung, M. Tambe, W.-M. Shen, and S. Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p. 264. [2] H. Schlenker and U. Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN-04), 2004, pp. 441- 446. [3] M. Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi-Agent Systems.",
                "Springer Verlag, 2000, springer Series on Agent Technology. [4] M. Yokoo, E. H. Durfee, T. Ishida, and K. Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol. 10, no. 5, pp. 673-685, September/October 1998. [5] R. Mailler and V. Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-04), 2004, pp. 446-453. [6] E. Tsang, Foundation of Constraint Satisfaction.",
                "Academic Press, 1993. [7] R. Mailler, R. Vincent, V. Lesser, T. Middlekoop, and J. Shen, Soft Real-Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001. [8] M. Yokoo, K. Suzuki, and K. Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol. 161, no. 1-2, pp. 229-246, 2005. [9] J. S. Rosenschein and G. Zlotkin, Rules of Encounter.",
                "The MIT Press, 1994. [10] M. Yokoo and K. Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS-98), 1998, pp. 372-379. [11] M. E. Bratman, Intentions, Plans and Practical Reason.",
                "Harvard University Press, Cambridge, M.A, 1987. [12] G. Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence.",
                "The MIT Press, London, U.K, 1999. [13] S. Minton, M. D. Johnson, A.",
                "B. Philips, and P. Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol. e58, no. 1-3, pp. 161-205, 1992.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 531"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        }
    }
}