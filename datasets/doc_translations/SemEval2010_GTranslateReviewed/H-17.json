{
    "id": "H-17",
    "original_text": "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept. Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information. In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results. While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index. Given the fierce competition in the online search market, this phenomenon is clearly undesirable. In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit. Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time. We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages. Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1. INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24]. According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages. Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web. Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index. An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword. In most cases, a query that the user issues may have thousands or even millions of matching documents. In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents. The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query. A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results. That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine. At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large. Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24]. One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index. While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20]. That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20]. Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible. In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit. That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index. Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time. These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines. Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results. IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries. When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2. CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly. Inverted indexes. Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents. For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti. Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc. The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information. For example, Google is estimated to answer more than 250 million user queries per day. In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a). The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines. We also suppose that one copy of IF can handle the query load of 1000 queries/sec. Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load. Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index. In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results. Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier. In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF . The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture. Example 2 Assume the same parameter settings as in Example 1. That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec. Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine. Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF . Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier. For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load. Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ). Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index. However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results. Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture? Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index. The algorithm in Figure 2 formalizes this idea. In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF . If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2). Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5). Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time. Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone. Question 1 How can we compute the correctness indicator function C? A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them. This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF . Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ? Question 2 How should we prune IF to IP to realize the maximum cost saving? The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1. If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF . What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries? In the next few sections, we try to address these questions. 3. OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher. When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF . Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving? To find the answer, we start with a simple example. Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines. But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries). Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries. Which one of the IP 1, IP 2 is preferable for the 1st -tier index? To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier. At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec. Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine. Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy). Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy). Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load. We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used. Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone. We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ). We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ). In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows. In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows. In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load. Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size. Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints. This theorem shows that the optimal point is when the slope of the f(s) curve is 1. For example, in Figure 3, the optimal size is when s = 0.16. Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy. For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s). Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s). Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy. In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4. PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP . In designing the pruning policies, we note the following two localities in the users search behavior: 1. Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads. This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2. Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16]. Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them). Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results. As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee. Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms. The goal of the search engine is to return the documents that are most relevant to query q. This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query. Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest. Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics). In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query. It is straightforward to extend our results to OR-semantics as well. The exact ranking function that search engines employ is a closely guarded secret. What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance. This particular factor of relevance captures how relevant the query is to every document. At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values. One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric. Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality. This is a factor that measures the overall quality of a document D independent of the particular query issued by the user. Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15]. Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function. The exact combination of these parts may be done in a variety of ways. In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores. More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part. In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine. Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning. Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning. Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2). Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms. In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load. Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned. In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF . Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP . It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm. We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries. This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof). Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution. A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9]. In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP . We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti). For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |. Figure 6: Approximation algorithm for the optimal keyword pruning. Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1. The cost of including I(ti) in the pindex is its size |I(ti)|. Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |. Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query. Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway. We depict the conceptual diagram of the document pruning policy in Figure 4. In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries. Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP . In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines. The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g. PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp). The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index. Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr. Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp. We refer to this pruning policy as global PR-based pruning (GPR). Variations of this pruning policy are possible. For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti). This policy is shown in Figure 8. We refer to this pruning policy as local PR-based pruning (LPR). Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way. Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP . Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)). Now consider another document Dj that was pruned from IP because pr(Dj) < τp. Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q). Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF . In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores. Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score. That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP . Otherwise, we prune it from IP . Figure 9 formally describes this algorithm. The threshold values, τpi and τti, may be selected in a number of different ways. For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti). This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index. We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)). There are three possible scenarios on how a document D appears in the pruned index IP . 1. D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2. D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score. However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2. Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3. D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values. However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2. Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values. This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score. In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k. The following theorem formally proves the correctness of the algorithm. In [11] Fagin et al., provides a similar proof in the context of multimedia middleware. Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6. For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP . In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk). That is, Dis score can never be larger than that of Dk. Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP . Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)). Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di). Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di). Therefore, r(Di) cannot be larger than r(Dk). 5. EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype. For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004. The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner. Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB. For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003. After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries. Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms. Some experiments require us to use a particular ranking function. For these, we use the ranking function similar to the one used in [20]. More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q. This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2. More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set. Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP . According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords. We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11. The horizontal axis denotes the size s of the p-index as a fraction of the size of IF . The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer. The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index. For example, approximately 73% of the queries can be answered using 30% of the original index. Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3. For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set. The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries. For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4. Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct. We have performed the experiment for varying index sizes s and the result is shown in Figure 12. Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries. This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size. From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy. We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12. Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%. For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size. Later in Section 5.3, we discuss the combination of the two policies. In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3. To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies. For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index. Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index. Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning. The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies. On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size. The fraction of queries that LPR can answer remains below that of EKS until about s = 37%. For any index size larger than 37%, LPR performs the best. In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index. However, in a practical scenario, it may be acceptable to have some of the results out of order. Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index. The result of the experiment is shown on Figure 14. The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index. Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes. One interesting question however is how do these policies perform in combination? What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ? To answer this question, we performed the following experiment. We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF . After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P . We then calculated the fraction of guaranteed queries in IP . We repeated the experiment for different values of sh and sv. The result is shown on Figure 15. The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings. For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries. By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well. For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries. In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5. For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6. RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems. Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33]. The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used. The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking. However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results. Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results. Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31]. This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost. The exact ranking functions employed by current search engines are closely guarded secrets. In general, however, the rankings are based on query-dependent relevance and queryindependent document quality. Query-dependent relevance can be calculated in a variety of ways (see [3, 30]). Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26]. Since our work does not assume a particular form of ranking function, it is complementary to this body of work. There has been a great body of work on top-k result calculation. The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8]. Our proof for the correctness indicator function was primarily inspired by [12]. 7. CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads. While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality. In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order. We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination. Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results. In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size. When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%. It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8. REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat. Vector-space ranking with effective early termination. In SIGIR, 2001. [2] V. N. Anh and A. Moffat. Pruning strategies for mixed-mode querying. In CIKM, 2006. [3] R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern Information Retrieval. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian. Evaluating top-k queries over web-accessible databases. In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke. A document-centric approach to static index pruning in text retrieval systems. In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu. Evaluating the performance of distributed architectures for information retrieval using a variety of workloads. ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer. Static index pruning for information retrieval systems. In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano. Optimizing queries over multimedia repositories. In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest. Introduction to Algorithms, 2nd Edition. MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin. Combining fuzzy information: an overview. In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor. Optimal aggregation algorithms for middleware. In PODS, 2001. [13] A. Gulli and A. Signorini. The indexable web is more than 11.5 billion pages. In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling. Towards efficient multi-feature queries in heterogeneous environments. In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen. Combating web spam with trustrank. In VLDB, 2004. [16] B. J. Jansen and A. Spink. An analysis of web documents retrieved and viewed. In International Conf. on Internet Computing, 2003. [17] J. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran. Predictive caching and prefetching of query results in search engines. In WWW, 2003. [19] R. Lempel and S. Moran. Optimizing result prefetching in web search engines with segmented indices. ACM Trans. Inter. Tech., 4(1), 2004. [20] X. Long and T. Suel. Optimized query execution in large search engines with global page ordering. In VLDB, 2003. [21] X. Long and T. Suel. Three-level caching for efficient query processing in large web search engines. In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina. Building a distributed full-text index for the web. ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. Whats new on the web? The evolution of the web from a search engine perspective. In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly. Detecting spam web pages through content analysis. In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: Bringing order to the web. Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis. Filtered document retrieval with frequency-sorted indexes. Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos. The intelligent surfer: Probabilistic combination of link and content information in pagerank. In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones. Relevance weighting of search terms. Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill. Introduction to modern information retrieval. McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto. Rank-preserving two-level caching for scalable search engines. In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel. Top-k query evaluation with probabilistic guarantees. In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina. Performance of inverted indices in shared-nothing distributed text document information retrieval systems. In Parallel and Distributed Information Systems, 1993.",
    "original_translation": "Políticas de poda para un índice invertido de dos niveles con garantía de corrección Alexandros ntoulas ∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. Antoulas@microsoft.com Junghoo Cho † UCLA Computer Science Dept. Boelter Hall Los Ángeles, CA 90095, EE. UU. Cho@cs.ucla.edu Resumen Los motores de búsqueda web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por los usuarios ansiosos por la información. Para hacer frente a las grandes cantidades de cargas de consulta, los motores de búsqueda podan su índice para mantener documentos que probablemente se devuelvan como resultados principales, y usen este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los resultados principales solo del índice podado, podemos notar una degradación significativa en la calidad de los resultados: si un documento debía estar en los mejores resultados pero no se incluyó enEl índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al tiempo que nos damos cuenta de la mayor parte de su beneficio. Nuestra contribución es una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas de coincidencia superior siempre se colocan en los mejores resultados de búsqueda, a pesar de que estamos calculando el primer lote de la poda de la podaíndice la mayor parte del tiempo. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y descriptores de sujetos H.3.1 [Almacenamiento y recuperación de información]: análisis e indexación de contenido;H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información Algoritmos de términos generales, medición, rendimiento, diseño, experimentación 1. Introducción La cantidad de información en la Web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios se están volviendo cada vez más dependientes de los motores de búsqueda web para localizar información relevante en la web. Por lo general, los motores de búsqueda web, similares a otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada Inverted Index. Un índice invertido proporciona la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que los problemas del usuario pueden tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. Luego, el usuario mira a través del primer lote de resultados y, si no encuentra la respuesta que está buscando, podría solicitar ver el próximo lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo los primeros 3 lotes de los resultados. Es decir, el 80% de los usuarios generalmente ven como máximo 30 a 60 resultados para cada consulta que emiten a un motor de búsqueda. Al mismo tiempo, dado el tamaño de la web, el índice invertido que mantienen los motores de búsqueda pueden crecer muy grandes. Dado que los usuarios están interesados en un pequeño número de resultados (y, por lo tanto, están viendo una pequeña porción del índice para cada consulta que emiten), utilizando un índice que sea capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo enTérminos de tiempo, espacio de almacenamiento y recursos computacionales, que seguramente empeorarán a medida que la web aumente con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devuelvan como los principales resultados (mediante el uso, por ejemplo, las técnicas de poda en [7, 20]) y calculen el primer lotede respuestas usando el índice podado. Si bien se ha demostrado que este enfoque ofrece una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, porque las respuestas principales se calculan solo del índice podado [7, 20]. Es decir, incluso si una página debe colocarse como la página de coincidencia superior de acuerdo con una métrica de clasificación de motores de búsqueda, la página puede colocarse detrás de las contenidas en el índice podado si la página no se convirtió en parte del índice podado para variosrazones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy, esta degradación es claramente indeseable y debe abordarse si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización del rendimiento anterior y al mismo tiempo nos damos cuenta de la mayor parte de su beneficio. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas de coincidencia superior (de acuerdo con la métrica de clasificación de los motores de búsqueda) siempre se colocan en la parte superior de los resultados de búsqueda, a pesar de que estamos calculando el primer lote de respuestas de la poda de las podas de las podas de las podas de las podas.índice la mayor parte del tiempo. Estas técnicas de poda mejoradas y algoritmos de computación de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleadas por los motores de búsqueda de hoy. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas al tiempo que proporcionan resultados de búsqueda de alta calidad. Si si si if si if if ip ip ip ip ip ip ip 5000 consultas/seg 5000 consultas/seg: 1000 consultas/seg: 1000 consultas/seg 2nd nivel 1er nivel (a) (b) Figura 1: (a) Replica el motor de búsqueda replicasu índice completo si aumentará la capacidad de consulta y respuesta.(b) En el primer nivel, los pequeños pindexes IP manejan la mayoría de las consultas. Cuando IP no puede responder una consulta, se redirige al segundo nivel, donde el índice completo si se usa para calcular la respuesta.2. La arquitectura de clúster y el ahorro de costos de un índice podado, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Suponga que hemos recopilado un conjunto de documentos d = {d1 ,..., Dm} y que hemos extraído todos los términos t = {t1 ,..., tn} de los documentos. Para cada término ti ∈ T mantenemos una lista I (ti) de ID de documento que contienen Ti. Cada entrada en I (Ti) se llama publicación y se puede extender para incluir información adicional, como cuántas veces aparece Ti en un documento, las posiciones de TI en el documento, si Ti es audaz/cursiva, etc. El conjunto de todas las listas i = {i (t1) ,..., I (tn)} es nuestro índice invertido.2.1 Los motores de búsqueda de arquitectura de índice de dos niveles aceptan una enorme cantidad de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde más de 250 millones de consultas de usuarios por día. Para hacer frente a esta gran carga de consulta, los motores de búsqueda generalmente replican su índice en un gran clúster de máquinas como lo ilustra el siguiente ejemplo: Ejemplo 1 considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1 (a). El tamaño de su índice invertido completo si es más grande de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consulta de 1000 consultas/seg. Suponiendo que el motor de búsqueda obtenga 5000 consultas/seg, debe replicarse si cinco veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster.2 Mientras replica completamente todo el índice si varias veces es una forma directa de escalar a una gran cantidad de consultas, las cargas de consultas típicas en los motores de búsqueda exhiben ciertas localidades, lo que permite una reducción significativa en el costo al replicar solo una pequeña porción del índice completo. En principio, esto generalmente se hace podando un índice completo si crear un índice más pequeño y podado (o índice P) IP, que contiene un subconjunto de los documentos que probablemente se devuelven como resultados principales. Dado el índice P, los motores de búsqueda operan empleando una arquitectura de índice de dos años como mostramos en la Figura 1 (b): todas las consultas entrantes se dirigen primero a uno de los índices P que se mantienen en el primer nivel. En los casos en que un índice P no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para regresar al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo si. El siguiente ejemplo ilustra la posible reducción en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2 Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda obtiene una carga de consulta de 5000 consultas/algoritmo de seg 2.1 Cálculo de respuesta con entrada de garantía de corrección q = ({t1, ..., tn}, [i, i + k]) donde {t1 ,..., TN}: Palabras clave en la consulta [i, i + k]: rango del procedimiento de respuesta para devolver (1) (a, c) = computteanswer (q, ip) (2) if (c = 1) entonces (3) Devuelve a (4) else (5) a = CopeAnswer (Q, If) (6) Devuelve una Figura 2: Calculando la respuesta debajo de la arquitectura de dos niveles con la garantía de corrección de resultados.y cada copia de un índice (tanto el IP y el IP-índice P) puede manejar hasta 1000 consultas/seg. También suponga que el tamaño de IP es un cuarto de IF y, por lo tanto, se puede almacenar en una sola máquina. Finalmente, supongamos que los índices P pueden manejar el 80% de las consultas de los usuarios por sí mismas y solo reenviar las consultas del 20% restantes a IF. En esta configuración, dado que las consultas de usuario de 5000/seg se dirigen primero a un índice P, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que se reenvían el 20% (o 1000 consultas/seg), necesitamos mantener una copia de IF para manejar la carga. En general, necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). En comparación con el Ejemplo 1, esta es una reducción de más del 50% en el número de máquinas.2 El ejemplo anterior demuestra el ahorro potencial de costos logrado mediante el uso de un índice P. Sin embargo, la arquitectura de dos niveles puede tener un inconveniente significativo en términos de calidad de resultados en comparación con la replicación completa de IF;Dado el hecho de que el índice P contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice P pueda no contener el documento mejor clasificado de acuerdo con los criterios de clasificación particulares utilizados por elEl motor de búsqueda y no lo devuelven como la página superior, lo que lleva a una notable degradación de calidad en los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de búsqueda para maximizar la satisfacción del usuario.2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la degradación potencial de la calidad de búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: usamos el resultado de Top-K del índice P solo si sabemos con certeza que el resultado es el mismo que el resultado de Top-K del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado de IP (paso 1), calculamos no solo el resultado de Top-K, sino también la función del indicador de corrección C definida de la siguiente manera: Definición 1 (función del indicador de corrección) dada una consulta Q,La IP del índice P devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntica (es decir, los mismos resultados en el mismo orden) al resultado calculado a partir del índice completo si. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el paso 2). De lo contrario, el algoritmo recomputa y devuelve el resultado del índice completo si (Paso 5). Por lo tanto, se garantiza que el algoritmo devolverá el mismo resultado que la replicación completa de todo el tiempo. Ahora, el verdadero desafío es averiguar (1) cómo podemos calcular la función del indicador de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función del indicador de corrección C? Una forma directa de calcular C es calcular la respuesta de Top-K tanto desde IP como de IF y compararla. Sin embargo, esta solución ingenua incurre en un costo incluso más alto que la replicación completa de si porque las respuestas se calculan dos veces: una vez de IP y una vez de IF. ¿Hay alguna forma de calcular la función del indicador de corrección c solo desde IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar si IP para realizar el ahorro máximo de costos? La efectividad del algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función del indicador de corrección C como 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar si a IP, de modo que c = 1 para una gran fracción de consultas? En las siguientes secciones, intentamos abordar estas preguntas.3. Tamaño óptimo del índice P intuitivamente, existe una compensación clara entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando la IP es grande y tiene más información, podrá manejar más consultas, pero el costoPara mantener y buscar IP será mayor. Cuando la IP es pequeña, por otro lado, el costo para la IP será más pequeño, pero se enviarán más consultas a si, requeriendo que mantengamos más copias de IF. Dada esta compensación, ¿cómo debemos determinar el tamaño óptimo de IP para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo simple. Ejemplo 3 Nuevamente, considere un escenario similar al Ejemplo 1, donde la carga de consulta es de 5000 consultas/seg, cada copia de un índice puede manejar 1000 consultas/seg, y el índice completo se extiende en 4 máquinas. Pero ahora, supongamos que si podamos en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% delconsultas). También suponga que si se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de las IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consulta de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (eso requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5 × 1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que IP 1 puede manejar el 40% de las consultas, el segundo nivel tiene que manejar 3000 consultas/seg (60% de las 5000 consultas/seg), por lo que necesitamos un total de 3 × 4 = 12 máquinas para el segundo nivel(3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos hacer un análisis similar cuando usamos IP 2 y ver que se necesitan un total de 14 máquinas cuando se usa IP 2. Dado este resultado, podemos concluir que el uso de IP 2 es preferible.2 El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice P y la fracción de las consultas que pueden manejar solo el índice de primer nivel. Usamos S para denotar el tamaño del índice P en relación con IF (es decir, si S = 0.2, por ejemplo, el índice P es el 20% del tamaño de IF). Usamos F (s) para denotar la fracción de las consultas que un índice P de tamaño S puede manejar (es decir, si F (s) = 0.3, el 30% de las consultas devuelve el valor C = 1 de IP). En general, podemos esperar que F (S) aumente a medida que S se hace más grande porque IP puede manejar más consultas a medida que crece su tamaño. En la Figura 3, mostramos un gráfico de ejemplo de F (s) sobre s.Dada la notación, podemos establecer el problema de la optimización del tamaño del índice P de la siguiente manera. Al formular el problema, suponemos que el número de máquinas requeridas para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 fracción de la fracción garantizada-F (s) de la fracción de índice de consultas garantizadas por fracción de la fracción de la fracción deTamaño óptimo del índice S = 0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas F (S) en un tamaño S dado S del índice P.es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consulta. Problema 1 (tamaño de índice óptimo) Dada una carga de consulta Q y la función F (s) F (s), encuentre el tamaño óptimo del índice P que minimiza el tamaño total de los índices necesarios para manejar la carga Q. 2 El siguiente teorema muestra cómopuede determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consulta Q es mínimo cuando el tamaño del índice p, s, satisface d f (s) d s = 1. 2 prueba de la prueba de esto y los siguientes teoremas se omiten debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva F (S) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando S = 0.16. Tenga en cuenta que la forma exacta del gráfico F (S) puede variar según la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice P, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice P, disminuyendo (o aumentando) F (s) F (s). Del mismo modo, si utilizamos una política de poda efectiva, IP manejará más consultas que cuando usamos una política de poda ineficaz, aumentando F (S). Por lo tanto, la función f (s) y el tamaño del índice óptimo pueden cambiar significativamente dependiendo de la carga de consulta y la política de poda. Sin embargo, en nuestros experimentos posteriores, encontramos que a pesar de que la forma del gráfico F (S) cambia notablemente entre los experimentos, el tamaño óptimo del índice se encuentra constantemente entre 10% y 30% en la mayoría de los experimentos.4. Políticas de poda En esta sección, mostramos cómo debemos podar el índice completo si a IP, de modo que (1) podamos calcular la función del indicador de corrección C de IP en sí y (2) podemos manejar una gran fracción de consultas por IP. Al diseñar las políticas de poda, observamos las siguientes dos localidades en el comportamiento de búsqueda de usuarios: 1. Localidad de palabras clave: aunque hay muchas palabras diferentes en la recopilación de documentos que el motor de búsqueda índice, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder una fracción significativa de consultas de usuarios, incluso si puede manejar solo estas pocas palabras clave populares.2. Localidad de documentos: incluso si una consulta tiene millones de documentos coincidentes, los usuarios generalmente solo miran los primeros resultados [16]. Por lo tanto, mientras los motores de búsqueda puedan calcular las primeras respuestas de Top-K correctamente, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Según las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar toda la lista invertida I (TI) para palabras clave impopulares TI y (2)Una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo unas pocas publicaciones en cada lista I (TI), que probablemente se incluya en los resultados de Top-K. Como discutimos antes, necesitamos poder calcular la función indicadora de corrección del índice podado solo para proporcionar la garantía de corrección. Dado que el cálculo de la función del indicador de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestros supuestos en la función de clasificación.4.1 Suposiciones sobre la función de clasificación Considere una consulta q = {t1, t2 ,..., tw} que contiene un subconjunto de los términos de índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos en la consulta. En segundo lugar, una vez que tenemos los documentos relevantes, calculamos el rango (o puntaje) de cada uno de los documentos con respecto a la consulta y volvemos al usuario los documentos que clasifican el más alto. La mayoría de los principales motores de búsqueda de hoy devuelven documentos que contienen todos los términos de consulta (es decir, usan y semántico). Para hacer que nuestras discusiones sean más concisas, también asumiremos lo popular y semántico mientras respondemos una consulta. Es sencillo extender nuestros resultados a o semánticos también. La función de clasificación exacta que emplean los motores de búsqueda es un secreto estrechamente guardado. Sin embargo, lo que se sabe es que los factores para determinar la clasificación de documentos se pueden clasificar aproximadamente en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura cuán relevante es la consulta para cada documento. En un nivel alto, dado un documento D, para cada término TI, un motor de búsqueda asigna una puntuación de relevancia de término TR (D, TI) a D. dados los puntajes TR (D, Ti) para cada TI, entonces la relevancia dependiente de la consultade D a la consulta, observada como TR (D, Q), se puede calcular combinando los valores de relevancia del término individual. Una forma popular para calcular la relevancia de consulta es representar tanto el documento D como la consulta Q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de TR (D, Ti) y TR (D, Q) difiere según el motor de búsqueda, no nos restringiremos a ninguna forma particular;En cambio, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula en función de los valores de relevancia del término individual en la consulta: tr (d, q) = ftr (TR (D, T1), ..., TR (D, TW)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independiente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], éxitos [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos Pr (D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. El puntaje de clasificación final R (D, Q) de un documento dependerá tanto de la consulta como de la consulta como independiente de la consultaPartes de la función de clasificación. La combinación exacta de estas partes se puede hacer de varias maneras. En general, podemos suponer que el puntaje de clasificación final de un documento es una función de sus puntajes de relevancia dependiente de la consulta e independiente de la consulta. Más formalmente: r (d, q) = fr (tr (d, q), pr (d)) (2) Por ejemplo, fr (tr (d, q), pr (d)) puede tomar la forma fr (tr (d, q), pr (d)) = α · tr (d, q) + (1-α) · pr (d), dando así α a la parte dependiente de la consulta y el peso 1-α ala parte independiente de la consulta. En las ecuaciones 1 y 2, la forma exacta de FR y FTR puede variar según el motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento, solo haremos la suposición genérica de que la función de clasificación R (D, Q) es monotónica en sus parámetros TR (D, T1),..., tr (d, tw) y pr (d).T1 → D1 D2 D3 D4 D5 D6 T2 → D1 D2 D3 T3 → D3 D5 D7 D8 T4 → D4 D10 T5 → D6 D8 D9 Figura 4: Pruning de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el procedimiento de poda de palabras clave (1) c = 1 (2) foreach ti ∈ Q (3) if (i (ti) /∈ Ip) Entonces c = 0 (4) return c Figura 5: Garantía de resultado enpoda de palabras clave. Definición 2 Una función F (α, β, ..., ω) es monotónica si ∀α1 ≥ α2, ∀β1 ≥ β2 ,...∀Ω1 ≥ ω2 sostiene que: F (α1, β1, ..., ω1) ≥ F (α2, β2, ..., ω2). Aproximadamente, la monotonicidad de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una mayor relevancia de consulta que D2 y también una puntuación independiente de consulta más alta que D2, entonces D1 debe clasificarse más alta que D2, lo que creemos que ISuna suposición razonable en la mayoría de los entornos prácticos.4.2 Pruning de palabras clave Dadas nuestras suposiciones en la función de clasificación, ahora investigamos la política de poda de palabras clave, que poda el índice invertido si es horizontalmente eliminando todo el I (Ti) S correspondiente a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para T3 y T5, suponiendo que no aparecen a menudo en la carga de consulta. Tenga en cuenta que después de la poda de palabras clave, si todas las palabras clave {T1 ,..., tn} En la consulta Q aparece en IP, el índice P tiene la misma información que mientras se preocupe Q. En otras palabras, si todas las palabras clave en Q aparecen en IP, la respuesta calculada desde IP se garantiza que es la misma que la respuesta calculada de IF. La Figura 5 formaliza esta observación y calcula la función del indicador de corrección C para una IP de índice privado de palabras clave. Es sencillo demostrar que la respuesta de IP es idéntica a la de si C = 1 en el algoritmo anterior. Ahora consideramos el problema de optimizar la IP de manera que pueda manejar la mayor fracción de consultas. Este problema se puede establecer formalmente de la siguiente manera: Problema 2 (poda de palabras clave óptimas) dada la carga de consulta Q y un tamaño de índice de meta S · | if |Para el índice podado, seleccione las listas invertidas IP = {I (T1) ,..., I (th)} tal que | ip |≤ s · | if |y se maximiza la fracción de consultas que IP puede responder (expresada por F (s)).2 Desafortunadamente, la solución óptima al problema anterior es intratable como podemos mostrar reduciendo la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda de palabras clave óptimas es NP-HARD.2 Dada la intratabilidad de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política codiciosa manteniendo los artículos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I (TI) es el número de consultas que puede ser respondida por IP cuando I (TI) se incluye en IP. Aproximamos este número por la fracción de consultas en la carga de consulta Q que incluyen el término Ti y lo representan como P (Ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, algoritmo 4.2 Procedimiento de Pruning HS de palabras clave codiciosas (1) ∀Ti, Calcule HS (Ti) = P (Ti) | I (Ti) |.(2) Incluya las listas invertidas con los valores más altos de HS (TI) de tal manera que | IP |≤ s · | if |. Figura 6: Algoritmo de aproximación para la poda de palabras clave óptima. Algoritmo 4.3 Pruning de documentos globales V SG Procedimiento (1) Ordene todos los documentos DI según PR (DI) (2) Encuentre el valor umbral τp, de modo que solo la fracción de los documentos tiene PR (di)> τp (4) Mantenga DIEn las listas invertidas si PR (DI)> τp Figura 7: Pruning de documentos globales basados en PR.Entonces P (computadora) = 0.1. El costo de incluir i (ti) en el pindex es su tamaño | i (ti) |. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I (Ti) s en el orden decreciente de P (Ti)/| I (Ti) |Mientras | IP |≤ s · | if |. Más adelante en nuestra sección del experimento, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política codiciosa de las palabras clave.4.3 Pruning de documentos a un alto nivel, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las pocas respuestas principales a una consulta. Dado esto, es innecesario mantener todas las publicaciones en una lista invertida I (TI), porque los usuarios no mirarán la mayoría de los documentos de la lista de todos modos. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de T1 y D8 de T3, suponiendo que es poco probable que estos documentos formen parte de las respuestas de Top-K a las consultas de los usuarios. Nuevamente, nuestro objetivo es desarrollar una política de poda de tal manera que (1) podamos calcular la función del indicador de corrección C solo con IP y (2) podemos manejar la mayor fracción de consultas con IP. En las siguientes secciones, discutimos algunos enfoques alternativos para la poda de documentos.4.3.1 Pruning global basada en relaciones públicas Primero investigamos la política de poda que comúnmente utiliza los motores de búsqueda existentes. La idea básica para esta política de poda es que el puntaje de calidad independiente de la consulta PR (D) es un factor muy importante para calcular la clasificación final del documento (p. Ej. Se sabe que PageRank es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda), por lo que construimos el índice P al mantener solo aquellos documentos cuyos valores de PR son altos (es decir, PR (D)> τp para un umbralvalor τp). La esperanza es que es probable que la mayoría de los resultados mejor clasificados tengan altos valores de PR (D), por lo que es probable que la respuesta calculada a partir de este índice P sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos por sus respectivos valores de PR (DI) y mantenemos una DI en el índice P cuando su algoritmo 4.4 Pruning de documentos locales V SL n: Tamaño máximo de una sola lista de publicacionesProcedimiento (1) foreach i (ti) ∈ if (2) clasificar dis en i (ti) basado en pr (di) (3) si | i (ti) |≤ n Luego mantenga todos los dis (4) de lo contrario Mantenga el DIS superior con el PR (DI) más alto Figura 8: Pruning de documentos locales basada en PR. Algoritmo 4.5 Procedimiento de poda de documento de palabras clave extendida (1) para cada i (ti) (2) Mantenga d ∈ I (Ti) si PR (D)> τpi o TR (D, Ti)> τti Figura 9: Palabra clave extendida-poda de documentos específico basada en PR y TR.El valor PR (DI) es más alto que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas (GPR). Las variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I (Ti), de modo que mantengamos al menos un cierto número de publicaciones para cada lista invertida I (TI). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda local basada en relaciones públicas (LPR). Desafortunadamente, la mayor parte de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo de IP cuando IP se construye de esta manera. Teorema 3 No hay podas de documentos basada en PR puede proporcionar la garantía de resultados.2 Prueba Suponga que creamos IP en función de la política GPR (generalizar la prueba de LPR es sencilla) y que cada documento D con PR (D)> τp se incluye en IP. Suponga que la entrada KTH en los resultados de Top-K tiene una puntuación de clasificación de R (DK, Q) = FR (TR (DK, Q), PR (DK)). Ahora considere otro documento DJ que fue podado de IP porque PR (DJ) <τp. Aun así, todavía es posible que el valor de los documentos tr (DJ, Q) sea muy alto que R (DJ, Q) = FR (Tr (DJ, Q), PR (DJ))> R (DK, Q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada a partir de IP puede ser significativamente peor que la de si y no es posible detectar esta degradación sin calcular la respuesta de IF. En la siguiente sección, proponemos cambios simples pero esenciales en esta política de poda que nos permite calcular la función de corrección C solo con IP.4.3.2 Pruning de palabras clave extendida El principal problema de las políticas globales de poda de documentos basadas en relacionesUn puntaje de clasificación más alto que los que regresaron de IP debido a sus puntajes de TR altos. Aquí, proponemos una nueva política de poda, llamada poda de documentos específicas de palabras clave extendidas (EKS), que evita este problema al podar no solo en función de la puntuación PR (D) independiente de la consulta, sino también basada en el término Relevancia TR (D, ti) puntaje. Es decir, para cada lista invertida I (Ti), elegimos dos valores de umbral, τpi para PR y τti para TR, de modo que si un documento d ∈ I (Ti) satisface PR (D)> τpi o TR (D, Ti)> τti, lo incluimos en i (ti) de IP. De lo contrario, lo podamos de IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden seleccionarse de varias maneras diferentes. Por ejemplo, si PR y TR tienen el mismo peso en la clasificación final y si queremos mantener en la mayoría de las publicaciones n en cada lista invertida I (Ti), es posible que deseemos establecer los dos valores de umbral iguales a τi (τpi = τti = =τi) y ajustar τi de modo que las publicaciones n permanezcan en i (ti). Esta nueva política de poda, cuando se combina con una función de puntuación monotónica, nos permite calcular la función del indicador de corrección C del índice podado. Usamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {T1, T2} y una función de clasificación monotónica, F (PR (D), Tr (D, T1), Tr (D, T2)). Hay tres escenarios posibles sobre cómo aparece un documento D en el IP de índice podado.1. D aparece tanto en I (T1) como en I (T2) de IP: dado que la información completa de D aparece en IP, podemos calcular el algoritmo exacto 4.6 Respuesta informática de la consulta de entrada IP Q = {T1 ,..., TW} Salida A: resultado de Top-K, C: Procedimiento de función del indicador de corrección (1) para cada di ∈ I (t1) ∪ · · · ∪ I (tw) (2) para cada tm ∈ Q (3)∈ I (tm) (4) tr ∗ (di, tm) = tr (di, tm) (5) else (6) tr ∗ (di, tm) = τtm (7) f (di) = f (pr (pr (Di), tr ∗ (di, t1), ..., tr ∗ (di, tn)) (8) a = top-k dis con valores más altos de f (di) (9) c = j 1 si todo di ∈A aparece en todo i (ti), ti ∈ Q 0 Figura 10: Ranking basado en los umbrales TRτ (Ti) y PRτ (Ti).puntaje de D basado en valores PR (D), TR (D, T1) y TR (D, T2) en IP: F (PR (D), TR (D, T1), TR (D, T2)).2. D aparece solo en I (T1) pero no en I (T2): dado que D no aparece en I (T2), no conocemos TR (D, T2), por lo que no podemos calcular su puntaje de clasificación exacta. Sin embargo, a partir de nuestros criterios de poda, sabemos que TR (D, T2) no puede ser mayor que el valor umbral τt2. Por lo tanto, de la monotonicidad de F (definición 2), sabemos que el puntaje de clasificación de D, F (PR (D), TR (D, T1), TR (D, T2)), no puede ser mayor que F (PR (PR(D), tr (d, t1), τt2).3. D no aparece en ninguna lista: dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores PR (D), TR (D, T1), TR (D, T2). Sin embargo, a partir de nuestros criterios de poda, sabemos que PR (D) ≤ τp1 y ≤ τp2 y que TR (D, T1) ≤ τt1 y TR (D, T2) ≤ τt2. Por lo tanto, a partir de la monotonicidad de F, sabemos que el puntaje de clasificación de D, no puede ser más grande que F (min (τp1, τp2), τt1, τt2).2 El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I (Ti) con ti ∈ Q, no podemos calcular su puntaje de clasificación exacta, pero aún podemos calcular su puntaje de límite superior utilizando el valor umbral τtipara los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado de Top-K de A de IP junto con la función indicadora de corrección C.En todas las listas invertidas I (Ti) con ti ∈ Q, por lo que conocemos su puntaje exacto. En este caso, debido a que estos documentos tienen puntajes más altos que las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en Top-K. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., Proporcionan una prueba similar en el contexto del middleware multimedia. Teorema 4 Dado un índice IP invertido podado por el algoritmo en la Figura 9, una consulta q = {t1 ,..., TW} y una función de clasificación monotónica, el resultado de Top-K de IP calculado por el algoritmo 4.6 es el mismo que el resultado de Top-K de IF IF C = 1. 2 Prueba supongamos que DK es el documento clasificado KTH calculado desde IPSegún el algoritmo 4.6. Para cada documento di ∈ Si eso no está en el resultado de Top-K de IP, hay dos escenarios posibles: Primero, DI no está en la respuesta final porque fue podada de todas las listas invertidas I (TJ), 1 ≤ J ≤W, en IP. En este caso, sabemos que PR (di) ≤ min1≤j≤wτpj <pr (dk) y que tr (di, tj) ≤ τtj <tr (dk, tj), 1 ≤ j ≤ w.De la suposición de monotonicidad, se deduce que el puntaje de clasificación de DI es R (DI) <R (DK). Es decir, la puntuación DIS nunca puede ser más grande que la de DK. En segundo lugar, Di no está en la respuesta porque DI se poda de algunas listas invertidas, digamos, I (T1) ,..., I (TM), en IP. Supongamos ¯r (di) = f (pr (di), τt1, .., τtm, tr (di, tm+1), .., tr (di, tw)). Luego, de TR (Di, Tj) ≤ τtj (1 ≤ J ≤ M) y el supuesto de monotonicidad, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.3 0.3 0.40.5 0.6 0.7 0.8 0.9 1 fracción de las personas garantizadas-f (s) Fracción del índice-s fracción de consultas garantizadas por fracción de consultas de índice garantizado Figura 11: fracción de consultas garantizadas F (s) respondida en un iníndico P de tamaño clave de tamaño clave S de tamaño S.Sabemos que r (di) ≤ ¯r (di). Además, el algoritmo 4.6 establece C = 1 solo cuando los documentos de Top-K tienen puntajes más grandes que ¯R (DI). Por lo tanto, R (Di) no puede ser más grande que R (DK).5. Evaluación experimental Para realizar pruebas realistas para nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este documento, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, se arrastró de la web durante marzo de 2004. El rastreo comenzó desde la página de inicio de los directores abiertos [10] y se procedió de manera amplia. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es de aproximadamente 1.9 TB, lo que produce un índice invertido completo si es de aproximadamente 1.2 TB. Para los experimentos informados en esta sección, utilizamos un conjunto real de consultas emitidas a Lookmart [22] a diario durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave que estaban presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es del 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que usemos una función de clasificación particular. Para estos, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación R (D, Q) es R (D, Q) = Prnorm (D) + Trnorm (D, Q) (3) donde Prnorm (D) es el Pagerank normalizado de D calculado a partir de las páginas descargadasy Trnorm (D, Q) es la distancia de coseno TF.IDF normalizada de d a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda.5.1 Pruning de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo si y creamos una IP de índice P de palabras clave de tamaño S.Para la construcción de nuestro índice P de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga de consulta de 20 días restante, medimos F (s) F (s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, IP puede manejar una consulta (es decir, c = 1) si IP incluye las listas invertidas para todas las palabras clave de consultas. Hemos repetido el experimento para diferentes valores de S, eligiendo las palabras clave con avidez como se discutió en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño S del índice P como una fracción del tamaño de IF. El eje vertical muestra la fracción F (s) de las consultas que el índice p del tamaño S puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas pueden responderse utilizando el 30% del índice original. Además, encontramos que cuando usamos la política de poda de palabras clave solamente, el tamaño óptimo del índice es S = 0.17.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 fracción de la fracción garantizada-F (s) Fracción de la fracción de índice-S de consultas garantizadas para la fracción superior de la fracción de índice de las preguntas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas F (s) respondida en un índice P de TAMAÑO SIEMBRE PREMIO DE DOCUMENTO.0 0 0.1 0.2 0.2 0.3 0.4 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.4 0.5 0.6 0.7 0.7 0.8 0.9 1 fracción de la fracción Tamaño del índice transparente - S Fracción de consultas respondidas para 20 por fracción del índice GPR LPR EKS Figura 13: Fracción de las consultas respondidas enUn índice P de tamaño de documento de tamaño s.5.2 Pruning de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos en la poda de documentos informados aquí, trabajamos con una muestra de 5.5% de todo el conjunto de consultas. La razón detrás de esto es simplemente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos tomaría aproximadamente un año de cálculo procesar las 462 millones de consultas. Para nuestro primer experimento, generamos un índice P de TAMAÑO SIEMPRE PRIMA DE DOCUMENTO utilizando la poda específica de palabras clave extendida (EKS) en la Sección 4. Dentro del índice P medimos la fracción de consultas que se pueden garantizar (según el teorema 4) para que sea correcta. Hemos realizado el experimento para diferentes tamaños de índice S y el resultado se muestra en la Figura 12. Según esta cifra, podemos ver que nuestro algoritmo de poda de documentos funciona bien en la escala de los tamaños de índice S: Para todos los tamaños de índice superiores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los resultados de los 20 mejores para el 70% de las consultas utilizando al menos el 40% del tamaño completo del índice. De la figura, podemos ver que el tamaño óptimo del índice S = 0.20 cuando usamos EK como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños del índice P ≤ 20%. Para los tamaños de índice P> 20%, la poda de palabras clave hace un trabajo mucho mejor, ya que proporciona un mayor número de garantías en cualquier tamaño de índice dado. Más adelante en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en relaciones públicas descritas en la Sección 4.3. Con este fin, aparte de EKS, también generamos Pindexes premedidos de documentos para la poda basada en relaciones públicas globales (GPR) y las políticas locales de poda PRBased (LPR). Para cada una de las políticas creamos índices P de documento de diferentes tamaños s.Dado que GPR y LPR no pueden proporcionar una garantía de corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados de Top-K calculados a partir del índice completo. Aquí, informaremos nuestros resultados para K = 20;Los resultados son similares para otros valores de k.Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.4 0.5 0.6 0.7 0.8 0.9 1 promedio de medidasLPR EKS Figura 14: Fracción promedio de los resultados de los 20 mejores del índice P con el tamaño S contenido en los resultados de los 20 mejores del índice completo. Fracción de consultas garantizadas para top -20 por fracción del índice, usando la palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.7 0.9 1 1 fracción de palabras clave del índice - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 documento fracción del índice -SV 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - F (s) Figura 15: Combinando la palabra clave y la poda de documentos. El eje horizontal muestra el tamaño S del índice P;El eje vertical muestra la fracción F (s) de las consultas cuyos resultados de los 20 mejores son idénticos a los resultados de los 20 mejores del índice completo, para un tamaño dado.Al observar la Figura 13, podemos ver que GPR realiza lo peor de las tres políticas. Por otro lado, EKS, recoge temprano, respondiendo una gran fracción de consultas (aproximadamente 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder permanece por debajo de la de EK hasta aproximadamente S = 37%. Para cualquier tamaño de índice mayor al 37%, LPR funciona mejor. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice P deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de servicio. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un índice P que se contiene dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño S del índice P;El eje vertical muestra la fracción promedio de los resultados comunes de los 20 mejores con los resultados de los 20 mejores del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos.5.3 Combinación de palabras clave y poda de documentos en las Secciones 5.1 y 5.2 Estudiamos el rendimiento individual de nuestros esquemas de poda de palabras y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la palabra clave como la poda de documentos en nuestro índice completo si? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo si y aplicamos la poda de palabras clave para crear un índice ih p de tamaño sh · 100% de IF. Después de eso, aplicamos además la poda de documentos a IH P, y creamos nuestra IP final de Pindex de tamaño SV · 100% de IH P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de SH y SV. El resultado se muestra en la Figura 15. El eje X muestra el tamaño del índice SH después de aplicar la poda de palabras clave;El eje Y muestra el tamaño del índice SV después de aplicar la poda de documentos;El eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante, aplicamos la poda de documentos manteniendo el 30% (creando así un pindex de tamaño 20% · 30%= 6% de si) podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para los tamaños de índice P más pequeños al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de palabras clave y una poda de documentos del 40% (que se traduce en un índice podado con S = 0.16) podemos proporcionar una garantía para aproximadamente el 60% de las consultas. En la Figura 15, también observamos una meseta para SH> 0.5 y SV> 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en S = 0.13, con SH = 0.46 y SV = 0.29.6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas IR. Los estudios experimentales y los análisis de varios esquemas de partición para un índice invertido se presentan en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este documento son independientes del esquema de partición utilizado. Las obras en [1, 5, 7, 20, 27] son las más relacionadas con las nuestras, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación.[32] presenta un marco genérico para calcular respuestas aproximadas de Top-K con algunos límites probabilísticos en la calidad de los resultados. Nuestro trabajo se extiende esencialmente [1, 2, 4, 7, 20, 27, 31] al proponer mecanismos para proporcionar la garantía de corrección a los resultados calculados de Top-K. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Este hilo de trabajo también es ortogonal para el nuestro porque un esquema de almacenamiento en caché puede funcionar además de nuestro índice P para minimizar el costo de cálculo de respuesta. Las funciones de clasificación exactas empleadas por los motores de búsqueda actuales son secretos estrechamente guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y la calidad de los documentos de consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de obras que miden la calidad de los documentos, generalmente capturados a través del análisis basado en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este cuerpo de trabajo. Ha habido un gran cuerpo de trabajo en el cálculo de los resultados de Top-K. La idea principal es detener el recorrido de las listas invertidas temprano o reducir las listas podando publicaciones de las listas [14, 4, 11, 8]. Nuestra prueba de la función indicadora de corrección se inspiró principalmente en [12].7. Observaciones finales Los motores de búsqueda web generalmente podan sus índices invertidos a gran escala para escalar enormes cargas de consultas. Si bien este enfoque puede mejorar el rendimiento, al calcular los resultados principales de un índice podado, podemos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para las nuevas técnicas de poda y los algoritmos de cálculo de respuesta que garantizan que las páginas coincidentes superiores siempre se colocan en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden usarse de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice premiado por palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice de documento previsto puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y más eficientes y, por lo tanto, proporcione una mejor experiencia de búsqueda de usuarios en la web.8. Referencias [1] V. N. Anh, O. de Kretser y A. Moffat. Ranking vectorial con terminación temprana efectiva. En Sigir, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas en modo mixto. En Cikm, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas Top-K sobre bases de datos accesibles para la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índice estático en los sistemas de recuperación de texto. En Cikm, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluación del rendimiento de las arquitecturas distribuidas para la recuperación de la información utilizando una variedad de cargas de trabajo. ACM Tois, 18 (1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek y A. Soffer. Poda de índice estático para sistemas de recuperación de información. En Sigir, 2001. [8] S. Chaudhuri y L. Gravano. Optimización de consultas sobre repositorios multimedia. En Sigmod, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los algoritmos, 2ª edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto.http://www.dmoz.org.[11] R. Fagin. Combinando información difusa: una descripción general. En Sigmod Record, 31 (2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para el middleware. En Pods, 2001. [13] A. Gulli y A. Signorini. La web indexable es de más de 11.5 mil millones de páginas. En www, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas multiformes eficientes en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. García-Molina y J. Pedersen. Combatir el spam web con Trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y vistas. En International conf.en Internet Computing, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hipervínculos. Journal of the ACM, 46 (5): 604-632, septiembre de 1999. [18] R. Lempel y S. Moran. El almacenamiento en caché predictivo y la captación previa de la consulta resulta en motores de búsqueda. En www, 2003. [19] R. Lempel y S. Moran. Optimización de los resultados previa en los motores de búsqueda web con índices segmentados. ACM Trans. Enterrar. Tech., 4 (1), 2004. [20] X. Long y T. Suel. Ejecución de consulta optimizada en grandes motores de búsqueda con pedidos de página global. En VLDB, 2003. [21] X. Long y T. Suel. El almacenamiento en caché de tres niveles para un procesamiento de consultas eficiente en grandes motores de búsqueda web. En www, 2005. [22] Lookmart Inc.http://www.looksmart.com.[23] S. Melnik, S. Raghavan, B. Yang y H. García-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19 (3): 217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde una perspectiva del motor de búsqueda. En www, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detección de páginas web de spam a través del análisis de contenido. En www, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. Ranking de citas de PageRank: traer orden a la web. Informe técnico, Universidad de Stanford.[27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices clasificados con frecuencia. Journal of the American Society of Information Science, 47 (10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: combinación probabilística de información de enlace e contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Sp¨arck-Jones. Ponderación de relevancia de los términos de búsqueda. Journal of the American Society for Information Science, 27: 129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, Primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. El almacenamiento en caché de dos niveles para preservar el rango para motores de búsqueda escalables. En Sigir, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas de Top-K con garantías probabilísticas. En VLDB, 2004. [33] A. Tomásico y H. García-Molina. Rendimiento de índices invertidos en sistemas de recuperación de información de documentos de texto distribuidos de texto compartido. En Paralelo y Sistemas de Información Distribuido, 1993.",
    "original_sentences": [
        "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
        "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
        "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
        "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
        "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
        "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
        "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
        "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
        "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
        "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
        "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
        "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
        "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
        "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
        "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
        "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
        "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
        "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
        "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
        "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
        "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
        "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
        "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
        "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
        "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
        "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
        "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
        "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
        "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
        "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
        "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
        "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
        "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
        "Inverted indexes.",
        "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
        "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
        "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
        "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
        "For example, Google is estimated to answer more than 250 million user queries per day.",
        "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
        "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
        "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
        "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
        "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
        "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
        "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
        "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
        "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
        "Example 2 Assume the same parameter settings as in Example 1.",
        "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
        "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
        "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
        "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
        "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
        "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
        "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
        "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
        "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
        "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
        "The algorithm in Figure 2 formalizes this idea.",
        "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
        "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
        "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
        "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
        "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
        "Question 1 How can we compute the correctness indicator function C?",
        "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
        "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
        "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
        "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
        "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
        "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
        "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
        "In the next few sections, we try to address these questions. 3.",
        "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
        "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
        "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
        "To find the answer, we start with a simple example.",
        "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
        "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
        "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
        "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
        "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
        "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
        "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
        "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
        "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
        "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
        "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
        "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
        "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
        "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
        "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
        "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
        "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
        "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
        "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
        "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
        "For example, in Figure 3, the optimal size is when s = 0.16.",
        "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
        "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
        "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
        "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
        "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
        "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
        "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
        "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
        "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
        "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
        "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
        "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
        "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
        "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
        "The goal of the search engine is to return the documents that are most relevant to query q.",
        "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
        "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
        "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
        "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
        "It is straightforward to extend our results to OR-semantics as well.",
        "The exact ranking function that search engines employ is a closely guarded secret.",
        "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
        "This particular factor of relevance captures how relevant the query is to every document.",
        "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
        "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
        "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
        "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
        "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
        "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
        "The exact combination of these parts may be done in a variety of ways.",
        "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
        "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
        "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
        "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
        "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
        "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
        "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
        "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
        "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
        "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
        "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
        "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
        "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
        "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
        "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
        "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
        "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
        "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
        "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
        "Figure 6: Approximation algorithm for the optimal keyword pruning.",
        "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
        "The cost of including I(ti) in the pindex is its size |I(ti)|.",
        "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
        "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
        "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
        "We depict the conceptual diagram of the document pruning policy in Figure 4.",
        "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
        "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
        "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
        "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
        "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
        "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
        "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
        "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
        "We refer to this pruning policy as global PR-based pruning (GPR).",
        "Variations of this pruning policy are possible.",
        "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
        "This policy is shown in Figure 8.",
        "We refer to this pruning policy as local PR-based pruning (LPR).",
        "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
        "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
        "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
        "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
        "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
        "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
        "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
        "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
        "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
        "Otherwise, we prune it from IP .",
        "Figure 9 formally describes this algorithm.",
        "The threshold values, τpi and τti, may be selected in a number of different ways.",
        "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
        "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
        "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
        "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
        "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
        "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
        "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
        "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
        "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
        "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
        "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
        "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
        "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
        "The following theorem formally proves the correctness of the algorithm.",
        "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
        "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
        "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
        "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
        "That is, Dis score can never be larger than that of Dk.",
        "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
        "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
        "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
        "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
        "Therefore, r(Di) cannot be larger than r(Dk). 5.",
        "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
        "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
        "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
        "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
        "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
        "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
        "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
        "Some experiments require us to use a particular ranking function.",
        "For these, we use the ranking function similar to the one used in [20].",
        "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
        "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
        "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
        "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
        "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
        "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
        "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
        "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
        "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
        "For example, approximately 73% of the queries can be answered using 30% of the original index.",
        "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
        "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
        "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
        "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
        "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
        "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
        "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
        "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
        "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
        "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
        "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
        "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
        "Later in Section 5.3, we discuss the combination of the two policies.",
        "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
        "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
        "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
        "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
        "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
        "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
        "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
        "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
        "For any index size larger than 37%, LPR performs the best.",
        "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
        "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
        "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
        "The result of the experiment is shown on Figure 14.",
        "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
        "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
        "One interesting question however is how do these policies perform in combination?",
        "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
        "To answer this question, we performed the following experiment.",
        "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
        "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
        "We then calculated the fraction of guaranteed queries in IP .",
        "We repeated the experiment for different values of sh and sv.",
        "The result is shown on Figure 15.",
        "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
        "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
        "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
        "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
        "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
        "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
        "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
        "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
        "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
        "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
        "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
        "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
        "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
        "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
        "The exact ranking functions employed by current search engines are closely guarded secrets.",
        "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
        "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
        "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
        "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
        "There has been a great body of work on top-k result calculation.",
        "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
        "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
        "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
        "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
        "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
        "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
        "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
        "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
        "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
        "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
        "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
        "Vector-space ranking with effective early termination.",
        "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
        "Pruning strategies for mixed-mode querying.",
        "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
        "A. Ribeiro-Neto.",
        "Modern Information Retrieval.",
        "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
        "Evaluating top-k queries over web-accessible databases.",
        "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
        "A document-centric approach to static index pruning in text retrieval systems.",
        "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
        "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
        "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
        "Static index pruning for information retrieval systems.",
        "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
        "Optimizing queries over multimedia repositories.",
        "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
        "Introduction to Algorithms, 2nd Edition.",
        "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
        "Combining fuzzy information: an overview.",
        "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
        "Optimal aggregation algorithms for middleware.",
        "In PODS, 2001. [13] A. Gulli and A. Signorini.",
        "The indexable web is more than 11.5 billion pages.",
        "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
        "Towards efficient multi-feature queries in heterogeneous environments.",
        "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
        "Combating web spam with trustrank.",
        "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
        "An analysis of web documents retrieved and viewed.",
        "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
        "Authoritative sources in a hyperlinked environment.",
        "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
        "Predictive caching and prefetching of query results in search engines.",
        "In WWW, 2003. [19] R. Lempel and S. Moran.",
        "Optimizing result prefetching in web search engines with segmented indices.",
        "ACM Trans.",
        "Inter.",
        "Tech., 4(1), 2004. [20] X.",
        "Long and T. Suel.",
        "Optimized query execution in large search engines with global page ordering.",
        "In VLDB, 2003. [21] X.",
        "Long and T. Suel.",
        "Three-level caching for efficient query processing in large web search engines.",
        "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
        "Building a distributed full-text index for the web.",
        "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
        "Whats new on the web?",
        "The evolution of the web from a search engine perspective.",
        "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
        "Detecting spam web pages through content analysis.",
        "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
        "The pagerank citation ranking: Bringing order to the web.",
        "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
        "Filtered document retrieval with frequency-sorted indexes.",
        "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
        "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
        "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
        "Relevance weighting of search terms.",
        "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
        "Introduction to modern information retrieval.",
        "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
        "Rank-preserving two-level caching for scalable search engines.",
        "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
        "Top-k query evaluation with probabilistic guarantees.",
        "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
        "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
        "In Parallel and Distributed Information Systems, 1993."
    ],
    "error_count": 0,
    "keys": {
        "web search engine": {
            "translated_key": "motor de búsqueda web",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in <br>web search engine</br>s with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large <br>web search engine</br>s.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Optimización de los resultados previos en el \"motor de búsqueda web\" con índices segmentados.",
                "El almacenamiento en caché de tres niveles para un procesamiento eficiente de consultas en un gran \"motor de búsqueda web\" s."
            ],
            "translated_text": "",
            "candidates": [
                "motor de búsqueda web",
                "motor de búsqueda web",
                "motor de búsqueda web",
                "motor de búsqueda web"
            ],
            "error": []
        },
        "large-scale inverted index": {
            "translated_key": "índice invertido a gran escala",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain <br>large-scale inverted index</br>es which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their <br>large-scale inverted index</br>es in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Boelter Hall Los Ángeles, CA 90095, EE. UU. Cho@cs.ucla.edu Resumen Los motores de búsqueda web mantienen el \"índice invertido a gran escala\" que son consultados miles de veces por segundo por los usuarios ansiosos por la información.",
                "Observaciones finales Los motores de búsqueda web generalmente podan sus \"índice invertido a gran escala\" para escalar en enormes cargas de consulta."
            ],
            "translated_text": "",
            "candidates": [
                "índice invertido a gran escala",
                "índice invertido a gran escala",
                "índice invertido a gran escala",
                "índice invertido a gran escala"
            ],
            "error": []
        },
        "query load": {
            "translated_key": "carga de consulta",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge <br>query load</br>, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the <br>query load</br> of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a <br>query load</br> of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the <br>query load</br> is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the <br>query load</br> of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the <br>query load</br>.",
                "Problem 1 (Optimal index size) Given a <br>query load</br> Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the <br>query load</br> Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the <br>query load</br> and the pruning policy.",
                "For example, even for the same p-index, if the <br>query load</br> changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the <br>query load</br> and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the <br>query load</br>.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the <br>query load</br> Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the <br>query load</br> Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day <br>query load</br>, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Para hacer frente a esta enorme \"carga de consulta\", los motores de búsqueda generalmente replican su índice en un gran clúster de máquinas como lo ilustra el siguiente ejemplo: Ejemplo 1 Considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1 (a).",
                "También suponemos que una copia de IF puede manejar la \"carga de consulta\" de 1000 consultas/seg.",
                "Es decir, el motor de búsqueda obtiene una \"carga de consulta\" de 5000 consultas/algoritmo 2.1 Cálculo de respuesta con la entrada de garantía de corrección q = ({t1, ..., tn}, [i, i + k]) donde {t1,..., TN}: Palabras clave en la consulta [i, i + k]: rango del procedimiento de respuesta para devolver (1) (a, c) = computteanswer (q, ip) (2) if (c = 1) entonces (3) Devuelve a (4) else (5) a = CopeAnswer (Q, If) (6) Devuelve una Figura 2: Calculando la respuesta debajo de la arquitectura de dos niveles con la garantía de corrección de resultados.y cada copia de un índice (tanto el IP y el IP-índice P) puede manejar hasta 1000 consultas/seg.",
                "Ejemplo 3 Nuevamente, considere un escenario similar al Ejemplo 1, donde la \"carga de consulta\" es de 5000 consultas/seg, cada copia de un índice puede manejar 1000 consultas/seg, y el índice completo se extiende a través de 4 máquinas.",
                "En el primer nivel, necesitamos 5 copias de IP 1 para manejar la \"carga de consulta\" de 5000 consultas/seg.",
                "Al formular el problema, suponemos que el número de máquinas requeridas para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 fracción de la fracción garantizada-F (s) de la fracción de índice de consultas garantizadas por fracción de la fracción de la fracción deTamaño óptimo del índice S = 0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas F (S) en un tamaño S dado S del índice P.es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la \"carga de consulta\".",
                "Problema 1 (tamaño de índice óptimo) Dada una \"carga de consulta\" Q y la función F (s), encuentre el tamaño óptimo del índice P que minimiza el tamaño total de los índices necesarios para manejar la carga Q. 2 El siguiente teorema muestraCómo podemos determinar el tamaño óptimo del índice.",
                "Teorema 1 El costo para manejar la \"carga de consulta\" Q es mínimo cuando el tamaño del índice p, s, satisface d f (s) d s = 1. 2 Prueba de la prueba de esto y los siguientes teoremas se omiten debido a restricciones de espacio.",
                "Tenga en cuenta que la forma exacta del gráfico F (S) puede variar según la \"carga de consulta\" y la política de poda.",
                "Por ejemplo, incluso para el mismo índice P, si la \"carga de consulta\" cambia significativamente, el índice P puede manejar menos (o más) consultas, disminuyendo (o aumentando) F (s)."
            ],
            "translated_text": "",
            "candidates": [
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta",
                "carga de consulta"
            ],
            "error": []
        },
        "pruned index": {
            "translated_key": "índice podado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this <br>pruned index</br> to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the <br>pruned index</br> we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the <br>pruned index</br>, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the <br>pruned index</br> and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the <br>pruned index</br> most of the time.",
                "We also show how to determine the optimal size of a <br>pruned index</br> and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the <br>pruned index</br>.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the <br>pruned index</br> [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the <br>pruned index</br> if the page did not become part of the <br>pruned index</br> for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the <br>pruned index</br>.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the <br>pruned index</br> most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A <br>pruned index</br> Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, <br>pruned index</br> (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the <br>pruned index</br> alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-<br>pruned index</br> IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the <br>pruned index</br>, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the <br>pruned index</br>.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the <br>pruned index</br> IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a <br>pruned index</br> with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a <br>pruned index</br> we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-<br>pruned index</br> can guarantee 73% of the queries with a size of 30% of the full index, while a document-<br>pruned index</br> can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Para hacer frente a las grandes cantidades de cargas de consulta, los motores de búsqueda podan su índice para mantener documentos que probablemente se devuelven como resultados principales, y usen este \"índice podado\" para calcular los primeros lotes de resultados.",
                "Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los resultados principales solo del \"índice podado\", podemos notar una degradación significativa en la calidad de los resultados: si un documento debería estar en los resultados superiores pero no fueIncluido en el \"índice podado\", se colocará detrás de los resultados calculados a partir del índice podado.",
                "Nuestra contribución es una serie de modificaciones en las técnicas de poda para crear el \"índice podado\" y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas de combate superior siempre se colocan en los mejores resultados de búsqueda, a pesar de que estamos calculando el primer lote deEl \"índice podado\" la mayor parte del tiempo.",
                "También mostramos cómo determinar el tamaño óptimo de un \"índice podado\" y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web.",
                "Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devuelvan como los principales resultados (mediante el uso, por ejemplo, las técnicas de poda en [7, 20]) y calculen el primer lotede respuestas usando el \"índice podado\".",
                "Si bien se ha demostrado que este enfoque da una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, porque las respuestas principales se calculan solo a partir del \"índice podado\" [7, 20].",
                "Es decir, incluso si una página debe colocarse como la página de coincidencia superior de acuerdo con una métrica de clasificación de motores de búsqueda, la página puede colocarse detrás de las contenidas en el \"índice podado\" si la página no se convirtió en parte de la \"podada.Índice \"por varias razones [7, 20].",
                "Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el \"índice podado\".",
                "Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas de coincidencia superior (de acuerdo con la métrica de clasificación de los motores de búsqueda) siempre se colocan en la parte superior de los resultados de búsqueda, a pesar de que estamos calculando el primer lote de respuestas del \"\"Índice podado \"la mayor parte del tiempo.",
                "La arquitectura de clúster y el ahorro de costos de un \"índice podado\", generalmente, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente."
            ],
            "translated_text": "",
            "candidates": [
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "índice podado",
                "podada.Índice ",
                "índice podado",
                "índice podado",
                "índice podado",
                "Índice podado ",
                "índice podado",
                "índice podado"
            ],
            "error": []
        },
        "online search market": {
            "translated_key": "mercado de búsqueda en línea",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the <br>online search market</br>, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the <br>online search market</br>, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Dada la feroz competencia en el \"mercado de búsqueda en línea\", este fenómeno es claramente indeseable.",
                "Dada la feroz competencia en el \"mercado de búsqueda en línea\", los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de búsqueda para maximizar la satisfacción del usuario.2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la degradación potencial de la calidad de búsqueda bajo la arquitectura de dos niveles?"
            ],
            "translated_text": "",
            "candidates": [
                "mercado de búsqueda en línea",
                "mercado de búsqueda en línea",
                "mercado de búsqueda en línea",
                "mercado de búsqueda en línea"
            ],
            "error": []
        },
        "degradation of result quality": {
            "translated_key": "degradación de la calidad de los resultados",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any <br>degradation of result quality</br> due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En este artículo, estudiamos cómo podemos evitar cualquier \"degradación de la calidad de los resultados\" debido a la optimización del rendimiento basada en la poda, al tiempo que nos damos cuenta de la mayor parte de su beneficio."
            ],
            "translated_text": "",
            "candidates": [
                "degradación de la calidad de los resultados",
                "degradación de la calidad de los resultados"
            ],
            "error": []
        },
        "result quality degradation": {
            "translated_key": "Degradación de la calidad de los resultados",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "pruning-based performance optimization": {
            "translated_key": "optimización del rendimiento basada en la poda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the <br>pruning-based performance optimization</br>, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la \"optimización del rendimiento basada en la poda\", al tiempo que nos damos cuenta de la mayor parte de su beneficio."
            ],
            "translated_text": "",
            "candidates": [
                "optimización del rendimiento basada en la poda",
                "optimización del rendimiento basada en la poda"
            ],
            "error": []
        },
        "pruning technique": {
            "translated_key": "técnica de poda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the <br>pruning technique</br>s for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the <br>pruning technique</br>s in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the <br>pruning technique</br>s for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced <br>pruning technique</br>s and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe <br>pruning technique</br>s based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new <br>pruning technique</br>s and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two <br>pruning technique</br>s, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nuestra contribución es una serie de modificaciones en las \"técnicas de poda\" s para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas de coincidencia superior siempre se colocan en los mejores resultados de búsqueda, a pesar de que estamos calculando el primer lotedel índice podado la mayor parte del tiempo.",
                "Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devuelven como los principales resultados (mediante el uso, por ejemplo, la \"técnica de poda\" en [7, 20]) y calculanEl primer lote de respuestas utilizando el índice podado.",
                "Es decir, presentamos una serie de cambios simples (pero importantes) en la \"técnica de poda\" para crear el índice podado.",
                "Estas \"técnicas de poda\" mejoradas y algoritmos de computación de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleado por los motores de búsqueda de hoy.",
                "Las obras en [1, 5, 7, 20, 27] son las más relacionadas con las nuestras, ya que describen la \"técnica de poda\" basada en la idea de mantener las publicaciones que más contribuyen en la clasificación final.",
                "En este artículo, proporcionamos un marco para los nuevos algoritmos de cálculo de \"técnicas de poda\" y respuestas que garantizan que las páginas de coincidencia de las mejores se colocan en la parte superior de los resultados de búsqueda en el orden correcto.",
                "Estudiamos dos \"técnicas de poda\", a saber, la poda basada en palabras clave y basada en documentos, así como su combinación."
            ],
            "translated_text": "",
            "candidates": [
                "técnica de poda",
                "técnicas de poda",
                "técnica de poda",
                "técnica de poda",
                "técnica de poda",
                "técnica de poda",
                "técnica de poda",
                "técnicas de poda",
                "técnica de poda",
                "técnica de poda",
                "técnica de poda",
                "técnicas de poda",
                "técnica de poda",
                "técnicas de poda"
            ],
            "error": []
        },
        "result computation algorithm": {
            "translated_key": "Algoritmo de cálculo de resultados",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new <br>result computation algorithm</br> that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nuestra contribución es una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo \"Algoritmo de cálculo de resultados\" que garantiza que las páginas de coincidencia superior siempre se colocan en los mejores resultados de búsqueda, a pesar de que estamos calculando el primer lote desdeEl índice podado la mayor parte del tiempo."
            ],
            "translated_text": "",
            "candidates": [
                "Algoritmo de cálculo de resultados",
                "Algoritmo de cálculo de resultados"
            ],
            "error": []
        },
        "top-matching page": {
            "translated_key": "página de coincidencia superior",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the <br>top-matching page</br> according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Es decir, incluso si una página debe colocarse como la \"página de coincidencia superior\" de acuerdo con una métrica de clasificación de motores de búsqueda, la página puede colocarse detrás de las contenidas en el índice podado si la página no se convirtió en parte del índice podadopor varias razones [7, 20]."
            ],
            "translated_text": "",
            "candidates": [
                "página de coincidencia superior",
                "página de coincidencia superior"
            ],
            "error": []
        },
        "top search result": {
            "translated_key": "resultado de búsqueda superior",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the <br>top search result</br>s, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nuestra contribución es una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas de combate superior siempre se colocan en el \"resultado de búsqueda superior\", a pesar de que estamos calculando el primer lotedel índice podado la mayor parte del tiempo."
            ],
            "translated_text": "",
            "candidates": [
                "Resultado de la búsqueda superior",
                "resultado de búsqueda superior"
            ],
            "error": []
        },
        "optimal size": {
            "translated_key": "tamaño óptimo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the <br>optimal size</br> of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "<br>optimal size</br> OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the <br>optimal size</br> of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index <br>optimal size</br> s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the <br>optimal size</br> is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "También mostramos cómo determinar el \"tamaño óptimo\" de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web.",
                "\"Tamaño óptimo\" del índice P intuitivamente, existe una compensación clara entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando la IP es grande y tiene más información, podrá manejar más consultas, peroEl costo de mantener y buscar IP será mayor.",
                "Dada esta compensación, ¿cómo debemos determinar el \"tamaño óptimo\" de IP para maximizar el ahorro de costos?",
                "Al formular el problema, suponemos que el número de máquinas requeridas para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 fracción de la fracción garantizada-F (s) de la fracción de índice de consultas garantizadas por fracción de la fracción de la fracción deÍndice \"Tamaño óptimo\" S = 0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas F (s) en un tamaño S dado S del índice P.es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consulta.",
                "Por ejemplo, en la Figura 3, el \"tamaño óptimo\" es cuando S = 0.16."
            ],
            "translated_text": "",
            "candidates": [
                "tamaño óptimo",
                "tamaño óptimo",
                "tamaño óptimo",
                "Tamaño óptimo",
                "tamaño óptimo",
                "tamaño óptimo",
                "tamaño óptimo",
                "Tamaño óptimo",
                "tamaño óptimo",
                "tamaño óptimo"
            ],
            "error": []
        },
        "invert index": {
            "translated_key": "invertir índice",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "prune": {
            "translated_key": "podar",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with Correctness Guarantee Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines <br>prune</br> their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with correctness guarantee Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result correctness guarantee. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 Correctness guarantee under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should <br>prune</br> the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we <br>prune</br> IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to <br>prune</br> IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we <br>prune</br> IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should <br>prune</br> the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the correctness guarantee.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically <br>prune</br> postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we <br>prune</br> it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a correctness guarantee, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the correctness guarantee to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically <br>prune</br> their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to <br>prune</br> an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Para hacer frente a las grandes cantidades de cargas de consulta, los motores de búsqueda \"podan\" su índice para mantener documentos que probablemente se devuelven como resultados principales, y usen este índice podado para calcular los primeros lotes de resultados.",
                "Ahora, el verdadero desafío es averiguar (1) cómo podemos calcular la función del indicador de corrección c y (2) cómo debemos \"podar\" el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP.",
                "Pregunta 2 ¿Cómo debemos \"podar\" si IP para realizar el ahorro máximo de costos?",
                "¿Cuál será la forma óptima de \"podar\" si a IP, de modo que C = 1 para una gran fracción de consultas?",
                "Pero ahora, supongamos que si \"podamos\" si es un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 por 40%de las consultas).",
                "Políticas de poda En esta sección, mostramos cómo debemos \"podar\" el índice completo si a IP, de modo que (1) podamos calcular la función del indicador de corrección C de IP en sí y (2) podemos manejar una gran fracción de consultas porIP.",
                "En la figura, \"podamos\" verticalmente las publicaciones correspondientes a D4, D5 y D6 de T1 y D8 de T3, suponiendo que es poco probable que estos documentos formen parte de las respuestas de Top-K a las consultas de los usuarios.",
                "De lo contrario, lo \"podamos\" de IP.",
                "Observaciones finales Los motores de búsqueda web generalmente \"podan\" sus índices invertidos a gran escala para escalar a enormes cargas de consulta.",
                "Nuestros resultados experimentales demostraron que nuestros algoritmos pueden usarse efectivamente para \"podar\" un índice invertido sin degradación en la calidad de los resultados."
            ],
            "translated_text": "",
            "candidates": [
                "ciruela pasa",
                "podan",
                "ciruela pasa",
                "podar",
                "ciruela pasa",
                "podar",
                "ciruela pasa",
                "podar",
                "ciruela pasa",
                "podamos",
                "ciruela pasa",
                "podar",
                "ciruela pasa",
                "podamos",
                "ciruela pasa",
                "podamos",
                "ciruela pasa",
                "podan",
                "ciruela pasa",
                "podar"
            ],
            "error": []
        },
        "correctness guarantee": {
            "translated_key": "Garantía de corrección",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Pruning Policies for Two-Tiered Inverted Index with <br>correctness guarantee</br> Alexandros Ntoulas∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, USA antoulas@microsoft.com Junghoo Cho† UCLA Computer Science Dept.",
                "Boelter Hall Los Angeles, CA 90095, USA cho@cs.ucla.edu ABSTRACT The Web search engines maintain large-scale inverted indexes which are queried thousands of times per second by users eager for information.",
                "In order to cope with the vast amounts of query loads, search engines prune their index to keep documents that are likely to be returned as top results, and use this pruned index to compute the first batches of results.",
                "While this approach can improve performance by reducing the size of the index, if we compute the top results only from the pruned index we may notice a significant degradation in the result quality: if a document should be in the top results but was not included in the pruned index, it will be placed behind the results computed from the pruned index.",
                "Given the fierce competition in the online search market, this phenomenon is clearly undesirable.",
                "In this paper, we study how we can avoid any degradation of result quality due to the pruning-based performance optimization, while still realizing most of its benefit.",
                "Our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top-matching pages are always placed at the top search results, even though we are computing the first batch from the pruned index most of the time.",
                "We also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million Web pages.",
                "Categories and Subject Descriptors H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms Algorithms, Measuring, Performance, Design, Experimentation 1.",
                "INTRODUCTION The amount of information on the Web is growing at a prodigious rate [24].",
                "According to a recent study [13], it is estimated that the Web currently consists of more than 11 billion pages.",
                "Due to this immense amount of available information, the users are becoming more and more dependent on the Web search engines for locating relevant information on the Web.",
                "Typically, the Web search engines, similar to other information retrieval applications, utilize a data structure called inverted index.",
                "An inverted index provides for the efficient retrieval of the documents (or Web pages) that contain a particular keyword.",
                "In most cases, a query that the user issues may have thousands or even millions of matching documents.",
                "In order to avoid overwhelming the users with a huge amount of results, the search engines present the results in batches of 10 to 20 relevant documents.",
                "The user then looks through the first batch of results and, if she doesnt find the answer she is looking for, she may potentially request to view the next batch or decide to issue a new query.",
                "A recent study [16] indicated that approximately 80% of the users examine at most the first 3 batches of the results.",
                "That is, 80% of the users typically view at most 30 to 60 results for every query that they issue to a search engine.",
                "At the same time, given the size of the Web, the inverted index that the search engines maintain can grow very large.",
                "Since the users are interested in a small number of results (and thus are viewing a small portion of the index for every query that they issue), using an index that is capable of returning all the results for a query may constitute a significant waste in terms of time, storage space and computational resources, which is bound to get worse as the Web grows larger over time [24].",
                "One natural solution to this problem is to create a small index on a subset of the documents that are likely to be returned as the top results (by using, for example, the pruning techniques in [7, 20]) and compute the first batch of answers using the pruned index.",
                "While this approach has been shown to give significant improvement in performance, it also leads to noticeable degradation in the quality of the search results, because the top answers are computed only from the pruned index [7, 20].",
                "That is, even if a page should be placed as the top-matching page according to a search engines ranking metric, the page may be placed behind the ones contained in the pruned index if the page did not become part of the pruned index for various reasons [7, 20].",
                "Given the fierce competition among search engines today this degradation is clearly undesirable and needs to be addressed if possible.",
                "In this paper, we study how we can avoid any degradation of search quality due to the above performance optimization while still realizing most of its benefit.",
                "That is, we present a number of simple (yet important) changes in the pruning techniques for creating the pruned index.",
                "Our main contribution is a new answer computation algorithm that guarantees that the top-matching pages (according to the search-engines ranking metric) are always placed at the top of search results, even though we are computing the first batch of answers from the pruned index most of the time.",
                "These enhanced pruning techniques and answer-computation algorithms are explored in the context of the cluster architecture commonly employed by todays search engines.",
                "Finally, we study and present how search engines can minimize the operational cost of answering queries while providing high quality search results.",
                "IF IF IF IF IF IF IF Ip Ip Ip Ip Ip Ip 5000 queries/sec 5000 queries/sec : 1000 queries/sec : 1000 queries/sec 2nd tier 1st tier (a) (b) Figure 1: (a) Search engine replicates its full index IF to increase query-answering capacity. (b) In the 1st tier, small pindexes IP handle most of the queries.",
                "When IP cannot answer a query, it is redirected to the 2nd tier, where the full index IF is used to compute the answer. 2.",
                "CLUSTER ARCHITECTURE AND COST SAVINGS FROM A PRUNED INDEX Typically, a search engine downloads documents from the Web and maintains a local inverted index that is used to answer queries quickly.",
                "Inverted indexes.",
                "Assume that we have collected a set of documents D = {D1, . . . , DM } and that we have extracted all the terms T = {t1, . . . , tn} from the documents.",
                "For every single term ti ∈ T we maintain a list I(ti) of document IDs that contain ti.",
                "Every entry in I(ti) is called a posting and can be extended to include additional information, such as how many times ti appears in a document, the positions of ti in the document, whether ti is bold/italic, etc.",
                "The set of all the lists I = {I(t1), . . . , I(tn)} is our inverted index. 2.1 Two-tier index architecture Search engines are accepting an enormous number of queries every day from eager users searching for relevant information.",
                "For example, Google is estimated to answer more than 250 million user queries per day.",
                "In order to cope with this huge query load, search engines typically replicate their index across a large cluster of machines as the following example illustrates: Example 1 Consider a search engine that maintains a cluster of machines as in Figure 1(a).",
                "The size of its full inverted index IF is larger than what can be stored in a single machine, so each copy of IF is stored across four different machines.",
                "We also suppose that one copy of IF can handle the query load of 1000 queries/sec.",
                "Assuming that the search engine gets 5000 queries/sec, it needs to replicate IF five times to handle the load.",
                "Overall, the search engine needs to maintain 4 × 5 = 20 machines in its cluster. 2 While fully replicating the entire index IF multiple times is a straightforward way to scale to a large number of queries, typical query loads at search engines exhibit certain localities, allowing for significant reduction in cost by replicating only a small portion of the full index.",
                "In principle, this is typically done by pruning a full index IF to create a smaller, pruned index (or p-index) IP , which contains a subset of the documents that are likely to be returned as top results.",
                "Given the p-index, search engines operate by employing a twotier index architecture as we show in Figure 1(b): All incoming queries are first directed to one of the p-indexes kept in the 1st tier.",
                "In the cases where a p-index cannot compute the answer (e.g. was unable to find enough documents to return to the user) the query is answered by redirecting it to the 2nd tier, where we maintain a full index IF .",
                "The following example illustrates the potential reduction in the query-processing cost by employing this two-tier index architecture.",
                "Example 2 Assume the same parameter settings as in Example 1.",
                "That is, the search engine gets a query load of 5000 queries/sec Algorithm 2.1 Computation of answer with <br>correctness guarantee</br> Input q = ({t1, . . . , tn}, [i, i + k]) where {t1, . . . , tn}: keywords in the query [i, i + k]: range of the answer to return Procedure (1) (A, C) = ComputeAnswer(q, IP ) (2) If (C = 1) Then (3) Return A (4) Else (5) A = ComputeAnswer(q, IF ) (6) Return A Figure 2: Computing the answer under the two-tier architecture with the result <br>correctness guarantee</br>. and every copy of an index (both the full IF and p-index IP ) can handle up to 1000 queries/sec.",
                "Also assume that the size of IP is one fourth of IF and thus can be stored on a single machine.",
                "Finally, suppose that the p-indexes can handle 80% of the user queries by themselves and only forward the remaining 20% queries to IF .",
                "Under this setting, since all 5000/sec user queries are first directed to a p-index, five copies of IP are needed in the 1st tier.",
                "For the 2nd tier, since 20% (or 1000 queries/sec) are forwarded, we need to maintain one copy of IF to handle the load.",
                "Overall we need a total of 9 machines (five machines for the five copies of IP and four machines for one copy of IF ).",
                "Compared to Example 1, this is more than 50% reduction in the number of machines. 2 The above example demonstrates the potential cost saving achieved by using a p-index.",
                "However, the two-tier architecture may have a significant drawback in terms of its result quality compared to the full replication of IF ; given the fact that the p-index contains only a subset of the data of the full index, it is possible that, for some queries, the p-index may not contain the top-ranked document according to the particular ranking criteria used by the search engine and fail to return it as the top page, leading to noticeable quality degradation in search results.",
                "Given the fierce competition in the online search market, search engine operators desperately try to avoid any reduction in search quality in order to maximize user satisfaction. 2.2 <br>correctness guarantee</br> under two-tier architecture How can we avoid the potential degradation of search quality under the two-tier architecture?",
                "Our basic idea is straightforward: We use the top-k result from the p-index only if we know for sure that the result is the same as the top-k result from the full index.",
                "The algorithm in Figure 2 formalizes this idea.",
                "In the algorithm, when we compute the result from IP (Step 1), we compute not only the top-k result A, but also the correctness indicator function C defined as follows: Definition 1 (Correctness indicator function) Given a query q, the p-index IP returns the answer A together with a correctness indicator function C. C is set to 1 if A is guaranteed to be identical (i.e. same results in the same order) to the result computed from the full index IF .",
                "If it is possible that A is different, C is set to 0. 2 Note that the algorithm returns the result from IP (Step 3) only when it is identical to the result from IF (condition C = 1 in Step 2).",
                "Otherwise, the algorithm recomputes and returns the result from the full index IF (Step 5).",
                "Therefore, the algorithm is guaranteed to return the same result as the full replication of IF all the time.",
                "Now, the real challenge is to find out (1) how we can compute the correctness indicator function C and (2) how we should prune the index to make sure that the majority of queries are handled by IP alone.",
                "Question 1 How can we compute the correctness indicator function C?",
                "A straightforward way to calculate C is to compute the top-k answer both from IP and IF and compare them.",
                "This naive solution, however, incurs a cost even higher than the full replication of IF because the answers are computed twice: once from IP and once from IF .",
                "Is there any way to compute the correctness indicator function C only from IP without computing the answer from IF ?",
                "Question 2 How should we prune IF to IP to realize the maximum cost saving?",
                "The effectiveness of Algorithm 2.1 critically depends on how often the correctness indicator function C is evaluated to be 1.",
                "If C = 0 for all queries, for example, the answers to all queries will be computed twice, once from IP (Step 1) and once from IF (Step 5), so the performance will be worse than the full replication of IF .",
                "What will be the optimal way to prune IF to IP , such that C = 1 for a large fraction of queries?",
                "In the next few sections, we try to address these questions. 3.",
                "OPTIMAL SIZE OF THE P-INDEX Intuitively, there exists a clear tradeoff between the size of IP and the fraction of queries that IP can handle: When IP is large and has more information, it will be able to handle more queries, but the cost for maintaining and looking up IP will be higher.",
                "When IP is small, on the other hand, the cost for IP will be smaller, but more queries will be forwarded to IF , requiring us to maintain more copies of IF .",
                "Given this tradeoff, how should we determine the optimal size of IP in order to maximize the cost saving?",
                "To find the answer, we start with a simple example.",
                "Example 3 Again, consider a scenario similar to Example 1, where the query load is 5000 queries/sec, each copy of an index can handle 1000 queries/sec, and the full index spans across 4 machines.",
                "But now, suppose that if we prune IF by 75% to IP 1 (i.e., the size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries (i.e., C = 1 for 40% of the queries).",
                "Also suppose that if IF is pruned by 50% to IP 2, IP 2 can handle 80% of the queries.",
                "Which one of the IP 1, IP 2 is preferable for the 1st -tier index?",
                "To find out the answer, we first compute the number of machines needed when we use IP 1 for the 1st tier.",
                "At the 1st tier, we need 5 copies of IP 1 to handle the query load of 5000 queries/sec.",
                "Since the size of IP 1 is 25% of IF (that requires 4 machines), one copy of IP 1 requires one machine.",
                "Therefore, the total number of machines required for the 1st tier is 5×1 = 5 (5 copies of IP 1 with 1 machine per copy).",
                "Also, since IP 1 can handle 40% of the queries, the 2nd tier has to handle 3000 queries/sec (60% of the 5000 queries/sec), so we need a total of 3×4 = 12 machines for the 2nd tier (3 copies of IF with 4 machines per copy).",
                "Overall, when we use IP 1 for the 1st tier, we need 5 + 12 = 17 machines to handle the load.",
                "We can do similar analysis when we use IP 2 and see that a total of 14 machines are needed when IP 2 is used.",
                "Given this result, we can conclude that using IP 2 is preferable. 2 The above example shows that the cost of the two-tier architecture depends on two important parameters: the size of the p-index and the fraction of the queries that can be handled by the 1st tier index alone.",
                "We use s to denote the size of the p-index relative to IF (i.e., if s = 0.2, for example, the p-index is 20% of the size of IF ).",
                "We use f(s) to denote the fraction of the queries that a p-index of size s can handle (i.e., if f(s) = 0.3, 30% of the queries return the value C = 1 from IP ).",
                "In general, we can expect that f(s) will increase as s gets larger because IP can handle more queries as its size grows.",
                "In Figure 3, we show an example graph of f(s) over s. Given the notation, we can state the problem of p-index-size optimization as follows.",
                "In formulating the problem, we assume that the number of machines required to operate a two-tier architecture 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed per fraction of index Optimal size s=0.16 Figure 3: Example function showing the fraction of guaranteed queries f(s) at a given size s of the p-index. is roughly proportional to the total size of the indexes necessary to handle the query load.",
                "Problem 1 (Optimal index size) Given a query load Q and the function f(s), find the optimal p-index size s that minimizes the total size of the indexes necessary to handle the load Q. 2 The following theorem shows how we can determine the optimal index size.",
                "Theorem 1 The cost for handling the query load Q is minimal when the size of the p-index, s, satisfies d f(s) d s = 1. 2 Proof The proof of this and the following theorems is omitted due to space constraints.",
                "This theorem shows that the optimal point is when the slope of the f(s) curve is 1.",
                "For example, in Figure 3, the optimal size is when s = 0.16.",
                "Note that the exact shape of the f(s) graph may vary depending on the query load and the pruning policy.",
                "For example, even for the same p-index, if the query load changes significantly, fewer (or more) queries may be handled by the p-index, decreasing (or increasing)f(s).",
                "Similarly, if we use an effective pruning policy, more queries will be handled by IP than when we use an ineffective pruning policy, increasing f(s).",
                "Therefore, the function f(s) and the optimal-index size may change significantly depending on the query load and the pruning policy.",
                "In our later experiments, however, we find that even though the shape of the f(s) graph changes noticeably between experiments, the optimal index size consistently lies between 10%-30% in most experiments. 4.",
                "PRUNING POLICIES In this section, we show how we should prune the full index IF to IP , so that (1) we can compute the correctness indicator function C from IP itself and (2) we can handle a large fraction of queries by IP .",
                "In designing the pruning policies, we note the following two localities in the users search behavior: 1.",
                "Keyword locality: Although there are many different words in the document collection that the search engine indexes, a few popular keywords constitute the majority of the query loads.",
                "This keyword locality implies that the search engine will be able to answer a significant fraction of user queries even if it can handle only these few popular keywords. 2.",
                "Document locality: Even if a query has millions of matching documents, users typically look at only the first few results [16].",
                "Thus, as long as search engines can compute the first few top-k answers correctly, users often will not notice that the search engine actually has not computed the correct answer for the remaining results (unless the users explicitly request them).",
                "Based on the above two localities, we now investigate two different types of pruning policies: (1) a keyword pruning policy, which takes advantage of the keyword locality by pruning the whole inverted list I(ti) for unpopular keywords tis and (2) a document pruning policy, which takes advantage of the document locality by keeping only a few postings in each list I(ti), which are likely to be included in the top-k results.",
                "As we discussed before, we need to be able to compute the correctness indicator function from the pruned index alone in order to provide the <br>correctness guarantee</br>.",
                "Since the computation of correctness indicator function may critically depend on the particular ranking function used by a search engine, we first clarify our assumptions on the ranking function. 4.1 Assumptions on ranking function Consider a query q = {t1, t2, . . . , tw} that contains a subset of the index terms.",
                "The goal of the search engine is to return the documents that are most relevant to query q.",
                "This is done in two steps: first we use the inverted index to find all the documents that contain the terms in the query.",
                "Second, once we have the relevant documents, we calculate the rank (or score) of each one of the documents with respect to the query and we return to the user the documents that rank the highest.",
                "Most of the major search engines today return documents containing all query terms (i.e. they use AND-semantics).",
                "In order to make our discussions more concise, we will also assume the popular AND-semantics while answering a query.",
                "It is straightforward to extend our results to OR-semantics as well.",
                "The exact ranking function that search engines employ is a closely guarded secret.",
                "What is known, however, is that the factors in determining the document ranking can be roughly categorized into two classes: Query-dependent relevance.",
                "This particular factor of relevance captures how relevant the query is to every document.",
                "At a high level, given a document D, for every term ti a search engine assigns a term relevance score tr(D, ti) to D. Given the tr(D, ti) scores for every ti, then the query-dependent relevance of D to the query, noted as tr(D, q), can be computed by combining the individual term relevance values.",
                "One popular way for calculating the querydependent relevance is to represent both the document D and the query q using the TF.IDF vector space model [29] and employ a cosine distance metric.",
                "Since the exact form of tr(D, ti) and tr(D, q) differs depending on the search engine, we will not restrict to any particular form; instead, in order to make our work applicable in the general case, we will make the generic assumption that the query-dependent relevance is computed as a function of the individual term relevance values in the query: tr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1) Query-independent document quality.",
                "This is a factor that measures the overall quality of a document D independent of the particular query issued by the user.",
                "Popular techniques that compute the general quality of a page include PageRank [26], HITS [17] and the likelihood that the page is a spam page [25, 15].",
                "Here, we will use pr(D) to denote this query-independent part of the final ranking function for document D. The final ranking score r(D, q) of a document will depend on both the query-dependent and query-independent parts of the ranking function.",
                "The exact combination of these parts may be done in a variety of ways.",
                "In general, we can assume that the final ranking score of a document is a function of its query-dependent and query-independent relevance scores.",
                "More formally: r(D, q) = fr(tr(D, q), pr(D)) (2) For example, fr(tr(D, q), pr(D)) may take the form fr(tr(D, q), pr(D)) = α · tr(D, q) + (1 − α) · pr(D), thus giving weight α to the query-dependent part and the weight 1 − α to the query-independent part.",
                "In Equations 1 and 2 the exact form of fr and ftr can vary depending on the search engine.",
                "Therefore, to make our discussion applicable independent of the particular ranking function used by search engines, in this paper, we will make only the generic assumption that the ranking function r(D, q) is monotonic on its parameters tr(D, t1), . . . , tr(D, tw) and pr(D). t1 → D1 D2 D3 D4 D5 D6 t2 → D1 D2 D3 t3 → D3 D5 D7 D8 t4 → D4 D10 t5 → D6 D8 D9 Figure 4: Keyword and document pruning.",
                "Algorithm 4.1 Computation of C for keyword pruning Procedure (1) C = 1 (2) Foreach ti ∈ q (3) If (I(ti) /∈ IP ) Then C = 0 (4) Return C Figure 5: Result guarantee in keyword pruning.",
                "Definition 2 A function f(α, β, . . . , ω) is monotonic if ∀α1 ≥ α2, ∀β1 ≥ β2, . . . ∀ω1 ≥ ω2 it holds that: f(α1, β1, . . . , ω1) ≥ f(α2, β2, . . . , ω2).",
                "Roughly, the monotonicity of the ranking function implies that, between two documents D1 and D2, if D1 has higher querydependent relevance than D2 and also a higher query-independent score than D2, then D1 should be ranked higher than D2, which we believe is a reasonable assumption in most practical settings. 4.2 Keyword pruning Given our assumptions on the ranking function, we now investigate the keyword pruning policy, which prunes the inverted index IF horizontally by removing the whole I(ti)s corresponding to the least frequent terms.",
                "In Figure 4 we show a graphical representation of keyword pruning, where we remove the inverted lists for t3 and t5, assuming that they do not appear often in the query load.",
                "Note that after keyword pruning, if all keywords {t1, . . . , tn} in the query q appear in IP , the p-index has the same information as IF as long as q is concerned.",
                "In other words, if all keywords in q appear in IP , the answer computed from IP is guaranteed to be the same as the answer computed from IF .",
                "Figure 5 formalizes this observation and computes the correctness indicator function C for a keyword-pruned index IP .",
                "It is straightforward to prove that the answer from IP is identical to that from IF if C = 1 in the above algorithm.",
                "We now consider the issue of optimizing the IP such that it can handle the largest fraction of queries.",
                "This problem can be formally stated as follows: Problem 2 (Optimal keyword pruning) Given the query load Q and a goal index size s · |IF | for the pruned index, select the inverted lists IP = {I(t1), . . . , I(th)} such that |IP | ≤ s · |IF | and the fraction of queries that IP can answer (expressed by f(s)) is maximized. 2 Unfortunately, the optimal solution to the above problem is intractable as we can show by reducing from knapsack (we omit the complete proof).",
                "Theorem 2 The problem of calculating the optimal keyword pruning is NP-hard. 2 Given the intractability of the optimal solution, we need to resort to an approximate solution.",
                "A common approach for similar knapsack problems is to adopt a greedy policy by keeping the items with the maximum benefit per unit cost [9].",
                "In our context, the potential benefit of an inverted list I(ti) is the number of queries that can be answered by IP when I(ti) is included in IP .",
                "We approximate this number by the fraction of queries in the query load Q that include the term ti and represent it as P(ti).",
                "For example, if 100 out of 1000 queries contain the term computer, Algorithm 4.2 Greedy keyword pruning HS Procedure (1) ∀ti, calculate HS(ti) = P (ti) |I(ti)| . (2) Include the inverted lists with the highest HS(ti) values such that |IP | ≤ s · |IF |.",
                "Figure 6: Approximation algorithm for the optimal keyword pruning.",
                "Algorithm 4.3 Global document pruning V SG Procedure (1) Sort all documents Di based on pr(Di) (2) Find the threshold value τp, such that only s fraction of the documents have pr(Di) > τp (4) Keep Di in the inverted lists if pr(Di) > τp Figure 7: Global document pruning based on pr. then P(computer) = 0.1.",
                "The cost of including I(ti) in the pindex is its size |I(ti)|.",
                "Thus, in our greedy approach in Figure 6, we include I(ti)s in the decreasing order of P(ti)/|I(ti)| as long as |IP | ≤ s · |IF |.",
                "Later in our experiment section, we evaluate what fraction of queries can be handled by IP when we employ this greedy keyword-pruning policy. 4.3 Document pruning At a high level, document pruning tries to take advantage of the observation that most users are mainly interested in viewing the top few answers to a query.",
                "Given this, it is unnecessary to keep all postings in an inverted list I(ti), because users will not look at most of the documents in the list anyway.",
                "We depict the conceptual diagram of the document pruning policy in Figure 4.",
                "In the figure, we vertically prune postings corresponding to D4, D5 and D6 of t1 and D8 of t3, assuming that these documents are unlikely to be part of top-k answers to user queries.",
                "Again, our goal is to develop a pruning policy such that (1) we can compute the correctness indicator function C from IP alone and (2) we can handle the largest fraction of queries with IP .",
                "In the next few sections, we discuss a few alternative approaches for document pruning. 4.3.1 Global PR-based pruning We first investigate the pruning policy that is commonly used by existing search engines.",
                "The basic idea for this pruning policy is that the query-independent quality score pr(D) is a very important factor in computing the final ranking of the document (e.g.",
                "PageRank is known to be one of the most important factors determining the overall ranking in the search results), so we build the p-index by keeping only those documents whose pr values are high (i.e., pr(D) > τp for a threshold value τp).",
                "The hope is that most of the top-ranked results are likely to have high pr(D) values, so the answer computed from this p-index is likely to be similar to the answer computed from the full index.",
                "Figure 7 describes this pruning policy more formally, where we sort all documents Dis by their respective pr(Di) values and keep a Di in the p-index when its Algorithm 4.4 Local document pruning V SL N: maximum size of a single posting list Procedure (1) Foreach I(ti) ∈ IF (2) Sort Dis in I(ti) based on pr(Di) (3) If |I(ti)| ≤ N Then keep all Dis (4) Else keep the top-N Dis with the highest pr(Di) Figure 8: Local document pruning based on pr.",
                "Algorithm 4.5 Extended keyword-specific document pruning Procedure (1) For each I(ti) (2) Keep D ∈ I(ti) if pr(D) > τpi or tr(D, ti) > τti Figure 9: Extended keyword-specific document pruning based on pr and tr. pr(Di) value is higher than the global threshold value τp.",
                "We refer to this pruning policy as global PR-based pruning (GPR).",
                "Variations of this pruning policy are possible.",
                "For example, we may adjust the threshold value τp locally for each inverted list I(ti), so that we maintain at least a certain number of postings for each inverted list I(ti).",
                "This policy is shown in Figure 8.",
                "We refer to this pruning policy as local PR-based pruning (LPR).",
                "Unfortunately, the biggest shortcoming of this policy is that we can prove that we cannot compute the correctness function C from IP alone when IP is constructed this way.",
                "Theorem 3 No PR-based document pruning can provide the result guarantee. 2 Proof Assume we create IP based on the GPR policy (generalizing the proof to LPR is straightforward) and that every document D with pr(D) > τp is included in IP .",
                "Assume that the kth entry in the top-k results, has a ranking score of r(Dk, q) = fr(tr(Dk, q), pr(Dk)).",
                "Now consider another document Dj that was pruned from IP because pr(Dj) < τp.",
                "Even so, it is still possible that the documents tr(Dj, q) value is very high such that r(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).",
                "Therefore, under a PR-based pruning policy, the quality of the answer computed from IP can be significantly worse than that from IF and it is not possible to detect this degradation without computing the answer from IF .",
                "In the next section, we propose simple yet essential changes to this pruning policy that allows us to compute the correctness function C from IP alone. 4.3.2 Extended keyword-specific pruning The main problem of global PR-based document pruning policies is that we do not know the term-relevance score tr(D, ti) of the pruned documents, so a document not in IP may have a higher ranking score than the ones returned from IP because of their high tr scores.",
                "Here, we propose a new pruning policy, called extended keyword-specific document pruning (EKS), which avoids this problem by pruning not just based on the query-independent pr(D) score but also based on the term-relevance tr(D, ti) score.",
                "That is, for every inverted list I(ti), we pick two threshold values, τpi for pr and τti for tr, such that if a document D ∈ I(ti) satisfies pr(D) > τpi or tr(D, ti) > τti, we include it in I(ti) of IP .",
                "Otherwise, we prune it from IP .",
                "Figure 9 formally describes this algorithm.",
                "The threshold values, τpi and τti, may be selected in a number of different ways.",
                "For example, if pr and tr have equal weight in the final ranking and if we want to keep at most N postings in each inverted list I(ti), we may want to set the two threshold values equal to τi (τpi = τti = τi) and adjust τi such that N postings remain in I(ti).",
                "This new pruning policy, when combined with a monotonic scoring function, enables us to compute the correctness indicator function C from the pruned index.",
                "We use the following example to explain how we may compute C. Example 4 Consider the query q = {t1, t2} and a monotonic ranking function, f(pr(D), tr(D, t1), tr(D, t2)).",
                "There are three possible scenarios on how a document D appears in the pruned index IP . 1.",
                "D appears in both I(t1) and I(t2) of IP : Since complete information of D appears in IP , we can compute the exact Algorithm 4.6 Computing Answer from IP Input Query q = {t1, . . . , tw} Output A: top-k result, C: correctness indicator function Procedure (1) For each Di ∈ I(t1) ∪ · · · ∪ I(tw) (2) For each tm ∈ q (3) If Di ∈ I(tm) (4) tr∗(Di, tm) = tr(Di, tm) (5) Else (6) tr∗(Di, tm) = τtm (7) f(Di) = f(pr(Di), tr∗(Di, t1), . . . , tr∗(Di, tn)) (8) A = top-k Dis with highest f(Di) values (9) C = j 1 if all Di ∈ A appear in all I(ti), ti ∈ q 0 otherwise Figure 10: Ranking based on thresholds trτ (ti) and prτ (ti). score of D based on pr(D), tr(D, t1) and tr(D, t2) values in IP : f(pr(D), tr(D, t1), tr(D, t2)). 2.",
                "D appears only in I(t1) but not in I(t2): Since D does not appear in I(t2), we do not know tr(D, t2), so we cannot compute its exact ranking score.",
                "However, from our pruning criteria, we know that tr(D, t2) cannot be larger than the threshold value τt2.",
                "Therefore, from the monotonicity of f (Definition 2), we know that the ranking score of D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than f(pr(D), tr(D, t1), τt2). 3.",
                "D does not appear in any list: Since D does not appear at all in IP , we do not know any of the pr(D), tr(D, t1), tr(D, t2) values.",
                "However, from our pruning criteria, we know that pr(D) ≤ τp1 and ≤ τp2 and that tr(D, t1) ≤ τt1 and tr(D, t2) ≤ τt2.",
                "Therefore, from the monotonicity of f, we know that the ranking score of D, cannot be larger than f(min(τp1, τp2), τt1, τt2). 2 The above example shows that when a document does not appear in one of the inverted lists I(ti) with ti ∈ q, we cannot compute its exact ranking score, but we can still compute its upper bound score by using the threshold value τti for the missing values.",
                "This suggests the algorithm in Figure 10 that computes the top-k result A from IP together with the correctness indicator function C. In the algorithm, the correctness indicator function C is set to one only if all documents in the top-k result A appear in all inverted lists I(ti) with ti ∈ q, so we know their exact score.",
                "In this case, because these documents have scores higher than the upper bound scores of any other documents, we know that no other documents can appear in the top-k.",
                "The following theorem formally proves the correctness of the algorithm.",
                "In [11] Fagin et al., provides a similar proof in the context of multimedia middleware.",
                "Theorem 4 Given an inverted index IP pruned by the algorithm in Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking function, the top-k result from IP computed by Algorithm 4.6 is the same as the top-k result from IF if C = 1. 2 Proof Let us assume Dk is the kth ranked document computed from IP according to Algorithm 4.6.",
                "For every document Di ∈ IF that is not in the top-k result from IP , there are two possible scenarios: First, Di is not in the final answer because it was pruned from all inverted lists I(tj), 1 ≤ j ≤ w, in IP .",
                "In this case, we know that pr(Di) ≤ min1≤j≤wτpj < pr(Dk) and that tr(Di, tj) ≤ τtj < tr(Dk, tj), 1 ≤ j ≤ w. From the monotonicity assumption, it follows that the ranking score of DI is r(Di) < r(Dk).",
                "That is, Dis score can never be larger than that of Dk.",
                "Second, Di is not in the answer because Di is pruned from some inverted lists, say, I(t1), . . . , I(tm), in IP .",
                "Let us assume ¯r(Di) = f(pr(Di),τt1,. . . ,τtm,tr(Di, tm+1),. . . ,tr(Di, tw)).",
                "Then, from tr(Di, tj) ≤ τtj(1 ≤ j ≤ m) and the monotonicity assumption, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed−f(s) Fraction of index − s Fraction of queries guaranteed per fraction of index queries guaranteed Figure 11: Fraction of guaranteed queries f(s) answered in a keyword-pruned p-index of size s. we know that r(Di) ≤ ¯r(Di).",
                "Also, Algorithm 4.6 sets C = 1 only when the top-k documents have scores larger than ¯r(Di).",
                "Therefore, r(Di) cannot be larger than r(Dk). 5.",
                "EXPERIMENTAL EVALUATION In order to perform realistic tests for our pruning policies, we implemented a search engine prototype.",
                "For the experiments in this paper, our search engine indexed about 130 million pages, crawled from the Web during March of 2004.",
                "The crawl started from the Open Directorys [10] homepage and proceeded in a breadth-first manner.",
                "Overall, the total uncompressed size of our crawled Web pages is approximately 1.9 TB, yielding a full inverted index IF of approximately 1.2 TB.",
                "For the experiments reported in this section we used a real set of queries issued to Looksmart [22] on a daily basis during April of 2003.",
                "After keeping only the queries containing keywords that were present in our inverted index, we were left with a set of about 462 million queries.",
                "Within our query set, the average number of terms per query is 2 and 98% of the queries contain at most 5 terms.",
                "Some experiments require us to use a particular ranking function.",
                "For these, we use the ranking function similar to the one used in [20].",
                "More precisely, our ranking function r(D, q) is r(D, q) = prnorm(D) + trnorm(D, q) (3) where prnorm(D) is the normalized PageRank of D computed from the downloaded pages and trnorm(D, q) is the normalized TF.IDF cosine distance of D to q.",
                "This function is clearly simpler than the real functions employed by commercial search engines, but we believe for our evaluation this simple function is adequate, because we are not studying the effectiveness of a ranking function, but the effectiveness of pruning policies. 5.1 Keyword pruning In our first experiment we study the performance of the keyword pruning, described in Section 4.2.",
                "More specifically, we apply the algorithm HS of Figure 6 to our full index IF and create a keyword-pruned p-index IP of size s. For the construction of our keyword-pruned p-index we used the query frequencies observed during the first 10 days of our data set.",
                "Then, using the remaining 20-day query load, we measured f(s), the fraction of queries handled by IP .",
                "According to the algorithm of Figure 5, a query can be handled by IP (i.e., C = 1) if IP includes the inverted lists for all of the querys keywords.",
                "We have repeated the experiment for varying values of s, picking the keywords greedily as discussed in Section 4.2.The result is shown in Figure 11.",
                "The horizontal axis denotes the size s of the p-index as a fraction of the size of IF .",
                "The vertical axis shows the fraction f(s) of the queries that the p-index of size s can answer.",
                "The results of Figure 11, are very encouraging: we can answer a significant fraction of the queries with a small fraction of the original index.",
                "For example, approximately 73% of the queries can be answered using 30% of the original index.",
                "Also, we find that when we use the keyword pruning policy only, the optimal index size is s = 0.17. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesguaranteed-f(s) Fraction of index - s Fraction of queries guaranteed for top-20 per fraction of index fraction of queries guaranteed (EKS) Figure 12: Fraction of guaranteed queries f(s) answered in a document-pruned p-index of size s. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fractionofqueriesanswered index size - s Fraction of queries answered for top-20 per fraction of index GPR LPR EKS Figure 13: Fraction of queries answered in a document-pruned p-index of size s. 5.2 Document pruning We continue our experimental evaluation by studying the performance of the various document pruning policies described in Section 4.3.",
                "For the experiments on document pruning reported here we worked with a 5.5% sample of the whole query set.",
                "The reason behind this is merely practical: since we have much less machines compared to a commercial search engine it would take us about a year of computation to process all 462 million queries.",
                "For our first experiment, we generate a document-pruned p-index of size s by using the Extended Keyword-Specific pruning (EKS) in Section 4.",
                "Within the p-index we measure the fraction of queries that can be guaranteed (according to Theorem 4) to be correct.",
                "We have performed the experiment for varying index sizes s and the result is shown in Figure 12.",
                "Based on this figure, we can see that our document pruning algorithm performs well across the scale of index sizes s: for all index sizes larger than 40%, we can guarantee the correct answer for about 70% of the queries.",
                "This implies that our EKS algorithm can successfully identify the necessary postings for calculating the top-20 results for 70% of the queries by using at least 40% of the full index size.",
                "From the figure, we can see that the optimal index size s = 0.20 when we use EKS as our pruning policy.",
                "We can compare the two pruning schemes, namely the keyword pruning and EKS, by contrasting Figures 11 and 12.",
                "Our observation is that, if we would have to pick one of the two pruning policies, then the two policies seem to be more or less equivalent for the p-index sizes s ≤ 20%.",
                "For the p-index sizes s > 20%, keyword pruning does a much better job as it provides a higher number of guarantees at any given index size.",
                "Later in Section 5.3, we discuss the combination of the two policies.",
                "In our next experiment, we are interested in comparing EKS with the PR-based pruning policies described in Section 4.3.",
                "To this end, apart from EKS, we also generated document-pruned pindexes for the Global pr-based pruning (GPR) and the Local prbased pruning (LPR) policies.",
                "For each of the polices we created document-pruned p-indexes of varying sizes s. Since GPR and LPR cannot provide a <br>correctness guarantee</br>, we will compare the fraction of queries from each policy that are identical (i.e. the same results in the same order) to the top-k results calculated from the full index.",
                "Here, we will report our results for k = 20; the results are similar for other values of k. The results are shown in Figure 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Averagefractionofdocsinanswer index size - s Average fraction of docs in answer for top-20 per fraction of index GPR LPR EKS Figure 14: Average fraction of the top-20 results of p-index with size s contained in top-20 results of the full index.",
                "Fraction of queries guaranteed for top-20 per fraction of index, using keyword and document 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Keyword fraction of index - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Document fraction of index - sv 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fraction of queries guaranteed - f(s) Figure 15: Combining keyword and document pruning.",
                "The horizontal axis shows the size s of the p-index; the vertical axis shows the fraction f(s) of the queries whose top-20 results are identical to the top-20 results of the full index, for a given size s. By observing Figure 13, we can see that GPR performs the worst of the three policies.",
                "On the other hand EKS, picks up early, by answering a great fraction of queries (about 62%) correctly with only 10% of the index size.",
                "The fraction of queries that LPR can answer remains below that of EKS until about s = 37%.",
                "For any index size larger than 37%, LPR performs the best.",
                "In the experiment of Figure 13, we applied the strict definition that the results of the p-index have to be in the same order as the ones of the full index.",
                "However, in a practical scenario, it may be acceptable to have some of the results out of order.",
                "Therefore, in our next experiment we will measure the fraction of the results coming from an p-index that are contained within the results of the full index.",
                "The result of the experiment is shown on Figure 14.",
                "The horizontal axis is, again, the size s of the p-index; the vertical axis shows the average fraction of the top-20 results common with the top-20 results from the full index.",
                "Overall, Figure 14 depicts that EKS and LPR identify the same high (≈ 96%) fraction of results on average for any size s ≥ 30%, with GPR not too far behind. 5.3 Combining keyword and document pruning In Sections 5.1 and 5.2 we studied the individual performance of our keyword and document pruning schemes.",
                "One interesting question however is how do these policies perform in combination?",
                "What fraction of queries can we guarantee if we apply both keyword and document pruning in our full index IF ?",
                "To answer this question, we performed the following experiment.",
                "We started with the full index IF and we applied keyword pruning to create an index Ih P of size sh · 100% of IF .",
                "After that, we further applied document pruning to Ih P , and created our final pindex IP of size sv ·100% of Ih P .",
                "We then calculated the fraction of guaranteed queries in IP .",
                "We repeated the experiment for different values of sh and sv.",
                "The result is shown on Figure 15.",
                "The x-axis shows the index size sh after applying keyword pruning; the y-axis shows the index size sv after applying document pruning; the z-axis shows the fraction of guaranteed queries after the two prunings.",
                "For example the point (0.2, 0.3, 0.4) means that if we apply keyword pruning and keep 20% of IF , and subsequently on the resulting index we apply document pruning keeping 30% (thus creating a pindex of size 20%·30% = 6% of IF ) we can guarantee 40% of the queries.",
                "By observing Figure 15, we can see that for p-index sizes smaller than 50%, our combined pruning does relatively well.",
                "For example, by performing 40% keyword and 40% document pruning (which translates to a pruned index with s = 0.16) we can provide a guarantee for about 60% of the queries.",
                "In Figure 15, we also observe a plateau for sh > 0.5 and sv > 0.5.",
                "For this combined pruning policy, the optimal index size is at s = 0.13, with sh = 0.46 and sv = 0.29. 6.",
                "RELATED WORK [3, 30] provide a good overview of inverted indexing in Web search engines and IR systems.",
                "Experimental studies and analyses of various partitioning schemes for an inverted index are presented in [6, 23, 33].",
                "The pruning algorithms that we have presented in this paper are independent of the partitioning scheme used.",
                "The works in [1, 5, 7, 20, 27] are the most related to ours, as they describe pruning techniques based on the idea of keeping the postings that contribute the most in the final ranking.",
                "However, [1, 5, 7, 27] do not consider any query-independent quality (such as PageRank) in the ranking function. [32] presents a generic framework for computing approximate top-k answers with some probabilistic bounds on the quality of results.",
                "Our work essentially extends [1, 2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the <br>correctness guarantee</br> to the computed top-k results.",
                "Search engines use various methods of caching as a means of reducing the cost associated with queries [18, 19, 21, 31].",
                "This thread of work is also orthogonal to ours because a caching scheme may operate on top of our p-index in order to minimize the answer computation cost.",
                "The exact ranking functions employed by current search engines are closely guarded secrets.",
                "In general, however, the rankings are based on query-dependent relevance and queryindependent document quality.",
                "Query-dependent relevance can be calculated in a variety of ways (see [3, 30]).",
                "Similarly, there are a number of works that measure the quality of the documents, typically as captured through link-based analysis [17, 28, 26].",
                "Since our work does not assume a particular form of ranking function, it is complementary to this body of work.",
                "There has been a great body of work on top-k result calculation.",
                "The main idea is to either stop the traversal of the inverted lists early, or to shrink the lists by pruning postings from the lists [14, 4, 11, 8].",
                "Our proof for the correctness indicator function was primarily inspired by [12]. 7.",
                "CONCLUDING REMARKS Web search engines typically prune their large-scale inverted indexes in order to scale to enormous query loads.",
                "While this approach may improve performance, by computing the top results from a pruned index we may notice a significant degradation in the result quality.",
                "In this paper, we provided a framework for new pruning techniques and answer computation algorithms that guarantee that the top matching pages are always placed at the top of search results in the correct order.",
                "We studied two pruning techniques, namely keyword-based and document-based pruning as well as their combination.",
                "Our experimental results demonstrated that our algorithms can effectively be used to prune an inverted index without degradation in the quality of results.",
                "In particular, a keyword-pruned index can guarantee 73% of the queries with a size of 30% of the full index, while a document-pruned index can guarantee 68% of the queries with the same size.",
                "When we combine the two pruning algorithms we can guarantee 60% of the queries with an index size of 16%.",
                "It is our hope that our work will help search engines develop better, faster and more efficient indexes and thus provide for a better user search experience on the Web. 8.",
                "REFERENCES [1] V. N. Anh, O. de Kretser, and A. Moffat.",
                "Vector-space ranking with effective early termination.",
                "In SIGIR, 2001. [2] V. N. Anh and A. Moffat.",
                "Pruning strategies for mixed-mode querying.",
                "In CIKM, 2006. [3] R. A. Baeza-Yates and B.",
                "A. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano, and A. Marian.",
                "Evaluating top-k queries over web-accessible databases.",
                "In ICDE, 2002. [5] S. B¨uttcher and C. L. A. Clarke.",
                "A document-centric approach to static index pruning in text retrieval systems.",
                "In CIKM, 2006. [6] B. Cahoon, K. S. McKinley, and Z. Lu.",
                "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads.",
                "ACM TOIS, 18(1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek, and A. Soffer.",
                "Static index pruning for information retrieval systems.",
                "In SIGIR, 2001. [8] S. Chaudhuri and L. Gravano.",
                "Optimizing queries over multimedia repositories.",
                "In SIGMOD, 1996. [9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest.",
                "Introduction to Algorithms, 2nd Edition.",
                "MIT Press/McGraw Hill, 2001. [10] Open directory. http://www.dmoz.org. [11] R. Fagin.",
                "Combining fuzzy information: an overview.",
                "In SIGMOD Record, 31(2), 2002. [12] R. Fagin, A. Lotem, and M. Naor.",
                "Optimal aggregation algorithms for middleware.",
                "In PODS, 2001. [13] A. Gulli and A. Signorini.",
                "The indexable web is more than 11.5 billion pages.",
                "In WWW, 2005. [14] U. Guntzer, G. Balke, and W. Kiessling.",
                "Towards efficient multi-feature queries in heterogeneous environments.",
                "In ITCC, 2001. [15] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen.",
                "Combating web spam with trustrank.",
                "In VLDB, 2004. [16] B. J. Jansen and A. Spink.",
                "An analysis of web documents retrieved and viewed.",
                "In International Conf. on Internet Computing, 2003. [17] J. Kleinberg.",
                "Authoritative sources in a hyperlinked environment.",
                "Journal of the ACM, 46(5):604-632, September 1999. [18] R. Lempel and S. Moran.",
                "Predictive caching and prefetching of query results in search engines.",
                "In WWW, 2003. [19] R. Lempel and S. Moran.",
                "Optimizing result prefetching in web search engines with segmented indices.",
                "ACM Trans.",
                "Inter.",
                "Tech., 4(1), 2004. [20] X.",
                "Long and T. Suel.",
                "Optimized query execution in large search engines with global page ordering.",
                "In VLDB, 2003. [21] X.",
                "Long and T. Suel.",
                "Three-level caching for efficient query processing in large web search engines.",
                "In WWW, 2005. [22] Looksmart inc. http://www.looksmart.com. [23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina.",
                "Building a distributed full-text index for the web.",
                "ACM TOIS, 19(3):217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston.",
                "Whats new on the web?",
                "The evolution of the web from a search engine perspective.",
                "In WWW, 2004. [25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly.",
                "Detecting spam web pages through content analysis.",
                "In WWW, 2006. [26] L. Page, S. Brin, R. Motwani, and T. Winograd.",
                "The pagerank citation ranking: Bringing order to the web.",
                "Technical report, Stanford University. [27] M. Persin, J. Zobel, and R. Sacks-Davis.",
                "Filtered document retrieval with frequency-sorted indexes.",
                "Journal of the American Society of Information Science, 47(10), 1996. [28] M. Richardson and P. Domingos.",
                "The intelligent surfer: Probabilistic combination of link and content information in pagerank.",
                "In Advances in Neural Information Processing Systems, 2002. [29] S. Robertson and K. Sp¨arck-Jones.",
                "Relevance weighting of search terms.",
                "Journal of the American Society for Information Science, 27:129-46, 1976. [30] G. Salton and M. J. McGill.",
                "Introduction to modern information retrieval.",
                "McGraw-Hill, first edition, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Riberio-Neto.",
                "Rank-preserving two-level caching for scalable search engines.",
                "In SIGIR, 2001. [32] M. Theobald, G. Weikum, and R. Schenkel.",
                "Top-k query evaluation with probabilistic guarantees.",
                "In VLDB, 2004. [33] A. Tomasic and H. Garcia-Molina.",
                "Performance of inverted indices in shared-nothing distributed text document information retrieval systems.",
                "In Parallel and Distributed Information Systems, 1993."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Políticas de poda para un índice invertido de dos niveles con \"Garantía de corrección\" Alexandros ntoulas ∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. Antulas@microsoft.",
                "Es decir, el motor de búsqueda obtiene una carga de consulta de 5000 consultas/algoritmo de segundo 2.1 Cálculo de respuesta con entrada \"Garantía de corrección\" q = ({t1, ..., tn}, [i, i + k]) donde {t1,..., TN}: Palabras clave en la consulta [i, i + k]: rango del procedimiento de respuesta para devolver (1) (a, c) = computteanswer (q, ip) (2) if (c = 1) entonces (3) Devuelve a (4) else (5) a = CopeAnswer (Q, If) (6) Devuelve una Figura 2: Calcula la respuesta debajo de la arquitectura de dos niveles con la \"Garantía de corrección\" del resultado.y cada copia de un índice (tanto el IP y el IP-índice P) puede manejar hasta 1000 consultas/seg.",
                "Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de búsqueda para maximizar la satisfacción del usuario.2.2 \"Garantía de corrección\" bajo arquitectura de dos niveles ¿Cómo podemos evitar la degradación potencial de la calidad de búsqueda bajo la arquitectura de dos niveles?",
                "Como discutimos antes, necesitamos poder calcular la función indicadora de corrección del índice podado solo para proporcionar la \"garantía de corrección\".",
                "Para cada una de las políticas creamos índices P de documento de diferentes tamaños s.Dado que GPR y LPR no pueden proporcionar una \"garantía de corrección\", compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados de Top-K calculados a partir del índice completo.",
                "Nuestro trabajo se extiende esencialmente [1, 2, 4, 7, 20, 27, 31] al proponer mecanismos para proporcionar la \"garantía de corrección\" a los resultados calculados de Top-K."
            ],
            "translated_text": "",
            "candidates": [
                "com Junghoo Cho † UCLA Ciencia de informática de la corrección Garantía de garantía",
                "Garantía de corrección",
                "Garantía de corrección",
                "Garantía de corrección",
                "Garantía de corrección",
                "Garantía de corrección",
                "Garantía de corrección",
                "Garantía de corrección",
                "garantía de corrección",
                "Garantía de corrección",
                "garantía de corrección",
                "Garantía de corrección",
                "garantía de corrección"
            ],
            "error": []
        }
    }
}