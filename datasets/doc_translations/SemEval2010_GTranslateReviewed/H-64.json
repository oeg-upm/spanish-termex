{
    "id": "H-64",
    "original_text": "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries. Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection. The goal of this discovery is twofold. First we desire a practical aid for information architects. Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces. The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text. In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations. Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1. INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 . Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces. To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques. In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site. The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]). Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems. The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections. By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures. Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site. Our approach combines supervised and unsupervised learning techniques. A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6]. But strictly supervised techniques [5] are inappropriate, too. Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal. Thus we hope to learn an additional set of concepts by letting the data speak for themselves. The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation. In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website. This section also describes evidence that this structure leaves room for improvement. Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text. Section 6 describes a two-part evaluation of the derived conceptual structures. Finally, we conclude in Section 7 by outlining upcoming work on the project. 2. STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad. Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences. The agencys website acts as a clearinghouse for this process. With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13]. The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics. In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 . The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate. Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2]. Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy. Within this subset of the collection, they might further eliminate documents published more than a year ago. Finally, they might request to see only documents published in PDF format. As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial. But successful implementations of the relation browser also rely on topical classification. This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access. Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website. As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories. These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether. However, this approach proved unsatisfactory. In personal meetings, BLS officials voiced dissatisfaction with the existing topics. Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space. In other words, the topics reflected official divisions rather than semantic clusters. The BLS agents suggested that re-designing this classification structure would be desirable. The agents misgivings were borne out in subsequent analysis. The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages. Thus there are 7 pages associated with Inflation. Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics). Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page. To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]). Figure 3 shows the resultant scree plot4 . Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank. During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0). What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues. The four largest eigenvlaues account for 62.2% of the total variance in the data. This fact suggests a high degree of redundancy among the topics. Topical redundancy is not in itself problematic. However, the documents in this very shallow classificatory structure are almost all gateways to more specific information. Thus the listing of the Producer Price Index under three categories could be confusing to the sites users. In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3. A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods. In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material. To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html. This led to a corpus of 15,165 documents. Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery. The problems with standard clustering are threefold. 1. Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2. Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc.), many documents terms provide noisy topical information. 3. For application to the relation browser, we require a small number (k ≈ 10) of topics. Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity. In light of these problems, we take a hybrid approach to topic discovery. First, we limit the clustering process to a sample of the entire collection, described in Section 4. Working on a focused subset of the data helps to overcome problems two and three, listed above. To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4. FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis. Let A be the n×p data matrix with n observations in p variables. Thus aij shows the measurement for the ith observation on the jth variable. As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation. Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance. Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject. Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]). However, k-means clustering requires that the researcher specify k, the number of clusters to define. When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal. This paramterization led to semantically intelligible clusters. However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons. Chief among these is the computational efficiency enjoyed by the k-means approach. Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms. In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser. Moreover, the granularity of these clusters was unsuitably fine. For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist. These words are certainly related, but they are related at a level of specificity far below what we sought. To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection. In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 . These are brief articles, written by BLS employees. BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency. The column is published daily, and each entry describes an important current issue in the BLS domain. The Editors Desk column has been written daily (five times per week) since 1998. As such, we operated on a set of N = 1279 documents. Limiting attention to these 1279 documents not only reduced the dimensionality of the problem. It also allowed the clustering process to learn on a relatively clean data set. While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc.), the Editors Desk documents are all written in clear, journalistic prose. Each document is highly topical, further aiding the discovery of termtopic relations. Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata. Each of the 1279 documents contains a list of one or more keywords. Additionally, a subset of the documents (1112) contained a subject heading. This metadata informed our learning and evaluation, as described in Section 6.1. 5. COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques. Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1). Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes. However, these clusters mark only the first step in a two-phase process of topic identification. At the end of the process, documentcluster affinity is measured by a real-valued number. Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck. We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs). All were implemented using McCallums BOW text classification library [14]. Prind is a probabilistic version of the Rocchio classification algorithm [9]. Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method. Like prind, naive Bayes attempts to classify documents into the most probable class. It is described in detail in [15]. Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10]. They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable. Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification. That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . . Ck. Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time. The output of this process is a score for every document in the collection on each of the automatically discovered topics. These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system. To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest. In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds. Also, evaluation of the utility of the learned topics for users will be undertaken. 6. EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects. To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments. During the first experiment we compared three methods of document representation for the clustering task. The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata. During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata. Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles. With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering. We hypothesized that keyword-based clustering would provide a useful model. But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations. To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively. Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector. These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data. To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20. As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions. To select a single integer value, we calculated which value of k led to the least variation in cluster size. This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters. Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10. Clusters based on document titles were constructed similarly. However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles. Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10. The dimensionality of the keyword-based clustering was very similar to that of the title-based approach. There were 299 keywords in the data, all of which were retained. The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index. It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS. Using the keywords, the documents were clustered into 10 classes. To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents. Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications. Like the keywords, subject headings were assigned to documents by BLS publishers. Unlike the keywords, however, subject headings were drawn from a controlled vocabulary. Our analysis began with the assumption that documents with the same subject headings should cluster together. To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique. Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class. Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents. As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned. These document-subject pairings formed the basis of our analysis. Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust. The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects. Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified. Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class. For instance, There were 92 documents whose subject heading was prices. Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster. Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6. Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56. Repeating this process for each topic across all three representations led to the contingency table shown in Table 2. The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions. Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001. Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords. The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio. Additionally, each cluster has been given a label by the researchers. Evaluating the results of clustering is notoriously difficult. In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions. Most problematic is the fact that we have assumed that each document belongs in only a single category. This assumption is certainly false. However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem. Analogically, this is akin to considering the location of books on a library shelf. Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health. The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects. This flattening obscures the multivalence of documents. We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser. The matter of roughly fourteen thousand unclassified documents remained to be addressed. To solve this problem, we trained the statistical classifiers described above in Section 5. For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class. All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters. The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av. Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model. To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents. During cross-validation the data are split randomly into n subsets (in this case n = 10). The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets. Cross validation is described in [15]. Using this methodology, we compared the performance of the three classification models described above. Table 4 gives the results from cross validation. Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance. Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation. Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small. In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set. For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class. Further, each query was limited to the domain www.bls.gov. For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google). This led to a training set of 4113 documents in the augmented model, as we call it below8 . Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32). As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment. The results of our cross validation experiment are encouraging. However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website. To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website. The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project. However, none of the reviewers had prior knowledge of the outcome of the classification before their participation. For the experiment, a random sample of 100 documents was drawn from the entire BLS collection. On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4]. Table 5: Human-Model Agreement on 100 Sample Docs. Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit. Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents. In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges. In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories. Thus a document with the correct class as its second choice would still be easily available to a user. Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes. There were 72 multiclass documents in our sample, as seen in Figure 4. The remaining 28 documents were assigned to 1 or 0 classes. Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50. The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole. However, the improvement afforded by the augmented model comes at some cost. In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes. Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model. For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable. But this is not necessarily the case in general. It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories. We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model. The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations. On the other hand, the naive Bayes classifier distributed classes more evenly across the topics. This behavior suggests areas for future improvement. Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations). This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7. CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here. Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time? Data mining and machine learning methods hold a great deal of promise with respect to this problem. Empirical methods of knowledge discovery can aid in the organization and retrieval of information. As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces. This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser. Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website. The goal of this initial stage is to discover the most basic and far-reaching topics in the collection. Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection. In the study reported here, this approach has demonstrated promise. In its favor, our approach is highly scalable. It also appears to give fairly good results. Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings. While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining. However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models. After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection. While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering. The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent. While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model. Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically. It also suggests that a more sophisticated modeling approach might yield 158 better results in the future. In upcoming work we will experiment with streamlining the two-phase technique described here. Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk. In current work we have defined algorithms to identify documents likely to help the topic discovery task. Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure. Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining. What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design. Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8. REFERENCES [1] A. Agresti. An Introduction to Categorical Data Analysis. Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman. Dynamic queries for information exploration: an implementation and evaluation. In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. ACM Press, 1999. [4] A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100. ACM Press, 1998. [5] H. Chen and S. Dumais. Hierarchical classification of web content. In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang. Implications of the recursive representation problem for automatic concept identification in on-line governmental information. In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery. How many clusters? which clustering method? answers via model-based cluster analysis. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims. A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization. In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997. Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims. Text categorization with support vector machines: learning with many relevant features. In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Principal Component Analysis. Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw. Finding Groups in Data: an Introduction to Cluster Analysis. Wiley, 1990. [13] G. Marchionini and B. Brunk. Toward a general relation browser: a GUI for information architects. Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Machine Learning. McGraw Hill, 1997. [16] E. Rasmussen. Clustering algorithms. In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie. Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. The Nature of Statistical Learning Theory. Springer, 2000. 159",
    "original_translation": "Aprendizaje automático para la arquitectura de la información en un gran sitio web gubernamental ∗ Miles Efron School of Information & Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan ELSAS Escuela de información yLibrary Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Hill, NC Hill, NC, NC27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 Junliang@email.Unc.Edu Resumen Este documento describe la investigación en curso en la investigación en curso en curso sobre la investigación en curso.La aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del proyecto Govstat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarca adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para los arquitectos de la información. En segundo lugar, las relaciones conceptuales de documentos derivadas automáticamente son una condición previa necesaria para el despliegue del mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje conceptual basados en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en el usuario, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos sobre representaciones de texto completo y de texto completo. Categorías y descriptores de sujetos H.3.7 [Almacenamiento y recuperación de información]: problemas de sistemas de bibliotecas digitales, problemas de usuario;H.3.3 [Almacenamiento y recuperación de información]: Búsqueda de información y recuperación del diseño de términos generales, experimentación 1. Introducción El Proyecto Govstat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y del Laboratorio de Interacción Human-Computadora de la Universidad de Maryland. Citando la dificultad del usuario final para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuario a la información estadística del gobierno de los Estados Unidos que se basa en modelos de datos realistas e interfaces innovadoras de usuarios. Para habilitar dichos modelos e interfaces, proponemos un enfoque basado en datos, basado en técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital particular, el sitio web de la Oficina de Estadísticas Laborales2 (BLS), en los esfuerzos para descubrir un pequeño número de conceptos, o contenedores lingüísticamente significativos que resumen colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido web de los sitios de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya utilizan la clasificación de contenido, tanto explícita como implícitamente;dividen sus recursos manualmente por relación tópica;Organizan contenido en sistemas de archivos orientados jerárquicamente. El objetivo del presente 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 Research es desarrollar otro medio para navegar por el contenido de estas colecciones. Al analizar la distribución de términos en todos los documentos, nuestro objetivo es complementar las agencias de estructuras de información preexistentes. Las tecnologías estadísticas de aprendizaje son atractivas en este contexto en la medida en que pueden definir un datos impulsado por datos, como se opone a una estructura navigational impulsada por la agencia para un sitio. Nuestro enfoque combina técnicas de aprendizaje supervisadas y no supervisadas. Un enfoque de agrupación de documentos puro [12] para una colección tan grande y diversa como BLS condujo a resultados pobres en las pruebas tempranas [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido los encabezados de sujetos de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Por lo tanto, esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de concepto y la evaluación posterior. En la Sección 2 describimos la estructura conceptual creada por humanos previamente existente del sitio web BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejorar. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido en tres representaciones de documentos: palabra clave, solo título y texto completo. La Sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 describiendo el próximo trabajo sobre el proyecto.2. Estructurar el acceso al sitio web de BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargado de compilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, el BLS publica una amplia gama de información, destinada a diversas audiencias. El sitio web de Agencys actúa como una casa de compensación para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes de TypeSet), proporcionar acceso a la colección proporciona un fuerte desafío a los arquitectos de la información.2.1 El navegador de relaciones El punto de partida de este trabajo es la noción de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica, como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios atravesar conjuntos de datos complejos cortando iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instanciación prototipo del navegador de relaciones, aplicada al sitio web de Fedstats3. El navegador Relation admite la búsqueda de información al permitir a los usuarios formar consultas de manera gradual, cortar y volver a encender los datos a medida que sus intereses dictan. Su motivación está en consonancia con la sugerencia de Shneidermans de que las consultas y sus resultados deben estar estrechamente acopladas [2]. Por lo tanto, en la Fig3 http://www.fedstats.gov Figura 1: Prototipo del navegador de relaciones Ure 1, los usuarios pueden limitar su búsqueda de búsqueda a esos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar aún más los documentos publicados hace más de un año. Finalmente, podrían solicitar solo ver documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también se basan en la clasificación tópica. Esto presenta dos bloques de tropiezo para diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto apropiado de temas para su colección • Los mantenedores del sitio deben clasificar cada documento en sus categorías apropiadas estas tareas, problemas comunes paralelos en la comunidad de metadatos: definir elementos apropiados y marcar documentospara admitir el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desalentadores, y los métodos automáticos para acercarse a ellos son altamente deseables.2.2 Una estructura preexistente antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como empleo y desempleo, productividad e inflación y gasto.152 Figura 2: La página de inicio de BLS que esperamos inicialmente que estas categorías predefinidas pudieran usarse para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de población del navegador de relaciones por completo. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron insatisfacción con los temas existentes. Se argumentó que su forma debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información del sitio web. En otras palabras, los temas reflejaron divisiones oficiales en lugar de grupos semánticos. Los agentes de BLS sugirieron que rediseñar esta estructura de clasificación sería deseable. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de BLS comprenden una estructura clasificatoria superficial;Cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la inflación. En conjunto, la estructura de enlace de este sistema clasificador contiene 65 documentos;Es decir, excluyendo los enlaces de navegación, hay 65 documentos vinculados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento a un tema (las páginas se pueden vincular a múltiples temas). Según esta estructura de hipervínculos, definimos M, una matriz simétrica de 65 × 65, donde MIJ cuenta la cantidad de temas en los que los documentos I y J se clasifican en la página de inicio de BLS. Para analizar la redundancia inherente a la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra la traza de scree resultante4. Debido a que los 65 documentos pertenecen a al menos un tema BLS, 4 Una trama de scree muestra la magnitud del valor propio de KTH versus su rango. Durante el análisis de componentes principales, las gráficas de scrhe visualizan la cantidad de varianza capturada por cada componente.M00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 M00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 EIGENVALVALVALIGENEGEN UE MagnitudeMeigenvlue Magnitudem Eigenvluemagnitude Figura 3: Gráfico de scree de BLS Categorías del rango deM se garantiza que es menor o igual a 15 (por lo tanto, valores propios 16 ... 65 = 0). Sin embargo, lo sorprendente de la Figura 3 es la disminución precipitada de la magnitud entre los primeros cuatro valores propios. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia tópica no es en sí misma problemática. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todas las puertas de enlace a información más específica. Por lo tanto, la lista del índice de precios del productor en tres categorías podría ser confuso para los usuarios de los sitios. A la luz de este potencial de confusión y la propia solicitud de rediseño de Agencys, realizamos la tarea de descubrimiento de temas descrita en las siguientes secciones.3. Un enfoque híbrido para el descubrimiento de temas para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En los esfuerzos por dejar que los datos hablen por sí mismos, deseamos un medio de descubrimiento de concepto que no se basara en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, arrastramos el sitio web de BLS, descargando todos los documentos de texto de tipo MIME/HTML. Esto condujo a un corpus de 15,165 documentos. Basado en este corpus, esperamos derivar K ≈ 10 categorías tópicas, de modo que cada documento DI se asigne a una o más clases.153 La agrupación de documentos (cf. [16]) proporcionó una solución obvia pero solo parcial al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con la agrupación estándar son triple.1. Los grupos mutuamente exclusivos son inapropiados para identificar el contenido tópico de los documentos, ya que los documentos pueden ser sobre muchos sujetos.2. Debido a la heterogeneidad de los datos ubicados en la recopilación BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información tópica ruidosa.3. Para la aplicación al navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, la agrupación basada en términos tiende a entregar grupos a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para el descubrimiento de temas. Primero, limitamos el proceso de agrupación a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, enumerados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos sin supervisión con los métodos de aprendizaje supervisados, como se describe en la Sección 5. 4. Centrando en documentos ricos en contenido para obtener temas evidenciados empíricamente evidenciados que inicialmente recurrimos al análisis de clúster. Deje que A sea la matriz de datos N × P con N observaciones en las variables P. Por lo tanto, AIJ muestra la medición para la observación ésica en la variable JTH. Como se describe en [12], el objetivo del análisis de clúster es asignar cada una de las N observaciones a uno de un pequeño número K de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-clúster y baja correlación entre grupos. Aunque los algoritmos para lograr dicha disposición son Legión, nuestro análisis se centra en la agrupación de K-means5, durante los cuales, cada observación OI se asigna al clúster CK cuyo centroide está más cerca de él, en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo se remiten a [12] para un tratamiento exhaustivo del sujeto. La agrupación de K-means está bien estudiada en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, la agrupación de K-means requiere que el investigador especifique k, el número de grupos para definir. Al aplicar K-Means a nuestra recopilación de documentos de 15,000, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de K sugirieron que K ≈ 80 era óptimo. Esta paramterización condujo a grupos semánticamente inteligibles. Sin embargo, 80 clústeres son demasiados para aplicar una interfaz como la relación 5 Nos hemos centrado en K-means en lugar de otros algoritmos de agrupación por varias razones. El principal de ellos es la eficiencia computacional que disfruta el enfoque K-Means. Debido a que solo necesitamos una agrupación plana, los algoritmos jerárquicos más costosos hay que obtener. En el trabajo futuro, recurriremos a la agrupación basada en modelos [7] como un método más de principios para seleccionar el número de grupos y de representar grupos.navegador. Además, la granularidad de estos grupos era inadecuadamente fino. Por ejemplo, la solución de 80 grupos derivó un grupo cuyas palabras más altamente asociadas (en términos de relación logarítmica [1]) fueron fármaco, farmacia y químico. Estas palabras están ciertamente relacionadas, pero están relacionadas en un nivel de especificidad muy por debajo de lo que buscamos. Para remediar la alta dimensionalidad de los datos, resolvimos limitar el algoritmo a un subconjunto de la recopilación. En consulta con los empleados de BLS, continuamos nuestro análisis en documentos que forman una serie titulada desde el editors Desk6. Estos son breves artículos, escritos por empleados de BLS. Los agentes de BLS sugirieron que nos centramos en el escritorio de editores porque está destinado a abarcar el dominio intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio BLS. La columna de escritorio de editores se ha escrito diariamente (cinco veces por semana) desde 1998. Como tal, operamos en un conjunto de documentos n = 1279. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupación aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección BLS contiene una gran cantidad de texto no prose (es decir, tablas, listas, etc.), los documentos de escritorio de editores están escritos en prosa clara y periodística. Cada documento es muy actual, ayudando aún más al descubrimiento de las relaciones térmicas. Finalmente, la columna de escritorio de editores proporcionó un entorno de aprendizaje ideal porque está bien formado con metadatos tópicos. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de sujeto. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1.5. Combinando el descubrimiento de aprendizaje supervisado y no supervisado para obtener temas adecuados para la aplicación de una interfaz dinámica a la colección BLS, combinamos la agrupación de documentos con técnicas de clasificación de texto. Específicamente, utilizando K-means, agrupamos cada uno de los 1279 documentos en uno de los grupos K, con el número de grupos elegidos analizando la distancia cuadrada media dentro del grupo a diferentes valores de K (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad de documentcluster se mide mediante un número de valor real. Una vez que los documentos de escritorio del editor se asignaron a los grupos, construimos un clasificador K-Way que estima la fortaleza de la evidencia de que un nuevo documento DI es miembro de la clase CK. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (Prind), Bayes ingenuos y máquinas de vectores de soporte (SVM). Todos se implementaron utilizando la Biblioteca de clasificación de texto de Bow McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Los lectores interesados son remitidos al artículo de Joachims para 6 http://www.bls.gov/opub/te 154 detalles adicionales del método de clasificación. Al igual que Prind, Naive Bayes intenta clasificar los documentos en la clase más probable. Se describe en detalle en [15]. Finalmente, Vapnik [18] explicó a fondo las máquinas de vectores de soporte, y se aplicó específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección se etiquetan por medio de clasificación automática. Es decir, para cada documento DI derivamos un vector k-dimensional, cuantificando la asociación entre DI y cada clase C1... Ck. La derivación de los puntajes de los temas a través de Naive Bayes para la recolección completa de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento de la colección de cada uno de los temas descubiertos automáticamente. Estos puntajes pueden usarse para poblar una interfaz de navegador de relaciones, o se pueden agregar a un sistema de recuperación de información tradicional. Para usar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo el puntaje más alto. En el trabajo futuro, adoptaremos un método más riguroso para derivar umbrales de peso documentales. Además, se realizará la evaluación de la utilidad de los temas aprendidos para los usuarios.6. Evaluación del descubrimiento de conceptos Antes de implementar una interfaz de navegador de relaciones y emprender los estudios de usuarios asistentes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a las materias apropiadas. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, realizamos dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupación. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creadas por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de las partes de la base de datos además del escritorio del editor.6.1 Comparación de representaciones de documentos Los documentos de la columna de escritorio editores se suministraron con metadatos de palabras clave generadas por humanos. Además, los títulos de los documentos de escritorio de los editores tienden a estar pertinentes al tema de sus respectivos artículos. Con tal variedad de evidencia destilada de cada tema de los documentos, emprendimos una comparación de representaciones de documentos para el descubrimiento de temas por agrupación. Presumimos que la agrupación basada en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si el rendimiento comparable podría alcanzarse mediante métodos que no requerían una indexación humana extensa, como las representaciones de texto completo o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documento-texto completo, solo el título y solo la palabra clave generamos tres conjuntos de temas, TFull, Ttitle y TKW, respectivamente. Los temas basados en documentos de texto completo se derivaron mediante la aplicación de la agrupación de K-means a los documentos de escritorio de 1279 editores, donde cada documento estaba representado por un vector dimensional de 1908. Estas 1908 dimensiones capturaron los pesos TF.IDF [3] de cada término TI en el documento DJ, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1...20. A medida que K se acercó a la reducción de la adición de más grupos disminuyó notablemente, lo que sugiere que K ≈ 10 produciría buenas divisiones. Para seleccionar un solo valor entero, calculamos qué valor de K condujo a la menor variación en el tamaño del clúster. Esta métrica se deriva del deseo de suprimir el resultado común donde un grupo grande emerge del algoritmo K-means, acompañado por varios grupos pequeños en consecuencia. Sin motivos para creer que cualquier tema solo debería tener probabilidades previas dramáticamente altas de membresía en el documento, esta heurística condujo a kfull = 10. Los grupos basados en títulos de documentos se construyeron de manera similar. Sin embargo, en este caso, cada documento estaba representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de documentos. Utilizando el mismo método para minimizar la varianza en la membresía de clúster Ktitle: el número de grupos en la representación basada en el título también se estableció en 10. La dimensionalidad de la agrupación basada en palabras clave fue muy similar a la del enfoque basado en el título. Hubo 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue 7, donde se entiende que una palabra clave es una sola palabra o un término de múltiples palabras, como el índice de precios al consumidor. Vale la pena señalar que las palabras clave no se extrajeron de ningún vocabulario controlado;Fueron asignados a documentos por editores en el BLS. Usando las palabras clave, los documentos se agruparon en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de sujetos que se incluyeron con 1112 de los documentos de escritorio de editores. A cada uno de estos 1112 documentos se les asignó uno o más encabezados de sujetos, que fueron retenidos de todas las aplicaciones de clúster. Al igual que las palabras clave, los encabezados de los temas fueron asignados a documentos por BLS Publishers. Sin embargo, a diferencia de las palabras clave, los encabezados de los sujetos se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de sujetos deben agruparse. Para facilitar este análisis, adoptamos un enfoque conservador;Consideramos que las clasificaciones de múltiples sujetos son únicas. Por lo tanto, si el documento DI se asignó a un solo precio de sujeto, mientras que el documento DJ se asignó a dos sujetos, no se considera que las comparaciones internacionales, los precios, los documentos DI y DJ provengan de la misma clase. La Tabla 1 muestra los encabezados de los asignaturas de escritorio de los editores que fueron asignados a al menos 10 documentos. Como se señaló en la tabla, 155 Tabla 1: Editores principales encabezados de sujetos de escritorio Precios de conteo de sujetos 92 desempleo 55 Seguridad y salud ocupacional 53 Comparaciones internacionales, precios 48 Fabricación, Precios 45 Empleo 44 Productividad 40 Gastos de consumo 36 Ganancias y salarios 27 Empleo y desempleo 27Costos de compensación 25 ganancias y salarios, metro.áreas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salario, regiones 13 paradas laborales 12 ganancias y salarios, industrias 11 total 609 Tabla 2: tabla contingecy para tres representaciones de documentos representaciones correctas incorrectas incorrectas-Text 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 Hubo 19 tales temas, que cubrieron en total 609 (54%) de los documentos con sujetos asignados. Estos emparejamientos de sujetos de documentos formaron la base de nuestro análisis. El análisis limitante de los sujetos con N> 10 mantuvo las pruebas χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación del documento fue probada por su capacidad de colocar documentos con los mismos sujetos. Por lo tanto, para cada uno de los 19 encabezados de sujetos en la Tabla 1, SI, calculamos la proporción de documentos asignados a Si que cada agrupación se clasificó. Además, asumimos que cualquier clúster capturó la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo tumbo se dirigían los precios. Tomando las clasificaciones de editores de BLS como verdad terrestre, los 92 de estos documentos deberían haber terminado en el mismo clúster. Bajo la representación de texto completo, 52 de estos documentos se agruparon en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la Categoría 6. Tomando el clúster mayoritario como el supuesto hogar derecho para estos documentos, consideramos que la precisión de este agrupamiento en este tema es 52/92 = 0.56. La repetición de este proceso para cada tema en las tres representaciones condujo a la tabla de contingencia que se muestra en la Tabla 2. La superioridad obvia de la agrupación basada en palabras clave evidenciada por la Tabla 2 fue confirmada por una prueba χ2 sobre las proporciones de precisión. Comparación de la proporción Derecho y Tabla 3: Clusters basados en palabras clave Costos de costos de empleos internacionales Compensación Impensación Importación de beneficios de empleo Precios Precios Empleados Beneficios Beneficios Petróleo Ocupación Juvenil Precio Productividad Seguridad Precio Productividad Seguridad Index Operadores de salud Inflación Inflación no agrícola Casto de empleo Gasto de desempleoEl gasto de desempleo incorrecto logrado por la palabra clave y la agrupación basada en el título condujo a P 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave de escritorio de editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más altamente asociados con cada clúster, en términos de la relación log-ODDS. Además, cada clúster ha recibido una etiqueta por los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para prestar nuestro análisis de rigor y utilidad adecuados, hicimos varios supuestos simplificadores. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al tomar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto multifunta y a menudo multipart como nuestra unidad de análisis, mitigamos este problema. Analógicamente, esto es similar a considerar la ubicación de los libros en un estante de la biblioteca. Aunque un libro determinado puede cubrir muchas materias, un sistema de clasificación debería ser capaz de colocar libros que sean extremadamente similares, digamos libros sobre seguridad y salud ocupacional. La responsabilidad más grave con esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de temas, dicen los precios: internacional en temas individuales. Este aplanamiento oscurece la multivalencia de documentos. Recurrimos a una evaluación más realista de las relaciones de clase de documento en la Sección 6.2.6.2 Precisión de los clasificadores de documentos Aunque los grupos de palabras clave parecen clasificar muy bien los documentos de escritorio de editores, su descubrimiento solo resolvió la mitad del problema requerido para la implementación exitosa de una interfaz de usuario dinámica, como el navegador de relaciones. La cuestión de aproximadamente catorce mil documentos no clasificados quedó para ser abordado. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección DI, estos clasificadores dan PI, un vector K de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde PIK cuantifica la fuerza de asociación entre el documento IPI y la clase KTH. Todos los clasificadores fueron entrenados en el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento se construyeron simplemente cambiando el 156 Tabla 4: Resultados de validación cruzada para 3 clasificadores Método AV. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 Variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar los documentos correctamente, primero realizamos una validación cruzada de 10 veces en los documentos de escritorio del editor. Durante la validación cruzada, los datos se dividen aleatoriamente en N subconjuntos (en este caso n = 10). El proceso continúa manteniendo iterativamente cada uno de los sub subconjuntos como una colección de prueba para un modelo capacitado en los subconjuntos N - 1 restantes. La validación cruzada se describe en [15]. Usando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La Tabla 4 da los resultados de la validación cruzada. Aunque Naive Bayes no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra selección de Naive Bayes se debe al hecho de que parece funcionar comparablemente con el enfoque SVM para estos datos, mientras que es mucho más simple, tanto en teoría como en implementación. Debido a que solo tenemos 1279 documentos y 10 clases, el número de documentos de capacitación por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de editores, construimos un cuarto modelo, complementando los conjuntos de capacitación de cada clase consultando el Google Search Engine7 y aplicando Bayes ingenuos al conjunto de pruebas aumentadas. Para cada clase, creamos una consulta enviando los tres términos con la relación más alta de log-ODDS con esa clase. Además, cada consulta se limitó al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real varió según el tamaño del conjunto de resultados devuelto por Google). Esto condujo a un conjunto de capacitación de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de la clasificación (precisión = 58.16%, con error estándar = 0.32). Sin embargo, como discutimos a continuación, el aumento del conjunto de capacitación pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de escritorio de editores que informaron el estudio de validación cruzada puede no ser buenos predictores del rendimiento de los modelos en el resto al sitio web de BLS. Para probar la generalidad del clasificador Naive Bayes, solicitamos aportes de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue elegida por conveniencia y consistió en estudiantes de profesores y posgrado que trabajan en el proyecto Govstat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección BLS. En promedio, cada RE7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo de modelo humano en 100 documentos de muestra. Juez humano 1st Choice Model Modelo 1st Choice Model 2nd Choice N. Bayes (agosto) 14 24 N. Bayes 24 1 Juez humano 2do Modelo de elección Modelo 1st Choice Model 2nd Choice N. Bayes (agosto) 14 21 N. Bayes 21 4 4El espectador clasificó 83 documentos, colocando cada documento en tantas categorías que se muestran en la Tabla 3 como él o ella consideró conveniente. Los resultados de este experimento sugieren que el margen de mejora permanece con respecto a la generalización de toda la colección de los modelos de clase instalados en los documentos de escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales los 11 jueces humanos votaron mejor o el segundo más probable. En el contexto de este experimento, consideramos que una clasificación de primer o segundo lugar por parte de la máquina es precisa porque la interfaz del navegador de relaciones funciona en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como su segunda opción aún estaría fácilmente disponible para un usuario. Del mismo modo, una clasificación correcta en la categoría más popular o segunda más popular entre los jueces humanos se considera correcta en los casos en que un documento dado se clasificó en múltiples clases. Hubo 72 documentos multiclase en nuestra muestra, como se ve en la Figura 4. Los 28 documentos restantes se asignaron a clases 1 o 0. Bajo esta justificación, el clasificador Naive Bayes aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo Naive Bayes para generalizar desde los documentos de escritorio de los editores a la colección en su conjunto. Sin embargo, la mejora que ofrece el modelo aumentado tiene a cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo capacitado únicamente en los documentos de escritorio de editores si nos preocupamos solo con los documentos seleccionados por la mayoría de los revisores humanos-I.E.Solo clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da p = 0.02 a favor del modelo no acuático. A los fines de aplicar el navegador de relaciones a contenido complejo de la biblioteca digital (donde los documentos se clasificarán a lo largo de múltiples categorías), el modelo aumentado es preferible. Pero este no es necesariamente el caso en general. También debe decirse que el 73% de precisión bajo una condición de prueba bastante liberal deja espacio para mejorar nuestra asignación de temas a las categorías. Podemos comenzar a comprender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en todos los documentos dados por los humanos y por el modelo ingenuo de Bayes aumentado. La mayoría de los revisores ponen 157 número de clases de clases asignadas por humanos de clases de clases asignadas a humanos. 20m 202525m25m 253030m30m 303535m35m 35Figura 4: Número de clases asignadas a documentos por parte de los documentos de jueces en solo tres categorías, trabajos, beneficios y ocupaciones. Por otro lado, el clasificador ingenuo de Bayes distribuyó clases de manera más uniforme en los temas. Este comportamiento sugiere áreas para la mejora futura. Lo más importante, observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo una correlación del 68% entre los beneficios y las ocupaciones). Esto sugiere que mejorar la agrupación para producir temas que eran más casi ortogonales podría mejorar el rendimiento.7. Conclusiones y trabajo futuro Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico que se llevan a cabo aquí. Dados los cuerpos de datos cada vez más grandes y complejos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios y, al tiempo que mantiene los sistemas receptivos a los cambios en el contenido a lo largo del tiempo? Los métodos de minería de datos y aprendizaje automático tienen una gran promesa con respecto a este problema. Los métodos empíricos de descubrimiento de conocimiento pueden ayudar en la organización y la recuperación de la información. Como hemos argumentado en este documento, estos métodos también pueden estar en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisadas, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de gran alcance de la colección. Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M0.00 0.050.100.10m0.10m 0.10 0.15 Figura 5: Distribución de clases en todos los documentos en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza el aprendizaje supervisado (en particular, un clasificador ingenuo de Bayes, entrenado en palabras individuales), paraAsigne relaciones tópicas a los documentos restantes en la colección. En el estudio informado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Comparación de tres modos de representación de documento-texto completo, título solo y palabras clave encontramos una precisión del 98% medida por la colocación de documentos con encabezados de sujetos idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor dan pruebas fuertes para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramático, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que los temas de aprendizaje de un subconjunto de la colección pueden conducir a modelos sobreinfectados. Después de agrupar 1279 documentos de escritorio editores en 10 categorías, instalamos un clasificador Naive Bayes de 10 bandas para clasificar los 14,000 documentos restantes en la colección. Si bien vimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos por agrupación. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del escritorio del editor no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestro entorno, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí proporcionan un comienzo alentador para nuestro trabajo para adquirir metadatos de sujeto para interfaces dinámicas automáticamente. También sugiere que un enfoque de modelado más sofisticado podría producir 158 mejores resultados en el futuro. En el próximo trabajo experimentaremos racionalizando la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es expandir la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de editores. En el trabajo actual, hemos definido algoritmos para identificar documentos que probablemente ayuden a la tarea de descubrimiento de temas. Suministro con un conjunto de capacitación más completo, esperamos experimentar con la agrupación basada en modelos, que combina los procesos de agrupación y clasificación en un solo procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos se han reconocido durante mucho tiempo como problemas fundamentales en la recuperación de la información y otras formas de minería de texto. Sin embargo, lo que está cada vez más claro, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a los problemas en el front-end de sistemas como la arquitectura de la información y el diseño de la interfaz. Finalmente, en el futuro trabajo construiremos sobre los estudios de usuarios realizados por Marchionini y Brunk en los esfuerzos por evaluar la utilidad de las interfaces dinámicas pobladas automáticamente para los usuarios de las bibliotecas digitales.8. Referencias [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de la información: una implementación y evaluación. En Actas de la Conferencia Sigchi sobre Factores Humanos en Sistemas de Computación, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y sin etiquetar con entrenamiento co-entrenamiento. En Actas de la Undécima Conferencia Anual sobre Teoría del Aprendizaje Computacional, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación del concepto automático en la información gubernamental en línea. En Actas del Grupo de Interés Especial ASIST sobre Investigación de Clasificación (Asist Sig-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos?¿Qué método de agrupación?Respuestas a través del análisis de clúster basado en modelos. The Computer Journal, 41 (8): 578-588, 1998. [8] A. K. Jain, M. N. Murty y P. J. Flynn. Clustering de datos: una revisión. ACM Computing Surveys, 31 (3): 264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo Rocchio con TFIDF para la categorización de texto. En D. H. Fisher, Editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Autor, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU.[10] T. Joachims. Categorización de texto con máquinas vectoriales de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea de Aprendizaje Machine, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, de.[11] I. T. Jolliffe. Análisis de componentes principales. Springer, 2ª edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrar grupos en datos: una introducción al análisis de clúster. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relación general: una GUI para arquitectos de la información. Journal of Digital Information, 4 (1), 2003. http://jodi.ecs.soton.ac.uk/articles/v04/i01/marchionini/.[14] A. K. McCallum. Bow: un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupación.http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupación. En W. B. Frakes y R. Baeza-Yates, editores, recuperación de información: estructuras de datos y algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimación del número de grupos en un conjunto de datos a través de la estadística GAP, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html.[18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159",
    "original_sentences": [
        "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
        "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
        "The goal of this discovery is twofold.",
        "First we desire a practical aid for information architects.",
        "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
        "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
        "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
        "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
        "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
        "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
        "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
        "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
        "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
        "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
        "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
        "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
        "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
        "Our approach combines supervised and unsupervised learning techniques.",
        "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
        "But strictly supervised techniques [5] are inappropriate, too.",
        "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
        "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
        "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
        "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
        "This section also describes evidence that this structure leaves room for improvement.",
        "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
        "Section 6 describes a two-part evaluation of the derived conceptual structures.",
        "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
        "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
        "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
        "The agencys website acts as a clearinghouse for this process.",
        "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
        "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
        "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
        "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
        "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
        "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
        "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
        "Finally, they might request to see only documents published in PDF format.",
        "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
        "But successful implementations of the relation browser also rely on topical classification.",
        "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
        "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
        "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
        "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
        "However, this approach proved unsatisfactory.",
        "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
        "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
        "In other words, the topics reflected official divisions rather than semantic clusters.",
        "The BLS agents suggested that re-designing this classification structure would be desirable.",
        "The agents misgivings were borne out in subsequent analysis.",
        "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
        "Thus there are 7 pages associated with Inflation.",
        "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
        "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
        "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
        "Figure 3 shows the resultant scree plot4 .",
        "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
        "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
        "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
        "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
        "This fact suggests a high degree of redundancy among the topics.",
        "Topical redundancy is not in itself problematic.",
        "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
        "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
        "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
        "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
        "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
        "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
        "This led to a corpus of 15,165 documents.",
        "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
        "The problems with standard clustering are threefold. 1.",
        "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
        "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
        "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
        "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
        "In light of these problems, we take a hybrid approach to topic discovery.",
        "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
        "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
        "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
        "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
        "Let A be the n×p data matrix with n observations in p variables.",
        "Thus aij shows the measurement for the ith observation on the jth variable.",
        "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
        "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
        "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
        "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
        "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
        "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
        "This paramterization led to semantically intelligible clusters.",
        "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
        "Chief among these is the computational efficiency enjoyed by the k-means approach.",
        "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
        "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
        "Moreover, the granularity of these clusters was unsuitably fine.",
        "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
        "These words are certainly related, but they are related at a level of specificity far below what we sought.",
        "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
        "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
        "These are brief articles, written by BLS employees.",
        "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
        "The column is published daily, and each entry describes an important current issue in the BLS domain.",
        "The Editors Desk column has been written daily (five times per week) since 1998.",
        "As such, we operated on a set of N = 1279 documents.",
        "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
        "It also allowed the clustering process to learn on a relatively clean data set.",
        "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
        "Each document is highly topical, further aiding the discovery of termtopic relations.",
        "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
        "Each of the 1279 documents contains a list of one or more keywords.",
        "Additionally, a subset of the documents (1112) contained a subject heading.",
        "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
        "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
        "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
        "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
        "However, these clusters mark only the first step in a two-phase process of topic identification.",
        "At the end of the process, documentcluster affinity is measured by a real-valued number.",
        "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
        "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
        "All were implemented using McCallums BOW text classification library [14].",
        "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
        "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
        "Like prind, naive Bayes attempts to classify documents into the most probable class.",
        "It is described in detail in [15].",
        "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
        "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
        "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
        "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
        "Ck.",
        "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
        "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
        "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
        "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
        "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
        "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
        "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
        "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
        "During the first experiment we compared three methods of document representation for the clustering task.",
        "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
        "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
        "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
        "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
        "We hypothesized that keyword-based clustering would provide a useful model.",
        "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
        "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
        "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
        "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
        "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
        "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
        "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
        "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
        "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
        "Clusters based on document titles were constructed similarly.",
        "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
        "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
        "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
        "There were 299 keywords in the data, all of which were retained.",
        "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
        "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
        "Using the keywords, the documents were clustered into 10 classes.",
        "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
        "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
        "Like the keywords, subject headings were assigned to documents by BLS publishers.",
        "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
        "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
        "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
        "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
        "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
        "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
        "These document-subject pairings formed the basis of our analysis.",
        "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
        "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
        "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
        "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
        "For instance, There were 92 documents whose subject heading was prices.",
        "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
        "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
        "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
        "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
        "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
        "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
        "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
        "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
        "Additionally, each cluster has been given a label by the researchers.",
        "Evaluating the results of clustering is notoriously difficult.",
        "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
        "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
        "This assumption is certainly false.",
        "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
        "Analogically, this is akin to considering the location of books on a library shelf.",
        "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
        "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
        "This flattening obscures the multivalence of documents.",
        "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
        "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
        "To solve this problem, we trained the statistical classifiers described above in Section 5.",
        "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
        "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
        "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
        "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
        "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
        "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
        "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
        "Cross validation is described in [15].",
        "Using this methodology, we compared the performance of the three classification models described above.",
        "Table 4 gives the results from cross validation.",
        "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
        "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
        "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
        "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
        "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
        "Further, each query was limited to the domain www.bls.gov.",
        "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
        "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
        "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
        "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
        "The results of our cross validation experiment are encouraging.",
        "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
        "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
        "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
        "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
        "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
        "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
        "Table 5: Human-Model Agreement on 100 Sample Docs.",
        "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
        "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
        "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
        "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
        "Thus a document with the correct class as its second choice would still be easily available to a user.",
        "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
        "There were 72 multiclass documents in our sample, as seen in Figure 4.",
        "The remaining 28 documents were assigned to 1 or 0 classes.",
        "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
        "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
        "However, the improvement afforded by the augmented model comes at some cost.",
        "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
        "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
        "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
        "But this is not necessarily the case in general.",
        "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
        "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
        "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
        "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
        "This behavior suggests areas for future improvement.",
        "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
        "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
        "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
        "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
        "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
        "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
        "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
        "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
        "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
        "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
        "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
        "In the study reported here, this approach has demonstrated promise.",
        "In its favor, our approach is highly scalable.",
        "It also appears to give fairly good results.",
        "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
        "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
        "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
        "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
        "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
        "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
        "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
        "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
        "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
        "In upcoming work we will experiment with streamlining the two-phase technique described here.",
        "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
        "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
        "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
        "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
        "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
        "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
        "REFERENCES [1] A. Agresti.",
        "An Introduction to Categorical Data Analysis.",
        "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
        "Dynamic queries for information exploration: an implementation and evaluation.",
        "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
        "Modern Information Retrieval.",
        "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
        "Combining labeled and unlabeled data with co-training.",
        "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
        "ACM Press, 1998. [5] H. Chen and S. Dumais.",
        "Hierarchical classification of web content.",
        "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
        "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
        "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
        "How many clusters? which clustering method? answers via model-based cluster analysis.",
        "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
        "Data clustering: a review.",
        "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
        "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
        "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
        "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
        "Text categorization with support vector machines: learning with many relevant features.",
        "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
        "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
        "Principal Component Analysis.",
        "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
        "Finding Groups in Data: an Introduction to Cluster Analysis.",
        "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
        "Toward a general relation browser: a GUI for information architects.",
        "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
        "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
        "Machine Learning.",
        "McGraw Hill, 1997. [16] E. Rasmussen.",
        "Clustering algorithms.",
        "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
        "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
        "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
        "The Nature of Statistical Learning Theory.",
        "Springer, 2000. 159"
    ],
    "error_count": 0,
    "keys": {
        "machine learning technique": {
            "translated_key": "técnica de aprendizaje automático",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of <br>machine learning technique</br>s for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and <br>machine learning technique</br>s.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Aprendizaje automático para la arquitectura de la información en un gran sitio web gubernamental ∗ Miles Efron School of Information & Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan ELSAS Escuela de información yLibrary Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Hill, NC Hill, NC, NC27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 Junliang@email.Unc.Edu Resumen Este documento describe la investigación en curso en la investigación en curso en curso sobre la investigación en curso.La aplicación de la \"técnica de aprendizaje automático\" para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas.",
                "Para habilitar dichos modelos e interfaces, proponemos un enfoque basado en datos, basado en la minería de datos y la \"técnica de aprendizaje automático\"."
            ],
            "translated_text": "",
            "candidates": [
                "técnica de aprendizaje automático",
                "técnica de aprendizaje automático",
                "técnica de aprendizaje automático",
                "técnica de aprendizaje automático"
            ],
            "error": []
        },
        "access": {
            "translated_key": "acceso",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving <br>access</br> to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user <br>access</br> to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING <br>access</br> TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing <br>access</br> to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that <br>access</br> to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information <br>access</br>.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve <br>access</br> to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Aprendizaje automático para la arquitectura de la información en un gran sitio web gubernamental ∗ Miles Efron School of Information & Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan ELSAS Escuela de información yLibrary Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Hill, NC Hill, NC, NC27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 Junliang@email.Unc.Edu Resumen Este documento describe la investigación en curso en la investigación en curso en curso sobre la investigación en curso.La aplicación de técnicas de aprendizaje automático para mejorar el \"acceso\" a la información gubernamental en bibliotecas digitales complejas.",
                "Citando la dificultad del usuario final para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de \"acceso\" al usuario a la información estadística del gobierno de los Estados Unidos que se basa en modelos de datos realistas e interfaces innovadoras de usuarios.",
                "Estructurar \"acceso\" al sitio web de BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargado de compilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero.",
                "Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes de TypeSet), proporcionar \"acceso\" a la colección proporciona un fuerte desafío a los arquitectos de la información.2.1 El navegador de relaciones El punto de partida de este trabajo es la noción de que el \"acceso\" a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica, como el navegador de relaciones descrito por Marchionini y Brunk [13].",
                "Esto presenta dos bloques de tropiezo para diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto apropiado de temas para su colección • Los mantenedores del sitio deben clasificar cada documento en sus categorías apropiadas estas tareas, problemas comunes paralelos en la comunidad de metadatos: definir elementos apropiados y marcar documentosPara admitir información de información \"Acceso\".",
                "Dados los cuerpos de datos cada vez más grandes y complejos, ¿cómo podemos mejorar el \"acceso\" a las colecciones sin incurrir en costos extraordinarios y, al tiempo que mantiene los sistemas receptivos a los cambios en el contenido con el tiempo?"
            ],
            "translated_text": "",
            "candidates": [
                "acceso",
                "acceso",
                "acceso",
                "acceso",
                "acceso",
                "acceso",
                "acceso",
                "acceso",
                "acceso",
                "acceso",
                "Acceso",
                "acceso",
                "acceso"
            ],
            "error": []
        },
        "complex digital library": {
            "translated_key": "biblioteca digital compleja",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to <br>complex digital library</br> content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "A los fines de aplicar el navegador de relaciones a contenido de \"biblioteca digital compleja\" (donde los documentos se clasificarán a lo largo de múltiples categorías), el modelo aumentado es preferible."
            ],
            "translated_text": "",
            "candidates": [
                "biblioteca digital compleja",
                "biblioteca digital compleja"
            ],
            "error": []
        },
        "data-driven approach": {
            "translated_key": "enfoque basado en datos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a <br>data-driven approach</br>, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Para habilitar dichos modelos e interfaces, proponemos un \"enfoque basado en datos\", basado en técnicas de minería de datos y aprendizaje automático."
            ],
            "translated_text": "",
            "candidates": [
                "enfoque basado en datos",
                "enfoque basado en datos"
            ],
            "error": []
        },
        "supervised and unsupervised learning technique": {
            "translated_key": "Técnica de aprendizaje supervisada y no supervisada",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines <br>supervised and unsupervised learning technique</br>s.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nuestro enfoque combina \"técnica de aprendizaje supervisada y no supervisada\" s."
            ],
            "translated_text": "",
            "candidates": [
                "Técnica de aprendizaje supervisada y no supervisada",
                "técnica de aprendizaje supervisada y no supervisada"
            ],
            "error": []
        },
        "bureau of labor statistics": {
            "translated_key": "Oficina de estadísticas laborales",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The <br>bureau of labor statistics</br> is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Estructurar el acceso al sitio web de BLS La \"Oficina de Estadísticas Laborales\" es una agencia del gobierno federal encargado de compilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero."
            ],
            "translated_text": "",
            "candidates": [
                "Oficina de estadísticas laborales",
                "Oficina de Estadísticas Laborales"
            ],
            "error": []
        },
        "eigenvalue": {
            "translated_key": "valor propio",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth <br>eigenvalue</br> versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 <br>eigenvalue</br> RankMEigenvalue RankM <br>eigenvalue</br> Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Debido a que los 65 documentos pertenecen a al menos un tema BLS, 4 Una trama de scree muestra la magnitud del KTH \"valor propio\" en comparación con su rango.",
                "Durante el análisis de componentes principales, las gráficas de scrhe visualizan la cantidad de varianza capturada por cada componente.m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 \"eigenvalue\" RankMEigenvalue RankM \"eigenvalue\" Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLSCategorías El rango de M se garantiza que es menor o igual a 15 (por lo tanto, valores propios 16 ... 65 = 0)."
            ],
            "translated_text": "",
            "candidates": [
                "valor propio",
                "valor propio",
                "valor propio",
                "eigenvalue",
                "eigenvalue"
            ],
            "error": []
        },
        "bls collection": {
            "translated_key": "Colección BLS",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the <br>bls collection</br> (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire <br>bls collection</br> contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the <br>bls collection</br>, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire <br>bls collection</br>.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Debido a la heterogeneidad de los datos ubicados en la \"Colección BLS\" (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información actual.3.",
                "Si bien toda la \"colección BLS\" contiene una gran cantidad de texto no prose (es decir, tablas, listas, etc.), los documentos de escritorio de editores están escritos en prosa clara y periodística.",
                "Combinando el descubrimiento de aprendizaje supervisado y no supervisado para obtener temas adecuados para la aplicación de una interfaz dinámica a la \"Colección BLS\", combinamos la agrupación de documentos con técnicas de clasificación de texto.",
                "Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la \"colección BLS\"."
            ],
            "translated_text": "",
            "candidates": [
                "Colección BLS",
                "Colección BLS",
                "Colección BLS",
                "colección BLS",
                "Colección BLS",
                "Colección BLS",
                "Colección BLS",
                "colección BLS"
            ],
            "error": []
        },
        "k-means clustering": {
            "translated_key": "agrupación de K-means",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, <br>k-means clustering</br> requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of <br>k-means clustering</br> to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Sin embargo, la \"agrupación de K-means\" requiere que el investigador especifique K, el número de grupos para definir.",
                "Los temas basados en documentos de texto completo se derivaron mediante la aplicación de \"clúster K-means\" a los documentos de escritorio de 1279 editores, donde cada documento estaba representado por un vector dimensional de 1908."
            ],
            "translated_text": "",
            "candidates": [
                "clúster K-means",
                "agrupación de K-means",
                "clúster K-means",
                "clúster K-means"
            ],
            "error": []
        },
        "multiway classification": {
            "translated_key": "clasificación de múltiples vías",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a <br>multiway classification</br>, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En el contexto de este experimento, consideramos que una clasificación de primer o segundo lugar por parte de la máquina es precisa porque la interfaz del navegador de relaciones funciona en una \"clasificación de múltiples vías\", donde cada documento se clasifica en múltiples categorías."
            ],
            "translated_text": "",
            "candidates": [
                "clasificación de múltiples vías",
                "clasificación de múltiples vías"
            ],
            "error": []
        },
        "digital library": {
            "translated_key": "biblioteca digital",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular <br>digital library</br>-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex <br>digital library</br> content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En particular, nuestro trabajo analiza una \"biblioteca digital\" particular, el sitio web de la Oficina de Estadísticas Laborales2 (BLS), en los esfuerzos para descubrir un pequeño número de conceptos o contenedores lingüísticamente significativos que resumen colectivamente el dominio semántico del sitio.",
                "A los fines de aplicar el navegador de relaciones a contenido complejo de \"biblioteca digital\" (donde los documentos se clasificarán a lo largo de múltiples categorías), el modelo aumentado es preferible."
            ],
            "translated_text": "",
            "candidates": [
                "libreria digital",
                "biblioteca digital",
                "libreria digital",
                "biblioteca digital"
            ],
            "error": []
        },
        "machine learn": {
            "translated_key": "aprendizaje automático",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of <br>machine learn</br>ing techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and <br>machine learn</br>ing techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised <br>machine learn</br>ing methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and <br>machine learn</br>ing methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Aprendizaje automático para la arquitectura de la información en un gran sitio web gubernamental ∗ Miles Efron School of Information & Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan ELSAS Escuela de información yLibrary Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Hill, NC Hill, NC, NC27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 Junliang@email.Unc.Edu Resumen Este documento describe la investigación en curso en la investigación en curso en curso sobre la investigación en curso.La aplicación de técnicas de \"aprendizaje de máquina\" para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas.",
                "Para habilitar dichos modelos e interfaces, proponemos un enfoque basado en datos, basado en la minería de datos y las técnicas de \"aprendizaje de la máquina\".",
                "Un enfoque híbrido para el descubrimiento de temas para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de \"aprendizaje de máquina\" sin supervisión.",
                "La minería de datos y los métodos de \"aprendizaje de máquina\" son muy prometedores con respecto a este problema."
            ],
            "translated_text": "",
            "candidates": [
                "Aprender a la máquina",
                "aprendizaje de máquina",
                "Aprender a la máquina",
                "aprendizaje de la máquina",
                "Aprender a la máquina",
                "aprendizaje de máquina",
                "Aprender a la máquina",
                "aprendizaje de máquina"
            ],
            "error": []
        },
        "information architecture": {
            "translated_key": "arquitectura de la información",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for <br>information architecture</br> in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level <br>information architecture</br> discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as <br>information architecture</br> and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Aprendizaje automático para \"arquitectura de información\" en un gran sitio web gubernamental ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela deInformación y biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu Resumen Este documento describe en curso en cursoInvestigación sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas.",
                "Basado en este corpus, esperamos derivar K ≈ 10 categorías tópicas, de modo que cada documento DI se asigne a una o más clases.153 La agrupación de documentos (cf. [16]) proporcionó una solución obvia pero solo parcial al problema de automatizar este tipo de descubrimiento de \"arquitectura de información\" de alto nivel.",
                "Sin embargo, lo que está cada vez más claro, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el front-end de sistemas como la \"arquitectura de la información\" y el diseño de interfaz."
            ],
            "translated_text": "",
            "candidates": [
                "arquitectura informacional",
                "arquitectura de información",
                "arquitectura informacional",
                "arquitectura de información",
                "arquitectura informacional",
                "arquitectura de la información"
            ],
            "error": []
        },
        "interface design": {
            "translated_key": "diseño de interfaz",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and <br>interface design</br>.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Sin embargo, lo que está cada vez más claro, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el front-end de sistemas como la arquitectura de la información y el \"diseño de interfaz\"."
            ],
            "translated_text": "",
            "candidates": [
                "diseño de interfaz",
                "diseño de interfaz"
            ],
            "error": []
        }
    }
}