{
    "id": "J-45",
    "original_text": "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings. We illustrate our approach with a design task from a supply-chain trading competition. Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient. Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect. More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent. Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1. MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game. TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain. The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year. As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation. During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0. Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory. Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13]. After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement. The task facing game organizers can be viewed as a problem in mechanism design. The designers have certain game features under their control, and a set of objectives regarding game outcomes. Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game. Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option. We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems. In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders. These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods. Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition. In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament. Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9]. The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking. Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations. Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose. The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options. Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment. Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design. In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem. Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted. Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise. We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used. Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem. Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available. Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions. We believe that most realistic problems are too complex to be amenable to exact analysis. Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2. PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players. Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players. We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am. It is often convenient to refer to a strategy of player i separately from that of the remaining players. To accommodate this, we use a−i to denote the joint strategy of all players other than player i. Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A. An s ∈ S is called a mixed strategy profile. When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i). When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i. We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously. This is appropriate for our current study, which treats strategies (agent programs) as atomic actions. We could capture finer-grained decisions about action over time in the extensive form. Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection). Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context. We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}. We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies. Faced with a game, an agent would ideally play its best strategy given those played by the other agents. A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium. DEFINITION 1. A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i). When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium. We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy. Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ . In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical. DEFINITION 2. A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3. THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game. The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ. All the participant agents observe the mechanism parameter θ and move simultaneously thereafter. For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules. Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}]. We refer to Γθ as a game induced by θ. Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR. Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria. However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available. For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary. DEFINITION 3. A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V . We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}. For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)). Using an aggregation function yields a more compact representation of strategy profiles. For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter. If all we care about is the total value played, we may take φ(a) = Pm i=1 ai. If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise. For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure. Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem. Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12]. However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets. Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs. We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}. Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.) In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4. EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations. Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence. Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above. Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail. Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium. In doing so, we consider several questions raised during and after the tournament. First, does increasing storage costs actually reduce day-0 procurement? Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational? And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been? It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data. We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament. We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium). All other behavior is based on the behavior of Deep Maize and is identical for all agents. This choice can provide only an estimate of the actual tournament behavior of a typical agent. However, we believe that the general form of the results should be robust to changes in the full agent behavior. We model the designers welfare function as a threshold on the sum of day-0 purchases. Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture). The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function. The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ . Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance. Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)). If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ. Thus, we need methods for approximating Nash equilibria for infinite games. Below, we describe the two methods we used in our study. The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives. Our approach takes as given some set of design options, in this case defined by the storage cost parameter. In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17]. Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model. In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time. One advantage of this method is that it can be applied to any data set and does not require the use of a simulator. Thus, we can apply it when Ds = ∅. If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR). We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19]. The quadratic regression model makes it possible to compute equilibria of the learned game analytically. For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game. The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation. DEFINITION 4. A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy. We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ). DEFINITION 5. The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}. We say that a is a candidate δ-equilibrium for δ ≥ ˆ. When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium. Our search method operates by exploring deviations from candidate equilibria. We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria. DEFINITION 6. For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ. We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ). In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ. This definition allows us to exploit structure arising from the aggregation function. If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds. In particular, if one is an equilibrium, the other may be as well. We present some theoretical support for this method of estimating the set of Nash equilibria below. Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation. In this work, we instead concentrate on search in strategy profile space. egy profiles. We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost. Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}. Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ. Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months. For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do. Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6. The results are shown in Figure 1. As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game. In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do. The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch. The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2. First, we note that the addition of the search data narrows the range of potential equilibria substantially. Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close. Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do. The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax. This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs. It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100. The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3. This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game. The maximum prediction is considerably higher at 4.5. In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9]. Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing. However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible. To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set. Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α. Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320. The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch. Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320. Strategy profiles explored are presented in terms of the corresponding values of φ(a). The gray region corresponds to ˆφ∗ (320) with δ =2.5M. The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200. Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2. Furthermore, payoffs to agents are almost always negative at θ = 320. Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed. Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result. We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter. That our predictions tend to underestimate tournament outcomes reinforces this conclusion. To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04. All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence. These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game. In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects. Suppose that all agents have finite (and small) pure strategy sets, A. Thus, it is feasible to sample the entire payoff matrix of the game. Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable. We designate the known variance of ˜ξi(a) by σ2 i (a). Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)). We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a. We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1). We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium. If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1. Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)). The proofs of this and all subsequent results are in the Appendix. The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function. Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ. Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}. The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria. Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled. We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium! Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game. If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium. The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled. Particularly, we would like to say something about what happens for the settings of θ for which we have no data. To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320]. We now define each subset j to be the interval between two points for which we have produced data. Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above. We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α. PROPOSITION 2. Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment. Instead, we take this as another piece of evidence to complement our findings. Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ. Thus, we are faced with a task of estimating it from data. Here, we tried three methods of doing this. The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval. This produces the most conservative bound, and in many situations it is unlikely to be informative. An alternative method is to take an upper bound on slope obtained within each subinterval using the available data. This produces a much less conservative upper bound on probabilities. However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving. A final method that we tried is a compromise between the two above. Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj. The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals. The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3. In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2. Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2. As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here. However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job. Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence. Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets). Nor can we expect ever to obtain enough evidence to make completely objective conclusions. Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5. CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower. As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs. We also assume that un,i(a) are independent for all a ∈ A and i ∈ I. We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}]. Similarly, we define n(r) to be (r) with respect to the game Γn. In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game. We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum. THEOREM 3. Suppose that |I| < ∞, |A| < ∞. Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ. If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4. For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s. PROOF. Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1. By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken. As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria. First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α. Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function. Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain. Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective. Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game. This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings. We first note that the function (s) is continuous in a finite game. LEMMA 5. Let S be a mixed strategy set defined on a finite game. Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation. First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y). Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ). Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ. Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ. Note that h(Nδ, N) = δ. We can then prove the following general result. THEOREM 6. Suppose |I| < ∞ and |A| < ∞. Then almost surely h(Nn, N) converges to 0. We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely. Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ). THEOREM 7. Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite. Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ. Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria. In fact, ˆθ → θ∗ a.s. in each of these cases. The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria. However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6. RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10]. Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant. In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality. Several related approaches to search for the best mechanism exist in the Computer Science literature. Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge. When payoff functions of players are unknown, a search using simulations has been explored as an alternative. One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria. An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming. In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning. Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7. CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design. We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game. We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available. Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired. A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods. In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact. Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence. In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer. In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability. The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains. The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings. Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work. This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8. REFERENCES [1] R. Arunachalam and N. M. Sadeh. The supply chain trading agent competition. Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz. A stochastic programming approach to scheduling in TAC SCM. In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang. Generalized confidence intervals for the largest value of some functions of parameters under normality. Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff. Evolution of market mechanism through a continuous space of auction-types. In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan. Active learning with statistical models. Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm. An algorithm for automatically designing deterministic mechanisms without payments. In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman. Evolutionary games in economics. Econometrica, 59(3):637-666, May 1991. [8] R. Keener. Statistical Theory: A Medley of Core Topics. University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman. An analysis of the 2004 supply chain management trading agent competition. In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J. Green. Microeconomic Theory. Oxford University Press, 1995. [11] R. B. Myerson. Optimal auction design. Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim. Simulation optimization. In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone. TacTex-03: A supply chain management agent. SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney. Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs. In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar. Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design. In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney. Using genetic programming to optimise pricing rules for a double-auction market. In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh. Learning payoff functions in infinite games. In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart. Analyzing complex strategic interactions in multi-agent systems. In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni. Strategic interactions in a supply chain game. Computational Intelligence, 21(1):1-26, February 2005. APPENDIX A. PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du. A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai. Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai). To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]). The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR. Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively. Let x∗ be the point at which these lines intersect. Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A . By substituting the expressions for cR and cL, we get the desired result. Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}. Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}. We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ. To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0. Putting everything together yields the desired result. A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|. To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|. Thus, the claim holds. By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A. That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α. Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α. Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum. Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|. An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i. Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞. Then V (b) = maxa∈A f(a, b) is uniformly continuous in b. To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ. Now take δ = mina∈A δ(a). Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ. Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)]. By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result. A.5 Proof of Theorem 6 Choose δ > 0. First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0. Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact. As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem. That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ. Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows. A.6 Proof of Theorem 7 Fix θ and choose δ > 0. Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < . By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1. Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < . Let us assume without loss of generality that there is a unique optimal choice of θ. Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ). Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ). Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1. Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315",
    "original_translation": "Diseño del mecanismo empírico: Métodos, con la aplicación a un escenario de cadena de suministro Yevgeniy Vorobeychik, Christopher Kiekintveld y Michael P. Wellman University of Michigan Informática e Ingeniería Ann Arbor, Mi 48109-2121 USA {Yvorobey, Ckiekint, Wellman} @umich.Resumen EDU Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características de los resultados de interés en función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir el comportamiento de adquisición particular, pero las medidas resultaron insuficientes. Nuestro análisis de mecanismo empírico modela la relación entre un parámetro de diseño clave y los resultados, confirmando el comportamiento observado e indicando que no se hubiera podido lograr una configuración de parámetros razonable el efecto deseado. En términos más generales, mostramos que bajo ciertas condiciones, el estimador de la configuración de parámetros de mecanismo óptimo basado en datos empíricos es consistente. Categorías y descriptores de sujetos I.6 [Metodologías de computación]: simulación y modelado;J.4 [Aplicaciones informáticas]: Ciencias sociales y conductuales-economía Algoritmos de términos generales, Economía, Diseño 1. Motivación. Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de la Cadena de Suministros de la Competencia de Agentes Comerciales de 2003 y 2004 (TAC) (SCM). TAC/SCM [1] define un escenario en el que los agentes compitan para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes obtienen componentes de los diversos proveedores y ensamblan productos terminados para la venta a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes obtuvieran grandes cantidades de componentes el día 0: el comienzo de la simulación. Durante las primeras rondas de la competencia SCM 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayoría de sus compras el día 0. Aunque la adquisición de la adquisición de Day-0 resultó ser un problema estratégico interesante en sí mismo [19], el fenómeno le resta valor a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica deproducción, ventas e inventario. Varios participantes señalaron que el predominio de la adquisición del día 0 eclipsó otros problemas de investigación clave, como la programación de fábricas [2] y la optimización de ofertas para los pedidos de los clientes [13]. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir a las grandes adquisiciones de día 0. La tarea que enfrenta los organizadores del juego puede verse como un problema en el diseño del mecanismo. Los diseñadores tienen ciertas características del juego bajo su control y un conjunto de objetivos con respecto a los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño del mecanismo, el objetivo es una característica de comportamiento (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se consideran solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de un solo disparo, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de la configuración de diseño de mecanismo práctico, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios de reglas destinados a penalizar grandes órdenes de día 0. Estos incluyeron modificaciones a las políticas de precios de proveedores e introducción de los costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición del día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el Gamemaster impuso un aumento de cinco veces de los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (por algunas medidas) desde 2003 [9]. La aparente dificultad para identificar las modificaciones de las reglas que afectan la moderación en la adquisición del día 0 es bastante sorprendente. Aunque los diseños se discutieron ampliamente, las predicciones para los efectos de varias propuestas fueron respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos de retroceso. Gran parte de la dificultad, por supuesto, anticipa las respuestas de los agentes (y sus desarrolladores) sin esencialmente ejecutar un ejercicio de juego para este propósito. El episodio nos hizo considerar si los nuevos proaches o herramientas AP306 podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de diseño teórico y de mecanismo del juego son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismo empírico. En la secuela, desarrollamos algunos métodos generales para el diseño del mecanismo empírico y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en la configuración de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el elemento disuasorio más directo para las adquisiciones tempranas adoptadas. Nuestros resultados confirman la intuición básica de que los incentivos para la disminución de la compra del día 0 a medida que aumentan los costos de almacenamiento. También confirmamos que la adquisición alta del día 0 observada en el torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos de nuestros datos que es muy poco probable que cualquier configuración razonable de los costos de almacenamiento resulte en niveles aceptables de adquisición del día 0, por lo que se habría requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismo indirecto en la configuración donde solo hay disponible una descripción de la caja negra de los utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios NASH y equilibrios de NASH de muestra, utilizados en conjunción para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que los problemas más realistas son demasiado complejos para ser susceptibles al análisis exacto. En consecuencia, abogamos por el enfoque de reunir evidencia para proporcionar apoyo indirecto de hipótesis específicas.2. Preliminarios Un juego de forma normal2 se denota por [i, {ri}, {ui (r)}], donde me refiere al conjunto de jugadores y m = | i |es el número de jugadores. RI es el conjunto de estrategias disponibles para el jugador I ∈ I, con R = R1 ×... × RM que representa el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador I por IA, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×... × AM. A menudo es conveniente referirse a una estrategia del jugador que estoy por separado de la de los jugadores restantes. Para acomodar esto, usamos A - I para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre IA y, de manera similar, es el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son finitos), la probabilidad de que A ∈ A se juegue bajo S (A) = S (Ai, A - I). Cuando la distribución no está correlacionada, simplemente podemos decir SI (AI) al referirnos al jugador de probabilidad que toca AI bajo s.A continuación, definimos la función de pago (utilidad) de cada jugador I por ui: a1 × · · · × am → r, donde ui (ai, a - i) indica la recompensa al jugador I para jugar a la estrategia pura cuando el restoLos jugadores juegan A - I. Podemos extender esta definición a las estrategias mixtas suponiendo que UI son von Neumann-Morgenstern (VNM) Utilidades de la siguiente manera: UI (S) = ES [UI], donde ES es la expectativa tomada con respecto a la distribución de probabilidad de juego inducida porLos jugadores mezclan estrategias s.2 Al emplear la forma normal, modelamos a los agentes como una sola acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones de grano más fino sobre la acción a lo largo del tiempo en la forma extensa. Aunque cualquier juego extenso puede ser refundido en forma normal, hacerlo puede sacrificar la compacidad y difuminar las distinciones relevantes (por ejemplo, la perfección subjama). Ocasionalmente, escribimos UI (x, y) para significar que x ∈ Ai o Si e Y ∈ A - I o S - I dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u (·) = {u1 (·) ,..., um (·)}. Definimos una función: R → R, interpretada como el máximo beneficio que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado.(r) = max i∈I max ai∈Ai [ui (ai, r - i) - ui (r)], (1) donde r pertenece a algún conjunto de estrategias, r, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada las que juegan los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a las demás constituye un equilibrio de Nash. Definición 1. Un perfil de estrategia r = (r1, ..., rm) constituye un equilibrio NASH de juego [i, {ri}, {ui (r)}] si por cada i ∈ I, ri ∈ Ri, ui (ri, r, r−i) ≥ ui (ri, r - i). Cuando r ∈ A, lo anterior define una estrategia pura Nash Equilibrio;De lo contrario, la definición describe un equilibrio de estrategia mixta Nash. A menudo apelamos al concepto de un equilibrio aproximado o -nash, donde es el beneficio máximo para cualquier agente para desviarse de la estrategia prescrita. Por lo tanto, (r) como se define anteriormente (1) es tal que el perfil r es un equilibrio de noh iff (r) ≤. En este estudio dedicamos especial atención a los juegos que exhiben simetría con respecto a los pagos, lo que hace que los agentes estratégicamente sean idénticos. Definición 2. Un juego [i, {ri}, {ui (r)}] es simétrico si para todo i, j ∈ I, (a) ri = rj y (b) ui (ri, r - i) = uJ (rj,r - j) cada vez que ri = rj y r - i = r - j 3. El modelo que modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador se mueve primero seleccionando un valor, θ, de un conjunto de configuraciones de mecanismo permitido, θ. Todos los agentes participantes observan el parámetro del mecanismo θ y se mueven simultáneamente a partir de entonces. Por ejemplo, el diseñador podría estar decidiendo entre un primer precio y los mecanismos de subasta de la chica sellada de primer precio, con la presunción de que después de que se haya tomado la elección, los postores participarán con plena conciencia de las reglas de subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como γθ = [i, {ri}, {ui (r, θ)}]. Nos referimos a γθ como un juego inducido por θ. Sea n (θ) el conjunto de perfiles de estrategia considerados soluciones del juego γθ.3 Suponga que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, w (r, θ), dependiente del parámetro de mecanismo y resultantejugar, r.Definimos una medida pesimista, w (ˆr, θ) = inf {w (r, θ): r ∈ ˆr}, representando el peor bienestar del juego inducido por θ, suponiendo que los agentes jueguen una estrategia conjunta en ˆr. Por lo general, nos importa W (n (θ), θ), el peor resultado de la que jugará alguna solución.4 En algunos problemas podemos obtener una ventaja considerable mediante el uso de una función de agregación para asignar el resultado del bienestar de un Juego 3 que generalmente adoptamosEl equilibrio de NASH como concepto de solución, y por lo tanto tomar N (θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría emplearse con criterios alternativos para derivar el comportamiento de los agentes de una definición del juego.4 Nuevamente, las alternativas están disponibles. Por ejemplo, si uno tiene una distribución de probabilidad sobre el conjunto de soluciones N (θ), sería natural tomar la expectativa de W (R, θ) en su lugar.307 especificado en términos de estrategias de agente a un resultado de bienestar equivalente especificado en términos de un resumen de baja dimensión. Definición 3. Una función φ: R1 × · · · × RM → RQ es una función de agregación si M ≥ Q y W (R, θ) = V (φ (R), θ) para alguna función v. Sobrecargamos el símbolo de la función para aplicar a los conjuntos de perfiles de estrategia: φ (ˆr) = {φ (r): r ∈ ˆr}. Para conveniencia de la exposición, escribimos φ ∗ (θ) para medir φ (n (θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, suponga: AS en nuestra aplicación debajo, que una estrategia de agentes se define por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ (a) = pm i = 1 ai. Si hemos elegido nuestro agregador con cuidado, también podemos capturar la estructura no obvia de lo contrario. Por ejemplo, φ ∗ (θ) podría estar disminuyendo en θ, mientras que N (θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de la solución n (θ) (de manera equivalente, φ ∗ (θ)), el diseñador enfrenta un problema de optimización estándar. Alternativamente, dado un simulador que podría producir una muestra imparcial a partir de la distribución de W (N (θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego γθ con pagos conocidos, puede ser computacionalmente intratable resolver los equilibrios de Nash, particularmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos donde los pagos no se dan explícitamente, pero deben determinarse a partir de la simulación u otra experiencia con el juego.5 En consecuencia, suponemos que se nos da un conjunto de datos (posiblemente ruidoso) de realizaciones de pago: do = = do = ={(θ1, a1, u1) ,..., (θk, AK, Reino Unido)}, donde para cada punto de datos θi es la configuración de parámetros del mecanismo observado, la IA es el perfil de estrategia pura observado de los participantes y la interfaz de usuario es la realización correspondiente de los pagos del agente. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): ds = {(θk+1, AK+1, Reino Unido+1) ,..., (θk+L, Ak+L, Reino Unido+L)}. Sea d = {do, ds} el conjunto de datos combinado.(O DO o DS pueden ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos teóricos empíricos del juego, para responder preguntas sobre el diseño del escenario TAC/SCM.4. Análisis de diseño empírico Dado que nuestros datos vienen en forma de experiencia de pago y no como el valor de una función objetivo para la configuración dada de la variable de control, ya no podemos confiar en los métodos para optimizar las funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia de equilibrio de Nash. Además, no podemos confiar directamente en los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilísticos adaptados para nuestra configuración de problemas.4.1 Problema de diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego SupplyChain decidieron aumentar drásticamente los costos de almacenamiento como una medida destinada a frenar la adquisición del día 0, a poco en vano. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y 5 Este es a menudo el caso de los juegos reales de interés, donde el lenguaje natural o las descripciones algorítmicas pueden sustituir una especificación formal de la estrategia y las funciones de pago.La cantidad agregada de componentes adquiridos el día 0 en equilibrio. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. Primero, ¿el aumento de los costos de almacenamiento en realidad reduce la adquisición de día 0? En segundo lugar, ¿fue la adquisición excesiva del día 0 que se observó durante el torneo racional de 2004? Y tercero, ¿podrían aumentar los costos de almacenamiento suficientemente haber reducido la adquisición de día 0 a un nivel aceptable, y de ser así, ¿cuál debería haber sido la configuración de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño del mecanismo de nuestro análisis.6 Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de agentes, la función de bienestar de los diseñadores, el espacio de los parámetros del mecanismo y la fuente de datos. Restringimos que las estrategias del agente sean un multiplicador en la cantidad de las solicitudes del día 0 de uno de los finalistas, el maíz profundo, en el torneo TAC/SCM 2004. Además, lo restringimos al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias superiores a 1.5 son extremadamente agresivas (por lo tanto, es poco probable que proporcione desviaciones de refutación más allá de las disponibles de las estrategias incluidas, y ciertamente no parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento del maíz profundo y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta a los cambios en el comportamiento del agente completo. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ (a) = p6 i = 1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego de cadena de suministro particular (para perfiles de estrategia mixta, esperamos φ con respecto ala mezcla). La función de bienestar de los diseñadores w (n (θ), θ) es dada por I {sup {φ ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de la adquisición del día 0 e I es la función indicadora. El diseñador selecciona un valor θ de los costos de almacenamiento, expresado como un porcentaje anual del valor de referencia de los componentes en el inventario (cargado diariamente), del conjunto θ = R+. Dado que la decisión de los diseñadores depende solo de φ ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación.4.2 Estimación del equilibrio de NASH El objetivo de los agentes TAC/SCM es maximizar las ganancias realizadas en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, u (a)). Si también hemos arreglado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de los jugadores y sus pagos correspondientes y, en consecuencia,Para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios NASH de cada juego γθ. Por lo tanto, necesitamos métodos para aproximar los equilibrios de Nash para juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero se ha explorado empíricamente antes, mientras que el segundo se introduce aquí como el método diseñado específicamente para aproximar un conjunto de equilibrios NASH.4.2.1 Aproximación de la función de pago El primer método para estimar los equilibrios de NASH basados en datos utiliza el aprendizaje supervisado para aproximar las funciones de pago de MECH6 No abordamos si otras medidas (por ejemplo, restringir la adquisición directamente) podrían haber logrado objetivos de diseño. Nuestro enfoque se toma como un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con el crecimiento de la complejidad correspondiente.308 participantes de anismo de un conjunto de datos de experiencia en el juego [17]. Una vez que las funciones de pago aproximadas están disponibles para todos los jugadores, los equilibrios NASH pueden encontrarse analíticamente o aproximarse utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de NASH de muestra utilizando esta técnica, aunque esta restricción se puede eliminar a expensas del tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para generar confianza en nuestras estimaciones iniciales.7 Intentamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado localmente (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variaciones de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis teórico de juego empírico anterior de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido analíticamente. Para los otros métodos, aplicamos la dinámica de replicador [7] a una aproximación discreta del juego aprendido. La adquisición total esperada del día 0 en equilibrio se tomó como la estimación de un resultado.4.2.2 Búsqueda en el espacio de perfil de estrategia Cuando tenemos acceso a un simulador, también podemos usar la búsqueda dirigida a través del espacio de perfil para estimar el conjunto de equilibrios NASH, que describimos aquí después de presentar alguna notación adicional. Definición 4. Un vecino estratégico de un perfil de estrategia puro es un perfil que es idéntico a una estrategia en toda la estrategia. Definimos SNB (a, d) como el conjunto de todos los vecinos estratégicos de un disponible en el conjunto de datos D. De manera similar, definimos SNB (a, ˜d) como todos vecinos estratégicos de un no en D. Finalmente, para cualquieraa ∈ Snb (a, d) Definimos el agente desviado como yo (a, a). Definición 5. El -bound, ˆ, de un perfil de estrategia puro a se define como maxa ∈Snb (a, d) max {ui (a, a) (a) −ui (a, a) (a), 0}. Decimos que A es un equilibrio δ candidato para δ ≥ ˆ. Cuando SNB (a, ˜d) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), A se confirma como un equilibrio de la red. Nuestro método de búsqueda funciona explorando las desviaciones de los equilibrios candidatos. Nos referimos a ello como BestIrstSearch, ya que selecciona con probabilidad uno de un perfil de estrategia a ∈ Snb (a, ˜d) que tiene el más pequeño D. Finalmente definimos un estimador para un conjunto de equilibrios Nash. Definición 6. Para un conjunto k, define Co (k) como el casco convexo de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ ∗ (θ) = Co ({φ (a): a ∈ Bδ}) para que un δ fijo sea un estimador de φ ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles de estrategia agregados con -bound debajo de algunos δ fijos. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles están cercanos en términos de valores de agregación, es probable que tengan fusiones similares. En particular, si uno es un equilibrio, el otro también puede ser. Presentamos cierto apoyo teórico para este método para estimar el conjunto de equilibrios NASH a continuación. Dado que el juego que nos interesa es infinito, es necesario terminar BestIrstSearch antes de explorar todo el espacio de Strat7, por ejemplo, podemos usar técnicas de aprendizaje activas [5] para mejorar la calidad de la aproximación de la función de pago. En este trabajo, en su lugar nos concentramos en la búsqueda en el espacio de perfil de estrategia.Perfiles de Egy. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos.8 4.3 Generación de datos Nuestros datos se recopilaron simulando juegos TAC/SCM en una versión local del servidor TAC/SCM 2004,que tiene una configuración de configuración para el costo de almacenamiento. Las estrategias de agente en juegos simulados se seleccionaron del conjunto {0, 0.3, 0.6 ,..., 1.5} Para tener una probabilidad positiva de generar vecinos estratégicos.9 Se generó un conjunto de datos de línea de base al muestreo 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varias fallas.10 Utilizamos la búsqueda para generar un conjunto de datos simulado DS, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de simulación es extremadamente alto (un juego tarda casi 1 hora en correr), pudimos ejecutar un total de 2670 juegos en el lapso de más de seis meses. A modo de comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategia conjunta finita restringida para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces 10 veces).4.4 Resultados 4.4.1 Análisis del conjunto de datos de línea de base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos de línea de base Do. Además, generamos una estimación de la correspondencia de equilibrio de Nash, ˆφ ∗ (θ), aplicando la definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ ∗ (θ) tiene poco poder predictivo basado en DO, y no revela una estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento.0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de almacenamiento Totalday-0 Procurement LWA LWLR QR Baselinemin Baselinemax Figura 1: Estimaciones de adquisiciones de día-0 agregadas basadas en Do. La correspondencia ˆφ ∗ (θ) es el intervalo entre Baselinemin y Baselinemax.8 En general, la búsqueda termina una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para sacar conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego.9 Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash para permanecer en este subconjunto discreto de [0,1.5].10 Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron bloqueos, problemas de conectividad de red y otras anomalías obvias), el juego se expulsaría.309 4.4.2 Análisis de datos de búsqueda para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ ∗ (θ) (nuevamente, usando Δ = 2.5e6) en el conjunto de datos d = {do, ds}, donde ds es datosGenerado a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se trazan contra los resultados de los métodos de aprendizaje entrenados en DO 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce el rango de equilibrios potenciales sustancialmente. Además, las predicciones puntuales reales de los métodos de aprendizaje y las basadas en los fondos después de la búsqueda son razonablemente cercanos. La combinación de la evidencia reunida de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquier método utilizado de forma aislada.0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 200 Costo de almacenamiento TOTAYDAY-0PROCURIMENTO LWA LWLR QR Searchmin Searchmax Figura 2: Estimaciones de adquisición de día-0 agregadas basadas en la búsqueda en el espacio de perfil de estrategia en comparación con las técnicas de aproximación de función capacitadas. La correspondencia ˆφ ∗ (θ) para d = {do, ds} es el intervalo entre Searchmin y Searchmax. Esta evidencia respalda la intuición inicial que la adquisición del día 0 debería ser disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición del día 0 son una respuesta racional a la configuración del torneo 2004 del costo de almacenamiento promedio, que corresponde a θ = 100. La predicción mínima para la adquisición agregada a este nivel de costos de almacenamiento dados por cualquier método experimental es de aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado de 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor en 4.5. En la competencia real de 2004, la adquisición agregada del día 0 fue equivalente a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado hasta cierto punto, pero demuestran que cualquier resultado racional probablemente tuviera una alta adquisición del día 0.4.4.3 Extrapolar la correspondencia de la solución Tenemos evidencia razonablemente fuerte de que la correspondencia de resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento en un valor que frenaría la adquisición de día 0 en equilibrio o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día-0.12 lineal 11 No está claro cuán significativos serían los resultados del aprendizaje si se agregaran DS al conjunto de datos de entrenamiento. De hecho, los datos adicionales en realidad pueden aumentar la varianza de aprendizaje.12 Recuerde que el objetivo de los diseñadores es incentivar la adquisición de Aggergate Day-0 que está por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultado estimada a partir de los rendimientos D θ = 320. Los datos para θ = 320 se recopilaron de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos de 33 iteraciones de Best FirstSearch. La Figura 3 muestra los bounds detallados para todos los perfiles en términos de sus valores correspondientes de φ.0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.63.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Día-0 Adquisición ε-Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ (a). La región gris corresponde a ˆφ ∗ (320) con δ = 2.5m. El conjunto estimado de resultados agregados del Día-0 es muy cercano a θ = 200, lo que indica que hay poco beneficio adicional para aumentar los costos de almacenamiento por encima de 200. Observe que incluso el límite inferior de nuestro conjunto estimado de equilibrios Nash está muy por encima de la adquisición objetivo de 2 de 2. Además, los pagos a los agentes casi siempre son negativos en θ = 320. En consecuencia, aumentar aún más los costos sería indeseable incluso si la adquisición del día 0 pudiera ser frenada. Dado que estamos razonablemente seguros de que φ ∗ (θ) está disminuyendo en θ, tampoco esperamos que la configuración θ en algún lugar entre 200 y 320 alcance el resultado deseado. Llegamos a la conclusión de que es poco probable que la adquisición de día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerzan esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 requiere rediseñar otros aspectos del mecanismo.4.5 Análisis probabilístico Nuestro análisis empírico ha producido evidencia en apoyo de la conclusión de que no es probable que ningún ajuste razonable de costo de almacenamiento frenara suficientemente la adquisición excesiva de día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de interpolación simple y extrapolación de estimaciones de la correspondencia de equilibrio de Nash. Estas estimaciones se basan en la simulación de instancias del juego, y están sujetas al ruido de muestreo aportado por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos unidos a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitas (y pequeñas), A. Por lo tanto, es factible probar toda la matriz de pago del juego. Además, suponga que el ruido es aditivo con cero medio todo el juego en promedio, por lo que en la práctica probablemente quisiéramos que el umbral sea aún más bajo.310 y varianza finita, es decir, ui (a) = ui (a) + ˜ξi (a), donde ui (a) es la recompensa observada a i cuando a se jugó, ui (a) es el pago correspondiente real,y ˜ξi (a) es una variable aleatoria normal de cero cero. Designamos la varianza conocida de ˜ξi (a) por σ2 I (a). Por lo tanto, suponemos que ˜ξi (a) es normal con la distribución n (0, σ2 i (a)). Tomamos que ¯Ui (a) sea la media de la muestra sobre toda la interfaz de usuario (a) en D, y seguimos a Chang y Huang [3] para asumir que tenemos un prior inadecuado sobre los pagos reales UI (a) y el muestreo fue independiente paraTodos yo y a. También confiamos en su resultado de que Ui (a) | ¯ui (a) = ¯ui (a) −zi (a)/ [σi (a)/ p ni (a)] son independientes con distribuciones posteriores n (¯ui(a), σ2 I (a)/ni (a)), donde Ni (a) es el número de muestras tomadas de pagos a I para el perfil puro a, y zi (a) ∼ n (0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio -nash. Si ui (·) | ¯ui (·) son independientes para todos los i ∈ I y a ∈ A, tenemos el siguiente resultado (desde este punto en omitir el acondicionamiento en ¯Ui (·) para la brevedad): Proposición 1. Pr „max i∈I max b∈Ai ui (b, a - i) - ui (a) ≤« = = y i∈I z r y b∈Ai \\ ai pr (ui (b, a - i) ≤ u +)fui (a) (u) du, (2) donde fui (a) (u) es el pdf de n (¯ui (a), σi (a)). Las pruebas de esto y todos los resultados posteriores están en el apéndice. La distribución posterior de la media óptima de las muestras de N, derivada por Chang y Huang [3], es PR (UI (A) ≤ C) = 1 - φ P Ni (A) (¯Ui (A) - C) σi (a) #, (3) donde a ∈ A y φ (·) es la función de distribución n (0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilística que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y usamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en datos) sobre la distribución de sup {φ ∗ (θ)} e inf {φ ∗ (θ)}(Suponiendo que ambos sean alcanzables): PR {sup {φ ∗ (θ)} ≤ x} ≤d pr {∃a ∈ D: φ (a) ≤ x ∧ a ∈ N (θ)} ≤ x a∈D:φ (a) ≤x pr {a ∈ N (θ)} = x a∈D: φ (a) ≤x pr {(a) = 0}, donde x es un número real y ≤d indica que el límite superiorCuentas solo de estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D: φ (a) ≤ x ∧ a ∈ N (θ)} y {inf {φ ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf {φ ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.00000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 1 Tabla 1: límites superioresEn la distribución de inf {φ ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando n (θ) es un conjunto de equilibrios Nash.φ ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 Tabla 2: límites superiores en la distribución de INF {φ ∗ (θ)} restringido a D para θ ∈ {150, 200, 320} cuando n (θ) es un conjunto de equilibrios NASH. Las tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ (a) <2.7 es poco probable para cualquier θ para los que tenemos datos, aunque este juicio, como mencionamos, es solo con respecto a los perfiles que realmente hemos probado. Entonces podemos aceptar esto como otra evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, ¡el diseñador parece poco probable que logre su objetivo incluso si pudiera persuadir a los participantes para que jueguen un equilibrio deseable! La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM 2004 eran racionales para adquirir un gran número de componentes al principio del juego. Si miramos la tercera columna de esta tabla, que corresponde a θ = 100, podemos recopilar que no hay perfil A en nuestros datos con φ (a) <3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan alguna evidencia general, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos probado. Particularmente, nos gustaría decir algo sobre lo que sucede para la configuración de θ para la cual no tenemos datos. Para derivar un límite probabilístico aproximado de la probabilidad de que no θ ∈ θ podría haber logrado el objetivo de los diseñadores, que ∪j j = 1θj, sea una partición de θ, y suponga que la función sup {φ ∗ (θ)} satisface los Lipschitzzcondición con Lipschitz constante AJ en cada subconjunto θj.13 Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a θ = [0, 320]. Ahora definimos que cada subconjunto J es el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, θ = [0, 50] [(50, 100] [(100, 150] [(150, 200] [(200, 320], con J en ejecución entre 1 y 5, correspondiente a los subintervalos anteriores. Denotaremos cada vez cada θj por (AJ, BJ] .14 Entonces, la siguiente proposición nos da un límite superior aproximado15 sobre la probabilidad de que sup {φ ∗ (θ)} ≤ α. Proposición 2. PR {_ θ∈θ Sup {φ (θ)} ≤ α} ≤d 5x J = 1 x y, z∈D: y+z≤cj 0 @ x a: φ (a) = z pr {(a)= 0} 1 a × × 0 @ x a: φ (a) = y pr {(a) = 0} 1 a, donde cj = 2α + aj (bj - aj) y ≤d indica que el límite superior solo explicaPara las estrategias que aparecen en el conjunto de datos D. 13 Una función que satisface la condición de Lipschitz se llama Lipschitz continuo.14 El tratamiento para el intervalo [0,50] es idéntico.15 Es aproximado en cierto sentido que solo tenemos en cuenta las estrategias que están presentes en los datos.311 Debido al hecho de que nuestros límites son aproximados, no podemos usarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra evidencia para complementar nuestros hallazgos. Incluso si podemos suponer que una función que aproximamos de los datos es Lipschitz continuo, rara vez conocemos el Lipschitz constante para cualquier subconjunto de θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subinterval. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenido dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior mucho menos conservador en las probabilidades. Sin embargo, dado que el límite superior real es generalmente mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un método final que probamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador en función de los datos en todo el dominio de la función θ, tomamos el promedio de los límites superiores obtenidos en cada θj. El límite en un intervalo se considera el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr {_ θ∈θ sup {φ ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en Maxj AJ AJ Max {AJ, Ave (AJ)} 1 0.00772 0.00791 Tabla 3: Aproximadamente un límite superior en la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con el objetivo α = 2 [0. Se utilizan diferentes métodos para aproximar el límite superior en la pendiente en cada subinterval. J se utilizan.Este trabajo, la expresión da un límite superior en la probabilidad de que una configuración de θ (es decir, el costo de almacenamiento) en el intervalo [0,320] dará como resultado una adquisición total del día 0 que no es mayor en ningún equilibrio que el objetivo especificado por αy tomado aquí para ser 2. Como habíamos sospechado, el enfoque más conservador para estimar el límite superior en la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, que se encuentran en las columnas dos y tres de la Tabla 3, sugieren que estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría hecho el trabajo. Dada la tremenda dificultad del problema, este resultado es muy fuerte.16 Aún así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y conjuntos de estrategias). Tampoco podemos esperar que obtenga suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que abogamos aquí es recopilar tanta evidencia como sea factible dadas las limitaciones de recursos, y hacer el juicio más convincente basado en esta evidencia, si es posible.5. Resultados de convergencia En este punto, exploramos de manera abstracta si una elección de parámetros de diseño basada en datos de pago puede ser asintóticamente confiable.16 Dado que no teníamos todas las desviaciones posibles para ningún perfil disponible en los datos, los límites superiores verdaderos pueden ser aún más bajos. Como cuestión de conveniencia, usaremos la notación un, I (a) para referirnos a una función de pago del jugador I basándose en un promedio sobre n i.i.d.Muestras de la distribución de pagos. También suponemos que Un, I (a) son independientes para todos A ∈ A e I ∈ I. Usaremos la notación γn para referirnos al juego [i, r, {ui, n (·)}], mientras que γ denotará el juego subyacente, [i, r, {ui (·)}]. Del mismo modo, definimos que N (R) sea (R) con respecto al juego γn. En esta sección, mostramos que n (s) → (s) A.S.Uniformemente en el espacio de estrategia mixta para cualquier juego finito y, además, que todos los equilibrios de Nash de estrategia mixta en juegos empíricos eventualmente se vuelven arbitrariamente cercanos a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para mostrar que, bajo ciertas condiciones, la elección óptima del parámetro de diseño basado en datos empíricos converge casi seguramente con el óptimo real. Teorema 3. Supongamos que | i |<∞, | a |<∞. Entonces n (s) → (s) a.s.Uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios Nash de γ. Si definimos nn, γ = {s ∈ S: n (s) ≤ γ}, tenemos el siguiente corolario al teorema 3: corolario 4. Para cada γ> 0, hay m tal que ∀n ≥ m, n ⊂ nn, γ a.s. PRUEBA. Dado que (s) = 0 para cada s ∈ N, podemos encontrar m lo suficientemente grande como para pr {supn≥m sups∈N n (s) <γ} = 1. Por el corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier> 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios empíricos -nash si se han tomado suficientes muestras. Como ahora mostramos, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un no distinto de cero como una estimación del conjunto de equilibrios Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup {ˆφ ∗ (θ)} ≤ α. Luego, dado que para cualquier fijo> 0, n (θ) ⊂ nn, (θ) cuando n es lo suficientemente grande, sup {φ ∗ (θ)} = sup s∈N (θ) φ (s) ≤ sup s∈Nn, (θ) φ (s) = sup {ˆφ ∗ (θ)} ≤ α para cualquier n.Por lo tanto, dado que definimos la función de bienestar del diseñador como i {sup {φ ∗ (θ)} ≤ α} En nuestro dominio de interés, la elección empírica de θ satisface el objetivo de los diseñadores, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf {ˆφ ∗ (θ)}> α para cada θ en el dominio. Entonces, α <inf {ˆφ ∗ (θ)} = inf S∈Nn, (θ) φ (s) ≤ inf s∈N (θ) φ (s) ≤ ≤ sup s∈N (θ) φ (s)= sup {φ ∗ (θ)}, para cada θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo de los diseñadores. Ahora, mostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de optimizadores basados en datos empíricos a la configuración de los parámetros de mecanismo óptimo real. Primero observamos que las funciones (s) son continuas en un juego finito. Lema 5. Sea s un conjunto de estrategias mixtas definidas en un juego finito. Entonces: S → R es continuo.312 Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, Sea (z, d) un espacio métrico, y x, y ⊂ z y defina la distancia de Hausdorff dirigida de x a y para ser h (x, y) = sup x∈X inf y∈Y d (x, y). Observe que u ⊂ x ⇒ h (u, y) ≤ h (x, y). Además, defina BS (x, δ) para que sea una bola abierta en S ⊂ Z con el centro x ∈ S y Radius δ. Ahora, deje que Nn denote todos los equilibrios NASH del juego γn y deje nδ = [x∈N BS (x, δ), es decir, la unión de bolas abiertas de radio δ con centros en equilibrios NASH de γ. Tenga en cuenta que h (nδ, n) = δ. Luego podemos probar el siguiente resultado general. Teorema 6. Supongamos | i |<∞ y | a |<∞. Entonces casi seguramente h (nn, n) converge a 0. Ahora mostraremos que en el caso especial cuando θ y A son finitos y cada γθ tiene un equilibrio NASH único, las estimaciones ˆθ del parámetro de diseñador óptimo convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈θ W (nn (θ), θ), donde n es el número de veces que cada perfil puro se muestreó en γθ para cada θ, y vamos θ ∗ = arg maxθ∈θ W (n (θ), θ). Teorema 7. Supongamos | n (θ) |= 1 para todos θ ∈ θ y suponga que θ y A son finitos. Sea W (s, θ) continuo en el único S ∗ (θ) ∈ N (θ) para cada θ ∈ θ. Entonces ˆθ es un estimador consistente de θ ∗ si W (n (θ), θ) se define como un supremum, infimum o expectativa sobre el conjunto de equilibrios Nash. De hecho, ˆθ → θ ∗ a.s.en cada uno de estos casos. La deficiencia del resultado anterior es que, dentro de nuestro marco, el diseñador no tiene forma de saber o garantizar que γθ haga, de hecho, tenga equilibrios únicos. Sin embargo, presta alguna justificación teórica para perseguir el diseño de esta manera y, tal vez, servirá como una guía para resultados más generales en el futuro.6. Trabajo relacionado La literatura de diseño del mecanismo en economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, hay una extensa literatura sobre el diseño de subasta óptimo [10], de la cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y contabilidad de restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de informática. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros del juego relevantes son de conocimiento común. Cuando se desconocen las funciones de pago de los jugadores, se ha explorado una búsqueda que usa simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es co-evolucionar los parámetros del mecanismo y las estrategias de agentes, utilizando alguna noción de utilidad social y pagos de agentes como criterios de aptitud física. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron el resultado de un juego inducido por un parámetro de mecanismo como resultado del aprendizaje de agentes conjuntos. Más recientemente, Phelps et al.[14] comparó dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en los juegos definidos por estrategias heurísticas, como en [18].7. Conclusión En este trabajo gastamos un esfuerzo considerable en desarrollar tácticas generales para el diseño del mecanismo empírico. Definimos un modelo de interacción gametheorético formal entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio NASH de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para tratar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de agente son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad TAC ha estado ansiosa por abordar nos proporciona una configuración para probar nuestros métodos. Al aplicar el análisis de juegos empíricos al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia de equilibrio de Nash. Al final, podemos tratar de proporcionar suficiente evidencia para prescribir una configuración de parámetros o sugerir que no es posible una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere con bastante fuerza que el costo de almacenamiento no podría haberse ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva de día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace optimistas de que nuestros métodos pueden proporcionar orientación para tomar decisiones de diseño del mecanismo en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismo empírico que hemos introducido, y aumenta nuestra confianza de que nuestro marco puede ser efectivo para estimar la mejor opción de parámetros de mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre borradores anteriores de este trabajo. Este trabajo fue apoyado en parte por NSF Grant IIS-0205435 y el programa de razonamiento estratégico Real DARPA.8. Referencias [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes comerciales de la cadena de suministro. Investigación y aplicaciones de comercio electrónico, 4: 63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la programación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P.Chang y W.-T.Huang. Intervalos de confianza generalizados para el mayor valor de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10: 1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subastas. En el Congreso sobre Computación Evolutiva, 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Journal of Artificial Intelligence Research, 4: 129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos deterministas sin pagos. En 313 Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas de Multi-Agentes, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59 (3): 637-666, mayo de 1991. [8] R. Keener. Teoría estadística: una mezcla de temas centrales. Departamento de Estadísticas de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre el diseño y el análisis del agente comercial, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson. Diseño de subasta óptimo. Matemáticas de la investigación de operaciones, 6 (1): 58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesano, C.-H.Chen, J. Snowdon y J. Charnes, editores, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe y P. Stone. TACTEX-03: Un agente de gestión de la cadena de suministro. Exchanges de Sigecom, 4 (3): 19-28, 2004. [14] S. Phelps, S. Parsons y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva del juego de dos diseños de mercado de doble subasta. En Taller sobre el Comercio Electrónico Mediado por el Agente VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Coevolución de los mecanismos de subastas y estrategias comerciales: hacia un enfoque novedoso para el diseño microeconómico. En Ecomas 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Uso de la programación genética para optimizar las reglas de precios para un mercado de doble subasta. En Taller sobre Agentes para Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprender funciones de pago en juegos infinitos. En la decimocoria Conferencia Conjunta Internacional sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Análisis de interacciones estratégicas complejas en sistemas de múltiples agentes. En el taller de AAAI-02 sobre los agentes teóricos y teóricos de la decisión del juego, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia computacional, 21 (1): 1-26, febrero de 2005. APÉNDICE A. Pruebas A.1 Prueba de la proposición 1 Pr „max i∈I max b∈Ai \\ ai ui (b, a - i) - ui (a) ≤« = y i∈I eui (a) »pr (max b (max b (max b)∈Ai \\ ai ui (b, a - i) - ui (a) ≤ | ui (a)) = = y i∈I z r y b∈Ai \\ ai pr (ui (b, a - i) ≤ u +) fui(a) (u) du. A.2 Prueba de la Proposición 2 Primero, supongamos que algún funcionamiento, F (x) definido en [AI, BI], satisface la condición de Lipschitz en (Ai, BI] con Lipschitz constante Ai. Entonces la siguiente afirmación es válida: afirmación: infx∈ (ai, bi] f (x) ≥ 0.5 (f (ai) + f (bi) - ai (bi - ai). Para probar esta afirmación, tenga en cuenta que la intersección de líneas en F (ai) y F (bi) con pendientes −a y ai respectivamente determinará el límite inferior en el mínimo de f (x) en [ai, bi] (que esun límite inferior en infimum de f (x) en (ai, bj]). La línea en f (ai) está determinada por f (ai) = −aiai + cl y la línea en f (bi) está determinada por f (bi) = aibi + cr. Por lo tanto, las intercepciones son cl = f (ai) + aiai y cr = f (bi) + aibi respectivamente. Sea x ∗ el punto en el que estas líneas se cruzan. Entonces, x ∗ = - f (x ∗) - cr a = f (x ∗) - cl a. Al sustituir las expresiones por CR y CL, obtenemos el resultado deseado. Ahora, la subadditividad nos da pr {_ θ∈θ sup {φ ∗ (θ)} ≤ α} ≤ 5x j = 1 pr {_ θ∈θj sup {φ ∗ (θ)} ≤ α} y, por la afirmación, Pr {_ θ∈θj sup {φ ∗ (θ)} ≤ α} = 1 - Pr {inf θ∈θj sup {φ ∗ (θ)}> α} ≤ pr {sup {φ ∗ (aj)} +sup {φ ∗ (bj)} ≤ 2α + aj (bj - aj)}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: PR {sup {φ ∗ (aj)} + sup {φ ∗ (bj)} ≤ cj} = d x y, z∈D: y+z≤cj pr {sup {φ ∗ (bj)} = y} pr {sup {φ ∗ (aj)} = z}. Ahora podemos restringir la atención a derivar un límite superior en PR {sup {φ ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr {sup {φ ∗ (θ)} = y} ≤d pr {_ a∈D: φ (a) = y (a) = 0} ≤ x a∈D: φ (a)= y Pr {(a) = 0} por subadditividad y el hecho de que un perfil a es un equilibrio Nash si y solo si (a) = 0. Poner todo juntos produce el resultado deseado. A.3 Prueba del teorema 3 Primero, necesitaremos el siguiente hecho: Reclamación: Dada una función fi (x) y un conjunto x, |maxx∈X f1 (x) - maxx∈X f2 (x) |≤ maxx∈X | f1 (x) - f2 (x) |. Para probar esta afirmación, observe que |max x∈X f1 (x) - max x∈X f2 (x) |=  maxx f1 (x) - maxx f2 (x) si maxx f1 (x) ≥ maxx f2 (x) maxx f2 (x) - maxx f1 (x) si maxx f2 (x) ≥ maxx f1 (x) en elPrimer caso, max x∈X f1 (x) - max x∈X f2 (x) ≤ max x∈X (f1 (x) - f2 (x)) ≤ ≤ max x∈X | f1 (x) - f2 (x) |.314 Del mismo modo, en el segundo caso, max x∈X f2 (x) - max x∈X f1 (x) ≤ max x∈X (f2 (x) - f1 (x)) ≤ ≤ max x∈X | f2 (x) - f1 (x) |= max x∈X | f1 (x) - f2 (x) |. Por lo tanto, la afirmación se mantiene. Por la fuerte ley de grandes números, un, i (a) → ui (a) a.s.Para todos los i ∈ I, a ∈ A. Es decir, pr {lim n → ∞ un, i (a) = ui (a)} = 1, o, de manera equivalente [8], para cualquier α> 0 y δ> 0, hay m (i, a)>>0 tal que pr {sup n≥m (i, a) | un, i (a) - ui (a) |<Δ 2 | a |} ≥ 1 - α. Al tomar m = maxi∈I maxa∈A m (i, a), tenemos pr {max i∈I max a∈A sup n≥m | un, i (a) - ui (a) |<Δ 2 | a |} ≥ 1 - α. Por lo tanto, por el reclamo, para cualquier n ≥ m, sup n≥m |n (s) - (s) |≤ max i∈I max ai∈Ai sup n≥m | un, i (ai, s - i) - ui (ai, s - i) | + + sup n≥m max i∈I | un, i (s) - ui (s) |≤ max i∈I max ai∈Ai x b∈A - i sup n≥m | un, i (ai, b) - ui (ai, b) | s - i (b) + + max i∈I x b∈A Sup n≥m | un, i (b) - ui (b) | s (b) ≤ max i∈I max ai∈Ai x b∈A - i sup n≥m | un, i (ai, b)- ui (ai, b) | + + max i∈I x b∈A sup n≥m | un, i (b) - ui (b) |<max i∈I max ai∈Ai x b∈A - i (Δ 2 | a |) + max i∈I x b∈A (Δ 2 | a |) ≤ δ con probabilidad al menos 1 - α. Tenga en cuenta que dado que S - I (a) y S (a) están limitados entre 0 y 1, pudimos dejarlas de las expresiones anteriores para obtener un límite que será válido independiente de la elección particular de s.Además, dado que el resultado anterior se puede obtener para un α> 0 y Δ> 0 arbitrario, tenemos PR {Limn → ∞ n (s) = (s)} = 1 uniformemente en S. A.4 Prueba de Lemma 5 Probamos el resultadoutilizando continuidad uniforme de UI (s) y preservación de la continuidad al máximo. Reclamación: una función f: rk → r definida por f (t) = pk i = 1 ziti, donde zi son constantes en r, es uniformemente continuo en t.La afirmación sigue porque | f (t) −f (t) |= |Pk I = 1 Zi (ti - ti) |≤ Pk i = 1 | zi || ti - ti |. Un resultado inmediato de esto para nuestros propósitos es que UI (S) es uniformemente continuo en S y UI (Ai, S - I) es uniformemente continuo en S - I. Reclamación: Sea f (a, b) ser uniformemente continuo en b ∈ B por cada a ∈ A, con | a |<∞. Entonces V (b) = maxa∈A f (a, b) es uniformemente continuo en b. Para mostrar esto, tome γ> 0 y deje b, b ∈ B tal que b - b <δ (a) ⇒ | f (a, b) - f (a, b) |<γ. Ahora tome δ = mina∈A δ (a). Luego, siempre que b - b <δ, | V (b) - V (b) |= |max a∈A f (a, b) - max a∈A f (a, b) |≤ max a∈A | f (a, b) - f (a, b) |<γ. Ahora, recuerde que (s) = maxi [maxai∈Ai ui (ai, s - i) - ui (s)]. Según las afirmaciones anteriores, maxai∈Ai ui (ai, s - i) es uniformemente continuo en s - i y ui (s) es uniformemente continuo en s.Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva al máximo por nuestro segundo reclamo, tenemos el resultado deseado. A.5 Prueba del teorema 6 Elija δ> 0. Primero, debemos determinar que la siguiente afirmación es contenida: afirma: ¯ = mins∈S \\ nδ (s) existe y ¯> 0. Dado que Nδ es un subconjunto abierto de S compacto, se deduce que S \\ Nδ es compacto. Como también habíamos demostrado en Lemma 5 que (s) es continua, la existencia se deriva del teorema de Weierstrass. Que ¯> 0 está claro ya que (s) = 0 si y solo si s es un equilibrio NASH de γ. Ahora, por el Teorema 3, para cualquier α> 0 hay M tal que Pr {sup n≥m sup s∈S |n (s) - (s) |<¯} ≥ 1 - α.En consecuencia, para cualquier δ> 0, PR {sup n≥m h (nn, nΔ) <Δ} ≥ pr {∀n ≥ m nn ⊂ nδ} ≥ pr {sup n≥m sup s∈N (s) <¯} ≥ pr {sup n≥m sup s∈S |n (s) - (s) |<¯} ≥ 1 - α. Dado que esto es válido para un α> 0 y δ> 0 arbitrario, el resultado deseado sigue. A.6 Prueba del teorema 7 FIJA θ y elija δ> 0. Dado que w (s, θ) es continuo en s ∗ (θ), dado> 0 hay δ> 0 tal que para cada s que está dentro de δ de s ∗ (θ), | w (s, θ) - w (S ∗ (θ), θ) |<. Por el Teorema 6, podemos encontrar m (θ) lo suficientemente grande como para que todos los s ∈ Nn estén dentro de δ de S ∗ (θ) para todos n ≥ m (θ) con probabilidad 1. En consecuencia, para cualquier> 0 podemos encontrar m (θ) lo suficientemente grande como para que con la probabilidad 1 tengamos supn≥m (θ) sups ∈Nn | w (s, θ) - w (s ∗ (θ), θ) |<. Supongamos sin pérdida de generalidad que existe una elección óptima única de θ. Ahora, dado que el conjunto θ es finito, también existe la segunda mejor opción de θ (si solo hay una θ ∈ θ esta discusión es discutible de todos modos): θ ∗∗ = arg max θ \\ θ ∗ w (s ∗ ((θ), θ). Supongamos que W.L.O.G.que θ ∗∗ también es único y deje ∆ = w (s ∗ (θ ∗), θ ∗) - w (s ∗ (θ ∗∗), θ ∗∗). Entonces, si dejamos <∆/2 y M = maxθ∈θ m (θ), donde cada m (θ) es lo suficientemente grande como como supn≥m (θ) sups ∈Nn | w (s, θ) - w (S ∗ (θ), θ) |<A.S., la elección óptima de θ basada en cualquier equilibrio empírico será θ ∗ con probabilidad 1. Por lo tanto, en particular, dada cualquier distribución de probabilidad sobre los equilibrios empíricos, la mejor opción de θ será θ ∗ con probabilidad 1 (de manera similar, si tomamos supremum o infimum de w (nn (θ), θ) sobre el conjunto de equilibrios empíricosal construir la función objetivo).315",
    "original_sentences": [
        "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
        "We illustrate our approach with a design task from a supply-chain trading competition.",
        "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
        "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
        "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
        "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
        "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
        "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
        "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
        "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
        "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
        "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
        "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
        "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
        "The task facing game organizers can be viewed as a problem in mechanism design.",
        "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
        "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
        "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
        "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
        "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
        "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
        "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
        "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
        "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
        "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
        "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
        "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
        "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
        "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
        "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
        "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
        "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
        "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
        "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
        "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
        "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
        "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
        "We believe that most realistic problems are too complex to be amenable to exact analysis.",
        "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
        "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
        "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
        "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
        "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
        "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
        "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
        "An s ∈ S is called a mixed strategy profile.",
        "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
        "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
        "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
        "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
        "We could capture finer-grained decisions about action over time in the extensive form.",
        "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
        "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
        "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
        "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
        "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
        "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
        "DEFINITION 1.",
        "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
        "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
        "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
        "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
        "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
        "DEFINITION 2.",
        "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
        "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
        "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
        "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
        "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
        "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
        "We refer to Γθ as a game induced by θ.",
        "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
        "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
        "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
        "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
        "DEFINITION 3.",
        "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
        "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
        "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
        "Using an aggregation function yields a more compact representation of strategy profiles.",
        "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
        "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
        "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
        "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
        "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
        "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
        "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
        "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
        "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
        "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
        "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
        "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
        "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
        "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
        "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
        "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
        "In doing so, we consider several questions raised during and after the tournament.",
        "First, does increasing storage costs actually reduce day-0 procurement?",
        "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
        "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
        "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
        "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
        "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
        "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
        "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
        "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
        "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
        "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
        "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
        "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
        "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
        "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
        "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
        "Thus, we need methods for approximating Nash equilibria for infinite games.",
        "Below, we describe the two methods we used in our study.",
        "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
        "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
        "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
        "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
        "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
        "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
        "Thus, we can apply it when Ds = ∅.",
        "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
        "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
        "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
        "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
        "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
        "DEFINITION 4.",
        "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
        "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
        "DEFINITION 5.",
        "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
        "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
        "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
        "Our search method operates by exploring deviations from candidate equilibria.",
        "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
        "DEFINITION 6.",
        "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
        "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
        "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
        "This definition allows us to exploit structure arising from the aggregation function.",
        "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
        "In particular, if one is an equilibrium, the other may be as well.",
        "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
        "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
        "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
        "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
        "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
        "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
        "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
        "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
        "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
        "The results are shown in Figure 1.",
        "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
        "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
        "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
        "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
        "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
        "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
        "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
        "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
        "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
        "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
        "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
        "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
        "The maximum prediction is considerably higher at 4.5.",
        "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
        "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
        "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
        "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
        "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
        "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
        "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
        "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
        "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
        "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
        "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
        "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
        "Furthermore, payoffs to agents are almost always negative at θ = 320.",
        "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
        "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
        "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
        "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
        "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
        "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
        "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
        "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
        "Suppose that all agents have finite (and small) pure strategy sets, A.",
        "Thus, it is feasible to sample the entire payoff matrix of the game.",
        "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
        "We designate the known variance of ˜ξi(a) by σ2 i (a).",
        "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
        "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
        "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
        "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
        "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
        "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
        "The proofs of this and all subsequent results are in the Appendix.",
        "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
        "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
        "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
        "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
        "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
        "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
        "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
        "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
        "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
        "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
        "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
        "We now define each subset j to be the interval between two points for which we have produced data.",
        "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
        "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
        "PROPOSITION 2.",
        "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
        "Instead, we take this as another piece of evidence to complement our findings.",
        "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
        "Thus, we are faced with a task of estimating it from data.",
        "Here, we tried three methods of doing this.",
        "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
        "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
        "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
        "This produces a much less conservative upper bound on probabilities.",
        "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
        "A final method that we tried is a compromise between the two above.",
        "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
        "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
        "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
        "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
        "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
        "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
        "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
        "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
        "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
        "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
        "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
        "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
        "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
        "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
        "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
        "Similarly, we define n(r) to be (r) with respect to the game Γn.",
        "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
        "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
        "THEOREM 3.",
        "Suppose that |I| < ∞, |A| < ∞.",
        "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
        "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
        "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
        "PROOF.",
        "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
        "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
        "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
        "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
        "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
        "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
        "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
        "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
        "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
        "We first note that the function (s) is continuous in a finite game.",
        "LEMMA 5.",
        "Let S be a mixed strategy set defined on a finite game.",
        "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
        "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
        "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
        "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
        "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
        "Note that h(Nδ, N) = δ.",
        "We can then prove the following general result.",
        "THEOREM 6.",
        "Suppose |I| < ∞ and |A| < ∞.",
        "Then almost surely h(Nn, N) converges to 0.",
        "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
        "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
        "THEOREM 7.",
        "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
        "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
        "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
        "In fact, ˆθ → θ∗ a.s. in each of these cases.",
        "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
        "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
        "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
        "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
        "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
        "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
        "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
        "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
        "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
        "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
        "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
        "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
        "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
        "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
        "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
        "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
        "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
        "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
        "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
        "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
        "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
        "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
        "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
        "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
        "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
        "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
        "The supply chain trading agent competition.",
        "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
        "A stochastic programming approach to scheduling in TAC SCM.",
        "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
        "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
        "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
        "Evolution of market mechanism through a continuous space of auction-types.",
        "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
        "Active learning with statistical models.",
        "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
        "An algorithm for automatically designing deterministic mechanisms without payments.",
        "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
        "Evolutionary games in economics.",
        "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
        "Statistical Theory: A Medley of Core Topics.",
        "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
        "An analysis of the 2004 supply chain management trading agent competition.",
        "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
        "Green.",
        "Microeconomic Theory.",
        "Oxford University Press, 1995. [11] R. B. Myerson.",
        "Optimal auction design.",
        "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
        "Simulation optimization.",
        "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
        "TacTex-03: A supply chain management agent.",
        "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
        "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
        "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
        "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
        "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
        "Using genetic programming to optimise pricing rules for a double-auction market.",
        "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
        "Learning payoff functions in infinite games.",
        "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
        "Analyzing complex strategic interactions in multi-agent systems.",
        "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
        "Strategic interactions in a supply chain game.",
        "Computational Intelligence, 21(1):1-26, February 2005.",
        "APPENDIX A.",
        "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
        "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
        "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
        "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
        "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
        "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
        "Let x∗ be the point at which these lines intersect.",
        "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
        "By substituting the expressions for cR and cL, we get the desired result.",
        "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
        "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
        "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
        "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
        "Putting everything together yields the desired result.",
        "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
        "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
        "Thus, the claim holds.",
        "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
        "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
        "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
        "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
        "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
        "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
        "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
        "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
        "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
        "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
        "Now take δ = mina∈A δ(a).",
        "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
        "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
        "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
        "A.5 Proof of Theorem 6 Choose δ > 0.",
        "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
        "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
        "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
        "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
        "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
        "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
        "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
        "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
        "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
        "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
        "Let us assume without loss of generality that there is a unique optimal choice of θ.",
        "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
        "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
        "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
        "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
    ],
    "error_count": 0,
    "keys": {
        "outcome features of interest": {
            "translated_key": "Características de los resultados de interés",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate <br>outcome features of interest</br> as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Diseño del mecanismo empírico: Métodos, con la aplicación a un escenario de cadena de suministro Yevgeniy Vorobeychik, Christopher Kiekintveld y Michael P. Wellman University of Michigan Informática e Ingeniería Ann Arbor, Mi 48109-2121 USA {Yvorobey, Ckiekint, Wellman} @umich.Resumen EDU Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las \"características de resultado de interés\" en función de la configuración de los parámetros del mecanismo."
            ],
            "translated_text": "",
            "candidates": [
                "Características de los resultados de interés",
                "características de resultado de interés"
            ],
            "error": []
        },
        "interest outcome feature": {
            "translated_key": "característica de resultado de interés",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "supply-chain trading": {
            "translated_key": "Comercio de cadena de suministro",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a <br>supply-chain trading</br> competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Ilustramos nuestro enfoque con una tarea de diseño de una competencia de \"comercio de cadena de suministro\"."
            ],
            "translated_text": "",
            "candidates": [
                "Comercio de cadena de suministro",
                "comercio de cadena de suministro"
            ],
            "error": []
        },
        "empirical mechanism": {
            "translated_key": "mecanismo empírico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>empirical mechanism</br> Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our <br>empirical mechanism</br> analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as <br>empirical mechanism</br> design.",
                "In the sequel, we develop some general methods for <br>empirical mechanism</br> design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for <br>empirical mechanism</br> design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the <br>empirical mechanism</br> design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Diseño de \"mecanismo empírico\": métodos, con aplicación a un escenario de cadena de suministro Yevgeniy Vorobeychik, Christopher Kiekintveld y Michael P. Wellman University of Michigan Informática e Ingeniería Ann Arbor, MI 48109-2121 USA {Yvorobey, Ckiekint, Wellman}@umich.edu Resumen Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características de los resultados de interés en función de la configuración de los parámetros del mecanismo.",
                "Nuestro análisis de \"mecanismo empírico\" modela la relación entre un parámetro de diseño clave y los resultados, confirmando el comportamiento observado e indicando que no se hubiera podido lograr una configuración de parámetros razonable el efecto deseado.",
                "Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como un diseño de \"mecanismo empírico\".",
                "En la secuela, desarrollamos algunos métodos generales para el diseño del \"mecanismo empírico\" y los aplicamos al problema de rediseño TAC/SCM.",
                "Conclusión En este trabajo gastamos un esfuerzo considerable en desarrollar tácticas generales para el diseño de \"mecanismo empírico\".",
                "Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño del \"mecanismo empírico\" que hemos introducido, y aumenta nuestra confianza de que nuestro marco puede ser efectivo para estimar la mejor opción de parámetros de mecanismo en entornos relativamente generales."
            ],
            "translated_text": "",
            "candidates": [
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico",
                "mecanismo empírico"
            ],
            "error": []
        },
        "parameter setting": {
            "translated_key": "configuración de parámetros",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism <br>parameter setting</br> based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism <br>parameter setting</br>, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a <br>parameter setting</br>, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En términos más generales, mostramos que bajo ciertas condiciones, el estimador de la \"configuración de parámetros\" de mecanismo óptimo basado en datos empíricos es consistente.",
                "Además, deseamos estudiar juegos donde los pagos no se dan explícitamente, pero deben determinarse a partir de la simulación u otra experiencia con el juego.5 En consecuencia, suponemos que se nos da un conjunto de datos (posiblemente ruidoso) de realizaciones de pago: do = = do = ={(θ1, a1, u1) ,..., (θk, AK, Reino Unido)}, donde para cada punto de datos θi es el mecanismo observado \"configuración de parámetros\", la IA es el perfil de estrategia pura observado de los participantes, y la interfaz de usuario es la realización correspondiente de los pagos del agente.",
                "Al final, podemos tratar de proporcionar suficiente evidencia para prescribir una \"configuración de parámetros\", o sugerir que no es posible una configuración que satisfaga al diseñador."
            ],
            "translated_text": "",
            "candidates": [
                "ajuste de parámetros",
                "configuración de parámetros",
                "ajuste de parámetros",
                "configuración de parámetros",
                "ajuste de parámetros",
                "configuración de parámetros"
            ],
            "error": []
        },
        "observed behavior": {
            "translated_key": "comportamiento observado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the <br>observed behavior</br> and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nuestro análisis de mecanismo empírico modela la relación entre un parámetro de diseño clave y los resultados, confirmando el \"comportamiento observado\" e indicando que no se hubiera podido lograr una configuración de parámetros razonable el efecto deseado."
            ],
            "translated_text": "",
            "candidates": [
                "comportamiento observado",
                "comportamiento observado"
            ],
            "error": []
        },
        "two-stage game": {
            "translated_key": "juego de dos etapas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a <br>two-stage game</br>.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a <br>two-stage game</br>.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "El modelo que modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un \"juego de dos etapas\".",
                "Definimos un modelo de interacción gametheorético formal entre el diseñador y los participantes del mecanismo como un \"juego de dos etapas\"."
            ],
            "translated_text": "",
            "candidates": [
                "juego de dos etapas",
                "juego de dos etapas",
                "juego de dos etapas",
                "juego de dos etapas"
            ],
            "error": []
        },
        "player": {
            "translated_key": "jugador",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to <br>player</br> i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to <br>player</br> i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of <br>player</br> i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than <br>player</br> i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability <br>player</br> i plays ai under s. Next, we define the payoff (utility) function of each <br>player</br> i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any <br>player</br> can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of <br>player</br> i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "RI es el conjunto de estrategias disponibles para el \"jugador\" i ∈ I, con r = r1 ×... × RM que representa el conjunto de estrategias conjuntas de todos los jugadores.",
                "Designamos el conjunto de estrategias puras disponibles para el \"jugador\" I por ai, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×... × AM.",
                "A menudo es conveniente referirse a una estrategia de \"jugador\" que yo es por separado de la de los jugadores restantes.",
                "Para acomodar esto, usamos A - I para denotar la estrategia conjunta de todos los jugadores que no sean \"jugador\" i.",
                "Cuando la distribución s no está correlacionada, simplemente podemos decir SI (AI) cuando nos referimos a la probabilidad \"jugador\" que juego ai bajo s.A continuación, definimos la función de pago (utilidad) de cada \"jugador\" I por ui: a1 × · · · × am → r, donde ui (ai, a - i) indica el pago al jugador I para jugar a la estrategia pura ai cuandoLos jugadores restantes juegan A - I.",
                "Definimos una función, R → R, interpretada como el beneficio máximo que cualquier \"reproductor\" puede obtener al desviarse de su estrategia en el perfil especificado.(r) = max i∈I max ai∈Ai [ui (ai, r - i) - ui (r)], (1) donde r pertenece a algún conjunto de estrategias, r, de estrategias puras o mixtas.",
                "Como una cuestión de conveniencia, usaremos la notación un, yo (a) referirnos a una función de pago del \"jugador\". Estoy basado en un promedio sobre n i.i.d.Muestras de la distribución de pagos."
            ],
            "translated_text": "",
            "candidates": [
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "jugador",
                "reproductor",
                "jugador",
                "jugador"
            ],
            "error": []
        },
        "participant": {
            "translated_key": "participante",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the <br>participant</br> agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Todos los agentes \"participantes\" observan el parámetro del mecanismo θ y se mueven simultáneamente a partir de entonces."
            ],
            "translated_text": "",
            "candidates": [
                "partícipe",
                "participantes"
            ],
            "error": []
        },
        "gametheoretic model": {
            "translated_key": "modelo gametheorético",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal <br>gametheoretic model</br> of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Definimos un \"modelo gametheorético\" formal de interacción entre el diseñador y los participantes del mecanismo como un juego de dos etapas."
            ],
            "translated_text": "",
            "candidates": [
                "modelo gametheorético",
                "modelo gametheorético"
            ],
            "error": []
        },
        "analysis": {
            "translated_key": "análisis",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism <br>analysis</br> models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic <br>analysis</br> of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our <br>analysis</br> focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic <br>analysis</br> to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact <br>analysis</br>.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN <br>analysis</br> Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic <br>analysis</br> methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design <br>analysis</br> methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our <br>analysis</br>6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic <br>analysis</br> of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 <br>analysis</br> of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 <br>analysis</br> of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic <br>analysis</br> Our empirical <br>analysis</br> has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game <br>analysis</br> to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our <br>analysis</br> in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An <br>analysis</br> of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and <br>analysis</br>, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Nuestro mecanismo empírico \"Análisis\" modela la relación entre un parámetro de diseño clave y los resultados, confirmando el comportamiento observado e indicando que no se habría logrado configuraciones de parámetros razonables el efecto deseado.",
                "El episodio nos hizo considerar si los nuevos proaches o herramientas AP306 podrían permitir un \"análisis\" más sistemático de las opciones de diseño.",
                "Nuestro \"análisis\" se centra en la configuración de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el elemento disuasorio más directo para las adquisiciones tempranas adoptadas.",
                "Nuestros métodos incorporan la estimación de conjuntos de equilibrios NASH y equilibrios de NASH de muestra, utilizados en conjunción para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un \"análisis\" probabilístico restringido para evaluar la probabilidad de conclusiones.",
                "Creemos que los problemas más realistas son demasiado complejos para ser susceptibles de \"análisis\" exactos.",
                "\"Análisis\" de diseño empírico Dado que nuestros datos vienen en forma de experiencia de pago y no como el valor de una función objetivo para la configuración dada de la variable de control, ya no podemos confiar en los métodos para optimizar las funciones utilizando simulaciones.",
                "Además, no podemos confiar directamente en los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos probabilísticos de \"análisis\" adaptados para nuestra configuración de problemas.4.1 Problema de diseño TAC/SCM Describimos nuestros métodos de \"análisis\" de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente.",
                "Es esta tercera pregunta la que define el aspecto del diseño del mecanismo de nuestro \"análisis\" 6 para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de agentes, la función de bienestar de los diseñadores, el espacio de los parámetros del mecanismo y la fuente de datos.",
                "También utilizamos variables de control para reducir la varianza de las estimaciones de pago, como en nuestro \"análisis\" teórico de juego empírico anterior de TAC/SCM-03 [19].",
                "A modo de comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategia conjunta finita restringida para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces 10 veces).4.4 Resultados 4.4.1 \"Análisis\" del conjunto de datos de línea de base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos de línea de base Do.",
                "La correspondencia ˆφ ∗ (θ) es el intervalo entre Baselinemin y Baselinemax.8 En general, la búsqueda termina una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para sacar conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego.9 Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash para permanecer en este subconjunto discreto de [0,1.5].10 Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron bloqueos, problemas de conectividad de red y otras anomalías obvias), el juego se expulsaría.309 4.4.2 \"Análisis\" de datos de búsqueda para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ ∗ (θ) (nuevamente, usando δ = 2.5e6) en el conjunto de datos d = {do, ds}, donde dsLos datos se generan mediante la aplicación de BestFirstSearch.",
                "Para lograr la reducción deseada en la adquisición del día 0 requiere rediseñar otros aspectos del mecanismo.4.5 \"Análisis\" probabilístico \"nuestro\" análisis \"empírico\" ha producido evidencia en apoyo de la conclusión de que no es probable que ningún ajuste razonable de costo de almacenamiento frene suficientemente la adquisición excesiva de día 0 en TAC/SCM 04.",
                "Al aplicar el \"análisis\" del juego empírico al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos.",
                "El éxito de nuestro \"análisis\" en este entorno extremadamente complejo con altos costos de simulación nos hace optimistas de que nuestros métodos pueden proporcionar orientación para tomar decisiones de diseño del mecanismo en otros dominios desafiantes.",
                "Un \"análisis\" de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004.",
                "En el taller IJCAI-05 sobre el diseño y el \"análisis\" de agentes comerciales, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J."
            ],
            "translated_text": "",
            "candidates": [
                "análisis",
                "Análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "Análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "Análisis",
                "análisis",
                "Análisis",
                "Análisis",
                "Análisis",
                "nuestro",
                "empírico",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "análisis",
                "Análisis",
                "análisis"
            ],
            "error": []
        },
        "nash equilibrium": {
            "translated_key": "equilibrio de Nash",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a <br>nash equilibrium</br>.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a <br>nash equilibrium</br> of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy <br>nash equilibrium</br>; otherwise the definition describes a mixed strategy <br>nash equilibrium</br>.",
                "We often appeal to the concept of an approximate, or -<br>nash equilibrium</br>, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -<br>nash equilibrium</br> iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt <br>nash equilibrium</br> as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the <br>nash equilibrium</br> correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample <br>nash equilibrium</br> using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-<br>nash equilibrium</br>.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the <br>nash equilibrium</br> correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our <br>nash equilibrium</br> estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the <br>nash equilibrium</br> correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -<br>nash equilibrium</br>.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some <br>nash equilibrium</br> strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every <br>nash equilibrium</br> of Γn is close to some <br>nash equilibrium</br> of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique <br>nash equilibrium</br>, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample <br>nash equilibrium</br> function when the data is extremely scarce, or a <br>nash equilibrium</br> correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the <br>nash equilibrium</br> correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a <br>nash equilibrium</br> if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a <br>nash equilibrium</br> of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a las otras constituye un \"equilibrio NASH\".",
                "Un perfil de estrategia r = (r1, ..., rm) constituye un \"equilibrio NASH\" del juego [i, {ri}, {ui (r)}] si por cada i ∈ I, ri ∈ Ri, ui (ri (ri, r - i) ≥ ui (ri, r - i).",
                "Cuando r ∈ A, lo anterior define una estrategia pura \"equilibrio Nash\";De lo contrario, la definición describe una estrategia mixta \"Equilibrio NASH\".",
                "A menudo apelamos al concepto de un \"equilibrio de Nash\" aproximado, donde es el máximo beneficio para cualquier agente para desviarse de la estrategia prescrita.",
                "Por lo tanto, (r) como se define anteriormente (1) es tal que el perfil R es un -\"equilibrio de Nash\" IFF (r) ≤.",
                "Por lo general, nos importa W (n (θ), θ), el peor resultado de la que jugará alguna solución.4 En algunos problemas podemos obtener una ventaja considerable mediante el uso de una función de agregación para asignar el resultado del bienestar de un Juego 3 que generalmente adoptamos\"Equilibrio de Nash\" como el concepto de solución, y así tomar N (θ) como el conjunto de equilibrios.",
                "De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia del \"equilibrio NASH\".",
                "En lo que sigue, estimamos solo una muestra de \"equilibrio NASH\" utilizando esta técnica, aunque esta restricción se puede eliminar a expensas del tiempo de cálculo adicional.",
                "Cuando SNB (a, ˜d) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), A se confirma como un ˆ- \"Nash Equilibrio\".",
                "Además, generamos una estimación de la correspondencia del \"equilibrio NASH\", ˆφ ∗ (θ), aplicando la definición 6 con δ = 2.5e6.",
                "La correspondencia ˆφ ∗ (θ) es el intervalo entre Baselinemin y Baselinemax.8 En general, la búsqueda termina una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para sacar conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego.9 Por supuesto, no restringimos nuestras estimaciones de \"equilibrio NASH\" para permanecer en este subconjunto discreto de [0,1.5].10 Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron bloqueos, problemas de conectividad de red y otras anomalías obvias), el juego se expulsaría.309 4.4.2 Análisis de datos de búsqueda para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ ∗ (θ) (nuevamente, usando Δ = 2.5e6) en el conjunto de datos d = {do, ds}, donde ds es datosGenerado a través de la aplicación de BestFirstSearch.",
                "Toda esta evidencia ha sido en forma de interpolación simple y extrapolación de las estimaciones de la correspondencia del \"equilibrio NASH\".",
                "Ahora derivamos un límite probabilístico genérico que un perfil a ∈ A es un \"equilibrio de Nash\".",
                "En esta sección, mostramos que n (s) → (s) A.S.Uniformemente en el espacio de estrategia mixta para cualquier juego finito y, además, que todos los equilibrios de estrategia mixta Nash en juegos empíricos eventualmente se vuelven arbitrariamente cercanos a algunas estrategias de \"equilibrio de Nash\" en el juego subyacente.",
                "Ahora, mostraremos que cuando el número de muestras es lo suficientemente grande, cada \"equilibrio de Nash\" de γn está cerca de algún \"equilibrio NASH\" del juego subyacente.",
                "Ahora mostraremos que en el caso especial cuando θ y A son finitos y cada γθ tiene un \"equilibrio NASH\" único, las estimaciones ˆθ del parámetro de diseño óptimo convergen a un optimizador real casi seguramente.",
                "También describimos en cierta generalidad los métodos para estimar una función de muestra de \"equilibrio NASH\" cuando los datos son extremadamente escasos, o una correspondencia de \"equilibrio NASH\" cuando hay más datos disponibles.",
                "Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia del \"equilibrio Nash\".",
                "Para hacer esto, observe que Pr {sup {φ ∗ (θ)} = y} ≤d pr {_ a∈D: φ (a) = y (a) = 0} ≤ x a∈D: φ (a)= y Pr {(a) = 0} por subadditividad y el hecho de que un perfil A es un \"equilibrio NASH\" si y solo si (a) = 0.",
                "Que ¯> 0 está claro ya que (s) = 0 si y solo si S es un \"equilibrio NASH\" de γ."
            ],
            "translated_text": "",
            "candidates": [
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio Nash",
                "Equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "Equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "Nash Equilibrio",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio Nash",
                "Equilibrio de Nash",
                "equilibrio NASH",
                "equilibrio de Nash",
                "equilibrio NASH"
            ],
            "error": []
        },
        "empirical mechanism design": {
            "translated_key": "diseño de mecanismo empírico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>empirical mechanism design</br>: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as <br>empirical mechanism design</br>.",
                "In the sequel, we develop some general methods for <br>empirical mechanism design</br> and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for <br>empirical mechanism design</br>.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the <br>empirical mechanism design</br> methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "\"Diseño de mecanismo empírico\": Métodos, con aplicación a un escenario de cadena de suministro Yevgeniy Vorobeychik, Christopher Kiekintveld y Michael P. Wellman University of Michigan Informática e Ingeniería Ann Arbor, MI 48109-2121 USA {Yvorobey, Ckiekint, Wellman}@umich.edu Resumen Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características de los resultados de interés en función de la configuración de los parámetros del mecanismo.",
                "Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como \"diseño de mecanismo empírico\".",
                "En la secuela, desarrollamos algunos métodos generales para el \"diseño de mecanismo empírico\" y los aplicamos al problema de rediseño TAC/SCM.",
                "Conclusión En este trabajo gastamos un esfuerzo considerable en desarrollar tácticas generales para el \"diseño de mecanismo empírico\".",
                "Los resultados teóricos confirman algunas intuiciones detrás de los métodos de \"diseño de mecanismo empírico\" que hemos introducido, y aumenta nuestra confianza de que nuestro marco puede ser efectivo para estimar la mejor opción de parámetros de mecanismo en entornos relativamente generales."
            ],
            "translated_text": "",
            "candidates": [
                "diseño de mecanismo empírico",
                "Diseño de mecanismo empírico",
                "diseño de mecanismo empírico",
                "diseño de mecanismo empírico",
                "diseño de mecanismo empírico",
                "diseño de mecanismo empírico",
                "diseño de mecanismo empírico",
                "diseño de mecanismo empírico",
                "diseño de mecanismo empírico",
                "diseño de mecanismo empírico"
            ],
            "error": []
        },
        "game theory": {
            "translated_key": "teoría de juego",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Empirical Mechanism Design: Methods, with Application to a Supply-Chain Scenario Yevgeniy Vorobeychik, Christopher Kiekintveld, and Michael P. Wellman University of Michigan Computer Science & Engineering Ann Arbor, MI 48109-2121 USA { yvorobey, ckiekint, wellman }@umich.edu ABSTRACT Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings.",
                "We illustrate our approach with a design task from a supply-chain trading competition.",
                "Designers adopted several rule changes in order to deter particular procurement behavior, but the measures proved insufficient.",
                "Our empirical mechanism analysis models the relation between a key design parameter and outcomes, confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect.",
                "More generally, we show that under certain conditions, the estimator of optimal mechanism parameter setting based on empirical data is consistent.",
                "Categories and Subject Descriptors I.6 [Computing Methodologies]: Simulation and Modeling; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics General Terms Algorithms, Economics, Design 1.",
                "MOTIVATION We illustrate our problem with an anecdote from a supply chain research exercise: the 2003 and 2004 Trading Agent Competition (TAC) Supply Chain Management (SCM) game.",
                "TAC/SCM [1] defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain.",
                "The agents procure components from the various suppliers and assemble finished goods for sale to customers, repeatedly over a simulated year.",
                "As it happened, the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0: the very beginning of the simulation.",
                "During the early rounds of the 2003 SCM competition, several agent developers discovered this, and the apparent success led to most agents performing the majority of their purchasing on day 0.",
                "Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself [19], the phenomenon detracted from other interesting problems, such as adapting production levels to varying demand (since component costs were already sunk), and dynamic management of production, sales, and inventory.",
                "Several participants noted that the predominance of day-0 procurement overshadowed other key research issues, such as factory scheduling [2] and optimizing bids for customer orders [13].",
                "After the 2003 tournament, there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement.",
                "The task facing game organizers can be viewed as a problem in mechanism design.",
                "The designers have certain game features under their control, and a set of objectives regarding game outcomes.",
                "Unlike most academic treatments of mechanism design, the objective is a behavioral feature (moderate day-0 procurement) rather than an allocation feature like economic efficiency, and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game.",
                "Replacing the supplychain negotiation procedures with a one-shot direct mechanism, for example, was not an option.",
                "We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings, where they are perhaps more commonly characterized as incentive engineering problems.",
                "In response to the problem, the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders.",
                "These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods.",
                "Despite the changes, day-0 procurement was very high in the early rounds of the 2004 competition.",
                "In a drastic measure, the GameMaster imposed a fivefold increase of storage costs midway through the tournament.",
                "Even this did not stem the tide, and day-0 procurement in the final rounds actually increased (by some measures) from 2003 [9].",
                "The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking.",
                "Although the designs were widely discussed, predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations.",
                "Much of the difficulty, of course, is anticipating the agents (and their developers) responses without essentially running a gaming exercise for this purpose.",
                "The episode caused us to consider whether new ap306 proaches or tools could enable more systematic analysis of design options.",
                "Standard game-theoretic and mechanism design methods are clearly relevant, although the lack of an analytic description of the game seems to be an impediment.",
                "Under the assumption that the simulator itself is the only reliable source of outcome computation, we refer to our task as empirical mechanism design.",
                "In the sequel, we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem.",
                "Our analysis focuses on the setting of storage costs (taking other game modifications as fixed), since this is the most direct deterrent to early procurement adopted.",
                "Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise.",
                "We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used.",
                "Finally, we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement, so a different design approach would have been required to eliminate this problem.",
                "Overall, we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players utilities is available.",
                "Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria, used in conjuction to support general claims about the structure of the mechanism designers utility, as well as a restricted probabilistic analysis to assess the likelihood of conclusions.",
                "We believe that most realistic problems are too complex to be amenable to exact analysis.",
                "Consequently, we advocate the approach of gathering evidence to provide indirect support of specific hypotheses. 2.",
                "PRELIMINARIES A normal form game2 is denoted by [I, {Ri}, {ui(r)}], where I refers to the set of players and m = |I| is the number of players.",
                "Ri is the set of strategies available to player i ∈ I, with R = R1 ×. . .×Rm representing the set of joint strategies of all players.",
                "We designate the set of pure strategies available to player i by Ai, and denote the joint set of pure strategies of all players by A = A1 ×. . .×Am.",
                "It is often convenient to refer to a strategy of player i separately from that of the remaining players.",
                "To accommodate this, we use a−i to denote the joint strategy of all players other than player i.",
                "Let Si be the set of all probability distributions (mixtures) over Ai and, similarly, S be the set of all distributions over A.",
                "An s ∈ S is called a mixed strategy profile.",
                "When the game is finite (i.e., A and I are both finite), the probability that a ∈ A is played under s is written s(a) = s(ai, a−i).",
                "When the distribution s is not correlated, we can simply say si(ai) when referring to the probability player i plays ai under s. Next, we define the payoff (utility) function of each player i by ui : A1 ×· · ·×Am → R, where ui(ai, a−i) indicates the payoff to player i to playing pure strategy ai when the remaining players play a−i.",
                "We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern (vNM) utilities as follows: ui(s) = Es[ui], where Es is the expectation taken with respect to the probability distribution of play induced by the players mixed strategy s. 2 By employing the normal form, we model agents as playing a single action, with decisions taken simultaneously.",
                "This is appropriate for our current study, which treats strategies (agent programs) as atomic actions.",
                "We could capture finer-grained decisions about action over time in the extensive form.",
                "Although any extensive game can be recast in normal form, doing so may sacrifice compactness and blur relevant distinctions (e.g., subgame perfection).",
                "Occasionally, we write ui(x, y) to mean that x ∈ Ai or Si and y ∈ A−i or S−i depending on context.",
                "We also express the set of utility functions of all players as u(·) = {u1(·), . . . , um(·)}.",
                "We define a function, : R → R, interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile. (r) = max i∈I max ai∈Ai [ui(ai, r−i) − ui(r)], (1) where r belongs to some strategy set, R, of either pure or mixed strategies.",
                "Faced with a game, an agent would ideally play its best strategy given those played by the other agents.",
                "A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium.",
                "DEFINITION 1.",
                "A strategy profile r = (r1, . . . , rm) constitutes a Nash equilibrium of game [I, {Ri}, {ui(r)}] if for every i ∈ I, ri ∈ Ri, ui(ri, r−i) ≥ ui(ri, r−i).",
                "When r ∈ A, the above defines a pure strategy Nash equilibrium; otherwise the definition describes a mixed strategy Nash equilibrium.",
                "We often appeal to the concept of an approximate, or -Nash equilibrium, where is the maximum benefit to any agent for deviating from the prescribed strategy.",
                "Thus, (r) as defined above (1) is such that profile r is an -Nash equilibrium iff (r) ≤ .",
                "In this study we devote particular attention to games that exhibit symmetry with respect to payoffs, rendering agents strategically identical.",
                "DEFINITION 2.",
                "A game [I, {Ri}, {ui(r)}] is symmetric if for all i, j ∈ I, (a) Ri = Rj and (b) ui(ri, r−i) = uj (rj, r−j) whenever ri = rj and r−i = r−j 3.",
                "THE MODEL We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game.",
                "The designer moves first by selecting a value, θ, from a set of allowable mechanism settings, Θ.",
                "All the participant agents observe the mechanism parameter θ and move simultaneously thereafter.",
                "For example, the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms, with the presumption that after the choice has been made, the bidders will participate with full awareness of the auction rules.",
                "Since the participants play with full knowledge of the mechanism parameter, we define a game between them in the second stage as Γθ = [I, {Ri}, {ui(r, θ)}].",
                "We refer to Γθ as a game induced by θ.",
                "Let N(θ) be the set of strategy profiles considered solutions of the game Γθ.3 Suppose that the goal of the designer is to optimize the value of some welfare function, W (r, θ), dependent on the mechanism parameter and resulting play, r. We define a pessimistic measure, W ( ˆR, θ) = inf{W (r, θ) : r ∈ ˆR}, representing the worst-case welfare of the game induced by θ, assuming that agents play some joint strategy in ˆR.",
                "Typically we care about W (N(θ), θ), the worst-case outcome of playing some solution.4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3 We generally adopt Nash equilibrium as the solution concept, and thus take N(θ) to be the set of equilibria.",
                "However, much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition. 4 Again, alternatives are available.",
                "For example, if one has a probability distribution over the solution set N(θ), it would be natural to take the expectation of W (r, θ) instead. 307 specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary.",
                "DEFINITION 3.",
                "A function φ : R1 × · · · × Rm → Rq is an aggregation function if m ≥ q and W (r, θ) = V (φ(r), θ) for some function V .",
                "We overload the function symbol to apply to sets of strategy profiles: φ( ˆR) = {φ(r) : r ∈ ˆR}.",
                "For convenience of exposition, we write φ∗ (θ) to mean φ(N(θ)).",
                "Using an aggregation function yields a more compact representation of strategy profiles.",
                "For example, suppose-as in our application below-that an agents strategy is defined by a numeric parameter.",
                "If all we care about is the total value played, we may take φ(a) = Pm i=1 ai.",
                "If we have chosen our aggregator carefully, we may also capture structure not obvious otherwise.",
                "For example, φ∗ (θ) could be decreasing in θ, whereas N(θ) might have a more complex structure.",
                "Given a description of the solution correspondence N(θ) (equivalently, φ∗ (θ)), the designer faces a standard optimization problem.",
                "Alternatively, given a simulator that could produce an unbiased sample from the distribution of W (N(θ), θ) for any θ, the designer would be faced with another much appreciated problem in the literature: simulation optimization [12].",
                "However, even for a game Γθ with known payoffs it may be computationally intractable to solve for Nash equilibria, particularly if the game has large or infinite strategy sets.",
                "Additionally, we wish to study games where the payoffs are not explicitly given, but must be determined from simulation or other experience with the game.5 Accordingly, we assume that we are given a (possibly noisy) data set of payoff realizations: Do = {(θ1 , a1 , U1 ), . . . , (θk , ak , Uk )}, where for every data point θi is the observed mechanism parameter setting, ai is the observed pure strategy profile of the participants, and Ui is the corresponding realization of agent payoffs.",
                "We may also have additional data generated by a (possibly noisy) simulator: Ds = {(θk+1 , ak+1 , Uk+1 ), . . . , (θk+l , ak+l , Uk+l )}.",
                "Let D = {Do, Ds} be the combined data set. (Either Do or Ds may be null for a particular problem.)",
                "In the remainder of this paper, we apply our modeling approach, together with several empirical game-theoretic methods, in order to answer questions regarding the design of the TAC/SCM scenario. 4.",
                "EMPIRICAL DESIGN ANALYSIS Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable, we can no longer rely on the methods for optimizing functions using simulations.",
                "Indeed, a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence.",
                "Furthermore, we cannot rely directly on the convergence results that abound in the simulation optimization literature, and must establish probabilistic analysis methods tailored for our problem setting. 4.1 TAC/SCM Design Problem We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above.",
                "Recall that during the 2004 tournament, the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement, to little avail.",
                "Here we systematically explore the relationship between storage costs and 5 This is often the case for real games of interest, where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions. the aggregate quantity of components procured on day 0 in equilibrium.",
                "In doing so, we consider several questions raised during and after the tournament.",
                "First, does increasing storage costs actually reduce day-0 procurement?",
                "Second, was the excessive day-0 procurement that was observed during the 2004 tournament rational?",
                "And third, could increasing storage costs sufficiently have reduced day-0 procurement to an acceptable level, and if so, what should the setting of storage costs have been?",
                "It is this third question that defines the mechanism design aspect of our analysis.6 To apply our methods, we must specify the agent strategy sets, the designers welfare function, the mechanism parameter space, and the source of data.",
                "We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists, Deep Maize, in the 2004 TAC/SCM tournament.",
                "We further restrict it to the set [0,1.5], since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive (thus unlikely to provide refuting deviations beyond those available from included strategies, and certainly not part of any desirable equilibrium).",
                "All other behavior is based on the behavior of Deep Maize and is identical for all agents.",
                "This choice can provide only an estimate of the actual tournament behavior of a typical agent.",
                "However, we believe that the general form of the results should be robust to changes in the full agent behavior.",
                "We model the designers welfare function as a threshold on the sum of day-0 purchases.",
                "Let φ(a) = P6 i=1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game (for mixed strategy profiles s, we take expectation of φ with respect to the mixture).",
                "The designers welfare function W (N(θ), θ) is then given by I{sup{φ∗ (θ)} ≤ α}, where α is the maximum acceptable level of day-0 procurement and I is the indicator function.",
                "The designer selects a value θ of storage costs, expressed as an annual percentage of the baseline value of components in the inventory (charged daily), from the set Θ = R+ .",
                "Since the designers decision depends only on φ∗ (θ), we present all of our results in terms of the value of the aggregation function. 4.2 Estimating Nash Equilibria The objective of TAC/SCM agents is to maximize profits realized over a game instance.",
                "Thus, if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end, we will have obtained a data point in the form (a, U(a)).",
                "If we also have fixed the parameter θ of the simulator, the resulting data point becomes part of our data set D. This data set, then, contains data only in the form of pure strategies of players and their corresponding payoffs, and, consequently, in order to formulate the designers problem as optimization, we must first determine or approximate the set of Nash equilibria of each game Γθ.",
                "Thus, we need methods for approximating Nash equilibria for infinite games.",
                "Below, we describe the two methods we used in our study.",
                "The first has been explored empirically before, whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria. 4.2.1 Payoff Function Approximation The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6 We do not address whether and how other measures (e.g., constraining procurement directly) could have achieved design objectives.",
                "Our approach takes as given some set of design options, in this case defined by the storage cost parameter.",
                "In principle our methods could be applied to a different or larger design space, though with corresponding complexity growth. 308 anism participants from a data set of game experience [17].",
                "Once approximate payoff functions are available for all players, the Nash equilibria may be either found analytically or approximated using numerical techniques, depending on the learning model.",
                "In what follows, we estimate only a sample Nash equilibrium using this technique, although this restriction can be removed at the expense of additional computation time.",
                "One advantage of this method is that it can be applied to any data set and does not require the use of a simulator.",
                "Thus, we can apply it when Ds = ∅.",
                "If a simulator is available, we can generate additional data to build confidence in our initial estimates.7 We tried the following methods for approximating payoff functions: quadratic regression (QR), locally weighted average (LWA), and locally weighted linear regression (LWLR).",
                "We also used control variates to reduce the variance of payoff estimates, as in our previous empirical game-theoretic analysis of TAC/SCM-03 [19].",
                "The quadratic regression model makes it possible to compute equilibria of the learned game analytically.",
                "For the other methods we applied replicator dynamics [7] to a discrete approximation of the learned game.",
                "The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome. 4.2.2 Search in Strategy Profile Space When we have access to a simulator, we can also use directed search through profile space to estimate the set of Nash equilibria, which we describe here after presenting some additional notation.",
                "DEFINITION 4.",
                "A strategic neighbor of a pure strategy profile a is a profile that is identical to a in all but one strategy.",
                "We define Snb(a, D) as the set of all strategic neighbors of a available in the data set D. Similarly, we define Snb(a, ˜D) to be all strategic neighbors of a not in D. Finally, for any a ∈ Snb(a, D) we define the deviating agent as i(a, a ).",
                "DEFINITION 5.",
                "The -bound, ˆ, of a pure strategy profile a is defined as maxa ∈Snb(a,D) max{ui(a,a )(a )−ui(a,a )(a), 0}.",
                "We say that a is a candidate δ-equilibrium for δ ≥ ˆ.",
                "When Snb(a, ˜D) = ∅ (i.e., all strategic neighbors are represented in the data), a is confirmed as an ˆ-Nash equilibrium.",
                "Our search method operates by exploring deviations from candidate equilibria.",
                "We refer to it as BestFirstSearch, as it selects with probability one a strategy profile a ∈ Snb(a, ˜D) that has the smallest ˆin D. Finally we define an estimator for a set of Nash equilibria.",
                "DEFINITION 6.",
                "For a set K, define Co(K) to be the convex hull of K. Let Bδ be the set of candidates at level δ.",
                "We define ˆφ∗ (θ) = Co({φ(a) : a ∈ Bδ}) for a fixed δ to be an estimator of φ∗ (θ).",
                "In words, the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with -bound below some fixed δ.",
                "This definition allows us to exploit structure arising from the aggregation function.",
                "If two profiles are close in terms of aggregation values, they may be likely to have similar -bounds.",
                "In particular, if one is an equilibrium, the other may be as well.",
                "We present some theoretical support for this method of estimating the set of Nash equilibria below.",
                "Since the game we are interested in is infinite, it is necessary to terminate BestFirstSearch before exploring the entire space of strat7 For example, we can use active learning techniques [5] to improve the quality of payoff function approximation.",
                "In this work, we instead concentrate on search in strategy profile space. egy profiles.",
                "We currently determine termination time in a somewhat ad-hoc manner, based on observations about the current set of candidate equilibria.8 4.3 Data Generation Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server, which has a configuration setting for the storage cost.",
                "Agent strategies in simulated games were selected from the set {0, 0.3, 0.6, . . . , 1.5} in order to have positive probability of generating strategic neighbors.9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each θ ∈ {0, 50, 100, 150, 200}.",
                "Between 5 and 10 games were run for each profile after discarding games that had various flaws.10 We used search to generate a simulated data set Ds, performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of θ.",
                "Since simulation cost is extremely high (a game takes nearly 1 hour to run), we were able to run a total of 2670 games over the span of more than six months.",
                "For comparison, to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of θ ∈ {0, 50, 100, 150, 200} would have required at least 23100 games (sampling each profile 10 times). 4.4 Results 4.4.1 Analysis of the Baseline Data Set We applied the three learning methods described above to the baseline data set Do.",
                "Additionally, we generated an estimate of the Nash equilibrium correspondence, ˆφ∗ (θ), by applying Definition 6 with δ =2.5E6.",
                "The results are shown in Figure 1.",
                "As we can see, the correspondence ˆφ∗ (θ) has little predictive power based on Do, and reveals no interesting structure about the game.",
                "In contrast, all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotalDay-0Procurement LWA LWLR QR BaselineMin BaselineMax Figure 1: Aggregate day-0 procurement estimates based on Do.",
                "The correspondence ˆφ∗ (θ) is the interval between BaselineMin and BaselineMax. 8 Generally, search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game. 9 Of course, we do not restrict our Nash equilibrium estimates to stay in this discrete subset of [0,1.5]. 10 For example, if we detected that any agent failed during the game (failures included crashes, network connectivity problems, and other obvious anomalies), the game would be thrown out. 309 4.4.2 Analysis of Search Data To corroborate the initial evidence from the learning methods, we estimated ˆφ∗ (θ) (again, using δ =2.5E6) on the data set D = {Do, Ds}, where Ds is data generated through the application of BestFirstSearch.",
                "The results of this estimate are plotted against the results of the learning methods trained on Do 11 in Figure 2.",
                "First, we note that the addition of the search data narrows the range of potential equilibria substantially.",
                "Furthermore, the actual point predictions of the learning methods and those based on -bounds after search are reasonably close.",
                "Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation. 0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Storage Cost TotayDay-0Procurement LWA LWLR QR SearchMin SearchMax Figure 2: Aggregate day-0 procurement estimates based on search in strategy profile space compared to function approximation techniques trained on Do.",
                "The correspondence ˆφ∗ (θ) for D = {Do, Ds} is the interval between SearchMin and SearchMax.",
                "This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs.",
                "It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost, which corresponds to θ = 100.",
                "The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3.",
                "This is quite high, as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game.",
                "The maximum prediction is considerably higher at 4.5.",
                "In the actual 2004 competition, aggregate day-0 procurement was equivalent to 5.71 on the scale used here [9].",
                "Our predictions underestimate this outcome to some degree, but show that any rational outcome was likely to have high day-0 procurement. 4.4.3 Extrapolating the Solution Correspondence We have reasonably strong evidence that the outcome correspondence is decreasing.",
                "However, the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible.",
                "To answer this question directly, suppose that we set a conservative threshold α = 2 on aggregate day-0 procurement.12 Linear 11 It is unclear how meaningful the results of learning would be if Ds were added to the training data set.",
                "Indeed, the additional data may actually increase the learning variance. 12 Recall that designers objective is to incentivize aggergate day-0 procurement that is below the threshold α.",
                "Our threshold here still represents a commitment of over 20% of the suppliers capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields θ = 320.",
                "The data for θ = 320 were collected in the same way as for other storage cost settings, with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch.",
                "Figure 3 shows the detailed -bounds for all profiles in terms of their corresponding values of φ. 0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.6 3.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Day-0 Procurement ε−boundFigure 3: Values of ˆ for profiles explored using search when θ = 320.",
                "Strategy profiles explored are presented in terms of the corresponding values of φ(a).",
                "The gray region corresponds to ˆφ∗ (320) with δ =2.5M.",
                "The estimated set of aggregate day-0 outcomes is very close to that for θ = 200, indicating that there is little additional benefit to raising storage costs above 200.",
                "Observe, that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2.",
                "Furthermore, payoffs to agents are almost always negative at θ = 320.",
                "Consequently, increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed.",
                "Since we are reasonably confident that φ∗ (θ) is decreasing in θ, we also do not expect that setting θ somewhere between 200 and 320 will achieve the desired result.",
                "We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter.",
                "That our predictions tend to underestimate tournament outcomes reinforces this conclusion.",
                "To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism. 4.5 Probabilistic Analysis Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM 04.",
                "All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence.",
                "These estimates are based on simulating game instances, and are subject to sampling noise contributed by the various stochastic elements of the game.",
                "In this section, we develop and apply methods for evaluating the sensitivity of our -bound calculations to such stochastic effects.",
                "Suppose that all agents have finite (and small) pure strategy sets, A.",
                "Thus, it is feasible to sample the entire payoff matrix of the game.",
                "Additionally, suppose that noise is additive with zero-mean the entire game on average, so in practice we would probably want the threshold to be even lower. 310 and finite variance, that is, Ui(a) = ui(a) + ˜ξi(a), where Ui(a) is the observed payoff to i when a was played, ui(a) is the actual corresponding payoff, and ˜ξi(a) is a mean-zero normal random variable.",
                "We designate the known variance of ˜ξi(a) by σ2 i (a).",
                "Thus, we assume that ˜ξi(a) is normal with distribution N(0, σ2 i (a)).",
                "We take ¯ui(a) to be the sample mean over all Ui(a) in D, and follow Chang and Huang [3] to assume that we have an improper prior over the actual payoffs ui(a) and sampling was independent for all i and a.",
                "We also rely on their result that ui(a)|¯ui(a) = ¯ui(a)−Zi(a)/[σi(a)/ p ni(a)] are independent with posterior distributions N(¯ui(a), σ2 i (a)/ni(a)), where ni(a) is the number of samples taken of payoffs to i for pure profile a, and Zi(a) ∼ N(0, 1).",
                "We now derive a generic probabilistic bound that a profile a ∈ A is an -Nash equilibrium.",
                "If ui(·)|¯ui(·) are independent for all i ∈ I and a ∈ A, we have the following result (from this point on we omit conditioning on ¯ui(·) for brevity): PROPOSITION 1.",
                "Pr „ max i∈I max b∈Ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du, (2) where fui(a)(u) is the pdf of N(¯ui(a), σi(a)).",
                "The proofs of this and all subsequent results are in the Appendix.",
                "The posterior distribution of the optimum mean of n samples, derived by Chang and Huang [3], is Pr (ui(a) ≤ c) = 1 − Φ p ni(a)(¯ui(a) − c) σi(a) # , (3) where a ∈ A and Φ(·) is the N(0, 1) distribution function.",
                "Combining the results (2) and (3), we obtain a probabilistic confidence bound that (a) ≤ γ for a given γ.",
                "Now, we consider cases of incomplete data and use the results we have just obtained to construct an upper bound (restricted to profiles represented in data) on the distribution of sup{φ∗ (θ)} and inf{φ∗ (θ)} (assuming that both are attainable): Pr{sup{φ∗ (θ)} ≤ x} ≤D Pr{∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} ≤ X a∈D:φ(a)≤x Pr{a ∈ N(θ)} = X a∈D:φ(a)≤x Pr{ (a) = 0}, where x is a real number and ≤D indicates that the upper bound accounts only for strategies that appear in the data set D. Since the events {∃a ∈ D : φ(a) ≤ x ∧ a ∈ N(θ)} and {inf{φ∗ (θ)} ≤ x} are equivalent, this also defines an upper bound on the probability of {inf{φ∗ (θ)} ≤ x}.",
                "The values thus derived comprise the Tables 1 and 2. φ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 Table 1: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {0, 50, 100} when N(θ) is a set of Nash equilibria. φ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 1 Table 2: Upper bounds on the distribution of inf{φ∗ (θ)} restricted to D for θ ∈ {150, 200, 320} when N(θ) is a set of Nash equilibria.",
                "Tables 1 and 2 suggest that the existence of any equilibrium with φ(a) < 2.7 is unlikely for any θ that we have data for, although this judgment, as we mentioned, is only with respect to the profiles we have actually sampled.",
                "We can then accept this as another piece of evidence that the designer could not find a suitable setting of θ to achieve his objectives-indeed, the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium!",
                "Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game.",
                "If we look at the third column of this table, which corresponds to θ = 100, we can gather that no profile a in our data with φ(a) < 3 is very likely to be played in equilibrium.",
                "The bounds above provide some general evidence, but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled.",
                "Particularly, we would like to say something about what happens for the settings of θ for which we have no data.",
                "To derive an approximate probabilistic bound on the probability that no θ ∈ Θ could have achieved the designers objective, let ∪J j=1Θj, be a partition of Θ, and assume that the function sup{φ∗ (θ)} satisfies the Lipschitz condition with Lipschitz constant Aj on each subset Θj.13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations, we restrict attention to Θ = [0, 320].",
                "We now define each subset j to be the interval between two points for which we have produced data.",
                "Thus, Θ = [0, 50] [ (50, 100] [ (100, 150] [ (150, 200] [ (200, 320], with j running between 1 and 5, corresponding to subintervals above.",
                "We will further denote each Θj by (aj , bj].14 Then, the following Proposition gives us an approximate upper bound15 on the probability that sup{φ∗ (θ)} ≤ α.",
                "PROPOSITION 2.",
                "Pr{ _ θ∈Θ sup{φ(θ)} ≤ α} ≤D 5X j=1 X y,z∈D:y+z≤cj 0 @ X a:φ(a)=z Pr{ (a) = 0} 1 A × × 0 @ X a:φ(a)=y Pr{ (a) = 0} 1 A , where cj = 2α + Aj(bj − aj) and ≤D indicates that the upper bound only accounts for strategies that appear in the data set D. 13 A function that satisfies the Lipschitz condition is called Lipschitz continuous. 14 The treatment for the interval [0,50] is identical. 15 It is approximate in a sense that we only take into account strategies that are present in the data. 311 Due to the fact that our bounds are approximate, we cannot use them as a conclusive probabilistic assessment.",
                "Instead, we take this as another piece of evidence to complement our findings.",
                "Even if we can assume that a function that we approximate from data is Lipschitz continuous, we rarely actually know the Lipschitz constant for any subset of Θ.",
                "Thus, we are faced with a task of estimating it from data.",
                "Here, we tried three methods of doing this.",
                "The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval.",
                "This produces the most conservative bound, and in many situations it is unlikely to be informative.",
                "An alternative method is to take an upper bound on slope obtained within each subinterval using the available data.",
                "This produces a much less conservative upper bound on probabilities.",
                "However, since the actual upper bound is generally greater for each subinterval, the resulting probabilistic bound may be deceiving.",
                "A final method that we tried is a compromise between the two above.",
                "Instead of taking the conservative upper bound based on data over the entire function domain Θ, we take the average of upper bounds obtained at each Θj.",
                "The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals.",
                "The results of evaluating the expression for Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} when α = 2 are presented in Table 3.",
                "In terms of our claims in maxj Aj Aj max{Aj ,ave(Aj)} 1 0.00772 0.00791 Table 3: Approximate upper bound on probability that some setting of θ ∈ [0, 320] will satisfy the designer objective with target α = 2.",
                "Different methods of approximating the upper bound on slope in each subinterval j are used. this work, the expression gives an upper bound on the probability that some setting of θ (i.e., storage cost) in the interval [0,320] will result in total day-0 procurement that is no greater in any equilibrium than the target specified by α and taken here to be 2.",
                "As we had suspected, the most conservative approach to estimating the upper bound on slope, presented in the first column of the table, provides us little information here.",
                "However, the other two estimation approaches, found in columns two and three of Table 3, suggest that we are indeed quite confident that no reasonable setting of θ ∈ [0, 320] would have done the job.",
                "Given the tremendous difficulty of the problem, this result is very strong.16 Still, we must be very cautious in drawing too heroic a conclusion based on this evidence.",
                "Certainly, we have not checked all the profiles but only a small proportion of them (infinitesimal, if we consider the entire continuous domain of θ and strategy sets).",
                "Nor can we expect ever to obtain enough evidence to make completely objective conclusions.",
                "Instead, the approach we advocate here is to collect as much evidence as is feasible given resource constraints, and make the most compelling judgment based on this evidence, if at all possible. 5.",
                "CONVERGENCE RESULTS At this point, we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable. 16 Since we did not have all the possible deviations for any profile available in the data, the true upper bounds may be even lower.",
                "As a matter of convenience, we will use notation un,i(a) to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs.",
                "We also assume that un,i(a) are independent for all a ∈ A and i ∈ I.",
                "We will use the notation Γn to refer to the game [I, R, {ui,n(·)}], whereas Γ will denote the underlying game, [I, R, {ui(·)}].",
                "Similarly, we define n(r) to be (r) with respect to the game Γn.",
                "In this section, we show that n(s) → (s) a.s. uniformly on the mixed strategy space for any finite game, and, furthermore, that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game.",
                "We use these results to show that under certain conditions, the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum.",
                "THEOREM 3.",
                "Suppose that |I| < ∞, |A| < ∞.",
                "Then n(s) → (s) a.s. uniformly on S. Recall that N is a set of all Nash equilibria of Γ.",
                "If we define Nn,γ = {s ∈ S : n(s) ≤ γ}, we have the following corollary to Theorem 3: COROLLARY 4.",
                "For every γ > 0, there is M such that ∀n ≥ M, N ⊂ Nn,γ a.s.",
                "PROOF.",
                "Since (s) = 0 for every s ∈ N, we can find M large enough such that Pr{supn≥M sups∈N n(s) < γ} = 1.",
                "By the Corollary, for any game with a finite set of pure strategies and for any > 0, all Nash equilibria lie in the set of empirical -Nash equilibria if enough samples have been taken.",
                "As we now show, this provides some justification for our use of a set of profiles with a non-zero -bound as an estimate of the set of Nash equilibria.",
                "First, suppose we conclude that for a particular setting of θ, sup{ˆφ∗ (θ)} ≤ α.",
                "Then, since for any fixed > 0, N(θ) ⊂ Nn, (θ) when n is large enough, sup{φ∗ (θ)} = sup s∈N (θ) φ(s) ≤ sup s∈Nn, (θ) φ(s) = sup{ˆφ∗ (θ)} ≤ α for any such n. Thus, since we defined the welfare function of the designer to be I{sup{φ∗ (θ)} ≤ α} in our domain of interest, the empirical choice of θ satisfies the designers objective, thereby maximizing his welfare function.",
                "Alternatively, suppose we conclude that inf{ˆφ∗ (θ)} > α for every θ in the domain.",
                "Then, α < inf{ˆφ∗ (θ)} = inf s∈Nn, (θ) φ(s) ≤ inf s∈N (θ) φ(s) ≤ ≤ sup s∈N (θ) φ(s) = sup{φ∗ (θ)}, for every θ, and we can conclude that no setting of θ will satisfy the designers objective.",
                "Now, we will show that when the number of samples is large enough, every Nash equilibrium of Γn is close to some Nash equilibrium of the underlying game.",
                "This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings.",
                "We first note that the function (s) is continuous in a finite game.",
                "LEMMA 5.",
                "Let S be a mixed strategy set defined on a finite game.",
                "Then : S → R is continuous. 312 For the exposition that follows, we need a bit of additional notation.",
                "First, let (Z, d) be a metric space, and X, Y ⊂ Z and define directed Hausdorff distance from X to Y to be h(X, Y ) = sup x∈X inf y∈Y d(x, y).",
                "Observe that U ⊂ X ⇒ h(U, Y ) ≤ h(X, Y ).",
                "Further, define BS(x, δ) to be an open ball in S ⊂ Z with center x ∈ S and radius δ.",
                "Now, let Nn denote all Nash equilibria of the game Γn and let Nδ = [ x∈N BS(x, δ), that is, the union of open balls of radius δ with centers at Nash equilibria of Γ.",
                "Note that h(Nδ, N) = δ.",
                "We can then prove the following general result.",
                "THEOREM 6.",
                "Suppose |I| < ∞ and |A| < ∞.",
                "Then almost surely h(Nn, N) converges to 0.",
                "We will now show that in the special case when Θ and A are finite and each Γθ has a unique Nash equilibrium, the estimates ˆθ of optimal designer parameter converge to an actual optimizer almost surely.",
                "Let ˆθ = arg maxθ∈Θ W (Nn(θ), θ), where n is the number of times each pure profile was sampled in Γθ for every θ, and let θ∗ = arg maxθ∈Θ W (N(θ), θ).",
                "THEOREM 7.",
                "Suppose |N(θ)| = 1 for all θ ∈ Θ and suppose that Θ and A are finite.",
                "Let W (s, θ) be continuous at the unique s∗ (θ) ∈ N(θ) for each θ ∈ Θ.",
                "Then ˆθ is a consistent estimator of θ∗ if W (N(θ), θ) is defined as a supremum, infimum, or expectation over the set of Nash equilibria.",
                "In fact, ˆθ → θ∗ a.s. in each of these cases.",
                "The shortcoming of the above result is that, within our framework, the designer has no way of knowing or ensuring that Γθ do, indeed, have unique equilibria.",
                "However, it does lend some theoretical justification for pursuing design in this manner, and, perhaps, will serve as a guide for more general results in the future. 6.",
                "RELATED WORK The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium [10].",
                "Additionally, there is an extensive literature on optimal auction design [10], of which the work by Roger Myerson [11] is, perhaps, the most relevant.",
                "In much of this work, analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality.",
                "Several related approaches to search for the best mechanism exist in the Computer Science literature.",
                "Conitzer and Sandholm [6] developed a search algorithm when all the relevant game parameters are common knowledge.",
                "When payoff functions of players are unknown, a search using simulations has been explored as an alternative.",
                "One approach in that direction, taken in [4] and [15], is to co-evolve the mechanism parameter and agent strategies, using some notion of social utility and agent payoffs as fitness criteria.",
                "An alternative to co-evolution explored in [16] was to optimize a well-defined welfare function of the designer using genetic programming.",
                "In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning.",
                "Most recently, Phelps et al. [14] compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies, as in [18]. 7.",
                "CONCLUSION In this work we spent considerable effort developing general tactics for empirical mechanism design.",
                "We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game.",
                "We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce, or a Nash equilibrium correspondence when more data is available.",
                "Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired.",
                "A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods.",
                "In applying empirical game analysis to the problem at hand, we are fully aware that our results are inherently inexact.",
                "Thus, we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence.",
                "In the end, we can try to provide enough evidence to either prescribe a parameter setting, or suggest that no setting is possible that will satisfy the designer.",
                "In the case of TAC/SCM, our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability.",
                "The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains.",
                "The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced, and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings.",
                "Acknowledgments We thank Terence Kelly, Matthew Rudary, and Satinder Singh for helpful comments on earlier drafts of this work.",
                "This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program. 8.",
                "REFERENCES [1] R. Arunachalam and N. M. Sadeh.",
                "The supply chain trading agent competition.",
                "Electronic Commerce Research and Applications, 4:63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy, and M. Tschantz.",
                "A stochastic programming approach to scheduling in TAC SCM.",
                "In Fifth ACM Conference on Electronic Commerce, pages 152-159, New York, 2004. [3] Y.-P. Chang and W.-T. Huang.",
                "Generalized confidence intervals for the largest value of some functions of parameters under normality.",
                "Statistica Sinica, 10:1369-1383, 2000. [4] D. Cliff.",
                "Evolution of market mechanism through a continuous space of auction-types.",
                "In Congress on Evolutionary Computation, 2002. [5] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [6] V. Conitzer and T. Sandholm.",
                "An algorithm for automatically designing deterministic mechanisms without payments.",
                "In 313 Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, pages 128-135, 2004. [7] D. Friedman.",
                "Evolutionary games in economics.",
                "Econometrica, 59(3):637-666, May 1991. [8] R. Keener.",
                "Statistical Theory: A Medley of Core Topics.",
                "University of Michigan Department of Statistics, 2004. [9] C. Kiekintveld, Y. Vorobeychik, and M. P. Wellman.",
                "An analysis of the 2004 supply chain management trading agent competition.",
                "In IJCAI-05 Workshop on Trading Agent Design and Analysis, Edinburgh, 2005. [10] A. Mas-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [11] R. B. Myerson.",
                "Optimal auction design.",
                "Mathematics of Operations Research, 6(1):58-73, February 1981. [12] S. Olafsson and J. Kim.",
                "Simulation optimization.",
                "In E. Yucesan, C.-H. Chen, J. Snowdon, and J. Charnes, editors, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe and P. Stone.",
                "TacTex-03: A supply chain management agent.",
                "SIGecom Exchanges, 4(3):19-28, 2004. [14] S. Phelps, S. Parsons, and P. McBurney.",
                "Automated agents versus virtual humans: an evolutionary game theoretic comparison of two double-auction market designs.",
                "In Workshop on Agent Mediated Electronic Commerce VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney, and E. Sklar.",
                "Co-evolution of auction mechanisms and trading strategies: towards a novel approach to microeconomic design.",
                "In ECOMAS 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar, and P. McBurney.",
                "Using genetic programming to optimise pricing rules for a double-auction market.",
                "In Workshop on Agents for Electronic Commerce, 2003. [17] Y. Vorobeychik, M. P. Wellman, and S. Singh.",
                "Learning payoff functions in infinite games.",
                "In Nineteenth International Joint Conference on Artificial Intelligence, pages 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro, and J. O. Kephart.",
                "Analyzing complex strategic interactions in multi-agent systems.",
                "In AAAI-02 Workshop on Game Theoretic and Decision Theoretic Agents, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld, and V. Soni.",
                "Strategic interactions in a supply chain game.",
                "Computational Intelligence, 21(1):1-26, February 2005.",
                "APPENDIX A.",
                "PROOFS A.1 Proof of Proposition 1 Pr „ max i∈I max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ « = = Y i∈I Eui(a) » Pr( max b∈Ai\\ai ui(b, a−i) − ui(a) ≤ |ui(a)) = = Y i∈I Z R Y b∈Ai\\ai Pr(ui(b, a−i) ≤ u + )fui(a)(u)du.",
                "A.2 Proof of Proposition 2 First, let us suppose that some function, f(x) defined on [ai, bi], satisfy Lipschitz condition on (ai, bi] with Lipschitz constant Ai.",
                "Then the following claim holds: Claim: infx∈(ai,bi] f(x) ≥ 0.5(f(ai) + f(bi) − Ai(bi − ai).",
                "To prove this claim, note that the intersection of lines at f(ai) and f(bi) with slopes −Ai and Ai respectively will determine the lower bound on the minimum of f(x) on [ai, bi] (which is a lower bound on infimum of f(x) on (ai, bj ]).",
                "The line at f(ai) is determined by f(ai) = −Aiai + cL and the line at f(bi) is determined by f(bi) = Aibi +cR.",
                "Thus, the intercepts are cL = f(ai)+Aiai and cR = f(bi) + Aibi respectively.",
                "Let x∗ be the point at which these lines intersect.",
                "Then, x∗ = − f(x∗ ) − cR A = f(x∗ ) − cL A .",
                "By substituting the expressions for cR and cL, we get the desired result.",
                "Now, subadditivity gives us Pr{ _ θ∈Θ sup{φ∗ (θ)} ≤ α} ≤ 5X j=1 Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α}, and, by the claim, Pr{ _ θ∈Θj sup{φ∗ (θ)} ≤ α} = 1 − Pr{ inf θ∈Θj sup{φ∗ (θ)} > α} ≤ Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ 2α + Aj(bj − aj )}.",
                "Since we have a finite number of points in the data set for each θ, we can obtain the following expression: Pr{sup{φ∗ (aj)} + sup{φ∗ (bj)} ≤ cj } =D X y,z∈D:y+z≤cj Pr{sup{φ∗ (bj )} = y} Pr{sup{φ∗ (aj)} = z}.",
                "We can now restrict attention to deriving an upper bound on Pr{sup{φ∗ (θ)} = y} for a fixed θ.",
                "To do this, observe that Pr{sup{φ∗ (θ)} = y} ≤D Pr{ _ a∈D:φ(a)=y (a) = 0} ≤ X a∈D:φ(a)=y Pr{ (a) = 0} by subadditivity and the fact that a profile a is a Nash equilibrium if and only if (a) = 0.",
                "Putting everything together yields the desired result.",
                "A.3 Proof of Theorem 3 First, we will need the following fact: Claim: Given a function fi(x) and a set X, | maxx∈X f1(x) − maxx∈X f2(x)| ≤ maxx∈X |f1(x) − f2(x)|.",
                "To prove this claim, observe that | max x∈X f1(x) − max x∈X f2(x)| =  maxx f1(x) − maxx f2(x) if maxx f1(x) ≥ maxx f2(x) maxx f2(x) − maxx f1(x) if maxx f2(x) ≥ maxx f1(x) In the first case, max x∈X f1(x) − max x∈X f2(x) ≤ max x∈X (f1(x) − f2(x)) ≤ ≤ max x∈X |f1(x) − f2(x)|. 314 Similarly, in the second case, max x∈X f2(x) − max x∈X f1(x) ≤ max x∈X (f2(x) − f1(x)) ≤ ≤ max x∈X |f2(x) − f1(x)| = max x∈X |f1(x) − f2(x)|.",
                "Thus, the claim holds.",
                "By the Strong Law of Large Numbers, un,i(a) → ui(a) a.s. for all i ∈ I, a ∈ A.",
                "That is, Pr{ lim n→∞ un,i(a) = ui(a)} = 1, or, equivalently [8], for any α > 0 and δ > 0, there is M(i, a) > 0 such that Pr{ sup n≥M(i,a) |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "By taking M = maxi∈I maxa∈A M(i, a), we have Pr{max i∈I max a∈A sup n≥M |un,i(a) − ui(a)| < δ 2|A| } ≥ 1 − α.",
                "Thus, by the claim, for any n ≥ M, sup n≥M | n(s) − (s)| ≤ max i∈I max ai∈Ai sup n≥M |un,i(ai, s−i) − ui(ai, s−i)|+ + sup n≥M max i∈I |un,i(s) − ui(s)| ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|s−i(b)+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)|s(b) ≤ max i∈I max ai∈Ai X b∈A−i sup n≥M |un,i(ai, b) − ui(ai, b)|+ + max i∈I X b∈A sup n≥M |un,i(b) − ui(b)| < max i∈I max ai∈Ai X b∈A−i ( δ 2|A| ) + max i∈I X b∈A ( δ 2|A| ) ≤ δ with probability at least 1 − α.",
                "Note that since s−i(a) and s(a) are bounded between 0 and 1, we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore, since the above result can be obtained for an arbitrary α > 0 and δ > 0, we have Pr{limn→∞ n(s) = (s)} = 1 uniformly on S. A.4 Proof of Lemma 5 We prove the result using uniform continuity of ui(s) and preservation of continuity under maximum.",
                "Claim: A function f : Rk → R defined by f(t) = Pk i=1 ziti, where zi are constants in R, is uniformly continuous in t. The claim follows because |f(t)−f(t )| = | Pk i=1 zi(ti−ti)| ≤ Pk i=1 |zi||ti − ti|.",
                "An immediate result of this for our purposes is that ui(s) is uniformly continuous in s and ui(ai, s−i) is uniformly continuous in s−i.",
                "Claim: Let f(a, b) be uniformly continuous in b ∈ B for every a ∈ A, with |A| < ∞.",
                "Then V (b) = maxa∈A f(a, b) is uniformly continuous in b.",
                "To show this, take γ > 0 and let b, b ∈ B such that b − b < δ(a) ⇒ |f(a, b) − f(a, b )| < γ.",
                "Now take δ = mina∈A δ(a).",
                "Then, whenever b − b < δ, |V (b) − V (b )| = | max a∈A f(a, b) − max a∈A f(a, b )| ≤ max a∈A |f(a, b) − f(a, b )| < γ.",
                "Now, recall that (s) = maxi[maxai∈Ai ui(ai, s−i) − ui(s)].",
                "By the claims above, maxai∈Ai ui(ai, s−i) is uniformly continuous in s−i and ui(s) is uniformly continuous in s. Since the difference of two uniformly continuous functions is uniformly continuous, and since this continuity is preserved under maximum by our second claim, we have the desired result.",
                "A.5 Proof of Theorem 6 Choose δ > 0.",
                "First, we need to ascertain that the following claim holds: Claim: ¯ = mins∈S\\Nδ (s) exists and ¯ > 0.",
                "Since Nδ is an open subset of compact S, it follows that S \\ Nδ is compact.",
                "As we had also proved in Lemma 5 that (s) is continuous, existence follows from the Weierstrass theorem.",
                "That ¯ > 0 is clear since (s) = 0 if and only if s is a Nash equilibrium of Γ.",
                "Now, by Theorem 3, for any α > 0 there is M such that Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α. Consequently, for any δ > 0, Pr{ sup n≥M h(Nn, Nδ) < δ} ≥ Pr{∀n ≥ M Nn ⊂ Nδ} ≥ Pr{ sup n≥M sup s∈N (s) < ¯} ≥ Pr{ sup n≥M sup s∈S | n(s) − (s)| < ¯} ≥ 1 − α.",
                "Since this holds for an arbitrary α > 0 and δ > 0, the desired result follows.",
                "A.6 Proof of Theorem 7 Fix θ and choose δ > 0.",
                "Since W (s, θ) is continuous at s∗ (θ), given > 0 there is δ > 0 such that for every s that is within δ of s∗ (θ), |W (s , θ) − W (s∗ (θ), θ)| < .",
                "By Theorem 6, we can find M(θ) large enough such that all s ∈ Nn are within δ of s∗ (θ) for all n ≥ M(θ) with probability 1.",
                "Consequently, for any > 0 we can find M(θ) large enough such that with probability 1 we have supn≥M(θ) sups ∈Nn |W (s , θ) − W (s∗ (θ), θ)| < .",
                "Let us assume without loss of generality that there is a unique optimal choice of θ.",
                "Now, since the set Θ is finite, there is also the second-best choice of θ (if there is only one θ ∈ Θ this discussion is moot anyway): θ∗∗ = arg max Θ\\θ∗ W (s∗ (θ), θ).",
                "Suppose w.l.o.g. that θ∗∗ is also unique and let ∆ = W (s∗ (θ∗ ), θ∗ ) − W (s∗ (θ∗∗ ), θ∗∗ ).",
                "Then if we let < ∆/2 and let M = maxθ∈Θ M(θ), where each M(θ) is large enough such that supn≥M(θ) sups ∈Nn |W (s , θ)− W (s∗ (θ), θ)| < a.s., the optimal choice of θ based on any empirical equilibrium will be θ∗ with probability 1.",
                "Thus, in particular, given any probability distribution over empirical equilibria, the best choice of θ will be θ∗ with probability 1 (similarly, if we take supremum or infimum of W (Nn(θ), θ) over the set of empirical equilibria in constructing the objective function). 315"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        }
    }
}