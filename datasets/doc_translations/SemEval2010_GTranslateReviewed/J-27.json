{
    "id": "J-27",
    "original_text": "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price. Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable. Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand. Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast. The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts. Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples. We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17]. Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1. INTRODUCTION A market is an institution by which economic agents meet and make transactions. Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist. The preference relation is therefore the key factor in understanding consumer behavior. One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint. This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory. Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave. This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable? Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint? Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference. Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable. These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions. Hence, an infinite amount of information is needed to refute the theory. It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility. Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations. If such parameters exist, we conclude that the stipulated utility form is consistent with the observations. This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices. The downside of this approach is that real life data is often inconsistent with convenient functional forms. Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization. Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data. He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions? He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference. Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function. Afriat [1] gives another set of rationalizability conditions the observations must satisfy. Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally. It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]). Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency. Varian [20] took this one step further progressing from consistency to forecasting. Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP. Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric. Knoblauch [9] shows these envelopes can be computed efficiently. Varian [21] provides an up to date survey on this line of research. A different approach is presented by Blundell et al. [3, 4]. These papers introduce a model where an agent observes prices and Engel curves for these prices. This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior. This model is in a sense a hybrid between Mas-Colell and Afriats aproaches. The former requires full information for all prices, the latter for a finite number of prices. On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories. The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information. Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget. Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds. Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner. However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations. Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast. In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions. We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable. Our first result is negative. We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable. However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable. In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy. In section 2 we briefly discuss the basic assumptions of demand theory and their implications. In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17]. We show that this algorithm is computationally efficient and can be used as a learning algorithm. In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions. We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity. We also sketch results on upper bounds. In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2. UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles. A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility. The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y). This reflects the assumption that agents will always prefer more of any one good. This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities. However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed. The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing. This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other. These assumptions imply that the utility function is concave and monotone on the observations. The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set. W.l.g. we assume u has marginal utility zero outside [0, 1]d . Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices. We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d. Note that with this metric ∆d is compact. A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d. This property reflects an assumption that preferences and demands have some sort of stability. It rules out different demands for the similar prices. We may therefore assume from here on that demand functions are single valued. 3. REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen. It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi. Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0. Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0. We call the latter condition the Afriat condition (AC). This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient. Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A. The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight. Theorem 1. There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC. Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC. In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible. The construction provides a utility function that is consistent with the observations. Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm. The construction is executed in two steps. First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise. The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles. Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints. Now we describe how to choose the sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise. D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn. Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 . We show that for this choice of s, D(A, s) contains no negative weight cycle. Suppose C = (i1, . . . , ik) is a cycle in D(A, s). If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done. Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1). For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv. Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s). If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction. Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q). Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0. Let p denote a vertex in C with the second smallest potential. Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero. To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set. Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4. SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling. This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations. The labels are usually binary values indicating the membership of the observed points in the set that is being learned. However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors. The learning problem has three major components: estimation, approximation and complexity. The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces. The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class. The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function. A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family. Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree. The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients. The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial. The complexity problem would be the assessment of the time required to compute the polynomial coefficients. In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class. It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed. If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points. The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling. The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations. The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast. In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices. Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +. The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity. An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4. Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree. In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation. Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability. Rather we are content with having small mean square errors on all coordinates. Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ. For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 . A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h). In the case of revealed preference, there is a function that takes the sample error to zero. Nevertheless, the upper bounds theorem we use does not require the sample error to be zero. Definition 1. A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ. There may be several learning algorithms for C with different sample complexities. The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p). A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p). For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]). An analog to this notion of dimension for real functions is the fat shattering dimension. We use an adaptation of this notion to real vector valued function sets. Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +. Definition 2. For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1. We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ. If this size is unbounded then the dimension is infinite. To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity. Lemma 2. Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}. Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d . Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d . This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3. Suppose that C is a class of functions mapping from Γ to Rd +. Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs. Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample. We construct such a distribution. Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}. Let fb be a function chosen uniformly at random from CS. It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss. Therefore Eb(||fb(p) − h(p)||∞) > 2ε. Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε. This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 . W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension. The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted. Theorem 4. Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞. Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m . Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5. LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations. As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from. We compute the fat shattering dimension for two classes of demands. The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable. The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz. We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant. Theorem 5. Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center. Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1). For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience). To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i . To show that such a function exists it suffices to show that Afriats conditions are satisfied. Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1. This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi . In fact, pick a utility function whose level sets are parallel to the budget constraint. Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference. To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling. For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices. Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j. This implies that if there is a negative cycle then all the points in the cycle must belong to the same level. The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope. Thus, the polytope defines a utility function for which these demands are utility maximizing. The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level. It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles. In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support. Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set. We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes. We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6. Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L . A standard packing argument implies n ≤ (L γ )d ✷ 6. ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7. REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference. Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference? European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function. The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis. The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality. Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory. Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption. In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42",
    "original_translation": "Aprendizaje de la preferencia revelada [Resumen extendido] Eyal Beigman CMS-EMS Kellogg School of Management University Northwestern Evanston IL 60208 e-Beigman@northwestern.edu Rakesh Vohra Meds Kellogg School of Management University Northwestern Evanston IL 60208 r-Vohra@northwestern.edu Abstract A Abstract A a a a a ALa secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona, de modo que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat [1] presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y luego Blundell et al.[3, 4] continuó esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados esencialmente caracterizan la capacidad de aprendizaje de las clases degeneradas de funciones de demanda y, por lo tanto, no alcanzan un grado general de confianza en el pronóstico. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de las clases de funciones de demanda y obtener un grado de confianza en los pronósticos. Nuestros resultados muestran que la clase de todas las funciones de demanda ha ilimitado la complejidad y, por lo tanto, no se puede aprender, pero que existen clases interesantes y potencialmente útiles que se pueden aprender de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva prueba del teorema de Afriats debido a Teo y Vohra [17]. Categorías y descriptores de sujetos F.2 [Teoría de la computación]: Análisis de algoritmos y complejidad del problema;J.4 [Aplicaciones informáticas]: ciencias sociales y conductuales-economía;I.2.6 [Aprendizaje]: Parámetros de aprendizaje de términos generales Economía, algoritmos, Teoría 1. Introducción Un mercado es una institución por la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles que indican que los agentes intentan reemplazar su paquete actual con paquetes que son más preferidos y alcanzables si tales paquetes existen. La relación de preferencia es, por lo tanto, el factor clave para comprender el comportamiento del consumidor. Uno de los supuestos comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, a medida que elaboramos en la Sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de servicios públicos son monótonos y cóncavos. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿en qué medida es refutable esta teoría? Dadas las observaciones de precio y demanda, ¿en qué circunstancias podemos concluir que los datos son consistentes con el comportamiento de un agente de maximización de utilidad equipado con una función de utilidad cóncava monótona y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente en la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Color [10, 11] introdujeron una noción de Lipschitz de ingresos y demostró que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren suposiciones paramétricas y son técnicamente refutables, pero asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo es el caso de que aparte de las observaciones de demanda Hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, a saber, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería de la fijación de los parámetros de la función de utilidad para ser consistente con las observaciones y con un conjunto de ecuaciones llamadas ecuaciones Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razones para hacer estas estipulaciones, ofrece una función de utilidad explícita que puede usarse para hacer pronósticos precisos a pedido de los precios atendidos de UNOB36. La desventaja de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de utilidad. Abordar estos problemas Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas. Él muestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de preferencia revelada. Richter [15] muestra que un axioma fuerte de preferencia revelada es equivalente a la racionalización por una función de utilidad monótona estrictamente cóncava. Afriat [1] ofrece otro conjunto de condiciones de racionalización que las observaciones deben satisfacer. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de condición de consistencia de Afriats que es más fácil de verificar computacionalmente. Es interesante observar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat [1] demostró su teorema mediante una construcción explícita de una función de utilidad que presenta la consistencia. Varian [20] dio este paso más progresando de la consistencia a la previsión. El algoritmo de pronóstico de los varianos básicamente descarta paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, presenta la métrica de dinero de Samuelson como una función de utilidad canónica y ofrece funciones de utilidad de envoltura superior e inferior para la métrica de dinero. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Blundell et al. Presentan un enfoque diferente.[3, 4]. Estos documentos introducen un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto da una mejora en los límites originales de los varianos, aunque la idea básica aún es descartar las demandas que se revelan inferiores. Este modelo es, en cierto sentido, un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al.Requiere información completa solo en un número finito de trayectorias de precios. La motivación para este crossover es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Los diferentes segmentos de la población enfrentan los mismos precios con diferentes presupuestos, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo la demanda varía con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y lo usan para obtener límites más estrictos. Ambos métodos probablemente darían un buen pronóstico para una función de demanda fija después de suficientes observaciones suponiendo que se extendieran de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este artículo examinamos la viabilidad de la pronóstico de la demanda con un alto grado de confianza utilizando condiciones de Afriats. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de las utilidades cóncavo monótono es eficientemente Pac-Learnable. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de rotura de grasa, que sin suposiciones previas, el conjunto de todas las funciones de demanda inducidas por las funciones de utilidad cóncavas monótonas es demasiado rico para ser eficientemente Pac-Learnable. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, mostramos que la dimensión de rotura de grasa es finita y, por lo tanto, los conjuntos correspondientes son PAC-Learnables. En estos casos, suponiendo que la distribución de probabilidad por la cual se generan los pares de demanda de precios observados se fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística de su precisión. En la Sección 2 discutimos brevemente los supuestos básicos de la teoría de la demanda y sus implicaciones. En la Sección 3 presentamos una nueva prueba al teorema de Afriats que incorpora un algoritmo para generar eficientemente una función de pronóstico debido a TEO y VOHRA [17]. Mostramos que este algoritmo es computacionalmente eficiente y puede usarse como un algoritmo de aprendizaje. En la Sección 4 damos una breve introducción al aprendizaje de PAC, incluidas varias modificaciones para aprender funciones valoradas de vectores reales. Introducimos la noción de dimensión de rotura de grasa y la usamos para idear un límite inferior en la complejidad de la muestra. También dibujamos los resultados en los límites superiores. En la Sección 5, estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de rotura de grasa de la clase de todas las funciones de demanda y una clase de funciones de demanda de los ingresos-Lipschitzian con una constante limitada de Lipschitz de Lipschitz de ingresos limitados.2. Utilidad y demanda Una función de utilidad U: Rn + → R es una función que relaciona los paquetes de productos con un cardenal de una manera que refleja las preferencias sobre los paquetes. Un agente racional con un presupuesto que w.l.g es igual a 1 frente a un vector de precio p ∈ Rn + elegirá entre su presupuesto B (p) = {x ∈ Rn +: p · x ≤ 1} un paquete x ∈ Rn + que la maximizautilidad privada. La primera suposición que hacemos es que la función está aumentando la monótona, a saber, si x ≥ y, en el sentido de que la desigualdad se mantiene coordinada, entonces u (x) ≥ u (y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquiera bueno. Esto, por supuesto, no necesariamente se mantiene en la práctica, ya que en muchos casos el exceso de suministro puede conducir a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos, la demanda será un punto interior del conjunto presupuestario y no se observan los paquetes menos preferidos. La segunda suposición que hacemos en la utilidad es que todos los marginales (derivados parciales) están disminuyendo monótonos. Esta es la ley de disminución de la utilidad marginal que supone que cuanto mayor sea el exceso de un bien sobre el otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estos supuestos implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: rn + → rn + satisfaciendo f (p) = argmax {u (x): p · x ≤ i} En general, esta correspondencia no es necesariamente valorada, pero está implícito enLa prueba del teorema de Afriats de que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda valorada para precios no observados.37 Dado que es probable que grandes cantidades de cualquier bien creen externalidades que disminuyan los servicios públicos, suponemos que los precios se limitan a un conjunto compacto. W.L.G.Suponemos que tiene utilidad marginal cero fuera [0, 1] d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximice en ningún punto fuera del soporte y, por lo tanto, es difícil de pronosticar para estos precios. Por lo tanto, estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv {(0, ..., 1, ..., 0)}. Para estos precios tomamos la métrica dp (p, p) = max {|1 pi - 1 pi |: i = 1 ,..., d} para p, p ∈ ∆D. Tenga en cuenta que con esta métrica ∆D es compacta. Una función de demanda es L-ingreso-lipschitz, para l ∈ R+, si || f (p)-f (p) || ∞ dp (p, p) ≤ l para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y las demandas tienen algún tipo de estabilidad. Describe diferentes demandas por los precios similares. Por lo tanto, podemos suponer desde aquí sobre que las funciones de demanda son valoradas.3. Reveló preferencia una secuencia de precios y demandas (P1, x1) ,..., (pn, xn) es racionalizable si existe una función de utilidad U de tal manera que xi = fu (pi) para i = 1 ,..., n.Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f (pi), entonces se prefiere xi sobre xj ya que el último está en el presupuesto establecido cuando se eligió el primero. Por lo tanto, se revela que u (xj) ≤ u (xi) implica pj · xj ≤ pj · xi. Supongamos que hay una secuencia (PI1, XI1) ,..., (pik, xik) tal que pij · (xij - xij+1) ≤ 0 para j = 1...K - 1 y PIK · (xik - xi1) ≤ 0. Entonces el mismo razonamiento muestra que u (xi1) = u (xi2) =...= u (xik) implicando pi1 · (xi1 - xi2) = Pi2 · (xi2 - xi3) =...= pik - 1 · (xik - 1 −xik) = 0. Llamamos a la última condición la condición Afriat (AC). Este argumento muestra que AC es necesario para la racionalización;El sorprendente resultado en el teorema de Afriats es que esta condición también es suficiente. Sea A una matriz N × N con entradas aij = pi · (xj - xi) (aij y aji son independientes), aii = 0 y D (a) sea el dígrafo ponderado asociado con A. La matriz satisface la CA si cada ciclo con peso total negativo incluye al menos un borde con peso positivo. Teorema 1. Existe y = (y1, ..., yn) ∈ Rn y s = (s1, ..., sn) ∈ Rn + satisfaciendo el conjunto de desigualdades l (a), yj ≤ yi + siaij i = j 1 ≤I, j ≤ n iff d (a) satisface ac. Prueba: si L (a) es factible, entonces es fácil ver que u (x) = min i {yi + sipi (x - xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestra observación anteriorSe deduce que d (a) satisface AC. En la otra dirección, se muestra mediante una construcción explícita que la condición de Afriats para D (a) implica que L (a) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] dan un algoritmo de tiempo fuertemente polinómico para esta construcción, que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + de modo que el dígrafo d (a, s) ponderado definido por la matriz ˜ij = siaij no tiene un ciclo con peso total negativo si d (a) satisface AC y devuelve un ciclo negativo de lo contrario. Las limitaciones dieron el doble de un problema de ruta más corto: yj - yi ≤ siaij i = j es un resultado estándar (ver [14] p 109) que el sistema es factible si no tiene ciclos negativos. Por lo tanto, en el segundo paso, si d (a) satisface AC, el algoritmo llama un algoritmo de ruta más corto para encontrar y ∈ Rn satisface las restricciones. Ahora describimos cómo elegir la hermana. Definir s = {(i, j): aij <0}, e = {(i, j): aij = 0} y t = {(i, j): aij> 0} y dejar g = ([n], S ∪ e) ser un dígrafo con pesos wij = −1 if (i, j) ∈ S y wij = 0 de lo contrario. D (a) no tiene ciclos negativos, por lo tanto, G es acíclico y la amplitud primera de búsqueda puede asignar potenciales φi tal que φJ ≤ φi + wij para (i, j) ∈ S ∪ E. Reabelamos los vértices para que φ1 ≥ φ2 ≥...≥ φn. Sea Δi = (n - 1) max (i, j) ∈S (−ij) min (i, j) ∈T aij si φi <φi - 1 y Δi = 1 de lo contrario, y defina si = iy j = 2 ΔJ= Δi · Si - 1. Mostramos que para esta elección de S, D (A, S) no contiene un ciclo de peso negativo. Supongamos que C = (I1, ..., Ik) es un ciclo en D (A, S). Si φ es constante en c, entonces aij ij+1 = 0 para j = 1 ,..., K y hemos terminado. De lo contrario, deje que IV ∈ C sea el vértice con el potencial más pequeño que satisfaga a W.L.O.G.φ (iv) <φ (IV+1). Para cualquier ciclo C en el dígrafo D (A, S), Sea (V, U) un borde en C de modo que (i) V tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu> φV. Tal borde existe, de lo contrario φi es idéntico para todos los vértices I en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D (A, S). If (iv, iv+1) ∈ S ∪ e, entonces tenemos φ (iv+1) ≤ φ (iv)+wiv, iv+1 ≤ ≤ (iv) una contradicción. Por lo tanto (IV, IV+1) ∈ T. ahora, tenga en cuenta que todos los vértices Q en C con el mismo potencial que IV deben ser incidentes a un borde (Q, T) en C de modo que φ (T) ≥ φ (Q). Por lo tanto, el borde (Q, T) debe tener un peso no negativo.es decir, aq, t ≥ 0. Deje que P denote un vértice en C con el segundo potencial más pequeño. Ahora, C tiene peso svavu+ x (k, l) ∈C \\ (v, u) skak, l ≥ svav, u+ sp (n - 1) max (i, j) ∈S {aij} ≥ 0, es decir,, es decir,C tiene peso no negativo ✷ Algoritmo 1 retornos en tiempo polinomial Una hipótesis que es una función lineal por partes y está de acuerdo con el etiquetado de la observación, es decir, el error de muestra cero. Para usar esta función para pronosticar la demanda de precios no observados, necesitamos el Algoritmo 2 que maximice la función en un conjunto de presupuesto determinado. Dado que u (x) = mini {yi + sipi (x - xi)} Este es un programa lineal y se puede resolver en el polinomio de tiempo en D, N, así como el tamaño del número más grande en la entrada.38 Algoritmo 1 Entrada de algoritmo de utilidad (x1, p1) ,..., (xn, pn) s ← {(i, j): aij <0} e ← {(i, j): aij = 0} para todos (i, j) ∈ S do wij ← −1 para todos(i, j) ∈ E do wij ← 0 finalizar mientras existen vértices no visitados visite el nuevo vértice J Asigne el potencial para que finalice los índices de reordenamiento para que φ1 ≤ φ2...≤ φn para todos 1 ≤ i ≤ n do Δi ← (n - 1) max (i, j) ∈S (−aij) min (i, j) ∈T aij si ← qi j = 2 ΔJ final para ruta más corta (yj - yi ≤ siaij) return y1 ,..., yn ∈ Rd y S1 ,..., sn ∈ R+ Algoritmo 2 Entrada de evaluación Y1 ,..., yn ∈ Rd y S1 ,..., sn ∈ R + max z z ≤ yi + sipi (x - xi) para i = 1 ,..., n px ≤ 1 retorno x para el maximizado z 4. El aprendizaje supervisado En un problema de aprendizaje supervisado, un algoritmo de aprendizaje recibe una muestra finita de observaciones marcadas como entrada y se requiere para devolver un modelo de la relación funcional subyacente al etiquetado. Este modelo, denominado hipótesis, suele ser una función computable que se utiliza para pronosticar las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la membresía de los puntos observados en el conjunto que se aprende. Sin embargo, no nos limitamos a los valores binarios y, de hecho, en las funciones de demanda estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se refiere a la compensación entre el tamaño de la muestra dada al algoritmo y el grado de confianza que tenemos en el pronóstico que produce. El problema de aproximación se refiere a la capacidad de las hipótesis de una determinada clase para aproximar las funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que se aproxima a la función objetivo. Un paradigma paramétrico supone que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción de Cobb-Douglas;El sistema debe aprender los parámetros que caracterizan a esta familia. Suponga que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que supone proviene de una función de producción de Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado limitado. El problema de estimación en este caso sería evaluar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación sería evaluar el error sostenido al aproximar una función racional por un polinomio. El problema de la complejidad sería la evaluación del tiempo requerido para calcular los coeficientes polinomiales. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones de hipótesis, que incluye o no la función objetivo en sí;No requiere ninguna suposición paramétrica en esta clase. También se supone que las observaciones se generan de forma independiente mediante alguna distribución en el dominio de la relación y que esta distribución es fija. Si la clase de funciones objetivo tiene una dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tiende a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tiende a estar de acuerdo con el etiquetado, con alta probabilidad, será una buena aproximación de la función objetivo para futuras observaciones. El objetivo principal de la teoría de PAC es desarrollar la noción relevante de dimensionalidad y formalizar la compensación entre dimensionalidad, tamaño de la muestra y el nivel de confianza en el pronóstico. En el entorno de preferencia revelado, nuestro objetivo es utilizar un conjunto de observaciones de los precios y la demanda para pronosticar la demanda de precios no observados. Por lo tanto, la función objetivo es un mapeo de precios a paquetes, a saber F: RD + → RD +. La teoría del aprendizaje de PAC para funciones valoradas reales se refiere predominantemente a las funciones de RD a R. En esta sección introducimos modificaciones en las nociones clásicas de PAC Learning a las funciones valoradas de vectores y los usamos para probar un límite más bajo para la complejidad de la muestra. También se puede probar un límite superior en la complejidad de la muestra para nuestra definición de ruptura de grasa, pero no lo traemos aquí, ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos continuar con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tendemos a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función H que con alta probabilidad concuerda con F.Luego tomaríamos la probabilidad pσ (f (x) = h (x)) como la medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que F y H estén de acuerdo con una alta probabilidad. Más bien estamos contentos con tener pequeños errores cuadrados medios en todas las coordenadas. Por lo tanto, nuestra medida de error de estimación viene dada por: erσ (f, h) = z (|| f - h || ∞) 2 dσ. Para observaciones dadas s = {(p1, x1) ,..., (pn, xn)} Medimos el acuerdo por el error de muestra ers (s, h) = x j (|| xj - h (pj) || ∞) 2. Un algoritmo de minimización de error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza los ER (S, H). En el caso de la preferencia revelada, hay una función que lleva el error de muestra a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de muestra sea cero. Definición 1. Un conjunto de funciones de demanda c probablemente sea aproximadamente correcta (pac) aprendiendo por hipótesis establecidas h si para alguna ε, Δ> 0, f ∈ C y distribución σ en los precios 39 existe un algoritmo l de que se observa una longitud de longitudml = ml (ε, δ) = poli (1 δ, 1 ε) encuentra una función h de H tal que erσ (f, h) <ε con probabilidad 1 - δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El ML mínimo se denomina complejidad de la muestra de C. Tenga en cuenta que en la definición no se menciona la complejidad del tiempo para encontrar H en H y evaluar H (P). Un conjunto C es eficientemente PAC-Learnable si hay un algoritmo de tiempo poli (1 δ, 1 ε) para elegir H y evaluar H (P). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de rotura de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones valorados en vector real. Sea γ ⊂ RD + y sea C un conjunto de funciones reales de γ a RD +. Definición 2. Para γ> 0, un conjunto de puntos P1 ,..., pn ∈ γ está γ-más roto por una clase de funciones reales c si existe x1 ,..., xn ∈ Rd + e hiperplanos afinos paralelos H0, H1 ⊂ Rd tal que 0 ∈ H- 0 ∩ H + 1, Dist (H0, H1)> γ y para cada B = (B1, ..., Bn) ∈ {0, 1} n existe una función fb ∈ C tal que fb (pi) ∈ Xi + h + 0 si bi = 0 y f (pi) ∈ Xi + h− 1 si bi = 1. Definimos la dimensión destrozada γ-grasas de C, denotó FATC (γ) como el tamaño máximo de un conjunto ruido de γ en γ. Si este tamaño está ilimitado, la dimensión es infinita. Para demostrar la utilidad de esta noción, la usamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Suponga que las funciones {fb: b ∈ {0, 1} n} se testigan de la rotura de {p1 ,..., pn}. Luego, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1} n tal que bi = bi se || fb (pi) - x || ∞> γ 2d o || fb (pi) - x || ∞> γ 2d. Prueba: dado que el máximo excede la media, se deduce que si FB y FB corresponden a etiquetas de modo que bi = bi entonces || fb (pi) - fb (pi) || ∞ ≥ 1 d || fb (pi) - fb(pi) || 2> γ d. Esto implica que para cualquier x ∈ Rd + ya sea || fb (pi) - x || ∞> γ 2d o || fb (pi) - x || ∞> γ 2d ✷ Teorema 3. Suponga que C es una clase de funciones mapeo de γ a RD +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface a ML (ε, Δ) ≥ 1 2 FATC (4Dε) Un análogo de este teorema para funciones valoradas reales con un límite más estrecho se puede encontrar en [2], esta versión será suficiente paranuestras necesidades. Prueba: Supongamos que n = 1 2 fatc (4dε) y luego existe un conjunto γs = {p1 ,..., p2n} que está destrozado por C. es suficiente para demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en γS y CS = {fb: b ∈ {0, 1} 2n} Sea el conjunto de funciones que son testigos de la rotura de {p1...., pn}. Deje que FB sea una función elegida uniformemente al azar de CS. Se deduce de Lemma 2 (con γ = 2D) que para cualquier función fija H, la probabilidad de que || fb (p) - h (p) || ∞> 2ε para p ∈ γs sea al menos tan alto como tener cabezas en unFair Coin Show. Por lo tanto, eB (|| fb (p) - h (p) || ∞)> 2ε. Supongamos una secuencia de observaciones z = ((PI1, x1), ..., (pin, xn)) Un algoritmo de aprendizaje l encuentra una función h.La observación anterior y Fubini implican EB (ERσ (H, FB))> ε.Aleatorizando en el espacio de muestras obtenemos EB, Z (ERσ (H, FB))> ε. Esto muestra EH, Z (Erσ (H, FB0))> ε para algunos FB0. W.L.G podemos suponer que el error está limitado (ya que estamos viendo lo que es esencialmente un conjunto finito), por lo tanto, la probabilidad de que Erσ (H, FB0)> ε no pueda ser demasiado pequeño, por lo tanto, FB0 no es pacificable con una muestra de tamaño n ✷ ✷ ✷El siguiente teorema proporciona un límite superior en la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de ruptura de grasa finita. El teorema se prueba en [2] para funciones valoradas reales, la prueba del caso del vector real es análoga y omitida. Teorema 4. Sea C un conjunto de funciones de valor real de X a [0, 1] con FATC (γ) <∞. Deje que A sea el algoritmo de SEM aproximado para C y defina l (z) = a (z, ε0 6) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de la muestra dada por: ml (ε, Δ) = O „1 ε2 (ln2 (1 ε) fatc (ε) + ln (1 δ))« para cualquier ε, δ> 0. 5. El aprendizaje del algoritmo de preferencia revelado 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con el error de muestra cero en el tiempo polinomio en el número de observaciones. Como hemos visto en la Sección 4, el número de observaciones requeridas para aprender la demanda depende de la dimensión de rotación de grasa de la clase de funciones de demanda que a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de rotura de grasa para dos clases de demandas. La primera es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión infinita destrozada (damos dos pruebas) y, por lo tanto, no se puede aprender PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de los servicios públicos con soporte limitado y lipschitz de ingresos. Mostramos que la clase tiene una dimensión de rotura de grasa finita que depende del soporte y de la constante de ingresos-Lipschitz. Teorema 5. Sea C un conjunto de funciones de demanda de RD + a RD + luego Fatc (γ) = ∞ PROGA 1: Para ε> 0, Pi = 2 - i p para i = 1 ,..., n ser un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelo BI y Let X1 ,..., xn será la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Deje que H0 y H1 sean hiperplanos que no son paralelos a P y Xi ∈ Bi bi ∩ (xi + h + 0) y xi ∈ Bi ∩ (xi + h− 1) para i = 1...n (ver Figura 1). Para cualquier etiquetado b = (b1, ..., bn) ∈ {0, 1} n Sea y = y (b) = (y1, ..., yn) ser un conjunto de demandas como yi = xi si bi bi= 0 y yi = xi si bi = 1 (omitimos un índice adicional b en y para mayor conveniencia). Para mostrar que P1 ,..., PN está destrozado, es suficiente encontrar para cada función de la demanda de B, compatible con la utilidad cóncava de tal manera que FB (PI) = yb i. Demuestre que tal función existe, es suficiente para demostrar que las condiciones de Afriats están satisfechas. Dado que yi están en el presupuesto 40 establecido yi · 2 - i p = 1, por lo tanto, pi · (yj - yi) = 2j - i - 1. Esto muestra que pi · (yj - yi) ≤ 0 iff j <i, por lo tanto, no puede haber ciclos negativos y la condición se cumple.✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriats en la primera prueba podrían ser triviales asignando la misma utilidad a Xi a XI. De hecho, elija una función de utilidad cuyos conjuntos de niveles son paralelos a la restricción presupuestaria. Por lo tanto, la ruptura de los precios P1 ,..., PN es el resultado de la indiferencia en lugar de la preferencia genuina. Para evitar este problema, reprendemos el teorema construyendo funciones de utilidad U de tal manera que u (xi) = u (xi) para todas las i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado. Para i = 1 ,...n Sea Pi1 ,..., PID BE Vectores de precios que satisfacen las siguientes condiciones: 1. Los establecimientos del presupuesto BS I están admitiendo hiperplanos de un politope convexo λi 2. yi es un vértice de λi 3. || yj || 1 · || pis - pi || ∞= o (1) para s = 1 ,...d y j = 1 ,..., n finalmente dejar yi1 ,..., Yid serán puntos en las facetas de λi que se cruzan yi, de modo que || pjr || 1 · || yi - yis || ∞ = o (1) para todos j, sy r.Llamamos al conjunto de puntos yi, yi1 ,..., Yid el nivel I demanda y Pi, PI1 ,..., Pid Nivel I Precios. Aplicando la desigualdad de H¨olders obtenemos | Pir · yjs - pi · yj |≤ | (piR - pi) · yj |+ | piR · (yjs - yj) ||| piR - pi || ∞ · || yj || 1 + || yjs - yj || ∞ · || pir || 1.= O (1) Esto muestra que PIR · (YJS - Yir) = Pi · (YS - Yi) + O (1) = 2J - I - 1 + O (1) Por lo tanto, PIR · (YJS - Yir) ≤ 0 IFFj <i o i = j. Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel. Los puntos de cualquier nivel se encuentran en las facetas de un Polyitope λi y los precios PI están apoyando los hiperplanos del Polyitope. Por lo tanto, el Politope define una función de utilidad para la cual estas demandas son la maximización de la utilidad. Por lo tanto, la otra dirección del teorema de Afriats implica que no puede haber ciclos negativos dentro de los puntos en el mismo nivel. Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, de ahí la secuencia de observaciones (Y1, P1), (Y11, P11), (Y12, P12) ,..., (YND, PND) es consistente con la maximización de la función de la utilidad cóncava monótona y nuevamente por el teorema de Afriats existe que admite una función de demanda FB ✷ La prueba anterior se basa en el hecho de que un agente tiene una utilidad de alta utilidad y una utilidad marginal para bundeos muy grandes. En muchos casos, es razonable suponer que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen soporte compacto. Desafortunadamente, el reescalado del ejemplo anterior muestra que incluso un conjunto compacto puede contener un gran conjunto destrozado. Sin embargo, notamos que en este caso obtenemos una función de utilidad que produce funciones de demanda que son muy sensibles a los pequeños cambios de precios. Mostramos que la clase de funciones de servicios públicos que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son los ingresos-Lipschitzian tienen una dimensión de rotura de grasa finita.✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1R X1 R X1 ❈ ❈ ❜ ❜❜ R X2 R X2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: La función de utilidad rompiendo el teorema X1 y X2 6. Sea C un conjunto de funciones de demanda de L-Lipschitz de L-Lipschitz de ∆D a RD + para una constante global l ∈ R. Entonces FATC (γ) ≤ (l γ) d Prueba: Sea P1 ,..., pn ∈ ∆D ser un conjunto destrozado con testigos x1 ,..., xn ∈ Rd +. W.L.G.xi + h + 0 ∩xj + h− 0 = ∅ implicando xi + h− 1 ∩ xj + h + 1 = ∅, para un etiquetado b = (b1, ..., bn) ∈ {0, 1} n.= 0 y bj = 1, || fb (pi) - fb (pj) || ∞> γ por lo tanto || pi - pj || ∞> γ l. Un argumento de embalaje estándar implica n ≤ (l γ) d ✷ 6. Agradecimientos Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio Gonz´alez d´ıaz, Rosa Matzkin, Gad Allon y Adam Galambos por sus útiles discusiones y sugerencias.7. REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de gastos Data International Economic Review 8, 67-77.[2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de la red neuronal: fundamentos teóricos Cambridge University Press.[3] Blundell R., Browning M. y Crawford I. (2003) Curvas Engel no paramétricas y preferencia revelada. Econometrica, 71 (1): 205-240.[4] Blundell R. (2005) ¿Cómo se revela la preferencia revelada? European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat y reveló la teoría de preferencias Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨uber Die Theorie der Einfachen Ungleichungen Journalf¨ur die reine und angewandte mathematik 124 1-27 [7] Houthakker H. (1950) reveló preferencia y la función de utilidad EconomiCa 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) una introducción aTeoría del aprendizaje computacional The MIT Press Cambridge MA.41 [9] Knoblauch V. (1992) Un límite superior apretado en la función de utilidad métrica de dinero. The American Economic Review, 82 (3): 660-663.[10] Mas-Colell A. (1977) La capacidad de recuperación de las preferencias de los consumidores de la demanda del mercado. Econometrica, 45 (6): 1409-1430.[11] Mas-Color A. (1978) sobre análisis de preferencias reveladas. La revisión de los estudios económicos, 45 (1): 121-131.[12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría microeconómica Oxford University Press.[13] Matzkin R. y Richter M. (1991) Prueba de racionalidad estrictamente cóncava. Journal of Economic Theory, 53: 287-303.[14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización combinatoria Dover Publications Inc.[15] Richter M. (1966) reveló la teoría de la preferencia. Econometrica, 34 (3): 635-645.[16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo. En K. J. Arrow, S. Karlin y P. Suppes, Editores, Modelos Matemáticos en Ciencias Sociales Stanford University Press, Stanford, CA.[17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriats y ciclos negativos Documento de trabajo [18] Samuelson P. A. (1948) Teoría del consumo en términos de preferencia revelada Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Aprendizaje estadístico)Teoría John Wiley & Sons Inc. [20] Varian H. R. (1982) El enfoque no paramétrico para el análisis de la demanda Econometrica 50, 945 - 974. [21] Varian H. R. (2005) reveló preferencia, en el editor de Michael Szenberg, Samuelson Economics y The the the theSiglo 21.[22] Ziegler G. M. (1994) Conferencias sobre Polytopes Springer.42",
    "original_sentences": [
        "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
        "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
        "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
        "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
        "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
        "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
        "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
        "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
        "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
        "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
        "The preference relation is therefore the key factor in understanding consumer behavior.",
        "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
        "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
        "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
        "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
        "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
        "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
        "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
        "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
        "Hence, an infinite amount of information is needed to refute the theory.",
        "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
        "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
        "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
        "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
        "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
        "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
        "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
        "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
        "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
        "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
        "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
        "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
        "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
        "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
        "Varian [20] took this one step further progressing from consistency to forecasting.",
        "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
        "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
        "Knoblauch [9] shows these envelopes can be computed efficiently.",
        "Varian [21] provides an up to date survey on this line of research.",
        "A different approach is presented by Blundell et al. [3, 4].",
        "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
        "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
        "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
        "The former requires full information for all prices, the latter for a finite number of prices.",
        "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
        "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
        "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
        "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
        "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
        "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
        "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
        "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
        "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
        "Our first result is negative.",
        "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
        "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
        "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
        "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
        "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
        "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
        "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
        "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
        "We also sketch results on upper bounds.",
        "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
        "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
        "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
        "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
        "This reflects the assumption that agents will always prefer more of any one good.",
        "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
        "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
        "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
        "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
        "These assumptions imply that the utility function is concave and monotone on the observations.",
        "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
        "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
        "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
        "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
        "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
        "Note that with this metric ∆d is compact.",
        "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
        "This property reflects an assumption that preferences and demands have some sort of stability.",
        "It rules out different demands for the similar prices.",
        "We may therefore assume from here on that demand functions are single valued. 3.",
        "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
        "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
        "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
        "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
        "We call the latter condition the Afriat condition (AC).",
        "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
        "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
        "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
        "Theorem 1.",
        "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
        "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
        "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
        "The construction provides a utility function that is consistent with the observations.",
        "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
        "The construction is executed in two steps.",
        "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
        "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
        "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
        "Now we describe how to choose the sis.",
        "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
        "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
        "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
        "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
        "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
        "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
        "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
        "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
        "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
        "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
        "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
        "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
        "Let p denote a vertex in C with the second smallest potential.",
        "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
        "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
        "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
        "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
        "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
        "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
        "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
        "The learning problem has three major components: estimation, approximation and complexity.",
        "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
        "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
        "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
        "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
        "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
        "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
        "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
        "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
        "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
        "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
        "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
        "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
        "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
        "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
        "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
        "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
        "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
        "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
        "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
        "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
        "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
        "Rather we are content with having small mean square errors on all coordinates.",
        "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
        "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
        "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
        "In the case of revealed preference, there is a function that takes the sample error to zero.",
        "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
        "Definition 1.",
        "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
        "There may be several learning algorithms for C with different sample complexities.",
        "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
        "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
        "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
        "An analog to this notion of dimension for real functions is the fat shattering dimension.",
        "We use an adaptation of this notion to real vector valued function sets.",
        "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
        "Definition 2.",
        "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
        "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
        "If this size is unbounded then the dimension is infinite.",
        "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
        "Lemma 2.",
        "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
        "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
        "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
        "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
        "Suppose that C is a class of functions mapping from Γ to Rd +.",
        "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
        "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
        "We construct such a distribution.",
        "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
        "Let fb be a function chosen uniformly at random from CS.",
        "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
        "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
        "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
        "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
        "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
        "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
        "Theorem 4.",
        "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
        "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
        "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
        "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
        "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
        "We compute the fat shattering dimension for two classes of demands.",
        "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
        "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
        "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
        "Theorem 5.",
        "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
        "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
        "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
        "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
        "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
        "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
        "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
        "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
        "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
        "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
        "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
        "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
        "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
        "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
        "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
        "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
        "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
        "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
        "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
        "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
        "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
        "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
        "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
        "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
        "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
        "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
        "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
        "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
        "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
        "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
        "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
        "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
        "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
        "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
    ],
    "error_count": 0,
    "keys": {
        "learning from revealed preference": {
            "translated_key": "Aprendizaje de la preferencia revelada",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>learning from revealed preference</br> [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "<br>learning from revealed preference</br> Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "\"Aprendizaje de la preferencia revelada\" [Resumen extendido] Eyal Beigman CMS-EMS Kellogg School of Management University Northwestern University Evanston IL 60208 e-Beigman@northwestern.edu Rakesh Vohra Meds Kellogg School of Management University Northwestern Evanston IL 60208 r-vohra@northwestern.eduResumen Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona de modo que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio.",
                "\"Aprender de la preferencia revelada\" El algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con el error de muestra cero en el tiempo polinomio en el número de observaciones."
            ],
            "translated_text": "",
            "candidates": [
                "Aprender de la preferencia revelada",
                "Aprendizaje de la preferencia revelada",
                "Aprender de la preferencia revelada",
                "Aprender de la preferencia revelada"
            ],
            "error": []
        },
        "complexity problem": {
            "translated_key": "problema de complejidad",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The <br>complexity problem</br> is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The <br>complexity problem</br> would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "El \"problema de complejidad\" se refiere a la complejidad computacional de encontrar una hipótesis que se aproxima a la función objetivo.",
                "El \"problema de complejidad\" sería la evaluación del tiempo requerido para calcular los coeficientes polinomiales."
            ],
            "translated_text": "",
            "candidates": [
                "problema de complejidad",
                "problema de complejidad",
                "problema de complejidad",
                "problema de complejidad"
            ],
            "error": []
        },
        "forecast": {
            "translated_key": "pronóstico",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the <br>forecast</br>.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good <br>forecast</br> for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good <br>forecast</br> or the degree of confidence in such a <br>forecast</br>.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a <br>forecast</br> and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to <br>forecast</br> for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to <br>forecast</br> demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to <br>forecast</br> the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the <br>forecast</br> it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the <br>forecast</br>.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to <br>forecast</br> demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by <br>forecast</br> and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Sus resultados esencialmente caracterizan la capacidad de aprendizaje de las clases degeneradas de funciones de demanda y, por lo tanto, no alcanzan un grado general de confianza en el \"pronóstico\".",
                "Es muy probable que ambos métodos darían un buen \"pronóstico\" para una función de demanda fija después de suficientes observaciones suponiendo que se extendieran de manera razonable.",
                "Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen \"pronóstico\" o el grado de confianza en tal \"pronóstico\".",
                "En estos casos, suponiendo la distribución de probabilidad por la cual se generan los pares de demanda de precios observados, estamos en condiciones de ofrecer un \"pronóstico\" y una estimación probabilística de su precisión.",
                "Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximice en ningún punto fuera del soporte y, por lo tanto, es difícil \"pronosticar\" para estos precios.",
                "Para usar esta función para \"pronosticar\" la demanda de precios no observados, necesitamos el Algoritmo 2 que maximice la función en un conjunto de presupuesto determinado.",
                "Este modelo, denominado hipótesis, suele ser una función computable que se utiliza para \"pronosticar\" las etiquetas de las observaciones futuras.",
                "El problema de estimación se refiere a la compensación entre el tamaño de la muestra dada al algoritmo y el grado de confianza que tenemos en el \"pronóstico\" que produce.",
                "El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar la compensación entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en el \"pronóstico\".",
                "En el entorno de preferencia revelado, nuestro objetivo es utilizar un conjunto de observaciones de los precios y la demanda de \"pronosticar\" la demanda de precios no observados.",
                "Antes de que podamos continuar con la definición formal, debemos aclarar lo que queremos decir con \"pronóstico\" y tendemos a estar de acuerdo."
            ],
            "translated_text": "",
            "candidates": [
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronosticar",
                "pronóstico",
                "pronosticar",
                "pronóstico",
                "pronosticar",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronóstico",
                "pronosticar",
                "pronóstico",
                "pronóstico"
            ],
            "error": []
        },
        "probably approximately correct": {
            "translated_key": "probablemente aproximadamente correcto",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the <br>probably approximately correct</br> (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is <br>probably approximately correct</br> (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "En el paradigma \"probablemente aproximadamente correcto\" (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones de hipótesis, que incluye o no la función objetivo en sí;No requiere ninguna suposición paramétrica en esta clase.",
                "Un conjunto de funciones de demanda C es \"probablemente aproximadamente correcta\" (Pac) aprendiendo por hipótesis establecidas H si para alguna ε, δ> 0, f ∈ C y distribución σ en los precios 39 existe un algoritmo l de un conjunto de observacionesde longitud ml = ml (ε, δ) = poli (1 δ, 1 ε) encuentra una función h de H tal que erσ (f, h) <ε con probabilidad 1 - δ."
            ],
            "translated_text": "",
            "candidates": [
                "Probablemente aproximadamente correcto",
                "probablemente aproximadamente correcto",
                "Probablemente aproximadamente correcto",
                "probablemente aproximadamente correcta"
            ],
            "error": []
        },
        "monotone concave utility function": {
            "translated_key": "función de utilidad cóncava monótona",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a <br>monotone concave utility function</br> and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with <br>monotone concave utility function</br> maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Dadas las observaciones de precio y demanda, ¿en qué circunstancias podemos concluir que los datos son consistentes con el comportamiento de un agente de maximización de utilidad equipado con una \"función de utilidad cóncava monótona\" y sujeto a una restricción presupuestaria?",
                "Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, de ahí la secuencia de observaciones (Y1, P1), (Y11, P11), (Y12, P12) ,..., (ynd, pnd) es consistente con la maximización de la \"función de utilidad cóncava monótona\" y nuevamente por el teorema de Afriats existe que admite una función de demanda FB ✷ La prueba anterior se basa en el hecho de que un agente tiene alta utilidad y utilidad marginal para bundeos muy grandes."
            ],
            "translated_text": "",
            "candidates": [
                "función de utilidad cóncava monótona",
                "función de utilidad cóncava monótona",
                "función de utilidad cóncava monótona",
                "función de utilidad cóncava monótona"
            ],
            "error": []
        },
        "demand function": {
            "translated_key": "función de demanda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire <br>demand function</br> and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed <br>demand function</br> after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The <br>demand function</br> of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a <br>demand function</br> that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A <br>demand function</br> is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a <br>demand function</br> fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a <br>demand function</br> fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Estas propiedades no requieren suposiciones paramétricas y son técnicamente refutables, pero asumen el conocimiento de toda la \"función de demanda\" y dependen en gran medida de las propiedades diferenciales de las funciones de demanda.",
                "Es muy probable que ambos métodos darían un buen pronóstico para una \"función de demanda\" fija después de suficientes observaciones suponiendo que se extendieran de manera razonable.",
                "La \"función de demanda\" del agente es la correspondencia fu: rn + → rn + satisfaciendo f (p) = argmax {u (x): p · x ≤ i} En general, esta correspondencia no es necesariamente valorada, pero lo esImplícito en la prueba del teorema de Afriats de que cualquier conjunto de observaciones puede ser racionalizado por una \"función de demanda\" que sea valorada para precios no observados.37 Dado que es probable que grandes cantidades de cualquier bien creen externalidades que disminuyan los servicios públicos, suponemos que los precios se limitan a un conjunto compacto.",
                "Una \"función de demanda\" es l-ingreso-lipschitz, para l ∈ R+, si || f (p)-f (p) || ∞ dp (p, p) ≤ l para cualquier p, p ∈ ∆d.",
                "Para mostrar que P1 ,..., PN está destrozado, es suficiente encontrar para cada b a una \"función de demanda\" fb compatible con utilidad cóncava de tal manera que fb (pi) = yb i.",
                "Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, de ahí la secuencia de observaciones (Y1, P1), (Y11, P11), (Y12, P12) ,..., (YND, PND) es consistente con la maximización de la función de la utilidad cóncava monótona y nuevamente por el teorema de Afriats existe que admite una \"función de demanda\" FB ✷ La prueba anterior se basa en el hecho de que un agente tiene alta utilidad y utilidad marginal para bundeos muy grandes."
            ],
            "translated_text": "",
            "candidates": [
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda",
                "función de demanda"
            ],
            "error": []
        },
        "rationalizability": {
            "translated_key": "racionalización",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that <br>rationalizability</br> of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to <br>rationalizability</br> by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of <br>rationalizability</br> conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for <br>rationalizability</br> are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for <br>rationalizability</br>; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Él muestra que la \"racionalización\" de un conjunto finito de observaciones es equivalente al fuerte axioma de preferencia revelada.",
                "Richter [15] muestra que un axioma fuerte de preferencia revelada es equivalente a la \"racionalización\" por una función de utilidad monótona estrictamente cóncava.",
                "Afriat [1] ofrece otro conjunto de condiciones de \"racionalización\" que las observaciones deben satisfacer.",
                "Es interesante observar que estas condiciones necesarias y suficientes para la \"racionalización\" son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]).",
                "Este argumento muestra que AC es necesario para la \"racionalización\";El sorprendente resultado en el teorema de Afriats es que esta condición también es suficiente."
            ],
            "translated_text": "",
            "candidates": [
                "racionalización",
                "racionalización",
                "racionalización",
                "racionalización",
                "racionalización",
                "racionalización",
                "racionalización",
                "racionalización",
                "racionalización",
                "racionalización"
            ],
            "error": []
        },
        "finite set of observation": {
            "translated_key": "conjunto finito de observación",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a <br>finite set of observation</br>s is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a <br>finite set of observation</br>s is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Pregunta cuándo se puede determinar que un \"conjunto finito de observación\" es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas.",
                "Él muestra que la racionalización de un \"conjunto finito de observación\" es equivalente al fuerte axioma de preferencia revelada."
            ],
            "translated_text": "",
            "candidates": [
                "conjunto finito de observación",
                "conjunto finito de observación",
                "conjunto finito de observación",
                "conjunto finito de observación"
            ],
            "error": []
        },
        "observation finite set": {
            "translated_key": "Conjunto finito de observación",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "income-lipschitz": {
            "translated_key": "ingresos-lipschitz",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of <br>income-lipschitz</br> and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global <br>income-lipschitz</br> constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-<br>income-lipschitz</br>, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and <br>income-lipschitz</br>.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the <br>income-lipschitz</br> constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-<br>income-lipschitz</br> demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Uzawa [16] y Mas-Color [10, 11] introdujeron una noción de \"ingresos-Lipschitz\" y demostró que las funciones de demanda con esta propiedad son racionalizables.",
                "En la Sección 5, estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de rotura de grasa de la clase de todas las funciones de demanda y una clase de funciones de demanda de ingresos de Lipschitzian con una constante global de \"Lipschitz de ingresos\" global limitado.2.",
                "Una función de demanda es l- \"ingreso-lipschitz\", para l ∈ R+, si || f (p)-f (p) || ∞ dp (p, p) ≤ l para cualquier p, p ∈ ∆d.",
                "La segunda clase que consideramos es la clase de funciones de demanda derivadas de servicios públicos con soporte limitado y \"ingresos-Lipschitz\".",
                "Mostramos que la clase tiene una dimensión de rotura de grasa finita que depende del soporte y la constante de \"ingresos-Lipschitz\".",
                "Sea C un conjunto de L- \"ingresos-Lipschitz\" Funciones de demanda de ∆D a RD + para alguna constante global l ∈ R. Entonces FATC (γ) ≤ (l γ) d Prueba: Sea P1 ,..., pn ∈ ∆D ser un conjunto destrozado con testigos x1 ,..., xn ∈ Rd +."
            ],
            "translated_text": "",
            "candidates": [
                "ingresos-lipschitz",
                "ingresos-Lipschitz",
                "Ingresos Lipschitz",
                "Lipschitz de ingresos",
                "ingresos-lipschitz",
                "ingreso-lipschitz",
                "ingresos-lipschitz",
                "ingresos-Lipschitz",
                "ingresos-lipschitz",
                "ingresos-Lipschitz",
                "ingresos-lipschitz",
                "ingresos-Lipschitz"
            ],
            "error": []
        },
        "fat shattering dimension": {
            "translated_key": "dimensión de rotura de grasa",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the <br>fat shattering dimension</br>, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the <br>fat shattering dimension</br> is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of <br>fat shattering dimension</br> and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the <br>fat shattering dimension</br> of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the <br>fat shattering dimension</br>.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-<br>fat shattering dimension</br> of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite <br>fat shattering dimension</br>.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the <br>fat shattering dimension</br> of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the <br>fat shattering dimension</br> for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite <br>fat shattering dimension</br> that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite <br>fat shattering dimension</br>. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Mostramos, al calcular la \"dimensión de rotura de grasa\", que sin suposiciones previas, el conjunto de todas las funciones de demanda inducidas por las funciones de utilidad cóncava monótona es demasiado rico para ser eficientemente Pac-Learnable.",
                "Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, mostramos que la \"dimensión de rotura de grasa\" es finita y, por lo tanto, los conjuntos correspondientes son PAC-learnables.",
                "Introducimos la noción de \"dimensión de rotura de grasa\" y la usamos para idear un límite inferior en la complejidad de la muestra.",
                "En la Sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la \"dimensión de rotura de grasa\" de la clase de todas las funciones de demanda y una clase de funciones de demanda de ingresos-Lipschitzian con una constante limitada de Lipschitz de ingresos globales.2.",
                "Un análogo a esta noción de dimensión para funciones reales es la \"dimensión de rotura de grasa\".",
                "Definimos la \"dimensión destrozante de grasa\" de C, denotó FATC (γ) como el tamaño máximo de un conjunto breve γ en γ.",
                "W.L.G podemos suponer que el error está limitado (ya que estamos viendo lo que es esencialmente un conjunto finito), por lo tanto, la probabilidad de que Erσ (H, FB0)> ε no pueda ser demasiado pequeño, por lo tanto, FB0 no es pacificable con una muestra de tamaño n ✷ ✷ ✷El siguiente teorema proporciona un límite superior en la complejidad de la muestra requerida para aprender un conjunto de funciones con una \"dimensión destrozante\" finita.",
                "Como hemos visto en la Sección 4, el número de observaciones requeridas para aprender la demanda depende de la \"dimensión de rotura de grasa\" de la clase de funciones de demanda que a su vez depende de la clase de funciones de utilidad de las que se derivan.",
                "Calculamos la \"dimensión destrozante de grasa\" para dos clases de demandas.",
                "Mostramos que la clase tiene una \"dimensión de rotura de grasa\" finita que depende del soporte y la constante de ingresos-Lipschitz.",
                "Mostramos que la clase de funciones de servicios públicos que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son los ingresos-Lipschitzian tienen una \"dimensión destrozante\" finita.✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1R X1 R X1 ❈ ❈ ❜ ❜❜ R X2 R X2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad Romete el teorema X1 y X2 6."
            ],
            "translated_text": "",
            "candidates": [
                "dimensión de rompecería grasa",
                "dimensión de rotura de grasa",
                "dimensión de rompecería grasa",
                "dimensión de rotura de grasa",
                "dimensión de rompecería grasa",
                "dimensión de rotura de grasa",
                "Dimensión de rompida de grasa",
                "dimensión de rotura de grasa",
                "dimensión de rompecería grasa",
                "dimensión de rotura de grasa",
                "dimensión de rompecería grasa",
                "dimensión destrozante de grasa",
                "dimensión de rompecería grasa",
                "dimensión destrozante",
                "dimensión de rompecería grasa",
                "dimensión de rotura de grasa",
                "dimensión de rompecería grasa",
                "dimensión destrozante de grasa",
                "dimensión de rompecería grasa",
                "dimensión de rotura de grasa",
                "Dimensión de ritmo de grasa",
                "dimensión destrozante"
            ],
            "error": []
        },
        "reveal preference": {
            "translated_key": "revelar preferencia",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "machine learn": {
            "translated_key": "Aprender a la máquina",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": []
        },
        "fat shatter": {
            "translated_key": "rotura de grasa",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the <br>fat shatter</br>ing dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the <br>fat shatter</br>ing dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of <br>fat shatter</br>ing dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the <br>fat shatter</br>ing dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of <br>fat shatter</br>ing, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the <br>fat shatter</br>ing dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-<br>fat shatter</br>ing dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite <br>fat shatter</br>ing dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the <br>fat shatter</br>ing dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the <br>fat shatter</br>ing dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite <br>fat shatter</br>ing dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite <br>fat shatter</br>ing dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [
                "Mostramos, al calcular la dimensión de \"Shatter\" de grasa \", que sin suposiciones previas, el conjunto de todas las funciones de demanda inducidas por las funciones de utilidad cóncavas monótonas es demasiado rico para ser eficientemente Pac-Learnable.",
                "Sin embargo, bajo algunos supuestos previos sobre el conjunto de funciones de demanda, mostramos que la dimensión de ing \"grasa\" es finita y, por lo tanto, los conjuntos correspondientes son PAC-learnables.",
                "Introducimos la noción de dimensión de \"Shatter\" de grasa \"y la usamos para idear un límite inferior en la complejidad de la muestra.",
                "En la Sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de \"rotura de grasa\" de la clase de todas las funciones de demanda y una clase de funciones de demanda de los ingresos-Lipschitzian con una constante limitada de Lipschitz de ingresos globales.2.",
                "Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de \"destrozar grasa\", pero no lo traemos aquí, ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4.",
                "Un análogo a esta noción de dimensión para funciones reales es la dimensión de \"violación de grasa\".",
                "Definimos la dimensión γ-\"destrozada\" de C, denotó FATC (γ) como el tamaño máximo de un conjunto breve γ en γ.",
                "W.L.G podemos suponer que el error está limitado (ya que estamos viendo lo que es esencialmente un conjunto finito), por lo tanto, la probabilidad de que Erσ (H, FB0)> ε no pueda ser demasiado pequeño, por lo tanto, FB0 no es pacificable con una muestra de tamaño n ✷ ✷ ✷El siguiente teorema proporciona un límite superior en la complejidad de la muestra requerida para aprender un conjunto de funciones con una dimensión finita de \"rotura de grasa\".",
                "Como hemos visto en la Sección 4, el número de observaciones requeridas para aprender la demanda depende de la dimensión de \"rotura de grasa\" de la clase de funciones de demanda que a su vez depende de la clase de funciones de utilidad de las que se derivan.",
                "Calculamos la dimensión \"Fat Shatter\" para dos clases de demandas.",
                "Mostramos que la clase tiene una dimensión finita de \"Shatter\" Fatter \"que depende del soporte y de la constante de ingresos-Lipschitz.",
                "Mostramos que la clase de funciones de servicios públicos que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son los ingresos-Lipschitzian tienen una dimensión finita de \"rotura de grasa\".✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1R X1 R X1 ❈ ❈ ❜ ❜❜ R X2 R X2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad que rompa el teorema X1 y X2 6."
            ],
            "translated_text": "",
            "candidates": [
                "Señimiento de la grasa",
                "Shatter",
                "Señimiento de la grasa",
                "grasa",
                "Señimiento de la grasa",
                "Shatter",
                "Ratante de grasa",
                "rotura de grasa",
                "Fat Shatter",
                "destrozar grasa",
                "Señimiento de la grasa",
                "violación de grasa",
                "Señimiento de la grasa",
                "destrozada",
                "Señimiento de la grasa",
                "rotura de grasa",
                "Señimiento de la grasa",
                "rotura de grasa",
                "Señimiento de la grasa",
                "Fat Shatter",
                "Señimiento de la grasa",
                "Shatter",
                "Fatter Shatter",
                "rotura de grasa"
            ],
            "error": []
        }
    }
}