{
    "original_text": "Apache Pig is a platform for creating MapReduce workflows with Hadoop. These workflows are expressed as directed acyclic graphs (DAGs) of tasks that exist at a conceptually higher level than their implementations as series of MapReduce jobs. Pig Latin is the procedural language used for building these workflows, providing syntax similar to the declarative SQL commonly used for relational database systems. In addition to standard SQL operations, Pig can be extended with user-defined functions (UDFs) commonly written in Java. We adopted Pig for our implementation of the correlator to speed up development time, allow for ad hoc workflow changes, and to embrace the Hadoop community׳s migration away from MapReduce towards more generalized DAG processing (Mayer, 2013). Specifically, in the event that future versions of Hadoop are optimized to support paradigms other than MapReduce, Pig scripts could take advantage of these advances without recoding, whereas explicit Java MapReduce jobs would need to be rewritten.",
    "original_translation": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir.",
    "error_count": 1,
    "errors": [
        "error in ['Pig', 'Pig', 'Pig', 'cerdo', 'de cerdo']"
    ],
    "keys": {
        "Apache Pig": {
            "translated_key": "Apache Pig",
            "translated_annotated_text": "\"Apache Pig\" es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "DAG processing": {
            "translated_key": "procesamiento DAG",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios en el flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el \"procesamiento DAG\" más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "DAGs": {
            "translated_key": "DAG",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (\"DAG\") de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "directed acyclic graphs": {
            "translated_key": "gráficos acíclicos dirigidos",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como \"gráficos acíclicos dirigidos\" (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "Hadoop": {
            "translated_key": "Hadoop",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con \"Hadoop\".Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad \"Hadoop\" lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las versiones futuras de \"Hadoop\" estén optimizadas para admitir paradigmas distintos de MapReduce, los guiones de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java MapReduce Jobs explícitos necesitaría reescribirse."
        },
        "Java MapReduce": {
            "translated_key": "Java MapReduce",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las versiones futuras de Hadoop estén optimizadas para admitir paradigmas distintos de MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que los trabajos explícitos de \"Java MapReduce\" deberían reescribirse."
        },
        "MapReduce": {
            "translated_key": "MapReduce",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo \"MapReduce\" con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de \"MapReduce\".Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de \"MapReduce\" hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las versiones futuras de Hadoop estén optimizadas para admitir paradigmas que no sean \"MapReduce\", los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que los trabajos explícitos de Java \"MapReduce\" deberían reescribirse."
        },
        "MapReduce workflows": {
            "translated_key": "flujos de trabajo MapReduce",
            "translated_annotated_text": "Apache Pig es una plataforma para crear \"flujos de trabajo MapReduce\" con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "Pig": {
            "translated_key": [
                "Pig",
                "Pig",
                "Pig",
                "cerdo",
                "de cerdo"
            ],
            "translated_annotated_text": "Apache \"Pig\" es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.\"Pig\" Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, \"Pig\" se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos \"cerdo\" para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las versiones futuras de Hadoop estén optimizadas para admitir paradigmas distintos de MapReduce, los scripts \"de cerdo\" podrían aprovechar estos avances sin recodificar, mientras que los trabajos explícitos de Java MapReduce deberían reescribirse."
        },
        "Pig Latin": {
            "translated_key": "Pig Latin",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.\"Pig Latin\" es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "Pig scripts": {
            "translated_key": "scripts de cerdo",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas distintos de MapReduce, los \"scripts de cerdo\" podrían aprovechar estos avances sin recodificar, mientras que los trabajos explícitos de Java MapReduce deberían reescribirse."
        },
        "SQL": {
            "translated_key": "SQL",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar a la \"SQL\" declarativa comúnmente utilizada para los sistemas de bases de datos relacionales.Además de las operaciones estándar de \"SQL\", el cerdo se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "SQL operations": {
            "translated_key": "operaciones SQL",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las \"operaciones SQL\" estándar, el cerdo se puede extender con funciones definidas por el usuario (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "UDFs": {
            "translated_key": "UDFS",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con funciones definidas por el usuario (\"UDFS\") comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        },
        "user-defined functions": {
            "translated_key": "funciones definidas por el usuario",
            "translated_annotated_text": "Apache Pig es una plataforma para crear flujos de trabajo MapReduce con Hadoop.Estos flujos de trabajo se expresan como gráficos acíclicos dirigidos (DAG) de tareas que existen en un nivel conceptualmente más alto que sus implementaciones como serie de trabajos de MapReduce.Pig Latin es el lenguaje de procedimiento utilizado para construir estos flujos de trabajo, proporcionando una sintaxis similar al SQL declarativo comúnmente utilizado para los sistemas de bases de datos relacionales.Además de las operaciones SQL estándar, el PIG se puede extender con \"funciones definidas por el usuario\" (UDF) comúnmente escritas en Java.Adoptamos a Pig para nuestra implementación del correlacionador para acelerar el tiempo de desarrollo, permitir cambios de flujo de trabajo ad hoc y adoptar la migración de la comunidad de Hadoop lejos de MapReduce hacia el procesamiento DAG más generalizado (Mayer, 2013).Específicamente, en el caso de que las futuras versiones de Hadoop estén optimizadas para admitir paradigmas que no sean MapReduce, los scripts de cerdo podrían aprovechar estos avances sin recodificar, mientras que Java Mapreduce Jobs explícitos necesitaría reescribir."
        }
    }
}