{
    "original_text": "Note that the presented architecture works at the frame level, meaning that each single frame (plus its corresponding context) is fed-forward through the network, obtaining a class posterior probability for all of the target languages. This fact makes the DNNs particularly suitable for real-time applications because, unlike other approaches (i.e. i-vectors), we can potentially make a decision about the language at each new frame. Indeed, at each frame, we can combine the evidence from past frames to get a single similarity score between the test utterance and the targetlanguages. A simple way of doing this combination is to assume that frames are independent and multiply the posterior estimates of the last layer. The score sl for language l of a given test utterance is computed by multiplying the output probabilities pl obtained for all of its frames; or equivalently, accumulating the logs as:(6)sl=1N∑t=1Nlogp(Ll|xt​, θ)where p(Ll|xt​, θ) represents the class probability output for the language l corresponding to the input example at time t, xt by using the DNN defined by parameters θ.",
    "original_translation": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNN sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), podemos tomar una decisión sobre el lenguaje en cada nuevo cuadro.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ.",
    "error_count": 1,
    "errors": [
        "error in ['enunciado de la prueba', 'expresión de prueba']"
    ],
    "keys": {
        "accumulating the logs as:(6)sl=1N∑t=1Nlogp(Ll|xt​, θ)": {
            "translated_key": "acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ)",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNN sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), podemos tomar una decisión sobre el lenguaje en cada nuevo cuadro.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, \"acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ)\" donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje l correspondiente alEjemplo de entrada en el tiempo t, XT utilizando el DNN definido por los parámetros θ."
        },
        "assume that frames are independent and multiply the posterior estimates of the last layer": {
            "translated_key": "suponer que los marcos son independientes y multiplicar las estimaciones posteriores de la última capa",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNN sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), podemos tomar una decisión sobre el lenguaje en cada nuevo cuadro.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es \"suponer que los marcos son independientes y multiplicar las estimaciones posteriores de la última capa\".La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        },
        "combine the evidence from past frames": {
            "translated_key": "combinar la evidencia de los marcos pasados",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNN sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), podemos tomar una decisión sobre el lenguaje en cada nuevo cuadro.De hecho, en cada cuadro, podemos \"combinar la evidencia de los marcos pasados\" para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        },
        "DNN": {
            "translated_key": "DNN",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que el \"DNN\" sea particularmente adecuado para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), potencialmente podemos tomar una decisión sobre el lenguaje en cada nuevo marco.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT utilizando el \"DNN\" definido por los parámetros θ."
        },
        "DNNs": {
            "translated_key": "DNN",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que el \"DNN\" sea particularmente adecuado para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), potencialmente podemos tomar una decisión sobre el lenguaje en cada nuevo marco.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        },
        "evidence from past frames": {
            "translated_key": "evidencia de los marcos pasados",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNN sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), podemos tomar una decisión sobre el lenguaje en cada nuevo cuadro.De hecho, en cada cuadro, podemos combinar la \"evidencia de los marcos pasados\" para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        },
        "i-vectors": {
            "translated_key": "Vectores I",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNNS sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, \"Vectores I\"), podemos tomar una decisión sobre el lenguaje en cada nuevo marco.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        },
        "multiplying the output probabilities pl obtained for all of its frames": {
            "translated_key": "multiplicando las probabilidades de salida PL obtenida para todos sus marcos",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNN sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), podemos tomar una decisión sobre el lenguaje en cada nuevo cuadro.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula \"multiplicando las probabilidades de salida PL obtenida para todos sus marcos\";o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        },
        "other approaches": {
            "translated_key": "otros enfoques",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNNS sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de \"otros enfoques\" (es decir, vectores I), potencialmente podemos tomar una decisión sobre el lenguaje en cada nuevo marco.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        },
        "target languages": {
            "translated_key": "lenguajes objetivo",
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los \"lenguajes objetivo\".Este hecho hace que los DNN sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), podemos tomar una decisión sobre el lenguaje en cada nuevo cuadro.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el enunciado de la prueba y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de un enunciado de prueba dado se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        },
        "test utterance": {
            "translated_key": [
                "enunciado de la prueba",
                "expresión de prueba"
            ],
            "translated_annotated_text": "Tenga en cuenta que la arquitectura presentada funciona a nivel de cuadro, lo que significa que cada cuadro único (más su contexto correspondiente) se alimenta a través de la red, obteniendo una probabilidad posterior de clase para todos los lenguajes de destino.Este hecho hace que los DNN sean particularmente adecuados para aplicaciones en tiempo real porque, a diferencia de otros enfoques (es decir, vectores I), podemos tomar una decisión sobre el lenguaje en cada nuevo cuadro.De hecho, en cada cuadro, podemos combinar la evidencia de los marcos pasados para obtener un puntaje de similitud único entre el \"enunciado de la prueba\" y los lenguajes de Target.Una forma simple de hacer esta combinación es suponer que los marcos son independientes y multiplican las estimaciones posteriores de la última capa.La puntuación SL para el lenguaje l de una \"expresión de prueba\" dada se calcula multiplicando las probabilidades de salida PL obtenida para todos sus marcos;o de manera equivalente, acumulando los registros como: (6) sl = 1n∑t = 1nlogp (ll | xt, θ) donde p (ll | xt, θ) representa la salida de probabilidad de clase para el lenguaje L correspondiente al ejemplo de entradaEn el momento T, XT usando el DNN definido por los parámetros θ."
        }
    }
}