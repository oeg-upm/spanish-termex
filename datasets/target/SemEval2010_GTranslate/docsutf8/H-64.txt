Aprendizaje automático para la arquitectura de la información en un gran sitio web gubernamental ∗ Miles Efron School of Information & Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan ELSAS Escuela de información yLibrary Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Hill, NC Hill, NC, NC27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteca CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 Junliang@email.Unc.Edu Resumen Este documento describe la investigación en curso en la investigación en curso en curso sobre la investigación en curso.La aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del proyecto Govstat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarca adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para los arquitectos de la información. En segundo lugar, las relaciones conceptuales de documentos derivadas automáticamente son una condición previa necesaria para el despliegue del mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje conceptual basados en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en el usuario, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos sobre representaciones de texto completo y de texto completo. Categorías y descriptores de sujetos H.3.7 [Almacenamiento y recuperación de información]: problemas de sistemas de bibliotecas digitales, problemas de usuario;H.3.3 [Almacenamiento y recuperación de información]: Búsqueda de información y recuperación del diseño de términos generales, experimentación 1. Introducción El Proyecto Govstat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y del Laboratorio de Interacción Human-Computadora de la Universidad de Maryland. Citando la dificultad del usuario final para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuario a la información estadística del gobierno de los Estados Unidos que se basa en modelos de datos realistas e interfaces innovadoras de usuarios. Para habilitar dichos modelos e interfaces, proponemos un enfoque basado en datos, basado en técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital particular, el sitio web de la Oficina de Estadísticas Laborales2 (BLS), en los esfuerzos para descubrir un pequeño número de conceptos, o contenedores lingüísticamente significativos que resumen colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido web de los sitios de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya utilizan la clasificación de contenido, tanto explícita como implícitamente;dividen sus recursos manualmente por relación tópica;Organizan contenido en sistemas de archivos orientados jerárquicamente. El objetivo del presente 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 Research es desarrollar otro medio para navegar por el contenido de estas colecciones. Al analizar la distribución de términos en todos los documentos, nuestro objetivo es complementar las agencias de estructuras de información preexistentes. Las tecnologías estadísticas de aprendizaje son atractivas en este contexto en la medida en que pueden definir un datos impulsado por datos, como se opone a una estructura navigational impulsada por la agencia para un sitio. Nuestro enfoque combina técnicas de aprendizaje supervisadas y no supervisadas. Un enfoque de agrupación de documentos puro [12] para una colección tan grande y diversa como BLS condujo a resultados pobres en las pruebas tempranas [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido los encabezados de sujetos de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Por lo tanto, esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de concepto y la evaluación posterior. En la Sección 2 describimos la estructura conceptual creada por humanos previamente existente del sitio web BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejorar. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido en tres representaciones de documentos: palabra clave, solo título y texto completo. La Sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 describiendo el próximo trabajo sobre el proyecto.2. Estructurar el acceso al sitio web de BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargado de compilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, el BLS publica una amplia gama de información, destinada a diversas audiencias. El sitio web de Agencys actúa como una casa de compensación para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes de TypeSet), proporcionar acceso a la colección proporciona un fuerte desafío a los arquitectos de la información.2.1 El navegador de relaciones El punto de partida de este trabajo es la noción de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica, como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios atravesar conjuntos de datos complejos cortando iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instanciación prototipo del navegador de relaciones, aplicada al sitio web de Fedstats3. El navegador Relation admite la búsqueda de información al permitir a los usuarios formar consultas de manera gradual, cortar y volver a encender los datos a medida que sus intereses dictan. Su motivación está en consonancia con la sugerencia de Shneidermans de que las consultas y sus resultados deben estar estrechamente acopladas [2]. Por lo tanto, en la Fig3 http://www.fedstats.gov Figura 1: Prototipo del navegador de relaciones Ure 1, los usuarios pueden limitar su búsqueda de búsqueda a esos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar aún más los documentos publicados hace más de un año. Finalmente, podrían solicitar solo ver documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también se basan en la clasificación tópica. Esto presenta dos bloques de tropiezo para diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto apropiado de temas para su colección • Los mantenedores del sitio deben clasificar cada documento en sus categorías apropiadas estas tareas, problemas comunes paralelos en la comunidad de metadatos: definir elementos apropiados y marcar documentospara admitir el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desalentadores, y los métodos automáticos para acercarse a ellos son altamente deseables.2.2 Una estructura preexistente antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como empleo y desempleo, productividad e inflación y gasto.152 Figura 2: La página de inicio de BLS que esperamos inicialmente que estas categorías predefinidas pudieran usarse para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de población del navegador de relaciones por completo. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron insatisfacción con los temas existentes. Se argumentó que su forma debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información del sitio web. En otras palabras, los temas reflejaron divisiones oficiales en lugar de grupos semánticos. Los agentes de BLS sugirieron que rediseñar esta estructura de clasificación sería deseable. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de BLS comprenden una estructura clasificatoria superficial;Cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la inflación. En conjunto, la estructura de enlace de este sistema clasificador contiene 65 documentos;Es decir, excluyendo los enlaces de navegación, hay 65 documentos vinculados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento a un tema (las páginas se pueden vincular a múltiples temas). Según esta estructura de hipervínculos, definimos M, una matriz simétrica de 65 × 65, donde MIJ cuenta la cantidad de temas en los que los documentos I y J se clasifican en la página de inicio de BLS. Para analizar la redundancia inherente a la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra la traza de scree resultante4. Debido a que los 65 documentos pertenecen a al menos un tema BLS, 4 Una trama de scree muestra la magnitud del valor propio de KTH versus su rango. Durante el análisis de componentes principales, las gráficas de scrhe visualizan la cantidad de varianza capturada por cada componente.M00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 M00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 EIGENVALVALVALIGENEGEN UE MagnitudeMeigenvlue Magnitudem Eigenvluemagnitude Figura 3: Gráfico de scree de BLS Categorías del rango deM se garantiza que es menor o igual a 15 (por lo tanto, valores propios 16 ... 65 = 0). Sin embargo, lo sorprendente de la Figura 3 es la disminución precipitada de la magnitud entre los primeros cuatro valores propios. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia tópica no es en sí misma problemática. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todas las puertas de enlace a información más específica. Por lo tanto, la lista del índice de precios del productor en tres categorías podría ser confuso para los usuarios de los sitios. A la luz de este potencial de confusión y la propia solicitud de rediseño de Agencys, realizamos la tarea de descubrimiento de temas descrita en las siguientes secciones.3. Un enfoque híbrido para el descubrimiento de temas para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En los esfuerzos por dejar que los datos hablen por sí mismos, deseamos un medio de descubrimiento de concepto que no se basara en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, arrastramos el sitio web de BLS, descargando todos los documentos de texto de tipo MIME/HTML. Esto condujo a un corpus de 15,165 documentos. Basado en este corpus, esperamos derivar K ≈ 10 categorías tópicas, de modo que cada documento DI se asigne a una o más clases.153 La agrupación de documentos (cf. [16]) proporcionó una solución obvia pero solo parcial al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con la agrupación estándar son triple.1. Los grupos mutuamente exclusivos son inapropiados para identificar el contenido tópico de los documentos, ya que los documentos pueden ser sobre muchos sujetos.2. Debido a la heterogeneidad de los datos ubicados en la recopilación BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información tópica ruidosa.3. Para la aplicación al navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, la agrupación basada en términos tiende a entregar grupos a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para el descubrimiento de temas. Primero, limitamos el proceso de agrupación a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, enumerados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos sin supervisión con los métodos de aprendizaje supervisados, como se describe en la Sección 5. 4. Centrando en documentos ricos en contenido para obtener temas evidenciados empíricamente evidenciados que inicialmente recurrimos al análisis de clúster. Deje que A sea la matriz de datos N × P con N observaciones en las variables P. Por lo tanto, AIJ muestra la medición para la observación ésica en la variable JTH. Como se describe en [12], el objetivo del análisis de clúster es asignar cada una de las N observaciones a uno de un pequeño número K de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-clúster y baja correlación entre grupos. Aunque los algoritmos para lograr dicha disposición son Legión, nuestro análisis se centra en la agrupación de K-means5, durante los cuales, cada observación OI se asigna al clúster CK cuyo centroide está más cerca de él, en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo se remiten a [12] para un tratamiento exhaustivo del sujeto. La agrupación de K-means está bien estudiada en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, la agrupación de K-means requiere que el investigador especifique k, el número de grupos para definir. Al aplicar K-Means a nuestra recopilación de documentos de 15,000, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de K sugirieron que K ≈ 80 era óptimo. Esta paramterización condujo a grupos semánticamente inteligibles. Sin embargo, 80 clústeres son demasiados para aplicar una interfaz como la relación 5 Nos hemos centrado en K-means en lugar de otros algoritmos de agrupación por varias razones. El principal de ellos es la eficiencia computacional que disfruta el enfoque K-Means. Debido a que solo necesitamos una agrupación plana, los algoritmos jerárquicos más costosos hay que obtener. En el trabajo futuro, recurriremos a la agrupación basada en modelos [7] como un método más de principios para seleccionar el número de grupos y de representar grupos.navegador. Además, la granularidad de estos grupos era inadecuadamente fino. Por ejemplo, la solución de 80 grupos derivó un grupo cuyas palabras más altamente asociadas (en términos de relación logarítmica [1]) fueron fármaco, farmacia y químico. Estas palabras están ciertamente relacionadas, pero están relacionadas en un nivel de especificidad muy por debajo de lo que buscamos. Para remediar la alta dimensionalidad de los datos, resolvimos limitar el algoritmo a un subconjunto de la recopilación. En consulta con los empleados de BLS, continuamos nuestro análisis en documentos que forman una serie titulada desde el editors Desk6. Estos son breves artículos, escritos por empleados de BLS. Los agentes de BLS sugirieron que nos centramos en el escritorio de editores porque está destinado a abarcar el dominio intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio BLS. La columna de escritorio de editores se ha escrito diariamente (cinco veces por semana) desde 1998. Como tal, operamos en un conjunto de documentos n = 1279. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupación aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección BLS contiene una gran cantidad de texto no prose (es decir, tablas, listas, etc.), los documentos de escritorio de editores están escritos en prosa clara y periodística. Cada documento es muy actual, ayudando aún más al descubrimiento de las relaciones térmicas. Finalmente, la columna de escritorio de editores proporcionó un entorno de aprendizaje ideal porque está bien formado con metadatos tópicos. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de sujeto. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1.5. Combinando el descubrimiento de aprendizaje supervisado y no supervisado para obtener temas adecuados para la aplicación de una interfaz dinámica a la colección BLS, combinamos la agrupación de documentos con técnicas de clasificación de texto. Específicamente, utilizando K-means, agrupamos cada uno de los 1279 documentos en uno de los grupos K, con el número de grupos elegidos analizando la distancia cuadrada media dentro del grupo a diferentes valores de K (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad de documentcluster se mide mediante un número de valor real. Una vez que los documentos de escritorio del editor se asignaron a los grupos, construimos un clasificador K-Way que estima la fortaleza de la evidencia de que un nuevo documento DI es miembro de la clase CK. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (Prind), Bayes ingenuos y máquinas de vectores de soporte (SVM). Todos se implementaron utilizando la Biblioteca de clasificación de texto de Bow McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Los lectores interesados son remitidos al artículo de Joachims para 6 http://www.bls.gov/opub/te 154 detalles adicionales del método de clasificación. Al igual que Prind, Naive Bayes intenta clasificar los documentos en la clase más probable. Se describe en detalle en [15]. Finalmente, Vapnik [18] explicó a fondo las máquinas de vectores de soporte, y se aplicó específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección se etiquetan por medio de clasificación automática. Es decir, para cada documento DI derivamos un vector k-dimensional, cuantificando la asociación entre DI y cada clase C1... Ck. La derivación de los puntajes de los temas a través de Naive Bayes para la recolección completa de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento de la colección de cada uno de los temas descubiertos automáticamente. Estos puntajes pueden usarse para poblar una interfaz de navegador de relaciones, o se pueden agregar a un sistema de recuperación de información tradicional. Para usar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo el puntaje más alto. En el trabajo futuro, adoptaremos un método más riguroso para derivar umbrales de peso documentales. Además, se realizará la evaluación de la utilidad de los temas aprendidos para los usuarios.6. Evaluación del descubrimiento de conceptos Antes de implementar una interfaz de navegador de relaciones y emprender los estudios de usuarios asistentes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a las materias apropiadas. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, realizamos dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupación. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creadas por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de las partes de la base de datos además del escritorio del editor.6.1 Comparación de representaciones de documentos Los documentos de la columna de escritorio editores se suministraron con metadatos de palabras clave generadas por humanos. Además, los títulos de los documentos de escritorio de los editores tienden a estar pertinentes al tema de sus respectivos artículos. Con tal variedad de evidencia destilada de cada tema de los documentos, emprendimos una comparación de representaciones de documentos para el descubrimiento de temas por agrupación. Presumimos que la agrupación basada en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si el rendimiento comparable podría alcanzarse mediante métodos que no requerían una indexación humana extensa, como las representaciones de texto completo o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documento-texto completo, solo el título y solo la palabra clave generamos tres conjuntos de temas, TFull, Ttitle y TKW, respectivamente. Los temas basados en documentos de texto completo se derivaron mediante la aplicación de la agrupación de K-means a los documentos de escritorio de 1279 editores, donde cada documento estaba representado por un vector dimensional de 1908. Estas 1908 dimensiones capturaron los pesos TF.IDF [3] de cada término TI en el documento DJ, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1...20. A medida que K se acercó a la reducción de la adición de más grupos disminuyó notablemente, lo que sugiere que K ≈ 10 produciría buenas divisiones. Para seleccionar un solo valor entero, calculamos qué valor de K condujo a la menor variación en el tamaño del clúster. Esta métrica se deriva del deseo de suprimir el resultado común donde un grupo grande emerge del algoritmo K-means, acompañado por varios grupos pequeños en consecuencia. Sin motivos para creer que cualquier tema solo debería tener probabilidades previas dramáticamente altas de membresía en el documento, esta heurística condujo a kfull = 10. Los grupos basados en títulos de documentos se construyeron de manera similar. Sin embargo, en este caso, cada documento estaba representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de documentos. Utilizando el mismo método para minimizar la varianza en la membresía de clúster Ktitle: el número de grupos en la representación basada en el título también se estableció en 10. La dimensionalidad de la agrupación basada en palabras clave fue muy similar a la del enfoque basado en el título. Hubo 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue 7, donde se entiende que una palabra clave es una sola palabra o un término de múltiples palabras, como el índice de precios al consumidor. Vale la pena señalar que las palabras clave no se extrajeron de ningún vocabulario controlado;Fueron asignados a documentos por editores en el BLS. Usando las palabras clave, los documentos se agruparon en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de sujetos que se incluyeron con 1112 de los documentos de escritorio de editores. A cada uno de estos 1112 documentos se les asignó uno o más encabezados de sujetos, que fueron retenidos de todas las aplicaciones de clúster. Al igual que las palabras clave, los encabezados de los temas fueron asignados a documentos por BLS Publishers. Sin embargo, a diferencia de las palabras clave, los encabezados de los sujetos se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de sujetos deben agruparse. Para facilitar este análisis, adoptamos un enfoque conservador;Consideramos que las clasificaciones de múltiples sujetos son únicas. Por lo tanto, si el documento DI se asignó a un solo precio de sujeto, mientras que el documento DJ se asignó a dos sujetos, no se considera que las comparaciones internacionales, los precios, los documentos DI y DJ provengan de la misma clase. La Tabla 1 muestra los encabezados de los asignaturas de escritorio de los editores que fueron asignados a al menos 10 documentos. Como se señaló en la tabla, 155 Tabla 1: Editores principales encabezados de sujetos de escritorio Precios de conteo de sujetos 92 desempleo 55 Seguridad y salud ocupacional 53 Comparaciones internacionales, precios 48 Fabricación, Precios 45 Empleo 44 Productividad 40 Gastos de consumo 36 Ganancias y salarios 27 Empleo y desempleo 27Costos de compensación 25 ganancias y salarios, metro.áreas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salario, regiones 13 paradas laborales 12 ganancias y salarios, industrias 11 total 609 Tabla 2: tabla contingecy para tres representaciones de documentos representaciones correctas incorrectas incorrectas-Text 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 Hubo 19 tales temas, que cubrieron en total 609 (54%) de los documentos con sujetos asignados. Estos emparejamientos de sujetos de documentos formaron la base de nuestro análisis. El análisis limitante de los sujetos con N> 10 mantuvo las pruebas χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación del documento fue probada por su capacidad de colocar documentos con los mismos sujetos. Por lo tanto, para cada uno de los 19 encabezados de sujetos en la Tabla 1, SI, calculamos la proporción de documentos asignados a Si que cada agrupación se clasificó. Además, asumimos que cualquier clúster capturó la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo tumbo se dirigían los precios. Tomando las clasificaciones de editores de BLS como verdad terrestre, los 92 de estos documentos deberían haber terminado en el mismo clúster. Bajo la representación de texto completo, 52 de estos documentos se agruparon en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la Categoría 6. Tomando el clúster mayoritario como el supuesto hogar derecho para estos documentos, consideramos que la precisión de este agrupamiento en este tema es 52/92 = 0.56. La repetición de este proceso para cada tema en las tres representaciones condujo a la tabla de contingencia que se muestra en la Tabla 2. La superioridad obvia de la agrupación basada en palabras clave evidenciada por la Tabla 2 fue confirmada por una prueba χ2 sobre las proporciones de precisión. Comparación de la proporción Derecho y Tabla 3: Clusters basados en palabras clave Costos de costos de empleos internacionales Compensación Impensación Importación de beneficios de empleo Precios Precios Empleados Beneficios Beneficios Petróleo Ocupación Juvenil Precio Productividad Seguridad Precio Productividad Seguridad Index Operadores de salud Inflación Inflación no agrícola Casto de empleo Gasto de desempleoEl gasto de desempleo incorrecto logrado por la palabra clave y la agrupación basada en el título condujo a P 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave de escritorio de editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más altamente asociados con cada clúster, en términos de la relación log-ODDS. Además, cada clúster ha recibido una etiqueta por los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para prestar nuestro análisis de rigor y utilidad adecuados, hicimos varios supuestos simplificadores. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al tomar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto multifunta y a menudo multipart como nuestra unidad de análisis, mitigamos este problema. Analógicamente, esto es similar a considerar la ubicación de los libros en un estante de la biblioteca. Aunque un libro determinado puede cubrir muchas materias, un sistema de clasificación debería ser capaz de colocar libros que sean extremadamente similares, digamos libros sobre seguridad y salud ocupacional. La responsabilidad más grave con esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de temas, dicen los precios: internacional en temas individuales. Este aplanamiento oscurece la multivalencia de documentos. Recurrimos a una evaluación más realista de las relaciones de clase de documento en la Sección 6.2.6.2 Precisión de los clasificadores de documentos Aunque los grupos de palabras clave parecen clasificar muy bien los documentos de escritorio de editores, su descubrimiento solo resolvió la mitad del problema requerido para la implementación exitosa de una interfaz de usuario dinámica, como el navegador de relaciones. La cuestión de aproximadamente catorce mil documentos no clasificados quedó para ser abordado. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección DI, estos clasificadores dan PI, un vector K de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde PIK cuantifica la fuerza de asociación entre el documento IPI y la clase KTH. Todos los clasificadores fueron entrenados en el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento se construyeron simplemente cambiando el 156 Tabla 4: Resultados de validación cruzada para 3 clasificadores Método AV. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 Variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar los documentos correctamente, primero realizamos una validación cruzada de 10 veces en los documentos de escritorio del editor. Durante la validación cruzada, los datos se dividen aleatoriamente en N subconjuntos (en este caso n = 10). El proceso continúa manteniendo iterativamente cada uno de los sub subconjuntos como una colección de prueba para un modelo capacitado en los subconjuntos N - 1 restantes. La validación cruzada se describe en [15]. Usando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La Tabla 4 da los resultados de la validación cruzada. Aunque Naive Bayes no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra selección de Naive Bayes se debe al hecho de que parece funcionar comparablemente con el enfoque SVM para estos datos, mientras que es mucho más simple, tanto en teoría como en implementación. Debido a que solo tenemos 1279 documentos y 10 clases, el número de documentos de capacitación por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de editores, construimos un cuarto modelo, complementando los conjuntos de capacitación de cada clase consultando el Google Search Engine7 y aplicando Bayes ingenuos al conjunto de pruebas aumentadas. Para cada clase, creamos una consulta enviando los tres términos con la relación más alta de log-ODDS con esa clase. Además, cada consulta se limitó al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real varió según el tamaño del conjunto de resultados devuelto por Google). Esto condujo a un conjunto de capacitación de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de la clasificación (precisión = 58.16%, con error estándar = 0.32). Sin embargo, como discutimos a continuación, el aumento del conjunto de capacitación pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de escritorio de editores que informaron el estudio de validación cruzada puede no ser buenos predictores del rendimiento de los modelos en el resto al sitio web de BLS. Para probar la generalidad del clasificador Naive Bayes, solicitamos aportes de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue elegida por conveniencia y consistió en estudiantes de profesores y posgrado que trabajan en el proyecto Govstat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección BLS. En promedio, cada RE7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo de modelo humano en 100 documentos de muestra. Juez humano 1st Choice Model Modelo 1st Choice Model 2nd Choice N. Bayes (agosto) 14 24 N. Bayes 24 1 Juez humano 2do Modelo de elección Modelo 1st Choice Model 2nd Choice N. Bayes (agosto) 14 21 N. Bayes 21 4 4El espectador clasificó 83 documentos, colocando cada documento en tantas categorías que se muestran en la Tabla 3 como él o ella consideró conveniente. Los resultados de este experimento sugieren que el margen de mejora permanece con respecto a la generalización de toda la colección de los modelos de clase instalados en los documentos de escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales los 11 jueces humanos votaron mejor o el segundo más probable. En el contexto de este experimento, consideramos que una clasificación de primer o segundo lugar por parte de la máquina es precisa porque la interfaz del navegador de relaciones funciona en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como su segunda opción aún estaría fácilmente disponible para un usuario. Del mismo modo, una clasificación correcta en la categoría más popular o segunda más popular entre los jueces humanos se considera correcta en los casos en que un documento dado se clasificó en múltiples clases. Hubo 72 documentos multiclase en nuestra muestra, como se ve en la Figura 4. Los 28 documentos restantes se asignaron a clases 1 o 0. Bajo esta justificación, el clasificador Naive Bayes aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo Naive Bayes para generalizar desde los documentos de escritorio de los editores a la colección en su conjunto. Sin embargo, la mejora que ofrece el modelo aumentado tiene a cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo capacitado únicamente en los documentos de escritorio de editores si nos preocupamos solo con los documentos seleccionados por la mayoría de los revisores humanos-I.E.Solo clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da p = 0.02 a favor del modelo no acuático. A los fines de aplicar el navegador de relaciones a contenido complejo de la biblioteca digital (donde los documentos se clasificarán a lo largo de múltiples categorías), el modelo aumentado es preferible. Pero este no es necesariamente el caso en general. También debe decirse que el 73% de precisión bajo una condición de prueba bastante liberal deja espacio para mejorar nuestra asignación de temas a las categorías. Podemos comenzar a comprender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en todos los documentos dados por los humanos y por el modelo ingenuo de Bayes aumentado. La mayoría de los revisores ponen 157 número de clases de clases asignadas por humanos de clases de clases asignadas a humanos. 20m 202525m25m 253030m30m 303535m35m 35Figura 4: Número de clases asignadas a documentos por parte de los documentos de jueces en solo tres categorías, trabajos, beneficios y ocupaciones. Por otro lado, el clasificador ingenuo de Bayes distribuyó clases de manera más uniforme en los temas. Este comportamiento sugiere áreas para la mejora futura. Lo más importante, observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo una correlación del 68% entre los beneficios y las ocupaciones). Esto sugiere que mejorar la agrupación para producir temas que eran más casi ortogonales podría mejorar el rendimiento.7. Conclusiones y trabajo futuro Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico que se llevan a cabo aquí. Dados los cuerpos de datos cada vez más grandes y complejos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios y, al tiempo que mantiene los sistemas receptivos a los cambios en el contenido a lo largo del tiempo? Los métodos de minería de datos y aprendizaje automático tienen una gran promesa con respecto a este problema. Los métodos empíricos de descubrimiento de conocimiento pueden ayudar en la organización y la recuperación de la información. Como hemos argumentado en este documento, estos métodos también pueden estar en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisadas, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de gran alcance de la colección. Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M0.00 0.050.100.10m0.10m 0.10 0.15 Figura 5: Distribución de clases en todos los documentos en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza el aprendizaje supervisado (en particular, un clasificador ingenuo de Bayes, entrenado en palabras individuales), paraAsigne relaciones tópicas a los documentos restantes en la colección. En el estudio informado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Comparación de tres modos de representación de documento-texto completo, título solo y palabras clave encontramos una precisión del 98% medida por la colocación de documentos con encabezados de sujetos idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor dan pruebas fuertes para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramático, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que los temas de aprendizaje de un subconjunto de la colección pueden conducir a modelos sobreinfectados. Después de agrupar 1279 documentos de escritorio editores en 10 categorías, instalamos un clasificador Naive Bayes de 10 bandas para clasificar los 14,000 documentos restantes en la colección. Si bien vimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos por agrupación. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del escritorio del editor no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestro entorno, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí proporcionan un comienzo alentador para nuestro trabajo para adquirir metadatos de sujeto para interfaces dinámicas automáticamente. También sugiere que un enfoque de modelado más sofisticado podría producir 158 mejores resultados en el futuro. En el próximo trabajo experimentaremos racionalizando la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es expandir la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de editores. En el trabajo actual, hemos definido algoritmos para identificar documentos que probablemente ayuden a la tarea de descubrimiento de temas. Suministro con un conjunto de capacitación más completo, esperamos experimentar con la agrupación basada en modelos, que combina los procesos de agrupación y clasificación en un solo procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos se han reconocido durante mucho tiempo como problemas fundamentales en la recuperación de la información y otras formas de minería de texto. Sin embargo, lo que está cada vez más claro, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a los problemas en el front-end de sistemas como la arquitectura de la información y el diseño de la interfaz. Finalmente, en el futuro trabajo construiremos sobre los estudios de usuarios realizados por Marchionini y Brunk en los esfuerzos por evaluar la utilidad de las interfaces dinámicas pobladas automáticamente para los usuarios de las bibliotecas digitales.8. Referencias [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de la información: una implementación y evaluación. En Actas de la Conferencia Sigchi sobre Factores Humanos en Sistemas de Computación, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y sin etiquetar con entrenamiento co-entrenamiento. En Actas de la Undécima Conferencia Anual sobre Teoría del Aprendizaje Computacional, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación del concepto automático en la información gubernamental en línea. En Actas del Grupo de Interés Especial ASIST sobre Investigación de Clasificación (Asist Sig-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos?¿Qué método de agrupación?Respuestas a través del análisis de clúster basado en modelos. The Computer Journal, 41 (8): 578-588, 1998. [8] A. K. Jain, M. N. Murty y P. J. Flynn. Clustering de datos: una revisión. ACM Computing Surveys, 31 (3): 264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo Rocchio con TFIDF para la categorización de texto. En D. H. Fisher, Editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Autor, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU.[10] T. Joachims. Categorización de texto con máquinas vectoriales de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea de Aprendizaje Machine, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, de.[11] I. T. Jolliffe. Análisis de componentes principales. Springer, 2ª edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrar grupos en datos: una introducción al análisis de clúster. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relación general: una GUI para arquitectos de la información. Journal of Digital Information, 4 (1), 2003. http://jodi.ecs.soton.ac.uk/articles/v04/i01/marchionini/.[14] A. K. McCallum. Bow: un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupación.http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupación. En W. B. Frakes y R. Baeza-Yates, editores, recuperación de información: estructuras de datos y algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimación del número de grupos en un conjunto de datos a través de la estadística GAP, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html.[18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159