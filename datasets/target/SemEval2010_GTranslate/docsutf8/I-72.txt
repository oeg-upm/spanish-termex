Aprendizaje de las preferencias del consumidor utilizando similitud semántica ∗ Reyhan aydo˘gan reyhan.aydogan@gmail.com Pınar yolum pinar.yolum@boun.edu.tr Departamento de Ingeniería Informática Bo˘gaziçi University Bebek, 34342, Istanbul, Turquía Resumen en línea en línea, entornos dinámicos dinámicos Entorimientos dinámicos, los servicios solicitados por los consumidores no pueden ser atendidos por los proveedores. Esto requiere que los consumidores y proveedores de servicios negocien sus necesidades y ofertas de servicio. Los enfoques de negociación múltiple generalmente asumen que las partes están de acuerdo en el contenido del servicio y se centran en encontrar un consenso sobre el precio del servicio. En contraste, este trabajo desarrolla un enfoque a través del cual las partes pueden negociar el contenido de un servicio. Esto exige un enfoque de negociación en el que las partes puedan comprender la semántica de sus solicitudes y ofertas y aprender las preferencias de los demás de forma incremental con el tiempo. En consecuencia, proponemos una arquitectura en la que tanto los consumidores como los productores usan una ontología compartida para negociar un servicio. A través de interacciones repetitivas, el proveedor aprende a los consumidores necesidades con precisión y puede hacer ofertas mejor específicas. Para habilitar un aprendizaje rápido y preciso de las preferencias, desarrollamos una extensión del espacio de versiones y lo comparamos con las técnicas de aprendizaje existentes. Desarrollamos una métrica para medir la similitud semántica entre los servicios y comparamos el rendimiento de nuestro enfoque utilizando diferentes métricas de similitud. Categorías y descriptores de sujetos I.2.11 [Inteligencia artificial distribuida]: Sistemas multiagentes Algoritmos de términos generales, Experimentación 1. Introducción Enfoques actuales para el comercio electrónico Trata el precio del servicio como la construcción principal para la negociación al suponer que el contenido del servicio es fijo [9]. Sin embargo, la negociación sobre el precio presupone que otras propiedades del servicio ya se han acordado. Sin embargo, muchas veces el proveedor de servicios puede no ofrecer el servicio exacto solicitado debido a la falta de recursos, limitaciones en su política comercial, etc. [3]. Cuando este es el caso, el productor y el consumidor deben negociar el contenido del servicio solicitado [15]. Sin embargo, la mayoría de los enfoques de negociación existentes suponen que todas las características de un servicio son igualmente importantes y se concentran en el precio [5, 2]. Sin embargo, en realidad, no todas las características pueden ser relevantes y la relevancia de una característica puede variar de un consumidor a otro. Por ejemplo, el tiempo de finalización de un servicio puede ser importante para un consumidor, mientras que la calidad del servicio puede ser más importante para un segundo consumidor. Sin duda, considerar las preferencias del consumidor tiene un impacto positivo en el proceso de negociación. Para este propósito, la evaluación de los componentes del servicio con diferentes pesos puede ser útil. Algunos estudios toman estos pesos como a priori y usan los pesos fijos [4]. Por otro lado, la mayoría del productor no conoce las preferencias de los consumidores antes de la negociación. Por lo tanto, es más apropiado que el productor aprenda estas preferencias para cada consumidor. Aprendizaje de preferencias: como alternativa, proponemos una arquitectura en la que los proveedores de servicios aprendan las características relevantes de un servicio para un cliente en particular con el tiempo. Representamos las solicitudes de servicio como un vector de funciones de servicio. Utilizamos una ontología para capturar las relaciones entre los servicios y construir las características para un servicio determinado. Al utilizar una ontología común, permitimos a los consumidores y productores compartir un vocabulario común para la negociación. El servicio particular que hemos utilizado es un servicio de venta de vinos. El vendedor de vinos aprende las preferencias del vino del cliente para vender vinos mejor dirigidos. El productor modela las solicitudes del consumidor y sus ofertas de mostrador para aprender qué características son más importantes para el consumidor. Dado que no hay información presente antes de que comiencen las interacciones, el algoritmo de aprendizaje debe ser incremental para que pueda ser entrenado en el tiempo de ejecución y pueda revisarse con cada nueva interacción. Generación de servicios: incluso después de que el productor aprende las características importantes para un consumidor, necesita un método para generar ofertas que sean los más relevantes para el consumidor entre su conjunto de posibles servicios. En otras palabras, la pregunta es cómo el productor usa la información que se aprendió de los diálogos para hacer la mejor oferta para el consumidor. Por ejemplo, suponga que el productor ha aprendido que el consumidor quiere comprar un vino tinto, pero el productor solo puede ofrecer vino rosa o blanco. ¿Qué deberían ofrecer los productores 1301 978-81-904262-7-5 (RPS) c 2007 Ifaamas contienen;¿Vino blanco o vino de rosa? Si el productor tiene algún conocimiento de dominio sobre la similitud semántica (por ejemplo, sabe que los vinos rojos y rosas son más similares al vino blanco), entonces puede generar mejores ofertas. Sin embargo, además del conocimiento del dominio, esta derivación requiere métricas apropiadas para medir la similitud entre los servicios disponibles y las preferencias aprendidas. El resto de este documento está organizado de la siguiente manera: la Sección 2 explica nuestra arquitectura propuesta. La Sección 3 explica los algoritmos de aprendizaje que fueron estudiados para aprender las preferencias del consumidor. La Sección 4 estudia los diferentes mecanismos de oferta de servicios. La Sección 5 contiene las métricas de similitud utilizadas en los experimentos. Los detalles del sistema desarrollado se analizan en la Sección 6. La Sección 7 proporciona nuestra configuración experimental, casos de prueba y resultados. Finalmente, la Sección 8 analiza y compara nuestro trabajo con otro trabajo relacionado.2. Arquitectura Nuestros componentes principales son los agentes de consumidores y productores, que se comunican entre sí para realizar una negociación orientada al contenido. La Figura 1 muestra nuestra arquitectura. El agente de consumo representa al cliente y, por lo tanto, tiene acceso a las preferencias del cliente. El agente del consumidor genera solicitudes de acuerdo con estas preferencias y negocia con el productor en función de estas preferencias. Del mismo modo, el agente de productores tiene acceso al inventario de productores y sabe qué vinos están disponibles o no. Una ontología compartida proporciona el vocabulario necesario y, por lo tanto, permite un lenguaje común para los agentes. Esta ontología describe el contenido del servicio. Además, dado que una ontología puede representar conceptos, sus propiedades y sus relaciones semánticamente, los agentes pueden razonar los detalles del servicio que se está negociando. Dado que un servicio puede ser cualquier cosa como vender un automóvil, reservando una habitación de hotel, etc., la arquitectura es independiente de la ontología utilizada. Sin embargo, para que nuestra discusión sea concreta, utilizamos la conocida ontología del vino [19] con cierta modificación para ilustrar nuestras ideas y probar nuestro sistema. La ontología del vino describe diferentes tipos de vino e incluye características como color, cuerpo, bodega del vino, etc. Con esta ontología, el servicio que se está negociando entre el consumidor y el productor es el de vender vino. El repositorio de datos en la Figura 1 es utilizado únicamente por el agente del productor y contiene la información de inventario del productor. El repositorio de datos incluye información sobre los productos que posee el productor, el número de productos y calificaciones de esos productos. Las calificaciones indican la popularidad de los productos entre los clientes. Esos se utilizan para decidir qué producto se ofrecerá cuando exista más de un producto que tenga la misma similitud con la solicitud del agente del consumidor. La negociación se lleva a cabo de una manera que toma turnos, donde el agente del consumidor comienza la negociación con una solicitud de servicio en particular. La solicitud se compone de características significativas del servicio. En el ejemplo del vino, estas características incluyen color, bodega, etc. Este es el vino particular que el cliente está interesado en comprar. Si el productor tiene el vino solicitado en su inventario, el productor ofrece el vino y la negociación termina. De lo contrario, el productor ofrece un vino alternativo del inventario. Cuando el consumidor recibe una contradecería del productor, la evaluará. Si es aceptable, la negociación terminará. De lo contrario, el cliente generará una nueva solicitud o se adhirirá a la solicitud anterior. Este proceso continuará hasta que el agente del consumidor acepte algún servicio o el productor presente un servicio al consumidor. Uno de los desafíos cruciales de la negociación orientada al contenido es la generación automática de ofertas de contadores del productor de servicios. Cuando el productor construye su oferta, debe considerar la Figura 1: Arquitectura de negociación propuesta Tres cosas importantes: la solicitud actual, las preferencias del consumidor y los servicios disponibles de los productores. Tanto la solicitud actual de los consumidores como los productores poseen los servicios disponibles por el productor. Sin embargo, las preferencias de los consumidores en la mayoría de los casos no estarán disponibles. Por lo tanto, el productor tendrá que comprender las necesidades del consumidor de sus interacciones y generar una oferta de contraportada que probablemente sea aceptada por el consumidor. Este desafío se puede estudiar en tres etapas: • Aprendizaje de preferencias: ¿Cómo pueden los productores aprender sobre las preferencias de cada cliente en función de las solicitudes y las ofertas de contadores?(Sección 3) • Oferta de servicio: ¿Cómo pueden los productores revisar sus ofertas en función de las preferencias de los consumidores que han aprendido hasta ahora?(Sección 4) • Estimación de similitud: ¿Cómo puede el agente del productor estimar la similitud entre la solicitud y los servicios disponibles?(Sección 5) 3. Aprendizaje de preferencia Las solicitudes del consumidor y las ofertas de contador del productor se representan como vectores, donde cada elemento en el vector corresponde al valor de una característica. Las solicitudes de los consumidores representan productos de vino individuales, mientras que sus preferencias son limitaciones sobre las características del servicio. Por ejemplo, un consumidor puede tener preferencia por el vino tinto. Esto significa que el consumidor está dispuesto a aceptar cualquier vino ofrecido por los productores siempre que el color sea rojo. En consecuencia, el consumidor genera una solicitud en la que la función de color se establece en rojo y otras características se establecen en valores arbitrarios, p.(Medio, fuerte, rojo). Al comienzo de la negociación, el agente del productor no conoce las preferencias de los consumidores, pero necesitará aprenderlas utilizando la información obtenida de los diálogos entre el productor y el consumidor. Las preferencias denotan la importancia relativa de las características de los servicios exigidos por los agentes del consumidor. Por ejemplo, el color del vino puede ser importante, por lo que el consumidor insiste en comprar el vino cuyo color es rojo y rechaza el 1302 el sexto INTL. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) Tabla 1: Cómo DCEA funciona Tipo Muestra El conjunto más general del conjunto específico + (completo, fuerte, blanco) {(?,?,?)} {(completo, fuerte, Blanco)} {{(? -Full),? ,?}, - (completo, delicado, rosa) {?, (? -Delicado) ,?}, {(Completo, fuerte, blanco)} {?,?, (? -Rose)}} {{(? -Full),?,?}, {{(Completo, fuerte, blanco)}, + (medio, moderado, rojo) {?, (?-Delicado) ,?}, {(Medio, moderado, rojo)}} {?,?, (? -Rose)}} Las ofertas que involucran el vino cuyo color es blanco o rosa. Por el contrario, la bodega puede no ser tan importante como el color de este cliente, por lo que el consumidor puede tener una tendencia a aceptar vinos de cualquier bodega siempre que el color sea rojo. Para abordar este problema, proponemos utilizar algoritmos de aprendizaje incremental [6]. Esto es necesario ya que no hay datos de capacitación disponibles antes de que comiencen las interacciones. Investigamos particularmente dos enfoques. El primero es el aprendizaje inductivo. Esta técnica se aplica para aprender las preferencias como conceptos. Elaboramos el algoritmo de eliminación de candidatos (CEA) para el espacio de versiones [10]. Se sabe que CEA se desempeña mal si la información a aprender es disyuntiva. Curiosamente, la mayoría de las preferencias del consumidor son disyuntivas. Digamos, estamos considerando un agente que está comprando vino. El consumidor puede preferir vino tinto o vino de rosa pero no vino blanco. Para usar CEA con tales preferencias, es necesaria una modificación sólida. El segundo enfoque son los árboles de decisión. Los árboles de decisión pueden aprender de ejemplos fácilmente y clasificar las nuevas instancias como positivas o negativas. Un árbol de decisión incremental bien conocido es ID5R [18]. Sin embargo, se sabe que ID5R sufre de alta complejidad computacional. Por esta razón, en su lugar usamos el algoritmo ID3 [13] y construimos iterativamente árboles de decisión para simular el aprendizaje incremental.3.1 CEA CEA [10] es uno de los algoritmos de aprendizaje inductivo que aprende conceptos de ejemplos observados. El algoritmo mantiene dos conjuntos para modelar el concepto a aprender. El primer conjunto es el conjunto más general G. G contiene hipótesis sobre todos los valores posibles que el concepto puede obtener. Como su nombre indica, es una generalización y contiene todos los valores posibles a menos que se haya identificado los valores para no representar el concepto. El segundo conjunto es el conjunto más específico de S. S contiene solo hipótesis que se sabe que identifican el concepto que se está aprendiendo. Al comienzo del algoritmo, G se inicializa para cubrir todos los conceptos posibles, mientras que S se inicializa para estar vacío. Durante las interacciones, cada solicitud del consumidor puede considerarse como un ejemplo positivo y cada oferta de contador generada por el productor y rechazada por el agente del consumidor puede considerarse como un ejemplo negativo. En cada interacción entre el productor y el consumidor, se modifican tanto G como S y S. Las muestras negativas hacen cumplir la especialización de algunas hipótesis para que G no cubra ninguna hipótesis que acepte las muestras negativas como positivas. Cuando llega una muestra positiva, el conjunto S más específico debe generalizarse para cubrir la nueva instancia de entrenamiento. Como resultado, las hipótesis más generales y las hipótesis más especiales cubren todas las muestras de entrenamiento positivo, pero no cubren las negativas. Ingramentalmente, G se especializa y se generaliza hasta que G y S sean iguales entre sí. Cuando estos conjuntos son iguales, el algoritmo converge mediante la alcance del concepto objetivo.3.2 CEA disyuntivo Desafortunadamente, CEA se dirige principalmente a conceptos conjuntivos. Por otro lado, necesitamos aprender conceptos disyuntivos en la negociación de un servicio ya que el consumidor puede tener varios deseos alternativos. Hay varios estudios sobre el aprendizaje de conceptos disyuntivos a través del espacio de la versión. Algunos de estos enfoques usan múltiples espacios de versión. Por ejemplo, Hong et al.Mantenga varios espacios de versión mediante operación de división y fusión [7]. Para poder aprender conceptos disyuntivos, crean nuevos espacios de versión examinando la consistencia entre G y S. Tratamos el problema de no apoyar conceptos disyuntivos de CEA al extender nuestro lenguaje de hipótesis para incluir hipótesis disyuntiva además de los conjuntos y negaciones. Cada atributo de la hipótesis tiene dos partes: lista inclusiva, que contiene la lista de valores válidos para ese atributo y lista exclusiva, que es la lista de valores que no se pueden tomar para esa característica. EJEMPLO 1. Suponga que el conjunto más específico es {(ligero, delicado, rojo)} y un ejemplo positivo, (ligero, delicado, blanco) viene. El CEA original generalizará esto como (ligero, delicado,?), Lo que significa que el color puede tomar cualquier valor. Sin embargo, de hecho, solo sabemos que el color puede ser rojo o blanco. En el DCEA, lo generalizamos como {(ligero, delicado, [blanco, rojo])}. Solo cuando todos los valores existen en la lista, serán reemplazados por? En otras palabras, dejamos que el algoritmo se generalice más lentamente que antes. Modificamos el algoritmo CEA para lidiar con este cambio. El algoritmo modificado, DCEA, se da como algoritmo 1. Tenga en cuenta que en comparación con los estudios anteriores de versiones disyuntivas, nuestro enfoque utiliza solo un espacio de versión en lugar de un espacio de versión múltiple. La fase de inicialización es la misma que el algoritmo original (líneas 1, 2). Si viene alguna muestra positiva, agregamos la muestra al conjunto especial como antes (línea 4). Sin embargo, no eliminamos las hipótesis en G que no cubren esta muestra ya que G ahora contiene una disyunción de muchas hipótesis, algunas de las cuales estarán conflictivas entre sí. La eliminación de una hipótesis específica de G dará como resultado una pérdida de información, ya que no se garantiza que otras hipótesis la cubran. Después de un tiempo, algunas hipótesis en S se pueden fusionar y pueden construir una hipótesis (líneas 6, 7). Cuando llega una muestra negativa, no cambiamos S como antes. Solo modificamos las hipótesis más generales para no cubrir esta muestra negativa (líneas 11-15). A diferencia del CEA original, intentamos especializar el G mínimamente. El algoritmo elimina la hipótesis que cubre la muestra negativa (línea 13). Luego, generamos nuevas hipótesis como el número de todos los atributos posibles mediante el uso de la hipótesis eliminada. Para cada atributo en la muestra negativa, agregamos uno de ellos en cada vez a la lista exclusiva de la hipótesis eliminada. Por lo tanto, se generan todas las hipótesis posibles que no cubren la muestra negativa (línea 14). Tenga en cuenta que la lista exclusiva contiene los valores que el atributo no puede tomar. Por ejemplo, considere el atributo de color. Si una hipótesis incluye rojo en su lista exclusiva y?En su lista inclusiva, esto significa que el color puede tomar cualquier valor, excepto el rojo. El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 1303 Algoritmo 1 Algoritmo de eliminación de candidatos disyuntivos 1: G ← El conjunto de hipótesis máximas generales en H 2: s ← el conjunto de hipótesis máximas específicas en H 3: para cada ejemplo de entrenamiento,D 4: Si D es un ejemplo positivo, entonces 5: Agregue D a S 6: Si S en S se puede combinar con D para hacer un elemento, entonces 7: Combinar S y D en SD {SD es la regla S y D}8: Fin si 9: Fin si 10: si D es un ejemplo negativo, entonces 11: para cada hipótesis G en G cubre D 12: * Suponga: G = (x1, x2, ..., xn) y d = ((D1, D2, ..., DN) 13: - Eliminar G de G 14: - Agregar hipótesis G1, G2, Gn donde G1 = (x1 -d1, x2, ..., xn), g2 = (x1, x2-d2, ..., xn), ... y gn = (x1, x2, ..., xn -dn) 15: -Eliminar de g cualquier hipótesis que sea menos general que otra hipótesis en G 16: finSi el ejemplo 2. La Tabla 1 ilustra las primeras tres interacciones y el funcionamiento de DCEA. El conjunto más general y el conjunto más específico muestran el contenido de G y S después de que entra la muestra. Después de la primera muestra positiva, S se generaliza para cubrir también la instancia. La segunda muestra es negativa. Por lo tanto, reemplazamos (?,?,?) Por tres hipótesis disyuntivas;Cada hipótesis es mínimamente especializada. En este proceso, en cada momento se aplica un valor de atributo de la muestra negativa a la hipótesis en el conjunto general. La tercera muestra es positiva y generaliza aún más. Tenga en cuenta que en la Tabla 1, no eliminamos {(? -Full),?,?} Del conjunto general mientras tiene una muestra positiva como (completo, fuerte, blanco). Esto se deriva de la posibilidad de usar esta regla en la generación de otras hipótesis. Por ejemplo, si el ejemplo continúa con una muestra negativa (completa, fuerte, roja), podemos especializar la regla anterior, como {(? -Full),?, (? -Red)}. Por algoritmo 1, no nos perdemos ninguna información.3.3 ID3 ID3 [13] es un algoritmo que construye árboles de decisión de manera superior a partir de los ejemplos observados representados en un vector con pares de valores de atributos. Aplicar este algoritmo a nuestro sistema con la intención de aprender las preferencias de los consumidores es apropiado ya que este algoritmo también respalda los conceptos disyuntivos de aprendizaje además de los conceptos conjuntivos. El algoritmo ID3 se utiliza en el proceso de aprendizaje con el propósito de clasificar las ofertas. Hay dos clases: positivas y negativas. Positivo significa que la descripción del servicio posiblemente será aceptada por el agente del consumidor, mientras que lo negativo implica que el consumidor lo rechazará potencialmente. Las solicitudes de los consumidores se consideran ejemplos de capacitación positivos y todas las contra-ofertas rechazadas se consideran negativas. El árbol de decisión tiene dos tipos de nodos: nodo de hoja en el que se mantienen las etiquetas de clase de las instancias y no los nodos no hojas en los que se mantienen los atributos de prueba. El atributo de prueba en un nodo no hojado es uno de los atributos que componen la descripción del servicio. Por ejemplo, el cuerpo, el sabor, el color, etc. son los posibles atributos de prueba para el servicio de vino. Cuando queremos encontrar si la descripción del servicio dada es aceptable, comenzamos a buscar desde el nodo raíz examinando el valor de los atributos de prueba hasta alcanzar un nodo de hoja. El problema con este algoritmo es que no es un algoritmo incremental, lo que significa que todos los ejemplos de capacitación deberían existir antes del aprendizaje. Para superar este problema, el sistema mantiene las solicitudes de los consumidores durante la interacción de la negociación como ejemplos positivos y todas las contra-ofertas rechazadas por el consumidor como ejemplos negativos. Después de cada solicitud que viene, se reconstruye el árbol de decisión. Sin duda, hay un inconveniente de la reconstrucción, como la carga de proceso adicional. Sin embargo, en la práctica hemos evaluado a ID3 para que sea rápido y el costo de reconstrucción sea insignificante.4. Oferta de servicios Después de aprender las preferencias de los consumidores, el productor debe hacer una contradictorio que sea compatible con las preferencias de los consumidores.4.1 Oferta de servicio a través de CEA y DCEA Para generar la mejor oferta, el agente productor utiliza su ontología de servicio y el algoritmo CEA. El mecanismo de oferta de servicios es el mismo para el CEA original y DCEA, pero como se explica antes de que sus métodos para actualizar G y S son diferentes. Cuando el productor recibe una solicitud del consumidor, el conjunto de aprendizaje del productor está capacitado con esta solicitud como una muestra positiva. Los componentes de aprendizaje, el conjunto S más específico y el conjunto G más general se utilizan activamente para ofrecer servicio. El productor utiliza G más general, G para evitar ofrecer los servicios, que serán rechazados por el agente del consumidor. En otras palabras, filtra el servicio establecido de los servicios no deseados, ya que G contiene hipótesis que son consistentes con las solicitudes del consumidor. El conjunto más específico se usa para encontrar la mejor oferta, que es similar a las preferencias de los consumidores. Dado que el conjunto S más específico contiene las solicitudes anteriores y la solicitud actual, estimar la similitud entre este conjunto y cada servicio en la lista de servicios es muy conveniente para encontrar la mejor oferta de la lista de servicios. Cuando el consumidor inicia la interacción con el agente productor, el agente de productores carga todos los servicios relacionados en el objeto de la lista de servicios. Esta lista constituye el inventario de servicios de proveedores. Al recibir una solicitud, si el productor puede ofrecer un servicio de coincidencia exactamente, entonces lo hace. Por ejemplo, para un vino, esto corresponde a vender un vino que coincida con las características especificadas de la solicitud de los consumidores de manera idéntica. Cuando el productor no puede ofrecer el servicio según lo solicitado, intenta encontrar el servicio que sea más similar a los servicios que ha solicitado el consumidor durante la negociación. Para hacer esto, el productor tiene que calcular la similitud entre los servicios que puede ofrecer y los servicios que se han solicitado (en S). Calculamos las similitudes de varias maneras como se explicará en la Sección 5. Después de calcular la similitud de los servicios disponibles con el S actual, puede haber más de un servicio con la máxima similitud. El agente productor puede romper el empate de varias maneras. Aquí, hemos asociado un valor de calificación con cada servicio y el productor prefiere el servicio con mayor calificación a otros.4.2 Oferta de servicio a través de ID3 Si el productor aprende las preferencias de los consumidores con ID3, se aplica un mecanismo similar con dos diferencias. Primero, dado que ID3 no mantiene G, la lista de servicios no aceptados que se clasifican como negativos se eliminan de la lista de servicios. En segundo lugar, las similitudes de posibles servicios no se miden con respecto a S, sino a todas las solicitudes realizadas anteriormente.4.3 Mecanismos de oferta de servicios alternativos Además de estos tres mecanismos de oferta de servicios (oferta de servicios con CEA, oferta de servicios con DCEA y oferta de servicios con ID3), incluimos otros dos mecanismos. 1304 El sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) • Oferta de servicio aleatorio (RO): el productor genera una contabilidad al azar de la lista de servicios disponible, sin considerar las preferencias de los consumidores.• Oferta de servicio teniendo en cuenta solo la solicitud actual (SCR): el productor selecciona una oferta de contador de acuerdo con la similitud de la solicitud actual de los consumidores, pero no considera las solicitudes anteriores.5. La similitud de estimación de similitud se puede estimar con una métrica de similitud que toma dos entradas y devuelve cuán similares son. Hay varias métricas de similitud utilizadas en el sistema de razonamiento basado en casos, como la suma ponderada de la distancia euclidiana, la distancia de hamming, etc. [12]. La métrica de similitud afecta el rendimiento del sistema al tiempo que decide qué servicio es el más cercano a la solicitud de los consumidores. Primero analizamos algunas métricas existentes y luego proponemos una nueva métrica de similitud semántica llamada Similitud RP.5.1 La métrica de similitud de similitud de Tverskys compara dos vectores en términos del número de características exactamente coincidentes [17]. En la ecuación (1), Common representa el número de atributos coincidentes, mientras que diferente representa el número de diferentes atributos. Nuestra suposición actual es que α y β son iguales entre sí. SMPQ = α (común) α (común) + β (diferente) (1) Aquí, cuando se comparan dos características, asignamos cero para la diferencia y una para la similitud al omitir la cercanía semántica entre los valores de características. La métrica de similitud de Tverskys está diseñada para comparar dos vectores de características. En nuestro sistema, mientras que la lista de servicios que puede ofrecer el productor son un vector de características, el conjunto S más específico no es un vector de características. S consiste en hipótesis de vectores de características. Por lo tanto, estimamos la similitud de cada hipótesis dentro del conjunto S más específico y luego tomamos el promedio de las similitudes. Ejemplo 3. Suponga que S contiene las siguientes dos hipótesis: {{luz, moderada, (roja, blanca)}, {completa, fuerte, rosa}}. Tome el servicio S como (ligero, fuerte, rosa). Entonces la similitud del primero es igual a 1/3 y el segundo es igual a 2/3 de acuerdo con la ecuación (1). Normalmente, tomamos el promedio y obtenemos (1/3 + 2/3)/2, igualmente 1/2. Sin embargo, la primera hipótesis implica el efecto de dos solicitudes y la segunda hipótesis implica solo una solicitud. Como resultado, esperamos que el efecto de la primera hipótesis sea mayor que el de la segunda. Por lo tanto, calculamos la similitud promedio al considerar el número de muestras que las hipótesis cubren. Deje que Ch denote el número de muestras que la hipótesis H cubre y (SM (H, servicio)) denota la similitud de la hipótesis H con el servicio dado. Calculamos la similitud de cada hipótesis con el servicio dado y los peso con el número de muestras que cubren. Encontramos la similitud dividiendo la suma ponderada de las similitudes de todas las hipótesis en S con el servicio por el número de todas las muestras que están cubiertas en S. Av G - SSM (Servicio, S) = | S || H |(ch ∗ sm (h, servicio)) | S || H |CH (2) Figura 2: Taxonomía de muestra para la estimación de similitud Ejemplo 4. Para el ejemplo anterior, la similitud de (ligera, fuerte, rosa) con el conjunto específico es (2 ∗ 1/3 + 2/3)/3, igualmente 4/9. El posible número de muestras que cubre una hipótesis se puede estimar con las cardinalidades multiplicadoras de cada atributo. Por ejemplo, la cardinalidad del primer atributo es dos y los demás es igual a uno para la hipótesis dada, como {Light, Moderate, (rojo, blanco)}. Cuando los multiplicamos, obtenemos dos (2 ∗ 1 ∗ 1 = 2).5.2 Métrica de similitud LINS Se puede utilizar una taxonomía al tiempo que estima la similitud semántica entre dos conceptos. La estimación de la similitud semántica en una taxonomía IS-A se puede hacer calculando la distancia entre los nodos relacionados con los conceptos comparados. Los enlaces entre los nodos pueden considerarse como distancias. Luego, la longitud de la ruta entre los nodos indica cuán similares son los conceptos. Lin propuso una estimación alternativa para usar contenido de información en la estimación de la similitud semántica en lugar del método de conteo de borde [8]. La ecuación (3) [8] muestra la similitud de LINS donde C1 y C2 son los conceptos comparados y C0 es el concepto más específico que subsume a ambos. Además, P (c) representa la probabilidad de un objeto seleccionado arbitrario pertenece al concepto C. Similitud (C1, C2) = 2 × log P (C0) log P (C1) + log P (C2) (3) 5.3 Wu &La métrica de similitud de palmers, diferente de Lin, Wu y Palmer, usa la distancia entre los nodos en la taxonomía IS-A [20]. La similitud semántica se representa con la ecuación (4) [20]. Aquí, la similitud entre C1 y C2 se estima y C0 es el concepto más específico que subsume estas clases. N1 es el número de bordes entre C1 y C0. N2 es el número de bordes entre C2 y C0. N0 es el número de enlaces IS-A de C0 desde la raíz de la taxonomía. SIMW U & P ALMER (C1, C2) = 2 × N0 N1 + N2 + 2 × N0 (4) Métrica semántica de 5.4 RP Proponemos estimar la distancia relativa en una taxonomía entre dos conceptos utilizando las siguientes intuiciones. Usamos la Figura 2 para ilustrar estas intuiciones.• Padre versus abuelo: el padre de un nodo es más similar al nodo que los abuelos de eso. Generalización del sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 1305, un concepto resulta razonablemente en ir más lejos ese concepto. Cuanto más generales sean conceptos, menos similares son. Por ejemplo, Anywinecolor es padre de ReddishColor y ReddishColor es padre de rojo. Luego, esperamos que la similitud entre ReddishColor y Red sea mayor que la de la similitud entre cualquiera de los dos años y el rojo.• Padre versus hermano: un nodo tendría mayor similitud con su padre que con su hermano. Por ejemplo, Red y Rose son hijos de Reddishcolor. En este caso, esperamos que la similitud entre Red y Reddishcolor sea mayor que la de Red y Rose.• Hermano versus abuelo: un nodo es más similar a su hermano que a su abuelo. Para ilustrar, Anywinecolor es abuelo de rojo, y el rojo y la rosa son hermanos. Por lo tanto, posiblemente anticipamos que Red y Rose son más similares a cualquiera de los dos años y rojo. Como una taxonomía se representa en un árbol, ese árbol puede atravesarse desde el primer concepto que se compare a través del segundo concepto. Al iniciar el nodo relacionado con el primer concepto, el valor de similitud es constante e igual a uno. Este valor disminuye por una constante en cada nodo que se visite a través de la ruta que alcanzará el nodo, incluido el segundo concepto. Cuanto más corto sea el camino entre los conceptos, mayor es la similitud entre los nodos. Algoritmo 2 Estimación estimada-RP-similitud (C1, C2) requiere: Las constantes deben ser m> n> m2 donde m, n ∈ R [0, 1] 1: Similitud ← 1 2: Si C1 es igual a C2, entonces 3:Similitud de retorno 4: Fin si 5: CommonParent ← FindCommonParent (C1, C2) {CommonParent es el concepto más específico que cubre tanto C1 como C2} 6: N1 ← FindIistance (CommonParent, C1) 7: N2 ← FindIstance (CommonParent, C2){N1 y n2 son el número de enlaces entre el concepto y el concepto principal} 8: if (comunesparent == c1) o (comunesparent == c2) luego 9: similitud ← similitud ∗ m (n1+n2) 10: else 11:Similitud ← Similitud ∗ n ∗ m (n1+n2-2) 12: final si 13: return similitud la distancia relativa entre los nodos C1 y C2 se estima de la siguiente manera. A partir de C1, el árbol se atraviesa para alcanzar C2. En cada salto, la similitud disminuye ya que los conceptos se están alejando el uno del otro. Sin embargo, según nuestras intuiciones, no todos los lúpulos disminuyen la similitud por igual. Deje que M represente el factor para saltar de un niño a un padre y N representa el factor para saltar de un hermano a otro hermano. Dado que saltar de un nodo a su abuelo cuenta como dos lúpulos para padres, el factor de descuento de pasar de un nodo a su abuelo es M2. De acuerdo con las intuiciones anteriores, nuestras constantes deben estar en la forma m> n> m2, donde el valor de myn debe estar entre cero y uno. El algoritmo 2 muestra el cálculo de la distancia. Según el algoritmo, en primer lugar, la similitud se inicializa con el valor de uno (línea 1). Si los conceptos son iguales entre sí, entonces, la similitud será uno (líneas 2-4). De lo contrario, calculamos al padre común de los dos nodos y la distancia de cada concepto al padre común sin considerar al hermano (líneas 5-7). Si uno de los conceptos es igual al padre común, entonces no hay una relación entre los conceptos. Para cada nivel, multiplicamos la similitud por M y no consideramos el factor hermano en la estimación de similitud. Como resultado, disminuimos la similitud en cada nivel con la tasa de M (Line9). De lo contrario, tiene que haber una relación entre hermanos. Esto significa que tenemos que considerar el efecto de N al medir la similitud. Recuerde que hemos contado los bordes N1+N2 entre los conceptos. Dado que hay una relación entre hermanos, dos de estos bordes constituyen la relación entre hermanos. Por lo tanto, al calcular el efecto de la relación principal, usamos bordes N1+N2 −2 (línea 11). Algunas estimaciones de similitud relacionadas con la taxonomía en la Figura 2 se dan en la Tabla 2. En este ejemplo, M se toma como 2/3 y N se toma como 4/7. Tabla 2: Estimación de similitud de muestra sobre la similitud de la taxonomía de la muestra (ReddishColor, Rose) = 1 ∗ (2/3) = 0.66666667 Similitud (rojo, rosa) = 1 ∗ (4/7) = 0.5714286 similitud (cualquier inecolor, rosa) = 1∗ (2/3) 2 = 0.444444445 Similitud (W Hite, Rose) = 1 ∗ (2/3) ∗ (4/7) = 0.3809524 Para todasontología. Para evaluar la similitud del vector de características, en primer lugar estimamos la similitud para la característica uno por uno y tomamos la suma promedio de estas similitudes. Entonces el resultado es igual a la similitud semántica promedio de todo el vector de características.6. Sistema desarrollado Hemos implementado nuestra arquitectura en Java. Para aliviar las pruebas del sistema, el agente de consumo tiene una interfaz de usuario que nos permite ingresar diversas solicitudes. El agente del productor está totalmente automatizado y el trabajo de operaciones de oferta de aprendizaje y servicio como se explicó anteriormente. En esta sección, explicamos los detalles de implementación del sistema desarrollado. Usamos búho [11] como nuestro lenguaje ontología y Jena como nuestro razonador de ontología. La ontología compartida es la versión modificada de Wine Ontology [19]. Incluye la descripción del vino como concepto y diferentes tipos de vino. Todos los participantes de la negociación usan esta ontología para comprenderse mutuamente. Según la ontología, siete propiedades constituyen el concepto de vino. El agente del consumidor y el agente productor obtienen los valores posibles para estas propiedades al consultar la ontología. Por lo tanto, todos los agentes pueden alcanzar todos los valores posibles para los componentes del concepto de vino, como el color, el cuerpo, el azúcar, etc. También se describe una variedad de tipos de vinos en esta ontología como Borgoña, Chardonnay, Cheninblanc, etc. Intuitivamente, cualquier tipo de vino descrito en la ontología también representa un concepto de vino. Esto nos permite considerar instancias de vino Chardonnay como instancias de la clase de vino. Además de la descripción del vino, la información jerárquica de algunas características se puede inferir de la ontología. Por ejemplo, podemos representar la información que Europe Continent cubre el país occidental. El país occidental cubre la región francesa, que cubre algunos territorios como Loira, Burdeos, etc. Esta información jerárquica se utiliza en la estimación de la similitud semántica. En esta parte, se puede hacer algún razonamiento, como si un concepto X cubre Y e Y cubre z, entonces el concepto X cubre Z. Por ejemplo, Europa Continent cubre a Burdeos.1306 El sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) para algunas características, como el cuerpo, el sabor y el azúcar, no hay información jerárquica, pero sus valores se nivelan semánticamente. Cuando ese es el caso, damos los valores de similitud razonables para estas características. Por ejemplo, el cuerpo puede ser ligero, medio o fuerte. En este caso, suponemos que la luz es 0.66 similar al medio pero solo 0.33 a fuerte. Winestock Ontology es el inventario de productores y describe una clase de producto como producto de vino. Esta clase es necesaria para que el productor grabe los vinos que vende. La ontología involucra a los individuos de esta clase. Las personas representan los servicios disponibles que posee el productor. Hemos preparado dos ontologías de Winestock separadas para las pruebas. En la primera ontología, hay 19 productos de vino disponibles y en la segunda ontología, hay 50 productos.7. Evaluación del rendimiento Evaluamos el rendimiento de los sistemas propuestos con respecto a la técnica de aprendizaje que utilizaron, DCEA e ID3, comparándolos con el CEA, RO (para la oferta aleatoria) y SCR (la oferta solo en función de la solicitud actual). Aplicamos una variedad de escenarios en este conjunto de datos para ver las diferencias de rendimiento. Cada escenario de prueba contiene una lista de preferencias para el usuario y el número de coincidencias de la lista de productos. La Tabla 3 muestra estas preferencias y disponibilidad de esos productos en el inventario para los primeros cinco escenarios. Tenga en cuenta que estas preferencias son internas para el consumidor y el productor intenta aprenderlas durante la negociación. Tabla 3: Disponibilidad de vinos en diferentes escenarios de prueba Preferencia de identificación de la disponibilidad del consumidor (de 19) 1 vino seco 15 2 vino rojo y seco 8 3 vino rojo, seco y moderado 4 4 vino rojo y fuerte 2 5 rojo o rosa, yFuerte 3 7.1 Comparación de algoritmos de aprendizaje En comparación con los algoritmos de aprendizaje, utilizamos los cinco escenarios en la Tabla 3. Aquí, primero usamos la medida de similitud de Tverskys. Con estos casos de prueba, estamos interesados en encontrar el número de iteraciones que se requieren para que el productor genere una oferta aceptable para el consumidor. Dado que el rendimiento también depende de la solicitud inicial, repetimos nuestros experimentos con diferentes solicitudes iniciales. En consecuencia, para cada caso, ejecutamos los algoritmos cinco veces con varias variaciones de las solicitudes iniciales. En cada experimento, contamos el número de iteraciones que se necesitaban para llegar a un acuerdo. Tomamos el promedio de estos números para evaluar estos sistemas de manera justa. Como es habitual, probamos cada algoritmo con las mismas solicitudes iniciales. La Tabla 4 compara los enfoques utilizando diferentes algoritmo de aprendizaje. Cuando las grandes partes del inventario son compatibles con las preferencias de los clientes como en el primer caso de prueba, el rendimiento de todas las técnicas es casi la misma (por ejemplo, escenario 1). A medida que el número de servicios compatibles cae, Ro funciona mal como se esperaba. El segundo peor método es SCR ya que solo considera a los clientes la solicitud más reciente y no aprende de solicitudes anteriores. CEA da los mejores resultados cuando puede generar una respuesta, pero no puede manejar los casos que contienen preferencias disyuntivas, como la del escenario 5. ID3 y DCEA logran los mejores resultados. Su rendimiento es comparable y pueden manejar todos los casos, incluido el escenario 5. Tabla 4: Comparación de algoritmos de aprendizaje en términos de número promedio de interacciones Ejecute dcea scr ro cEA ID3 Escenario 1: 1.2 1.4 1.2 1.2 1.2 Escenario 2: 1.4 1.4 2.6 1.4 Escenario 3: 1.4 1.8 4.4 1.4 1.4 Escenario 4: 2.2 2.8 9.61.8 2 Escenario 5: 2 2.6 7.6 1.75+ Sin oferta 1.8 avg.De todos los casos: 1.64 2 5.08 1.51+sin oferta 1.56 7.2 Comparación de métricas de similitud para comparar las métricas de similitud que se explicaron en la Sección 5, fijamos el algoritmo de aprendizaje con DCEA. Además de los escenarios que se muestran en la Tabla 3, agregamos siguientes cinco nuevos escenarios considerando la información jerárquica.• El cliente quiere comprar vino cuya bodega se encuentra en California y cuya uva es un tipo de uva blanca. Además, la bodega del vino no debería ser costosa. Solo hay cuatro productos que cumplen con estas condiciones.• El cliente quiere comprar vino cuyo color es rojo o rosa y tipo de uva es la uva roja. Además, la ubicación del vino debe estar en Europa. Se desea que el título de dulzura esté seco o fuera de secado. El sabor debe ser delicado o moderado donde el cuerpo debe ser medio o ligero. Además, la bodega del vino debería ser una bodega costosa. Hay dos productos que cumplen con todos estos requisitos.• El cliente quiere comprar vino de rosa moderado, que se encuentra alrededor de la región francesa. La categoría de bodega debe ser una bodega moderada. Solo hay un producto que cumple con estos requisitos.• El cliente quiere comprar vino tinto caro, que se encuentra alrededor de la región de California o el vino blanco barato, que se encuentra en la región de Texas. Hay cinco productos disponibles.• El cliente quiere comprar un delicado vino blanco cuyo productor en la categoría de bodegas caras. Hay dos productos disponibles. Los primeros siete escenarios se prueban con el primer conjunto de datos que contiene un total de 19 servicios y los últimos tres escenarios se prueban con el segundo conjunto de datos que contiene 50 servicios. La Tabla 5 proporciona la evaluación del desempeño en términos del número de interacciones necesarias para llegar a un consenso. Tverskys Metric da los peores resultados ya que no considera la similitud semántica. El rendimiento de Lins es mejor que Tversky pero peor que otros. La medida de similitud métrica y RP de Wu Palmers casi dan el mismo rendimiento y mejor que otros. Cuando se examinan los resultados, considerar la cercanía semántica aumenta el rendimiento.8. Discusión Revisamos la literatura reciente en comparación con nuestro trabajo. Tama et al.[16] propone un nuevo enfoque basado en la ontología para la negociación. Según su enfoque, los protocolos de negociación utilizados en el comercio electrónico pueden modelarse como ontologías. Por lo tanto, los agentes pueden realizar el protocolo de negociación mediante el uso de esta ontología compartida sin la necesidad de ser difíciles de codificar los detalles del protocolo de negociación. Mientras que el sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 1307 Tabla 5: Comparación de métricas de similitud en términos de número de interacciones Ejecutar Tversky Lin Wu Palmer RP Escenario 1: 1.2 1.2 1 1 Escenario 2: 1.4 1.4 1.6 1.6 Escenario 3: 1.41.8 2 2 Escenario 4: 2.2 1 1.2 1.2 Escenario 5: 2 1.6 1.6 1.6 Escenario 6: 5 3.8 2.4 2.6 Escenario 7: 3.2 1.2 1 1 Escenario 8: 5.6 2 2 2.2 Escenario 9: 2.6 2.2 2.2 2.6 Escenario 10: 4.4 2 22 1.8 Promedio de todos los casos: 2.9 1.82 1.7 1.76 Tama et al.Modele el protocolo de negociación utilizando ontologías, en su lugar, hemos modelado el servicio a negociar. Además, hemos creado un sistema con el que se pueden aprender las preferencias de negociación. Sadri et al.Negociación del estudio en el contexto de la asignación de recursos [14]. Los agentes tienen recursos limitados y necesitan requerir recursos faltantes de otros agentes. Se propone un mecanismo que se basa en secuencias de diálogo entre los agentes como una solución. El mecanismo se basa en el ciclo de agente Observe-think-acción. Estos diálogos incluyen ofrecer recursos, intercambios de recursos y ofrecer recursos alternativos. Cada agente en el sistema planea sus acciones para alcanzar un estado de meta. Contrariamente a nuestro enfoque, el estudio de Sadri et al.s no se preocupa por las preferencias de aprendizaje entre sí. BrZostowski y Kowalczyk proponen un enfoque para seleccionar un socio de negociación apropiado mediante la investigación de negociaciones anteriores de atributos múltiples [1]. Para lograr esto, utilizan el razonamiento basado en casos. Su enfoque es probabilístico ya que el comportamiento de los socios puede cambiar en cada iteración. En nuestro enfoque, estamos interesados en negociar el contenido del servicio. Después de que el consumidor y el productor acuerden el servicio, los mecanismos de negociación orientados a los precios pueden usarse para acordar el precio. Fátima et al.Estudie los factores que afectan la negociación, como las preferencias, la fecha límite, el precio, etc., ya que el agente que desarrolla una estrategia contra su oponente debería considerarlos a todos [5]. En su enfoque, el objetivo del agente del vendedor es vender el servicio por el precio más alto posible, mientras que el objetivo del agente del comprador es comprar el bien con el precio más bajo posible. El intervalo de tiempo afecta a estos agentes de manera diferente. En comparación con Fátima et al.Nuestro enfoque es diferente. Si bien estudian el efecto del tiempo en la negociación, nuestro enfoque es en las preferencias de aprendizaje para una negociación exitosa. Faratin et al.Proponga un mecanismo de negociación de problemas múltiples, donde las variables de servicio para la negociación, como el precio, la calidad del servicio, etc., se consideran negociadas entre sí (es decir, un precio más alto para la entrega más temprana) [4]. Generan un modelo heurístico para las compensaciones que incluyen una estimación de similitud difusa y una exploración de escalada para ofertas posiblemente aceptables. Aunque abordamos un problema similar, aprendemos las preferencias del cliente mediante la ayuda del aprendizaje inductivo y generamos contraofers de acuerdo con estas preferencias aprendidas. Faratin et al.Solo use la última oferta hecha por el consumidor para calcular la similitud para elegir la contradictorio. A diferencia de ellos, también tenemos en cuenta las solicitudes anteriores del consumidor. En sus experimentos, Faratin et al.Suponga que los pesos para las variables de servicio se fijan a priori. Por el contrario, aprendemos estas preferencias con el tiempo. En nuestro trabajo futuro, planeamos integrar el razonamiento ontológico en el algoritmo de aprendizaje para que la información jerárquica se pueda aprender de la jerarquía de relaciones de subsunción. Además, al usar relaciones entre las características, el productor puede descubrir nuevos conocimientos del conocimiento existente. Estas son direcciones interesantes que seguiremos en nuestro trabajo futuro.9. REFERENCIAS [1] J. BRZOSTOWSKI Y R. KOWALCZYK. Sobre el razonamiento basado en casos posibilidades para seleccionar socios para la negociación de agentes de atributo múltiple. En Actas del 4to Intl. Conferencia conjunta sobre agentes autónomos y sistemas multiagentes (AAMAS), páginas 273-278, 2005. [2] L. Busch e I. Horstman. Un comentario sobre las negociaciones de emisión por emisión. Juegos y comportamiento económico, 19: 144-148, 1997. [3] J. K. Debenham. Gestión de la negociación del mercado electrónico en contexto con un sistema multiagente. En Actas 21a Conferencia Internacional sobre Sistemas Basados en el Conocimiento e Inteligencia Artificial Aplicada, ES2002:, 2002. [4] P. Faratin, C. Sierra y N. R. Jennings. Uso de criterios de similitud para hacer compensaciones de problemas en negociaciones automatizadas. Artificial Intelligence, 142: 205-237, 2002. [5] S. Fatima, M. Wooldridge y N. Jennings. Agentes óptimos para la negociación de múltiples problemas. En proceder del segundo intl. Conferencia conjunta sobre agentes autónomos y sistemas múltiples (AAMAS), páginas 129-136, 2003. [6] C. Giraud-Carrier. Una nota sobre la utilidad del aprendizaje incremental. AI Communications, 13 (4): 215-223, 2000. [7] T.-P.Hong y S.-S.Tseng. Dividir y fusionar espacios de versión para aprender conceptos disyuntivos. Transacciones IEEE sobre conocimiento e ingeniería de datos, 11 (5): 813-815, 1999. [8] D. Lin. Una definición teórica de similitud de información. En Proc.15º Conf. Internacional.En el aprendizaje automático, páginas 296-304. Morgan Kaufmann, San Francisco, CA, 1998. [9] P. Maes, R. H. Guttman y A. G. Moukas. Agentes que compran y venden. Comunicaciones de la ACM, 42 (3): 81-91, 1999. [10] T. M. Mitchell. Aprendizaje automático. McGraw Hill, NY, 1997. [11] Owl. OWL: Guía de lenguaje de ontología web, 2003. http://www.w3.org/tr/2003/cr-owl-guide-20030818/.[12] S. K. Pal y S. C. K. Shiu. Fundamentos del razonamiento basado en casos blandos. John Wiley & Sons, Nueva Jersey, 2004. [13] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1 (1): 81-106, 1986. [14] F. Sadri, F. Toni y P. Torroni. Diálogos para la negociación: variedades de agentes y secuencias de diálogo. En Atal 2001, documentos revisados, volumen 2333 de LNAi, páginas 405-421. Springer-Verlag, 2002. [15] M. P. Singh. Comercio electrónico orientado al valor. IEEE Internet Computing, 3 (3): 6-7, 1999. [16] V. Tamma, S. Phelps, I. Dickinson y M. Wooldridge. Ontologías para apoyar la negociación en comercio electrónico. Aplicaciones de ingeniería de inteligencia artificial, 18: 223-236, 2005. [17] A. Tversky. Características de similitud. Psychological Review, 84 (4): 327-352, 1977. [18] P. E. Utgoff. Inducción incremental de árboles de decisión. Machine Learning, 4: 161-186, 1989. [19] Wine, 2003. http://www.w3.org/tr/2003/cr-owl-guide20030818/wine.rdf.[20] Z. Wu y M. Palmer. Semántica verbal y selección léxica. En 32º. Reunión anual de la Asociación de Lingüística Computacional, páginas 133-138, 1994. 1308 El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07)