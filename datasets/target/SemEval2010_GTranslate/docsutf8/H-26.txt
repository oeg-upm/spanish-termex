Un método de vector de soporte para optimizar la precisión promedio de la Universidad de Yisong Yue Cornell Ithaca, NY, EE. UU. Yyue@cs.cornell.edu Thomas Finley Cornell University Ithaca, NY, EE. UU.@cs.cornell.edu Thorsten Joachims Cornell University Ithaca, NY, EE. UU. TJ@cs.cornell.edu Abstract Machine Learning se usa comúnmente para mejorar los sistemas de recuperación clasificados. Debido a las dificultades computacionales, se han desarrollado pocas técnicas de aprendizaje para optimizar directamente la precisión promedio media (MAP), a pesar de su uso generalizado en la evaluación de dichos sistemas. Los enfoques existentes de optimización del mapa no encuentran una solución globalmente óptima o son computacionalmente costosos. En contraste, presentamos un algoritmo general de aprendizaje SVM que encuentra eficientemente una solución globalmente óptima para una relajación directa del mapa. Evaluamos nuestro enfoque utilizando los corpus de seguimiento web TREC 9 y TREC 10 (WT10G), comparando contra SVM optimizados para la precisión y Rocarea. En la mayoría de los casos, mostramos nuestro método para producir mejoras estadísticamente significativas en los puntajes de los mapas. Categorías y descriptores de sujetos H.3.3 [Búsqueda y recuperación de información]: Modelos de recuperación Algoritmo de términos generales, teoría, experimentación 1. Introducción Los sistemas de recuperación de información de última generación utilizan comúnmente técnicas de aprendizaje automático para aprender funciones de clasificación. Sin embargo, la mayoría de los enfoques actuales no optimizan para la medida de evaluación utilizada con mayor frecuencia, a saber, la precisión promedio media (MAP). En cambio, los algoritmos actuales tienden a adoptar uno de los dos enfoques generales. El primer enfoque es aprender un modelo que estima la probabilidad de que un documento sea relevante dada una consulta (por ejemplo, [18, 14]). Si se resuelve de manera efectiva, la clasificación con el mejor rendimiento del mapa puede derivarse fácilmente de las probabilidades de relevancia. Sin embargo, lograr un mapa alto solo requiere encontrar un buen pedido de los documentos. Como resultado, encontrar buenas probabilidades requiere resolver un problema más difícil de lo necesario, lo que probablemente requiere más datos de capacitación para lograr el mismo rendimiento del mapa. El segundo enfoque común es aprender una función que maximice una medida sustituta. Las medidas de rendimiento optimizadas incluyen precisión [17, 15], Rocarea [1, 5, 10, 11, 13, 21] o modificaciones de Rocarea [4] y NDCG [2, 3]. Aprender un modelo para optimizar para tales medidas podría dar lugar al rendimiento del mapa subóptimo. De hecho, aunque algunos sistemas anteriores han obtenido un buen rendimiento del mapa, se sabe que ni lograr una precisión óptima ni Rocarea puede garantizar un rendimiento óptimo del mapa [7]. En este artículo, presentamos un enfoque general para las funciones de clasificación de aprendizaje que maximizan el rendimiento del mapa. Específicamente, presentamos un algoritmo SVM que a nivel mundial optimiza una relajación de mapa de la pérdida de bisagra. Este enfoque simplifica el proceso de obtener funciones de clasificación con un alto rendimiento del mapa evitando pasos intermedios y heurísticas adicionales. El nuevo algoritmo también hace que conceptualmente sea tan fácil optimizar los SVM para el mapa como era posible solo para la precisión y ROCAREA. En contraste con el trabajo reciente, optimización directamente para el rendimiento del mapa de Metzler & Croft [16] y Caruana et al.[6], nuestra técnica es computacionalmente eficiente al tiempo que encuentra una solución globalmente óptima. Al igual que [6, 16], nuestro método aprende un modelo lineal, pero es mucho más eficiente en la práctica y, a diferencia de [16], puede manejar muchos miles de características. Ahora describimos el algoritmo en detalle y proporcionamos pruebas de corrección. Después de esto, proporcionamos un análisis del tiempo de ejecución. Terminamos con los resultados empíricos de los experimentos en el Corpus de pista web TREC 9 y TREC 10. También hemos desarrollado un paquete de software que implementa nuestro algoritmo que está disponible para uso público1.2. El problema de aprendizaje que sigue a la configuración de aprendizaje automático estándar, nuestro objetivo es aprender una función h: x → y entre un espacio de entrada x (todas las consultas posibles) y el espacio de salida Y (clasificaciones sobre un corpus). Para cuantificar la calidad de una predicción, ˆy = h (x), consideraremos una función de pérdida ∆: y × y →.∆ (y, ˆy) cuantifica la penalización por hacer una predicción ˆy si la salida correcta es y. La función de pérdida nos permite incorporar medidas de rendimiento específicas, que explotaremos 1 http://svmrank.yisongyue.com para optimizar el mapa. Nos restringimos al escenario de aprendizaje supervisado, donde los pares de entrada/salida (x, y) están disponibles para el entrenamiento y se supone que provienen de alguna distribución fija P (x, y). El objetivo es encontrar una función h de tal manera que el riesgo (es decir, pérdida esperada), r∆ p (h) = z x × y ∆ (y, h (x)) dp (x, y) se minimice. Por supuesto, P (x, y) es desconocido. Pero dado un conjunto finito de pares de entrenamiento, s = {(xi, yi) ∈ X × Y: i = 1 ,..., n}, el rendimiento de H en S puede medirse por el riesgo empírico, r∆ s (h) = 1 n nx i = 1 ∆ (yi, h (xi)). En el caso de aprender una función de recuperación clasificada, X denota un espacio de consultas, y y el espacio de clasificaciones (posiblemente débiles) sobre algún corpus de documentos c = {d1 ,..., D | C |}. Podemos definir la pérdida promedio de precisión como ∆map (y, ˆy) = 1 - mapa (rango (y), rango (ˆy)), donde el rango (y) es un vector de los valores de rango de cada documento en C. por ejemplo, para un corpus de dos documentos, {d1, d2}, con d1 que tiene rango más alto que d2, rango (y) = (1, 0). Suponemos que las clasificaciones verdaderas tienen dos valores de rango, donde los documentos relevantes tienen valor 1 de rango 1 y documentos no relevantes Valor de rango 0. Además, asumimos que todas las clasificaciones predichas son clasificaciones completas (sin lazos). Sea p = rango (y) y ˆp = rango (ˆy). El puntaje de precisión promedio se define como map (p, ˆp) = 1 rel x j: pj = 1 prec@j, donde rel = | {i: pi = 1} |es el número de documentos relevantes, y prec@j es el porcentaje de documentos relevantes en los documentos J superiores en la clasificación predicha ˆy. El mapa es la media de los puntajes de precisión promedio de un grupo de consultas.2.1 MAP vs ROCAREA La mayoría de los algoritmos de aprendizaje se optimizan para la precisión o ROCAREA. Si bien la optimización de estas medidas puede lograr un buen rendimiento del mapa, usamos dos ejemplos simples para mostrar que también puede ser subóptimo en términos de mapa. Rocarea asigna la misma penalización a cada pedido erróneo de un par relevante/no relevante. Por el contrario, MAP asigna mayores sanciones a los errores más altos en la clasificación prevista. Usando nuestra notación, Rocarea se puede definir como roc (p, ˆp) = 1 rel · (| c | - rel) x i: pi = 1 x j: pj = 0 1 [ˆpi> ˆpj], donde p es el verdadero(débil) Ranking, ˆp es la clasificación predicha, y 1 [b] es la función indicadora condicionada en b.ID de DOC 1 2 3 4 5 6 7 8 P 1 0 0 0 0 0 1 1 0 Rango (H1 (x)) 8 7 6 5 4 3 2 1 Rango (H2 (x)) 1 2 3 4 5 6 7 8 Tabla1: Ejemplo y modelos de juguete Suponga que tenemos un espacio de hipótesis con solo dos funciones de hipótesis, H1 y H2, como se muestra en la Tabla 1. Estas dos hipótesis predicen una clasificación para la consulta X sobre un corpus de ocho documentos. Mapa de hipótesis Rocarea H1 (X) 0.59 0.47 H2 (X) 0.51 0.53 Tabla 2: Performance de los modelos de juguete La Tabla 2 muestra el mapa y las puntuaciones de Rocarea de H1 y H2. Aquí, un método de aprendizaje que optimiza para Rocarea elegiría H2, ya que eso da como resultado una puntuación ROCAREA más alta, pero esto produce una puntuación de MAP subóptima.2.2 Mapa vs precisión utilizando un ejemplo muy similar, ahora demostramos cómo la optimización para la precisión podría dar como resultado un mapa subóptimo. Los modelos que optimizan para la precisión no se preocupan directamente por la clasificación. En cambio, aprenden un umbral de tal manera que los documentos que obtienen puntaje más alto que el umbral pueden clasificarse como relevantes y los documentos que tienen una puntuación más baja como no relevante. Doc ID 1 2 3 4 5 6 7 8 9 10 11 P 1 0 0 0 0 0 1 1 1 1 0 0 Rango (H1 (x)) 11 10 9 8 7 6 5 4 3 2 1 Rango (H2 (x))1 2 3 4 5 6 7 8 9 10 11 Tabla 3: Ejemplo de juguete y modelos Consideramos nuevamente un espacio de hipótesis con dos hipótesis. La Tabla 3 muestra las predicciones de las dos hipótesis en una sola consulta x.Mapa de hipótesis mejor acc.H1 (Q) 0.70 0.64 H2 (Q) 0.64 0.73 Tabla 4: Rendimiento de los modelos de juguete La Tabla 4 muestra el mapa y las mejores puntuaciones de precisión de H1 (Q) y H2 (Q). La mejor precisión se refiere a la mayor precisión alcanzable en esa clasificación al considerar todos los umbrales posibles. Por ejemplo, con H1 (Q), un umbral entre los documentos 1 y 2 da 4 errores (documentos 6-9 clasificados incorrectamente como no relevantes), lo que produce una precisión de 0.64. Del mismo modo, con H2 (Q), un umbral entre los documentos 5 y 6 da 3 errores (documentos 10-11 clasificados incorrectamente como relevantes, y el documento 1 como no relevante), lo que produce una precisión de 0.73. Un método de aprendizaje que optimiza para la precisión elegiría H2, ya que eso da como resultado una puntuación de precisión más alta, pero esto produce una puntuación de mapa subóptima.3. Optimización de la precisión promedio, construimos sobre el enfoque utilizado por [13] para optimizar Rocarea. Sin embargo, a diferencia de Rocarea, MAP no se descompone linealmente en los ejemplos y requiere un algoritmo sustancialmente extendido, que describimos en esta sección. Recuerde que la clasificación verdadera es una clasificación débil con dos valores de rango (relevantes y no relevantes). Deje que CX y C¯x denoten el conjunto de documentos relevantes y no relevantes de C para la consulta X, respectivamente. Nos centramos en las funciones que se parametrizan por un vector de peso W, y por lo tanto deseamos encontrar W para minimizar el riesgo empírico, r∆ s (w) ≡ r∆ s (h (·; w)). Nuestro enfoque es aprender una función discriminante F: x × y → sobre pares de entrada-salida. Dada la consulta x, podemos derivar una predicción encontrando la clasificación y que maximiza la función discriminante: h (x; w) = argmax y∈Y f (x, y; w).(1) Suponemos que F es lineal en alguna representación de características combinadas de entradas y salidas ψ (x, y) ∈ Rn, es decir, F (x, y; w) = wt ψ (x, y).(2) La función de característica combinada que usamos es ψ (x, y) = 1 | cx |· | C¯x |X i: di∈Cx x j: dj ∈C¯x [yij (φ (x, di) - φ (x, dj))], donde φ: x × c → n es una función de mapeo de características de una consulta/Documentar el par a un punto en el espacio n dimensional2. Representamos las clasificaciones como una matriz de pedidos por pares, y ⊂ {−1, 0, +1} | c | × | c |. Para cualquier y ∈ Y, yij = +1 si Di se clasifica por delante de DJ, y yij = −1 si DJ se clasifica por delante de DI, y yij = 0 si DI y DJ tienen igual rango. Consideramos solo matrices que corresponden a clasificaciones válidas (es decir, obedecer la antisimetría y la transitividad). Intuitivamente, ψ es una suma sobre las diferencias vectoriales de todos los emparejamientos de documentos relevantes/no relevantes. Como asumimos que las clasificaciones predichas son clasificaciones completas, YIJ es +1 o −1 (nunca 0). Dado un vector de peso aprendido w, predecir una clasificación (es decir, la ecuación de resolución (1)) dada la consulta x se reduce a elegir cada YIJ para maximizar WT ψ (x, y). Como también se discute en [13], esto se logra clasificando los documentos por WT φ (x, d) en orden descendente. Más adelante discutiremos las opciones de φ que utilizamos para nuestros experimentos.3.1 SVM estructurales La formulación anterior es muy similar a aprender un modelo lineal directo mientras se capacita en la diferencia por pares de emparejamientos de documentos relevantes/no relevantes. Muchos enfoques basados en SVM se optimizan sobre estas diferencias por pares (por ejemplo, [5, 10, 13, 4]), aunque estos métodos no optimizan para MAP durante el entrenamiento. Anteriormente, no estaba claro cómo incorporar funciones de pérdida multivariadas no lineales, como la pérdida de mapas directamente en problemas de optimización global, como la capacitación SVM. Ahora presentamos un método basado en SVM estructurales [19] para abordar este problema. Usamos la formulación SVM estructural, presentada en el problema de optimización 1, para aprender un w ∈ Rn. Problema de optimización 1. (SVM estructural) Min W, ξ≥0 1 2 W 2 + C N Nx I = 1 ξi (3) S.T.∀i, ∀y ∈ Y \ yi: wt ψ (xi, yi) ≥ wt ψ (xi, y) + ∆ (yi, y) - ξi (4) La función objetivo que se minimiza (3) es una compensación entreComplejidad del modelo, W 2, y una relajación de pérdida de bisagra de la pérdida de mapas, p ξi. Como es habitual en el entrenamiento SVM, C es un 2 Por ejemplo, una dimensión podría ser la cantidad de veces que las palabras de consulta aparecen en el documento. Algoritmo 1 Algoritmo de plano de corte para resolver OP 1 dentro de la tolerancia.1: Entrada: (x1, y1) ,..., (xn, yn), c, 2: wi ← ∅ para todos i = 1 ,..., N 3: Repita 4: para i = 1 ,..., n do 5: h (y; w) ≡ ∆ (yi, y) + wt ψ (xi, y) - wt ψ (xi, yi) 6: Compute ˆy = argmaxy∈Y H (y; W) 7: Computξi = max {0, maxy∈Wi h (y; w)} 8: si h (ˆy; w)> ξi + entonces 9: wi ← wi ∪ {ˆy} 10: w ← optimizar (3) sobre w = sI WI 11: Fin si 12: finalice para 13: hasta que no haya cambiado WI durante el parámetro de iteración que controla esta compensación y puede ajustarse para lograr un buen rendimiento en diferentes tareas de capacitación. Para cada (xi, yi) en el conjunto de entrenamiento, se agrega un conjunto de restricciones de la forma en la ecuación (4) al problema de optimización. Tenga en cuenta que wt ψ (x, y) es exactamente nuestra función discriminante f (x, y; w) (ver ecuación (2)). Durante la predicción, nuestro modelo elige la clasificación que maximiza el discriminante (1). Si el valor discriminante para una clasificación incorrecta y es mayor que para la verdadera clasificación yi (por ejemplo, F (xi, y; w)> f (xi, yi; w)), entonces la variable de holgura correspondiente, ξi, debe ser al menos∆ (yi, y) para que esa restricción esté satisfecha. Por lo tanto, la suma de las holguras, p ξi, los límites superiores la pérdida del mapa. Esto se indica formalmente en la Propuesta 1. Proposición 1. Sea ξ ∗ (w) la solución óptima de las variables flojas para OP 1 para un vector de peso dado w.Entonces 1 n pn i = 1 ξi es un límite superior en el riesgo empírico r∆ s (w).(Ver [19] para la prueba) La propuesta 1 muestra que OP 1 aprende una función de clasificación que optimiza un límite superior en el error del mapa en el conjunto de entrenamiento. Desafortunadamente, hay un problema: se requiere una restricción para cada salida incorrecta posible y, y el número de posibles salidas incorrectas es exponencial en el tamaño de C. Afortunadamente, podemos emplear el Algoritmo 1 para resolver OP 1. El algoritmo 1 es un algoritmo de plano de corte, introduciendo iterativamente restricciones hasta que hayamos resuelto el problema original dentro de una tolerancia deseada [19]. El algoritmo comienza sin restricciones, y se encuentra iterativamente para cada ejemplo (xi, yi) la salida ˆy asociada con la restricción más violada. Si la restricción correspondiente es violada por más de lo que introducimos en el conjunto de trabajo WI de las restricciones activas, por ejemplo, I, y volver a resolver (3) utilizando el W. Actualizado se puede demostrar que el algoritmo 1S externo se garantiza que se detenga dentro deUn número polinomial de iteraciones para cualquier precisión deseada. Teorema 1. Sea ¯r = maxi maxy ψ (xi, yi) - ψ (xi, y), ¯∆ = maxi maxy ∆ (yi, y), y para cualquier> 0, el algoritmo 1 termina después de agregar como máximo max  ¯ ¯ ¯ ¯ ¯, 8c ¯∆ ¯r2 2 FF restricciones al conjunto de trabajo W. (ver [19] para la prueba) Sin embargo, dentro del bucle interno de este algoritmo tenemos que calcular argmaxy∈Y H (y; w), donde h (y;w) = ∆ (yi, y) + wt ψ (xi, y) - wt ψ (xi, yi), o de manera equivalente, argmax y∈Y ∆ (yi, y) + wt ψ (xi, y), ya que wtΨ (xi, yi) es constante con respecto a y. Aunque estrechamente relacionado con el procedimiento de clasificación, esto tiene la complicación sustancial de que debemos lidiar con el término adicional ∆ (yi, y). Sin la capacidad de encontrar eficientemente la restricción más violada (es decir, resolver argmaxy∈Y h (y, w)), el procedimiento de generación de restricciones no es manejable.3.2 Encontrar la restricción más violada usando OP 1 y optimizar a la pérdida de rocarea (∆ROC), el problema de encontrar la restricción más violada o resolver argmaxy∈ H (y, w) (en adelante argmax h), se aborda en [13]. Resolver Argmax H para ∆map es más difícil. Esto se debe principalmente a que Rocarea se descompone muy bien en una suma de puntajes calculados de forma independiente en cada orden relativo de un par de documentos relevante/no relevante. El mapa, por otro lado, no se descompone de la misma manera que Rocarea. La principal contribución algorítmica de este documento es un método eficiente para resolver Argmax H para ∆MAP. Una propiedad útil de ∆map es que es invariante al intercambiar dos documentos con igual relevancia. Por ejemplo, si los documentos DA y DB son relevantes, entonces intercambiar las posiciones de DA y DB en cualquier clasificación no afecta a ∆map. Por extensión, ∆map es invariante a cualquier permutación arbitraria de los documentos relevantes entre ellos y de los documentos no relevantes entre ellos. Sin embargo, esta reshu afectará la puntuación discriminante, wt ψ (x, y). Esto nos lleva a la observación 1. Observación 1. Considere las clasificaciones que están limitadas al fijar la relevancia en cada posición en la clasificación (por ejemplo, el tercer documento en la clasificación debe ser relevante). Cada clasificación que satisface el mismo conjunto de restricciones tendrá el mismo ∆map. Si los documentos relevantes son ordenados por WT φ (x, d) en orden descendente, y los documentos no relevantes también están ordenados por WT φ (x, d), entonces el intercalación de las dos listas ordenadas que satisface las restricciones maximizaránH para ese conjunto restringido de clasificaciones. La observación 1 implica que en la clasificación que maximiza H, los documentos relevantes serán ordenados por WT φ (x, d), y los documentos no relevantes también se clasificarán de la misma manera. Al clasificar primero los documentos relevantes y no relevantes, el problema se simplifica para encontrar el intercalación óptima de dos listas ordenadas. Para el resto de nuestra discusión, suponemos que los documentos relevantes y los documentos no relevantes se clasifican descendiendo WT φ (x, d). Por conveniencia, también nos referimos a documentos relevantes como {dx 1 ,...dx | cx |} = cx, y documentos no relevantes como {d¯x 1 ,...d¯x | c¯x |} = c¯x. Definimos ΔJ (i1, i2), con i1 <i2, como el cambio en H desde cuando el documento relevante mejor clasificado clasificado después de d¯x j es dx i1 a cuando es dx i2. Para i2 = i1 + 1, tenemos ΔJ (i, i + 1) = 1 | cx |„J J + I - J - 1 J + I - 1« - 2 · (SX I - S¯x J), (5) donde Si = Wt φ (x, di). El primer término en (5) es el cambio en ∆map cuando el documento relevante con IPI tiene documentos J no relevantes clasificados ante él, en lugar de J −1. El segundo término es el cambio en la puntuación discriminante, wt ψ (x, y), cuando YIJ cambia de +1 a −1...., DX I, D¯x J, DX I+1 ,......, D¯x J, DX I, DX I+1 ,... Figura 1: Ejemplo para ΔJ (i, i + 1) La Figura 1 da un ejemplo conceptual para ΔJ (i, i + 1). La clasificación inferior difiere de la parte superior solo donde D¯x J se desliza hacia arriba de un rango. La diferencia en el valor de H para estas dos clasificaciones es exactamente ΔJ (i, i + 1). Para cualquier i1 <i2, podemos definir ΔJ (i1, i2) como ΔJ (i1, i2) = i2−1 x k = i1 ΔJ (k, k + 1), (6) o de manera equivalente, ΔJ (i1,i2) = i2−1 x k = i1 »1 | cx |„J J + K - J - 1 J + K - 1« - 2 · (SX K - S¯x J). Sea O1 ,..., o | c¯x |Codifique las posiciones de los documentos no relevantes, donde DX OJ es el documento relevante mejor clasificado clasificado después del documento JTH no relevante. Debido a la observación 1, esta codificación identifica de manera única una clasificación completa. Podemos recuperar la clasificación como yij = 8 >>> <>>>: 0 si i = j signo (si - sj) Si di, dj signo de igual relevancia (oj - i - 0.5) si di = dx i, dj =d¯x j signo (j - oi + 0.5) si di = d¯x i, dj = dx j.(7) Ahora podemos reformular h en una nueva función objetivo, H (O1, ..., o | c¯x || w) = h (¯y | w) + | c¯x |X k = 1 ΔK (OK, | CX | + 1), donde ¯y es la clasificación verdadera (débil). Conceptualmente H comienza con una clasificación perfecta y agrega el cambio en H cuando cada documento no relevante sucesivo desliza por la clasificación. Entonces podemos reformular el problema de Argmax H como argmax h = argmax o1, ..., o | c¯x || C¯x |X k = 1 ΔK (OK, | CX | + 1) (8) S.T.O1 ≤...≤ o | c¯x |.(9) El algoritmo 2 describe el algoritmo utilizado para resolver la ecuación (8). Conceptualmente, el algoritmo 2 comienza con una clasificación perfecta. Luego, para cada documento no relevante sucesivo, el algoritmo modifica la solución deslizando que documenta la clasificación para maximizar localmente H mientras mantiene constante las posiciones de los otros documentos no relevantes.3.2.1 El algoritmo de prueba de corrección 2 es codicioso en el sentido de que encuentra la mejor posición de cada documento no relevante independientemente de los otros documentos no relevantes. En otras palabras, el algoritmo maximiza H para cada documento no relevante, D¯x J, Algoritmo 2 Encontrar la restricción más violada (Argmax H) para el algoritmo 1 con ∆Map 1: Entrada: W, CX, C¯x 2: OrdenarCx y c¯x en orden descendente de wt φ (x, d) 3: sx i ← wt φ (x, dx i), i = 1 ,..., | Cx |4: S¯x I ← Wt φ (x, d¯x i), i = 1 ,..., | C¯x |5: para j = 1 ,..., | C¯x |Do 6: Optj ← ArgMaxk ΔJ (k, | cx | + 1) 7: Fin para 8: codifica ˆy de acuerdo con (7) 9: return ˆy sin considerar las posiciones de los otros documentos no relevantes, y así ignora las restriccionesde (9). Para que la solución sea factible, el documento JTH no relevante debe clasificarse después de los primeros documentos no relevantes J-1, satisfaciendo así Opt1 ≤ Opt2 ≤...≤ opt | c¯x |.(10) Si la solución es factible, se resuelve claramente (8). Por lo tanto, es suficiente demostrar que el algoritmo 2 satisface (10). Primero demostramos que ΔJ (·, ·) está disminuyendo monotónicamente en j.Lema 1. Para cualquier 1 ≤ i1 <i2 ≤ | cx |+ 1 y 1 ≤ j <| c¯x |, debe ser el caso que ΔJ+ 1 (i1, i2) ≤ ΔJ (i1, i2). Prueba. Recuerde de (6) que tanto ΔJ (i1, i2) como ΔJ+1 (i1, i2) son sumaciones de términos I2 - I1. Mostraremos que cada término en la suma de ΔJ+1 (i1, i2) no es mayor que el término correspondiente en ΔJ (i1, i2) o ΔJ+1 (k, k+1) ≤ ΔJ (k, k+ 1) para k = i1 ,..., i2 - 1. Cada término en ΔJ (k, k +1) y ΔJ +1 (k, k +1) puede descomponerse aún más en dos partes (ver (5)). Mostraremos que cada parte de ΔJ + 1 (k, k + 1) no es mayor que la parte correspondiente en ΔJ (k, k + 1). En otras palabras, mostraremos que tanto J + 1 J + K + 1 - J J + K ≤ J J + K - J - 1 J + K - 1 (11) como −2 · (SX K - S¯x J +1) ≤ −2 · (sx k - s¯x j) (12) son verdaderos para los valores mencionados de j y k.Es fácil ver que (11) es cierto al observar que para dos enteros positivos 1 ≤ a <b, a + 1 b + 1 - a b ≤ a b - a - 1 b - 1, y eligiendo a = j y b= j + k.La segunda desigualdad (12) se mantiene porque el algoritmo 2 primero tipos d¯x en orden descendente de s¯x, lo que implica s¯x j+1 ≤ s¯x j. Por lo tanto, vemos que cada término en ΔJ+1 no es mayor que el término correspondiente en ΔJ, lo que completa la prueba. El resultado de Lemma 1 conduce directamente a nuestro principal resultado de corrección: Teorema 2. En el algoritmo 2, los valores calculados de OPTJ satisfacen (10), lo que implica que la solución devuelta por el algoritmo 2 es factible y, por lo tanto, óptima. Prueba. Probaremos que OPTJ ≤ OptJ+1 se mantiene para cualquier 1 ≤ J <| C¯x |, lo que implica (10). Dado que el algoritmo 2 calcula optj como optj = argmax k Δj (k, | cx | + 1), (13) entonces, por definición de ΔJ (6), para cualquier 1 ≤ i <optj, ΔJ (i, optj) = ΔJ ((i, | cx | + 1) - ΔJ (optj, | cx | + 1) <0. Usando Lemma 1, sabemos que ΔJ+1 (i, Optj) ≤ ΔJ (i, Optj) <0, lo que implica que para cualquier 1 ≤ i <optJ, ΔJ+1 (i, | cx |+1) - ΔJ+1 (optj, | cx | + 1) <0. Supongamos por contradicción que optj+1 <optj. Entonces ΔJ+1 (optj+1, | cx |+1) <ΔJ+1 (optj, | cx |+1), que contradice (13). Por lo tanto, debe ser el caso que optj ≤ optj+1, que completa la prueba.3.2.2 Tiempo de ejecución El tiempo de ejecución del Algoritmo 2 se puede dividir en dos partes. La primera parte es el tipo de wt φ (x, d), que requiere o (n log n) tiempo, donde n = | cx |+ | C¯x |. La segunda parte calcula cada optj, que requiere tiempo o (| cx | · | c¯x |). Aunque en el peor de los casos, este es O (N2), el número de documentos relevantes, | cx |, a menudo es muy pequeño (por ejemplo, constante con respecto a n), en cuyo caso el tiempo de ejecución de la segunda parte es simplemente o (norte). Para la mayoría de los conjuntos de datos del mundo real, el algoritmo 2 está dominado por el tipo y tiene complejidad o (n log n). Se garantiza que el algoritmo 1 se detendrá en un número polinomial de iteraciones [19], y cada iteración ejecuta el Algoritmo 2. Prácticamente todos los modelos bien realizados fueron entrenados en una cantidad razonable de tiempo (generalmente menos de una hora). Una vez que se completa el entrenamiento, hacer predicciones sobre la consulta x utilizando la hipótesis resultante h (x | w) requiere solo clasificación por wt φ (x, d). Desarrollamos nuestro software utilizando una interfaz de Python3 para svmstruct, ya que el lenguaje de Python simplificó enormemente el proceso de codificación. Para mejorar el rendimiento, es aconsejable utilizar la implementación estándar C4 de SVMstruct.4. Configuración del experimento El objetivo principal de nuestros experimentos es evaluar si la optimización directa del MAP conduce a un mejor rendimiento del mapa en comparación con los métodos SVM convencionales que optimizan una pérdida sustitutiva, como la precisión o la rocarea. Evaluamos empíricamente nuestro método utilizando dos conjuntos de consultas de pista web TREC, una de TREC 9 y TREC 10 (Temas 451-500 y 501-550), los cuales utilizaron el Corpus WT10G. Para cada consulta, TREC proporciona los juicios de relevancia de los documentos. Generamos nuestras características utilizando los puntajes de las funciones de recuperación existentes en estas consultas. Si bien nuestro método es agnóstico para el significado de las características, elegimos utilizar las funciones de recuperación existentes como una forma simple pero efectiva de adquirir características útiles. Como tal, nuestro 3 http://www.cs.cornell.edu/~tomf/svmpython/ 4 http://svmlight.joachims.org/svm_struct.html DataSet base base características Trec 9 Indri 15 750 Trec 10 Indri 15 750TREC 9 SUMISIONES 53 2650 TREC 10 SUMISIONES 18 900 Tabla 5: Experimentos de estadísticas del conjunto de datos esencialmente prueban nuestros métodos la capacidad de volver a clasificar los documentos altamente clasificados (por ejemplo, volver a combinar las puntuaciones de las funciones de recuperación) para mejorar el mapa. Comparamos nuestro método con las mejores funciones de recuperación entrenadas (en adelante funciones base), así como contra los métodos SVM propuestos previamente. La comparación con las mejores funciones base prueba nuestra capacidad de métodos para aprender una combinación útil. La comparación con los métodos SVM anteriores nos permite probar si la optimización directamente para MAP (en lugar de precisión o ROCAREA) logra una puntuación de MAP más alta en la práctica. El resto de esta sección describe las funciones base y el método de generación de características en detalle.4.1 Elegir funciones de recuperación, elegimos dos conjuntos de funciones base para nuestros experimentos. Para el primer set, generamos tres índices sobre el Corpus WT10G usando Indri5. El primer índice se generó utilizando la configuración predeterminada, el segundo portero usado y el último de portador usado y las palabras de parada predeterminadas de Indris. Tanto para TREC 9 como TREC 10, utilizamos la parte de descripción de cada consulta y calificamos los documentos utilizando cinco de los métodos de recuperación de Indris incorporados, que son similitudes de coseno, TFIDF, OKAPI, modelo de lenguaje con Dirichlet Prior y modelo de idioma con Jelinek-Mercer Prior. Todos los parámetros se mantuvieron como sus valores predeterminados. Calculamos los puntajes de estos cinco métodos de recuperación sobre los tres índices, dando 15 funciones base en total. Para cada consulta, consideramos los puntajes de los documentos encontrados en la unión de los 1000 principales documentos de cada función base. Para nuestro segundo conjunto de funciones base, utilizamos puntajes de las presentaciones de pista web TREC 9 [8] y TREC 10 [9]. Utilizamos solo las presentaciones no manuales y sin escortes de ambos años. Para TREC 9 y TREC 10, hubo 53 y 18 de este tipo, respectivamente. Una presentación típica contenía puntajes de sus 1000 documentos principales.B CA WT φ (X, D) F (D | X) Figura 2: Ejemplo de características Binning 4.2 Generación de características Para generar ejemplos de entrada para nuestro método, se debe proporcionar una instanciación concreta de φ. Para cada DOC5 http://www.lemurproject.org trec 9 trec 10 mapa de modelo w/l w/l svm∆ mapa 0.242 - 0.236best func.0.204 39/11 ** 0.181 37/13 ** 2nd mejor 0.199 38/12 ** 0.174 43/7 ** 3rd mejor 0.188 34/16 ** 0.174 38/12 ** Tabla 6: Comparación con las funciones de Indri Umento D anotadoPor un conjunto de funciones de recuperación f en la consulta x, generamos las características como un vector φ (x, d) = 1 [f (d | x)> k]: ∀f ∈ F, ∀k ∈ Kf, donde f ((D | X) denota la puntuación que la función de recuperación F asigna al documento D para la consulta X, y cada KF es un conjunto de valores reales. Desde un alto nivel, estamos expresando la puntuación de cada función de recuperación usando | KF |+ 1 contenedores. Dado que estamos utilizando núcleos lineales, uno puede pensar en el problema de aprendizaje como encontrar una buena combinación por partes constantes de las puntuaciones de las funciones de recuperación. La Figura 2 muestra un ejemplo de nuestro método de mapeo de características. En este ejemplo tenemos una sola característica f = {f}. Aquí, kf = {a, b, c}, y el vector de peso es w = wa, wb, wc. Para cualquier documento d y consulta x, tenemos wt φ (x, d) = 8 >> <>>: 0 si f (d | x) <a wa si a ≤ f (d | x) <b wa + wbSi b ≤ f (d | x) <c wa + wb + wc si c ≤ f (d | x). Esto se expresa cualitativamente en la Figura 2, donde WA y WB son positivos, y WC es negativo. Ejecutamos nuestros principales experimentos utilizando cuatro opciones de F: el conjunto de funciones de recuperación de Indri mencionadas anteriormente para TREC 9 y TREC 10, y las presentaciones de la pista web para TREC 9 y TREC 10. Para cada F y cada función f ∈ F, elegimos 50 valores para KF que están razonablemente espaciados y capturan la región sensible de f.Usando las cuatro opciones de F, generamos cuatro conjuntos de datos para nuestros experimentos principales. La Tabla 5 contiene estadísticas de los conjuntos de datos generados. Hay muchas formas de generar características, y no estamos abogando por nuestro método sobre los demás. Este era simplemente un medio eficiente para normalizar las salidas de diferentes funciones y permitir un modelo más expresivo.5. Experimentos para cada conjunto de datos en la Tabla 5, realizamos 50 ensayos. Para cada ensayo, entrenamos en 10 consultas seleccionadas al azar y seleccionamos otras 5 consultas al azar para un conjunto de validación. Los modelos fueron entrenados utilizando una amplia gama de valores de C. El modelo que funcionó mejor en el conjunto de validación se seleccionó y probó en las 35 consultas restantes. Todas las consultas fueron seleccionadas para estar en la capacitación, validación y prueba establece el mismo número de veces. Usando esta configuración, realizamos los mismos experimentos mientras usamos nuestro método (mapa SVM∆), una optimización SVM para ROCAREA (SVM∆ ROC) [13] y una clasificación convencional SVM (SVMACC) [20]. Todos los métodos SVM utilizaron un núcleo lineal. Informamos el rendimiento promedio de todos los modelos en los 50 ensayos.5.1 Comparación con las funciones base en el análisis de nuestros resultados, la primera pregunta que responde es, ¿puede svm∆ mapa aprender un modelo que supera el mejor mapa de modelos de trec 9 trec 10 w/l w/l svm∆ mapa 0.290 - 0.287 mejor funce.0.280 28/22 0.283 29/21 2nd mejor 0.269 30/20 0.251 36/14 ** 3rd mejor 0.266 30/20 0.233 36/14 ** Tabla 7: Comparación con los envíos TREC TREC 9 TREC 10 Mapa de modelo W/L W W/L W W/L MAP W/L/L svm∆ mapa 0.284 - 0.288 mejor func.0.280 27/23 0.283 31/19 2nd mejor 0.269 30/20 0.251 36/14 ** 3er mejor 0.266 30/20 0.233 35/15 ** Tabla 8: Comparación con TREC Subt.(sin las mejores) funciones? La Tabla 6 presenta la comparación del mapa SVM∆ con las mejores funciones base de Indri. Cada grupo de columna contiene el rendimiento del mapa de macro promediado del mapa SVM∆ o una función base. Las columnas W/L muestran el número de consultas donde el mapa SVM∆ logró una puntuación de mapa más alta. Las pruebas de significancia se realizaron utilizando la prueba de rango firmada de Wilcoxon de dos colas. Dos estrellas indican un nivel de significancia de 0.95. Todas las tablas que muestran nuestros resultados experimentales están estructuradas de manera idéntica. Aquí, encontramos que el mapa SVM∆ supera significativamente las mejores funciones base. La Tabla 7 muestra la comparación cuando se entrena en las presentaciones de TREC. Si bien logran una puntuación de mapa más alta que las mejores funciones base, la diferencia de rendimiento entre el mapa SVM∆ las funciones base no es significativa. Dado que muchas de estas presentaciones utilizan funciones de puntuación que están cuidadosamente elaboradas para lograr un mapa alto, es posible que las presentaciones de mejor rendimiento usen técnicas que subsumen las técnicas de las otras presentaciones. Como resultado, el mapa SVM∆ no podría aprender una hipótesis que puede superar significativamente la mejor presentación. Por lo tanto, ejecutamos los mismos experimentos utilizando un conjunto de datos modificado donde se eliminaron las características calculadas utilizando el mejor envío. La Tabla 8 muestra los resultados (tenga en cuenta que todavía estamos comparando con la mejor presentación, aunque no la estamos utilizando para capacitar). Observe que si bien el rendimiento del mapa SVM∆ se degradó ligeramente, el rendimiento aún era comparable con el de la mejor presentación.5.2 Comparación con métodos SVM anteriores La siguiente pregunta para responder es: ¿El mapa SVM∆ produce puntajes de mapas más altos que los métodos SVM anteriores? Las tablas 9 y 10 presentan los resultados del mapa SVM∆, SVM∆ ROC y SVMACC cuando se entrenan en las funciones de recuperación de Indri y las presentaciones de TREC, respectivamente. La Tabla 11 contiene los resultados correspondientes cuando se entrenan en las presentaciones de TREC sin la mejor presentación. Para comenzar, nuestros resultados indican que SVMACC no fue competitivo con SVM∆ MAP y SVM∆ ROC, y a veces tuvo un rendimiento inferior dramáticamente. Como tal, probamos varios enfoques para mejorar el rendimiento de SVMACC.5.2.1 Métodos alternativos de SVMACC Un problema que puede hacer que SVMACC tenga un rendimiento inferior es el desequilibrio severo entre el Doctrec -Rocio relevante y no relevante 9 TREC 10 MAP W/L MAP W/L SVM∆ MAP 0.242 - 0.236SVM∆ ROC 0.237 29/210.234 24/26 SVMACC 0.147 47/3 ** 0.155 47/3 ** SVMACC2 0.219 39/11 ** 0.207 43/7 ** SVMACC3 0.113 49/1 ** 0.153 45/5 ** SVMACC4 0.155 48/2 **0.155 48/2 ** Tabla 9: Entrenado en funciones de Indri TREC 9 TREC 10 MAPE MOMENTO W/L MAP W/L SVM∆ MAP 0.290 - 0.287SVM∆ ROC 0.282 29/21 0.278 35/15 ** SVMACC 0.213 49/1** 0.222 49/1 ** SVMACC2 0.270 34/16 ** 0.261 42/8 ** SVMACC3 0.133 50/0 ** 0.182 46/4 ** SVMACC4 0.233 47/3 ** 0.238 46/4 ** Tabla 10:Entrenado en TREC presentaciones Uments. La gran mayoría de los documentos no son relevantes. SVMACC2 aborda este problema asignando más penalización a errores falsos negativos. Para cada conjunto de datos, la relación de las penalizaciones falsas a falsas positivas es igual a la relación del número de documentos no relevantes y relevantes en ese conjunto de datos. Las tablas 9, 10 y 11 indican que SVMACC2 todavía funciona significativamente peor que el mapa SVM∆. Otro posible problema es que SVMACC intenta encontrar un solo umbral bisural B que sea invariante de la consulta. Puede ser que diferentes consultas requieran diferentes valores de b. Tener el método de aprendizaje tratando de encontrar un buen valor B (cuando uno no existe) puede ser perjudicial. Tomamos dos enfoques para abordar este problema. El primer método, SVMACC3, convierte los puntajes de la función de recuperación en percentiles. Por ejemplo, para el documento D, la consulta Q y la función de recuperación F, si la puntuación F (d | Q) está en el 90% superior de los puntajes F (· | Q) para la consulta Q, entonces el puntaje convertido es F (D| q) = 0.9. Cada KF contiene 50 valores espaciados uniformemente entre 0 y 1. Las Tablas 9, 10 y 11 muestran que el rendimiento de SVMACC3 tampoco fue competitivo con el mapa SVM∆. El segundo método, SVMACC4, normaliza los puntajes dados por F para cada consulta. Por ejemplo, suponga la consulta Q que F emite puntajes en el rango 0.2 a 0.7. Luego, para el documento D, si F (D | Q) = 0.6, la puntuación convertida sería F (D | Q) = (0.6 - 0.2)/(0.7 - 0.2) = 0.8. Cada KF contiene 50 valores espaciados uniformemente entre 0 y 1. Nuevamente, las Tablas 9, 10 y 11 muestran que SVMACC4 no fue competitivo con SVM∆ MAP 5.2.2 MAP vs ROCAREA SVM∆ ROC funcionó mucho mejor que SVMACC en nuestros experimentos. Cuando se entrenan en funciones de recuperación de Indri (ver Tabla 9), el rendimiento de SVM∆ ROC fue leve, aunque no significativamente, peor que las actuaciones del mapa SVM∆. Sin embargo, la Tabla 10 muestra que el mapa SVM∆ superó significativamente a SVM∆ ROC cuando fue entrenado en las presentaciones de TREC. La Tabla 11 muestra el rendimiento de los modelos cuando se entrenan en las presentaciones de TREC con la mejor presentación eliminada. El rendimiento de la mayoría de los modelos degradado por una pequeña cantidad, con el mapa SVM∆ todavía tiene el mejor rendimiento. Trec 9 trec 10 mapa modelo mapa w/l w/l svm∆ mapa 0.284 - 0.288svm∆ roc 0.274 31/19 ** 0.272 38/12 ** SVMACC 0.215 49/1 ** 0.211 50/0 ** SVMACC2 0.267 35/15 ** 0.258 44/6 ** SVMACC3 0.133 50/0 ** 0.174 46/4 ** SVMACC4 0.228 46/4 ** 0.234 45/5 ** Tabla 11: Entrenado en Trec Subt.(sin el mejor) 6. Conclusiones y trabajos futuros hemos presentado un método SVM que optimiza directamente el MAP. Proporciona un enfoque de principios y evita que sean difíciles de controlar las heurísticas. Formulamos el problema de optimización y presentamos un algoritmo que probablemente encuentra la solución en el tiempo polinomial. Hemos demostrado empíricamente que nuestro método es generalmente superior o competitivo con los métodos SVMS convencionales. Nuestro nuevo método hace que conceptualmente sea tan fácil de optimizar los SVM para el MAP como era posible solo para la precisión y Rocarea. El costo computacional para la capacitación es muy razonable en la práctica. Dado que otros métodos generalmente requieren ajustar múltiples heurísticas, también esperamos entrenar menos modelos antes de encontrar uno que logre un buen rendimiento. El marco de aprendizaje utilizado por nuestro método es bastante general. Una extensión natural de este marco sería desarrollar métodos para optimizar otras medidas IR importantes, como la ganancia acumulativa con descuento normalizada [2, 3, 4, 12] y el rango recíproco medio.7. Agradecimientos Este trabajo fue financiado bajo el premio NSF IIS-0412894, NSF Carrerae Award 02373381 y un regalo de Yahoo! Investigación. El tercer autor también fue apoyado en parte por una beca de investigación de Microsoft.8. Referencias [1] B. T. Bartell, G. W. Cottrell y R. K. Belew. Combinación automática de sistemas de recuperación de rango múltiple. En Actas de la Conferencia de ACM sobre Investigación y Desarrollo en Recuperación de Información (Sigir), 1994. [2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificarse usando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Autor (ICML), 2005. [3] C. J. C. Burges, R. Ragno y Q. Le. Aprender a clasificarse con funciones de costo no suaves. En Actas de la Conferencia Internacional sobre Avances en Sistemas de Procesamiento de Información Neural (NIPS), 2006. [4] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang y H.-W.Excmo Adaptación de ranking SVM para la recuperación de documentos. En Actas de la Conferencia de ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2006. [5] B. Carterette y D. Petkova. Aprender una clasificación de preferencias por pares. En Actas de la Conferencia de ACM sobre Investigación y Desarrollo en Recuperación de Información (Sigir), 2006. [6] R. Caruana, A. Niculescu-Mizil, G. Crew y A. Ksikes. Selección de conjunto de bibliotecas de modelos. En Actas de la Conferencia Internacional sobre Aprendizaje Autor (ICML), 2004. [7] J. Davis y M. Goadrich. La relación entre las curvas de recepción de precisión y ROC. En Actas de la Conferencia Internacional sobre Aprendizaje Autor (ICML), 2006. [8] D. Hawking. Descripción general de la pista web TREC-9. En Actas de TREC-2000, 2000. [9] D. Hawking y N. Craswell. Descripción general de la pista web TREC-2001. En Actas de TREC-2001, noviembre de 2001. [10] R. Herbrich, T. Graepel y K. Obermayer. Límites de rango de margen grande para la regresión ordinal. Avances en clasificadores de margen grande, 2000. [11] A. Herschtal y B. Raskutti. Optimización del área bajo la curva ROC utilizando descenso de gradiente. En Actas de la Conferencia Internacional sobre Aprendizaje Autor (ICML), 2004. [12] K. Jarvelin y J. Kekalainen. IR Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2000. [13] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Actas de la Conferencia Internacional sobre Aprendizaje Autor (ICML), páginas 377-384, Nueva York, NY, EE. UU., 2005. ACM Press.[14] J. Lafferty y C. Zhai. Documentar modelos de lenguaje, modelos de consulta y minimización de riesgos para la recuperación de información. En Actas de la Conferencia de ACM sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), Páginas 111-119, 2001. [15] Y. Lin, Y. Lee y G. Wahba. Soporte de máquinas vectoriales para la clasificación en situaciones no estándar. Machine Learning, 46: 191-202, 2002. [16] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias de términos. En Actas de la 28ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 472-479, 2005. [17] K. Morik, P. Brockhausen y T. Joachims. Combinando el aprendizaje estadístico con un enfoque basado en el conocimiento. En Actas de la Conferencia Internacional sobre Aprendizaje Machine, 1999. [18] S. Robertson. El principio de clasificación de probabilidad en IR.Revista de documentación. Journal of Documentation, 33 (4): 294-304, 1977. [19] I. Tsochantaridis, T. Hofmann, T. Joachims e Y. Altun. Métodos de margen grande para variables de salida estructuradas e interdependientes. Journal of Machine Learning Research (JMLR), 6 (sep): 1453-1484, 2005. [20] V. Vapnik. Teoría del aprendizaje estadístico. Wiley and Sons Inc., 1998. [21] L. Yan, R. Dodier, M. Mozer y R. Wolniewicz. Optimización del rendimiento del clasificador a través de la aproximación a la estadística de Wilcoxon-Mann-Whitney. En Actas de la Conferencia Internacional sobre Aprendizaje Autor (ICML), 2003.