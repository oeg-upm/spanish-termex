Segmentación de temas con detección de temas compartidos y alineación de múltiples documentos Bingjun Sun*, Prasenjit Mitra*†, Hongyuan Zha ‡, C. Lee Giles*†, John Yen*†*Departamento de Ciencias de la Computación e Ingeniería † Colegio de Ciencias y Tecnología de la InformaciónPennsylvania State University University Park, PA 16802 ‡ Colegio de computación El Instituto de Tecnología de Georgia Atlanta, GA 30332 *BSUN@CSE.PSU.EDU, † {PMITRA, GILES, JYEN}@ist.psu.edu, ‡ Zha@cc.Detección y seguimiento de temas abstractos de Gatech.edu [26] y segmentación de temas [15] juegan un papel importante en la captura de la información local y secuencial de los documentos. El trabajo previo en esta área generalmente se centra en documentos individuales, aunque hay múltiples documentos similares disponibles en muchos dominios. En este documento, presentamos un nuevo método no supervisado para la detección de temas compartidos y la segmentación de temas de múltiples documentos similares basados en información mutua (MI) e información mutua ponderada (WMI) que es una combinación de IM y pesos a término. La idea básica es que la segmentación óptima maximiza el MI (o WMI). Nuestro enfoque puede detectar temas compartidos entre documentos. Puede encontrar los límites óptimos en un documento y alinear segmentos entre documentos al mismo tiempo. También puede manejar la segmentación de un solo documento como un caso especial de la segmentación y alineación de múltiples documentos. Nuestros métodos pueden identificar y fortalecer los términos de referencia que pueden usarse para la segmentación y eliminar parcialmente las palabras de detención utilizando pesos de términos basados en entropía aprendida de múltiples documentos. Nuestros resultados experimentales muestran que nuestro algoritmo funciona bien para las tareas de segmentación de un solo documento, detección de temas compartidos y segmentación de documentos múltiples. La utilización de información de múltiples documentos puede mejorar enormemente el rendimiento de la segmentación de temas, y usar WMI es incluso mejor que usar MI para la segmentación de múltiples documentos. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: búsqueda de información y agrupación de recuperación;H.3.1 [Almacenamiento y recuperación de información]: Análisis de contenido y procesamiento indexinglinguista;I.2.7 [Inteligencia artificial]: análisis de texto de procesamiento del lenguaje natural;I.5.3 [Reconocimiento de patrones]: algoritmos de agrupación; algoritmos de términos generales mide los términos generales, diseño, experimentación 1. Introducción Muchos investigadores han trabajado en detección y seguimiento de temas (TDT) [26] y segmentación de temas durante la última década. La segmentación del tema tiene la intención de identificar los límites en un documento con el objetivo de capturar la estructura tópica latente. Las tareas de segmentación de temas generalmente se dividen en dos categorías [15]: segmentación de flujo de texto donde se identifica la transición del tema y la segmentación coherente de documentos en la que los documentos se dividen en subtópicos. La primera categoría tiene aplicaciones en el reconocimiento automático de voz, mientras que la segunda tiene más aplicaciones, como consulta de texto parcial de documentos largos en recuperación de información, resumen de texto y medición de calidad de múltiples documentos. Investigaciones previas en relación con TDT se encuentran en la primera categoría, dirigida al seguimiento de temas de datos de discurso de transmisión y texto de Newswire, mientras que la última categoría no se ha estudiado muy bien. Los enfoques tradicionales realizan la segmentación de temas en los documentos uno a la vez [15, 25, 6]. La mayoría de ellos se desempeñan mal en tareas sutiles como la segmentación de documentos coherentes [15]. A menudo, los usuarios finales buscan documentos que tengan contenido similar. Los motores de búsqueda, como, Google, proporcionan enlaces para obtener páginas similares. Con una granularidad más fina, los usuarios pueden estar buscando obtener secciones de un documento similar a una sección particular que presumiblemente discute un tema del interés de los usuarios. Por lo tanto, la extensión de la segmentación de temas de documentos individuales a identificar segmentos similares de múltiples documentos similares con el mismo tema es una dirección natural y necesaria, y se espera que la segmentación de temas de documentos múltiples tenga un mejor rendimiento ya que se utiliza más información. Los enfoques tradicionales que utilizan la medición de similitud basada en la frecuencia del término generalmente tienen la misma suposición de que el vocabulario similar tiende a estar en un segmento de temas coherente [15, 25, 6]. Sin embargo, generalmente sufren el problema de identificar las palabras de detención. Por ejemplo, las palabras de parada dependientes de documentos adicionales se eliminan junto con las palabras de parada genérica en [15]. Hay dos razones por las que no eliminamos las palabras de detención directamente. Primero, la identificación de palabras de parada es otro problema [12] que requiere estimación en cada dominio. La eliminación de palabras de parada comunes puede dar lugar a la pérdida de información útil en un dominio específico. En segundo lugar, a pesar de que se pueden identificar palabras de parada, la clasificación dura de las palabras de parada y las palabras sin parar no puede representar la cantidad cambiante de contenido de información de cada palabra. Empleamos una clasificación suave utilizando pesos de términos. En este documento, vemos el problema de la segmentación de temas como un problema de optimización utilizando técnicas teóricas de información para encontrar los límites óptimos de un documento dado el número de segmentos de texto para minimizar la pérdida de información mutua (MI) (o una mutua ponderadaInformación (WMI)) después de la segmentación y alineación. Esto es igual a maximizar el MI (o WMI). El MI se centra en medir la diferencia entre los segmentos, mientras que las investigaciones previas se centraron en encontrar la similitud (por ejemplo, la distancia coseno) de los segmentos [15, 25, 6]. La alineación del tema de múltiples documentos similares se puede lograr agrupando oraciones sobre el mismo tema en el mismo clúster. La segmentación de temas de un solo documento es solo un caso especial del problema de segmentación y alineación de temas multi-documentos. Los términos se pueden agrupar como en [10] al mismo tiempo, dado el número de grupos, pero nuestros resultados experimentales muestran que este método da como resultado una peor segmentación (ver Tablas 1, 4 y 6). Por lo general, los lectores humanos pueden identificar la transición del tema basada en palabras de referencia y pueden ignorar las palabras de detención. Inspirados por esto, le damos a cada término (o clúster de término) un peso basado en la entropía entre diferentes documentos y diferentes segmentos de documentos. Este enfoque no solo puede aumentar la contribución de las palabras de referencia, sino que también puede disminuir el efecto de las palabras de parada comunes, la palabra ruidosa y las palabras de parada dependientes del documento. Estas palabras son comunes en un documento. Muchos métodos basados en la similitud de oraciones requieren que estas palabras se eliminen antes de que se pueda realizar la segmentación del tema [15]. Nuestros resultados en la Figura 3 muestran que los pesos de término son útiles para la segmentación y alineación de temas de documentos múltiples. La principal contribución de este documento es que introduce un método novedoso para la segmentación de temas utilizando MI y muestra que este método funciona mejor que los criterios previamente utilizados. Además, hemos abordado el problema de la segmentación y la alineación de los temas en múltiples documentos, mientras que la mayoría de la investigación existente se centró en la segmentación de documentos individuales. La segmentación y la alineación de múltiples documentos pueden utilizar información de documentos similares y mejorar en gran medida el rendimiento de la segmentación de temas. Obviamente, nuestro enfoque puede manejar documentos individuales como un caso especial cuando múltiples documentos no están disponibles. Puede detectar temas compartidos entre documentos para juzgar si son múltiples documentos sobre el mismo tema. También presentamos el nuevo criterio de WMI basado en los pesos de términos aprendidos de múltiples documentos similares, lo que puede mejorar aún más el rendimiento de la segmentación de temas. Proponemos un algoritmo codicioso iterativo basado en la programación dinámica y mostramos que funciona bien en la práctica. Parte de nuestro trabajo anterior está en [24]. El resto de este documento está organizado de la siguiente manera: en la Sección 2, revisamos el trabajo relacionado. La Sección 3 contiene una formulación del problema de la segmentación de temas y la alineación de múltiples documentos con la agrupación de términos, una revisión del criterio de MI para la agrupación, y finalmente una introducción a WMI. En la Sección 4, primero proponemos el algoritmo codicioso iterativo de la segmentación y la alineación de los temas con la agrupación de plazo, y luego describimos cómo el algoritmo puede optimizarse mediante USFIGURE 1: Ilustración de la segmentación y alineación de documentos múltiples.ing programación dinámica. En la Sección 5, se describen experimentos sobre la segmentación de un solo documento, la detección de temas compartidos y la segmentación de múltiples documentos, y se presentan y discuten los resultados para evaluar el rendimiento de nuestro algoritmo. Las conclusiones y algunas direcciones futuras del trabajo de investigación se discuten en la Sección 6. 2. Trabajo previo en general, los enfoques existentes para la segmentación de texto se dividen en dos categorías: aprendizaje supervisado [19, 17, 23] y aprendizaje no supervisado [3, 27, 5, 6, 15, 25, 21]. El aprendizaje supervisado generalmente tiene un buen rendimiento, ya que aprende funciones de conjuntos de capacitación etiquetados. Sin embargo, a menudo obtener grandes conjuntos de capacitación con etiquetas manuales en oraciones de documentos es prohibitivamente costoso, por lo que se desean enfoques no supervisados. Algunos modelos consideran la dependencia entre oraciones y secciones, como el modelo oculto de Markov [3, 27], el modelo de Markov máximo de entropía [19] y los campos aleatorios condicionales [17], mientras que muchos otros enfoques se basan en la cohesión léxica o la similitud de las oraciones [[5, 6, 15, 25, 21]. Algunos enfoques también se centran en las palabras de referencia como indicios de transiciones de temas [11]. Mientras que algunos métodos existentes solo consideran la información en documentos individuales [6, 15], otros utilizan múltiples documentos [16, 14]. No hay muchos trabajos en la última categoría, a pesar de que se espera que el rendimiento de la segmentación sea mejor con la utilización de información de múltiples documentos. Investigaciones anteriores estudiaron métodos para encontrar temas compartidos [16] y segmentación de temas y resumen entre solo un par de documentos [14]. La clasificación de texto y la agrupación es un área de investigación relacionada que clasifica los documentos en grupos que utilizan métodos supervisados o no supervisados. La clasificación o agrupación tópica es una dirección importante en esta área, especialmente la agrupación conjunta de documentos y términos, como LSA [9], PLSA [13] y enfoques basados en distancias y partición gráfica bipartita [28] o MI máximo [2 [2, 10], o entropía máxima [1, 18]. Los criterios de estos enfoques se pueden utilizar en el tema de la segmentación de temas. Algunos de esos métodos se han extendido al área de la segmentación de temas, como PLSA [5] y la máxima entropía [7], pero para nuestro mejor conocimiento, no se ha estudiado el uso de MI para la segmentación de temas.3. Formulación del problema Nuestro objetivo es segmentar documentos y alinear los segmentos entre los documentos (Figura 1). Sea t el conjunto de términos {t1, t2, ..., tl}, que aparecen en el conjunto no etiquetado de documentos d = {d1, d2, ..., dm}. Sea SD el conjunto de oraciones para el documento d ∈ D, es decir, {S1, S2, ..., Snd}. Tenemos una matriz 3D de frecuencia de término, en la que las tres dimensiones son variables aleatorias de D, SD y T. SD en realidad es un vector aleatorio que incluye una variable aleatoria para cada d ∈ D. La frecuencia del término se puede usar para estimar elDistribución de probabilidad conjunta P (D, SD, T), que es P (T, D, S) = T (T, D, S)/Nd, donde T (T, D, S) es el número de T en DSLa oración S y ND es el número total de términos en D. ˆs representa el conjunto de segmentos {ˆs1, ˆs2, ..., ˆSp} Después de la segmentación y alineación entre múltiples documentos, donde el número de segmentos |ˆS |= p.Un segmento ˆSi del documento D es una secuencia de oraciones adyacentes en d.Dado que para diferentes documentos, SI puede discutir diferentes subtópicos, nuestro objetivo es agrupar oraciones adyacentes en cada documento en segmentos y alinear segmentos similares entre documentos, de modo que para diferentes documentos ˆSi es aproximadamente el mismo subtema. El objetivo es encontrar la segmentación de temas óptima y la asignación de alineación Segd (Si): {S1, S2, ..., SND} → {ˆS1, ˆS2, ..., ˆSp} y Alid (ˆSi): {ˆs1, ˆs22, ..., ˆSP} → {ˆS1, ˆS2, ..., ˆSP}, para todos d ∈ D, donde ˆSi es un segmento con la restricción de que solo las oraciones adyacentes se pueden asignar al mismo segmento, es decir, para d,{Si, Si+1, ..., Sj} → {ˆSQ}, donde q ∈ {1, ..., p}, donde p es el número de segmento, y si i> j, entonces para d, ˆSQ esdesaparecido. Después de la segmentación y la alineación, el vector aleatorio SD se convierte en una variable aleatoria alineada ˆS. Así, P (D, Sd, T) se convierte en P (D, ˆs, T). La co-clúster de términos es una técnica que se ha empleado [10] para mejorar la precisión de la agrupación de documentos. Evaluamos el efecto del mismo para la segmentación de temas. Un término t se asigna a exactamente un clúster de término. El término co-agrupado implica encontrar simultáneamente el mapeo de agrupación de término óptimo clu (t): {t1, t2, ..., tl} → {ˆt1, ˆt2, ..., ˆtk}, donde k ≤ l, l es el totalNúmero de palabras en todos los documentos, y k es el número de grupos.4. Metodología ahora describimos un algoritmo novedoso que puede manejar la segmentación de SingledOcument, la detección de temas compartidos y la segmentación y alineación multidocumento basadas en MI o WMI.4.1 Información mutua Mi I (x; y) es una cantidad para medir la cantidad de información que está contenida en dos o más variables aleatorias [8, 10]. Para el caso de dos variables aleatorias, tenemos i (x; y) = x∈X y∈Y p (x, y) log p (x, y) p (x) p (y), (1) obviamente,Cuando las variables aleatorias x e y son independientes, i (x; y) = 0. Por lo tanto, intuitivamente, el valor de MI depende de cómo las variables aleatorias dependan entre sí. La co-agrupación óptima es el mapeo clux: x → ˆx y cluy: y → ˆy que minimiza la pérdida: i (x; y)-i (ˆx; ˆy), que es igual a maximizar i (ˆx; ˆy). Este es el criterio de MI para la agrupación. En el caso de la segmentación del tema, las dos variables aleatorias son la variable de término t y la variable de segmento S, y cada muestra es una aparición de un término t = t en un segmento particular s = s.I (T; s) se usa para medir cuán dependientes son los T y S. Sin embargo, yo (t; s) no se puede calcular para documentos antes de la segmentación, ya que no tenemos un conjunto de S debido al hecho de que las oraciones del documento d, si ∈ Sd no están alineadas con otros documentos. Por lo tanto, en lugar de minimizar la pérdida de MI, podemos maximizar el MI después de la segmentación de temas, calculado como: i (ˆt; ˆs) = ˆt∈ ˆt ˆs∈ ˆs p (ˆt, ˆs) log p (ˆt, ˆs) p (ˆt) p (ˆs), (2) donde p (ˆt, ˆs) se estima por el término frecuencia tf del clúster de término ˆt y segmento ˆs en el conjunto de entrenamiento D. Tenga en cuenta que aquí un segmento ˆS incluye oraciones sobre el mismo tema entretodos los documentos. La solución óptima es el mapeo Clut: T → ˆt, Segd: SD → ˆs y Alid: ˆs → ˆs, que maximiza i (ˆt; ˆs).4.2 Información mutua ponderada en la segmentación y alineación de temas de múltiples documentos, si se conoce p (d, ˆs, t), en función de las distribuciones marginales P (d | t) y p (ˆs | t) para cada término t ∈ T,Podemos clasificar los términos en cuatro tipos en el conjunto de datos: • Las palabras de parada comunes son comunes tanto a lo largo de las dimensiones de documentos y segmentos.• Las palabras de detención dependientes del documento que depende del estilo de escritura personal son comunes solo a lo largo de la dimensión de segmentos para algunos documentos.• Las palabras de referencia son los elementos más importantes para la segmentación. Son comunes a lo largo de la dimensión de los documentos solo para el mismo segmento, y no son comunes a lo largo de las dimensiones de los segmentos.• Las palabras ruidosas son otras palabras que no son comunes a lo largo de ambas dimensiones. La entropía basada en P (D | T) y P (ˆs | T) se puede usar para identificar diferentes tipos de términos. Para reforzar la contribución de las palabras de referencia en el cálculo de MI, y reducir simultáneamente el efecto de los otros tres tipos de palabras, similar a la idea del peso TF-IDF [22], usamos entropías de cada término a lo largo de las dimensiones del documentoD y segmento ˆs, es decir Ed (ˆt) y eˆs (ˆt), para calcular el peso. Una palabra de referencia generalmente tiene un gran valor de ed (ˆt) pero un pequeño valor de eˆs (ˆt). Introducimos pesos de términos (o pesos de clúster de términos) wˆt = (ed (ˆt) maxˆt ∈ ˆt (ed (ˆt))) A (1 - eˆs (ˆt) maxˆt ∈ ˆt (eˆs (ˆt))) b, (3)donde ed (ˆt) = d∈D p (d | ˆt) log | d |1 p (d | ˆt), eˆs (ˆt) = ˆs∈ ˆs p (ˆs | ˆt) log |ˆS |1 p (ˆs | ˆt), y a> 0 y b> 0 son poderes para ajustar los pesos de los términos. Por lo general, a = 1 y b = 1 como predeterminado, y maxˆt ∈ ˆt (ed (ˆt)) y maxˆt ∈ ˆt (eˆs (ˆt)) se usan para normalizar los valores de entropía. Los pesos del clúster del término se utilizan para ajustar p (ˆt, ˆs), pw (ˆt, ˆs) = wˆtp (ˆt, ˆs) ˆt∈ ˆt; ˆs∈ ˆs wˆtp (ˆt, ˆs), (4) e iw (ˆt; ˆs;) = ˆT∈ ˆT ˆS∈ ˆS pw (ˆt, ˆs) log pw (ˆt, ˆs) pw (ˆt) pw (ˆ), (5) donde pw (ˆt) y pw (ˆs) son distribuciones marginales de pw (ˆt, s). Sin embargo, dado que no conocemos el término pesos ni p (d, ˆs, t), necesitamos estimarlos, pero wˆt depende de p (ˆs | t) y ˆs, mientras que ˆs y p (ˆs | t) tambiénDepende de Wˆt que aún se desconoce. Por lo tanto, se requiere un algoritmo iterativo para estimar los pesos de los términos wˆt y encontrar la mejor segmentación y alineación para optimizar la función objetivo IW simultáneamente. Después de que un documento se segmenta en la entrada de oraciones: distribución de probabilidad conjunta P (D, SD, T), número de segmentos de texto p ∈ {2, 3, ..., max (SD)}, número de grupos de término k ∈ {2, 3, ..., l} (si k = l, no se requiere un término co-clúster), y tipo de peso w ∈ {0, 1}, lo que indica usar i o iw, respectivamente. Salida: Mapeo de los pesos CLU, SEG, ALI y Término Wˆt. Inicialización: 0. i = 0. Inicializar Clu (0) T, Seg (0) D, y Ali (0) D;Inicializar w (0) ˆt usando la ecuación (6) si w = 1;Etapa 1: 1. Si | D |= 1, k = l, y w = 0, verifique todas las segmentos secuenciales de D en segmentos P y encuentre el mejor segd (s) = argmaxˆsi (ˆt; ˆs) y return segd;de lo contrario, si w = 1 y k = l, vaya a 3.1;Etapa 2: 2.1 Si k <l, para cada término t, encuentre el mejor grupo ˆt como clu (i+1) (t) = argmaxˆti (ˆt; ˆs (i)) basado en seg (i) y ali (i);2.2 Para cada d, verifique todas las segmentaciones secuenciales de D en segmentos P con mapeo S → ˆs → ˆs, y encuentre el mejor Ali (i+1) d (Seg (i+1) d (s)) = argmaxˆsi (ˆT(i+1); ˆs) basado en CLU (i+1) (t) si k <l o clu (0) (t) si k = l;2.3 I + +. Si Clu, Seg o Ali cambian, vaya a 2.1;de lo contrario, si w = 0, return clu (i), seg (i) y ali (i);más j = 0, vaya a 3.1;Etapa 3: 3.1 Actualización W (i+j+1) ˆt basada en Seg (i+j), ali (i+j) y clu (i) usando la ecuación (3);3.2 Para cada D, verifique todas las segmentaciones secuenciales de D en segmentos P con mapeo S → ˆs → ˆs, y encuentre el mejor Ali (i+j+1) d (Seg (i+j+1) d (s))= argmaxˆsiw (ˆt (i); ˆs) basado en Clu (i) y w (i+j+1) ˆt;3.3 J + +. Si cambia iw (ˆt; ˆs), vaya al paso 6;De lo contrario, detén y devuelva Clu (i), Seg (i+j), Ali (i+j) y w (i+j) ˆt;Figura 2: Algoritmo: segmentación de temas y alineación basadas en MI o WMI.y cada oración se segmenta en palabras, cada palabra se mueve. Luego se puede estimar la distribución de probabilidad conjunta P (D, SD, T). Finalmente, esta distribución se puede usar para calcular el MI en nuestro algoritmo.4.3 Algoritmo codicioso iterativo Nuestro objetivo es maximizar la función objetivo, I (ˆt; ˆs) o IW (ˆT; ˆs), que puede medir la dependencia de los acontecimientos de términos en diferentes segmentos. En general, primero no conocemos los pesos del término estimado, que dependen de la segmentación y alineación de temas óptimos, y los grupos de término. Además, este problema es NP-Hard [10], aunque si conocemos el término pesos. Por lo tanto, se desea un algoritmo codicioso iterativo para encontrar la mejor solución, aunque probablemente solo se alcance los máximos locales. Presentamos el algoritmo codicioso iterativo en la Figura 2 para encontrar un máximo local de i (ˆt; ˆs) o iw (ˆt; ˆs) con una estimación de peso de término simultáneo. Este algoritmo es iterativo y codicioso para casos de documentos múltiples o casos de un solo documento con estimación de peso a término y/o clúster de plazo. De lo contrario, dado que es solo un algoritmo de un paso para resolver la tarea de segmentación de un solo documento [6, 15, 25], se garantiza el máximo global de MI. Más adelante mostraremos que el término co-agrupación reduce la precisión de los resultados y no es necesario, y para la segmentación de colocación de solteros, tampoco se requiere pesos de término.4.3.1 Inicialización En el paso 0, el término inicial agrupa y la segmentación de temas segmentan y alineación SEGD y ALID son importantes para evitar los máximos locales y reducir el número de iteraciones. Primero, se puede hacer una buena suposición de los pesos de términos utilizando las distribuciones de frecuencia de término a lo largo de las oraciones para cada documento y promediarlas para obtener los valores iniciales de wˆt: wt = (ed (t) maxt ∈T (ed (t))) (1 - es (t) maxt ∈T (es (t))), (6) donde es (t) = 1 | dt |d∈Dt (1 - s∈Sd p (s | t) log | sd | 1 p (s | t)), donde dt es el conjunto de documentos que contienen el término t.Luego, para la segmentación inicial SEG (0), simplemente podemos segmentar documentos igualmente por oraciones. O podemos encontrar la segmentación óptima solo para cada documento D que maximiza el WMI, Seg (0) d = argmaxˆsiw (t; ˆs), donde w = w (0) ˆt. Para la alineación inicial Ali (0), primero podemos suponer que el orden de los segmentos para cada D es el mismo. Para el término inicial de agrupación CLU (0), las etiquetas del primer clúster se pueden establecer al azar, y después de la primera vez del paso 3, se obtiene una buena agrupación de término inicial.4.3.2 Casos diferentes después de la inicialización, hay tres etapas para diferentes casos. Totalmente hay ocho casos, | D |= 1 o | D |> 1, k = l o k <l, w = 0 o w = 1. La segmentación de documentos individuales sin agrupación de término y estimación de peso de término (| d | = 1, k = l, w = 0) solo requiere la etapa 1 (paso 1). Si se requiere la agrupación de términos (k <l), la etapa 2 (paso 2.1, 2.2 y 2.3) se ejecuta de forma iterativa. Si se requiere una estimación de peso a término (w = 1), la etapa 3 (paso 3.1, 3.2 y 3.3) se ejecuta de forma iterativa. Si se requieren ambos (k <l, w = 1), las etapas 2 y 3 corren uno tras otro. Para la segmentación de documentos múltiples sin agrupación de término y estimación de peso de término (| d |> 1, k = l, w = 0), solo se requiere iteración del paso 2.2 y 2.3. En la etapa 1, el máximo global se puede encontrar basado en I (ˆT; ˆs) usando programación dinámica en la Sección 4.4. Simultáneamente, encontrar una agrupación de buen término y los pesos de término estimados es imposible, ya que al trasladar un término a un nuevo clúster de término para maximizar IW (ˆt; ˆs), no sabemos que el peso de este término debería ser el nuevo clústero el viejo clúster. Por lo tanto, primero hacemos la agrupación de términos en la etapa 2, y luego estimamos los pesos de término en la etapa 3. En la etapa 2, el paso 2.1 es encontrar la mejor agrupación de término y el paso 2.2 es encontrar la mejor segmentación. Este ciclo se repite para encontrar un máximo local basado en MI I hasta que converge. Los dos pasos son: (1) basado en la agrupación de términos actuales Cluˆt, para cada documento D, los segmentos de algoritmo todas las oraciones SD en segmentos P secuencialmente (algunos segmentos pueden estar vacíos), y las colocan en los segmentos p de todoConjunto de capacitación D (todos los casos posibles de diferentes segmentación SEGD y alineación Alid se verifican) para encontrar el caso óptimo, y (2) basado en la segmentación y alineación actuales, para cada término t, el algoritmo encuentra el mejor clúster de término de T basado en TEn el SEGD y la alineación de segmentación actual. Después de encontrar una agrupación de buen término, los pesos de término se estiman si w = 1. En la etapa 3, similar como la etapa 2, el paso 3.1 es la restimación de peso a término y el paso 3.2 es encontrar una mejor segmentación. Se repiten para encontrar un máximo local basado en WMI IW hasta que converge. Sin embargo, si el término agrupación en la etapa 2 no es precisa, entonces la estimación de peso del término en la etapa 3 puede tener un mal resultado. Finalmente, en el paso 3.3, este algoritmo converge y devuelve la salida. Este algoritmo puede manejar tanto el documento único como la segmentación de múltiples documentos. También puede detectar temas compartidos entre documentos verificando la proporción de oraciones superpuestas sobre los mismos temas, como se describe en la Sec.4.4 Optimización del algoritmo En muchos trabajos anteriores sobre segmentación, la programación dinámica es una técnica utilizada para maximizar la función objetivo. Del mismo modo, en el paso 1, 2.2 y 3.2 de nuestro algoritmo, podemos usar programación dinámica. Para la etapa 1, el uso de programación dinámica aún puede encontrar el óptimo global, pero para la etapa 2 y la etapa 3, solo podemos encontrar el óptimo para cada paso de la segmentación de temas y la alineación de un documento. Aquí solo mostramos la programación dinámica para el paso 3.2 usando WMI (el paso 1 y 2.2 son similares, pero pueden usar I o IW). Hay dos casos que no se muestran en el algoritmo en la Figura 2: (a) segmentación de un solo documento o segmentación de múltiples documentos con el mismo orden secuencial de segmentos, donde no se requiere alineación, y (b) segmentación múltiple conDiferentes órdenes secuenciales de segmentos, donde es necesaria la alineación. La función de mapeo de alineación del primer caso es simplemente alid (ˆsi) = ˆSi, mientras que para la última función de mapeo de alineación de alineación (ˆsi) = ˆSJ, I y J pueden ser diferentes. Los pasos computacionales para los dos casos se enumeran a continuación: Caso 1 (sin alineación): para cada documento D: (1) Calcule PW (ˆT), PW parcial (ˆt, ˆs) y PW parcial (ˆ) sin contar oraciones de D.Luego coloque oraciones de I a J en la Parte K, y calcule WMI PIW (ˆT; ˆSK (Si, Si+1, ..., Sj)) ˆT∈ ˆT PW (ˆT, ˆSK) log PW (ˆT, ˆSK)PW (ˆT) PW (ˆSK), donde Alid (Si, Si+1, ..., Sj) = K, K ∈ {1, 2, ..., P}, 1 ≤ I ≤ J ≤ Nd, ySEGD (SQ) = ˆSK para todos los i ≤ q ≤ j.(2) Sea M (Sm, 1) = PIW (ˆT; ˆS1 (S1, S2, ..., SM)). Entonces m (sm, l) = maxi [m (si - 1, l - 1) + piw (ˆt; ˆsl (si, ..., sm))], donde 0 ≤ m ≤ nd, 1 <l <l, 1 ≤ I ≤ m + 1, y cuando i> m, no se ponen oraciones en ˆSK cuando calculan PIW (nota PIW (ˆT; ˆs (Si, ..., Sm)) = 0 para la segmentación de un solo documento).(3) Finalmente m (Snd, P) = maxi [M (Si - 1, P - 1)+ PIW (ˆT; ˆSp (Si, ..., SND))], donde 1 ≤ I ≤ nd+ 1. Se encuentra el IW óptimo y la segmentación correspondiente es la mejor. Caso 2 (se requiere alineación): para cada documento d: (1) Calcule PW (ˆT), PW parcial (ˆT, ˆS) y PW parcial (ˆs) y PIW (ˆT; ˆSK (Si, Si+1 ,..., sj)) Del mismo modo como el caso 1. (2) Sea M (Sm, 1, K) = Piw (ˆT; ˆSk (S1, S2, ..., Sm)), donde k ∈ {1, 2, 2,..., pags}. Entonces M (Sm, L, Kl) = Maxi, J [M (Si - 1, L - 1, Kl/J) + PIW (ˆT; ˆSalid (ˆSl) = J (Si, Si + 1, ...,,,,,,,,,,,,,,,,,,, ...,sm))], donde 0 ≤ m ≤ nd, 1 <l <p, 1 ≤ i ≤ m + 1, kl ∈ Set (p, l), que es el conjunto de todas las p! ¡L! (P - L)!Combinaciones de segmentos L elegidos de todos los segmentos P, J ∈ Kl, el conjunto de segmentos L elegidos de todos los segmentos P, y KL/J es la combinación de segmentos L - 1 en KL excepto el segmento J.(3) Finalmente, M (Snd, P, Kp) = Maxi, J [M (Si - 1, P - 1, Kp/J) +PIW (ˆT; ˆSalid (ˆll) = J (Si, Si +1,..., snd))], donde KP es solo la combinación de todos los segmentos P y 1 ≤ I ≤ nd + 1, que es la IW óptima y la segmentación correspondiente es la mejor. Los pasos del caso 1 y 2 son similares, excepto en el caso 2, la alineación se considera además de la segmentación. Primero, los elementos básicos de probabilidad para calcular IW se calculan excluyendo Doc D, y luego WMI parcial colocando cada segmento secuencial posible (incluido el segmento vacío) de D en cada segmento del conjunto. En segundo lugar, se encuentra la suma óptima de PIW para los segmentos L y las oraciones más a la izquierda, M (SM, L). Finalmente, el WMI máximo se encuentra entre diferentes sumas de M (SM, P - 1) y PIW para el segmento P.5. Se probarán experimentos en esta sección, segmentación de un solo documento, detección de temas compartidos y segmentación de documentos múltiples. Se estudian diferentes hiper parámetros de nuestro método. Por conveniencia, nos referimos al método usando i como mik si w = 0, e iw como wmik si w = 2 o como wmik si w = 1, donde k es el número de clústeres de término, y si k = l, donde les el número total de términos, entonces no se requiere una agrupación de términos, es decir, Mil y Wmil.5.1 Segmentación de un solo documento 5.1.1 Datos y evaluación de prueba El primer conjunto de datos que probamos es uno sintético utilizado en investigaciones anteriores [6, 15, 25] y muchos otros documentos. Tiene 700 muestras. Cada uno es una concatenación de diez segmentos. Cada segmento es la primera n oración seleccionada al azar del Corpus Brown, que se supone que tiene un tema diferente entre sí. Actualmente, los mejores resultados en este conjunto de datos lo logran Ji et.al.[15]. Para comparar el rendimiento de nuestros métodos, se aplica ampliamente el criterio utilizado ampliamente en investigaciones anteriores, en lugar del criterio imparcial introducido en [20]. Elige un par de palabras al azar. Si están en diferentes segmentos (diferentes) para la segmentación real (real), pero predicho (pred) como en el mismo segmento, es una falla. Si están en el mismo segmento (igual), pero predichos como en diferentes segmentos, es una falsa alarma. Por lo tanto, la tasa de error se calcula utilizando la siguiente ecuación: p (err | real, pred) = p (señorita | real, pred, diff) p (diff | real) +p (falsa alarma | real, pred, lo mismo) p(Igual | Real).5.1.2 Resultados del experimento probamos el caso cuando se conoce el número de segmentos. La Tabla 1 muestra los resultados de nuestros métodos con diferentes valores de hiper parámetros y tres enfoques anteriores, C99 [25], U00 [6] y ADDP03 [15], en este conjunto de datos cuando se conoce el número de segmento. En WMI para la segmentación de un solo documento, los pesos del término se calculan de la siguiente manera: wˆt = 1–eˆs (ˆt)/maxˆt ∈ ˆt (eˆs (ˆt)). Para este caso, nuestros métodos MIL y WMIL superan a todos los enfoques anteriores. Comparamos nuestros métodos con la prueba T unilateral unilateral de ADDP03using unilateral y los valores P se muestran en la Tabla 2. A partir de los valores p, podemos ver que principalmente las diferencias son muy importantes: tasas de error promedio de segmentación de un solo documento dada números de segmento rango conocido de n 3-11 3-5 6-8 9-11 Tamaño de muestra 400 100 100 100 100 100100 C99 12% 11% 10% 9% U00 10% 9% 7% 5% ADDP03 6.0% 6.8% 5.2% 4.3% mil 4.68% 5.57% 2.59% 1.59% WMIL 4.94% 6.33% 2.76% 1.62% MI100 9.62% 12.92% 8.66% 6.67% Tabla 2: Segmentación de un solo documento: Valores p de la prueba t en el rango de tasas de error de N 3-11 3-5 6-8 9-11 ADDP03, MIL 0.000 0.000 0.000 0.000 ADDP03, WMIL 0.000 0.0990.000 0.000 mil, WMIL 0.061 0.132 0.526 0.898 significativo. También comparamos las tasas de error entre nuestros dos métodos utilizando la prueba t de dos lados de dos muestras para verificar la hipótesis de que son iguales. No podemos rechazar la hipótesis de que son iguales, por lo que la diferencia no es significativa, aunque todas las tasas de error para MIL son más pequeñas que WMIL. Sin embargo, podemos concluir que los pesos del término contribuyen poco en la segmentación de un solo documento. Los resultados también muestran que el MI que usa la clúster de términos (k = 100) disminuye el rendimiento. Probamos diferentes grupos de grupos y descubrimos que el rendimiento mejora cuando el número de clúster aumenta para alcanzar l.Wmik <L tiene resultados similares que no mostramos en la tabla. Como se mencionó anteriormente, el uso de MI puede ser inconsistente en los límites óptimos dados diferentes números de segmentos. Esta situación ocurre especialmente cuando las similitudes entre los segmentos son bastante diferentes, es decir, algunas transiciones son muy obvias, mientras que otras no. Esto se debe a que generalmente un documento es una estructura jerárquica en lugar de solo una estructura secuencial. Cuando los segmentos no están al mismo nivel, esta situación puede ocurrir. Por lo tanto, se desea un enfoque de segmentación de temas jerárquico, y la estructura depende en gran medida del número de segmentos para cada nodo interno y los criterios de división de división. Para este conjunto de datos de segmentación de SingledOcument, dado que es solo un conjunto sintético, que es solo una concatenación de varios segmentos sobre diferentes temas, es razonable que los enfoques simplemente basados en la frecuencia de términos tengan un buen rendimiento. Por lo general, para las tareas de segmentar documentos coherentes para los subtópicos, la efectividad disminuye mucho.5.2 Detección de temas compartidos 5.2.1 Datos y evaluación de pruebas El segundo conjunto de datos contiene 80 artículos de noticias de Google News. Hay ocho temas y cada uno tiene 10 artículos. Dividimos aleatoriamente el conjunto en subconjuntos con diferentes números de documentos y cada subconjunto tiene los ocho temas. Comparamos nuestro enfoque MIL y WMIL con LDA [4]. LDA trata un documento en el conjunto de datos como una bolsa de palabras, encuentra su distribución en los temas y su tema principal. MIL y WMIL ve cada oración como una bolsa de palabras y la etiquetan con una etiqueta de tema. Luego, para cada par de documentos, LDA determina si están en el mismo tema, mientras que MIL y Tabla 3: Detección de temas compartidos: tasas de error promedio para diferentes números de documentos en cada subconjunto #DOC 10 20 40 80 LDA 8.89% 16.33% 1.35% 0.60% mil, θ = 0.6 4.17% 1.71% 1.47% 0.0% WMIL, θ = 0.8 18.6% 3.16% 1.92% 0.0% WMIL Verifique si la proporción superpuesta las oraciones en el mismo tema es mayor que el umbral ajustable θ. Es decir, en Mil y Wmil, para un par de documentos d, d, if [s∈Sd, s ∈Sd 1 (temas = temas)/min (| sd |, | sd |)]> θ, donde sd está esEl conjunto de oraciones de D, y | SD |es el número de oraciones de D, entonces D y D tienen el tema compartido. Para un par de documentos seleccionados al azar, la tasa de error se calcula utilizando la siguiente ecuación: p (err | real, pred) = p (señorita | real, pred, lo mismo) p (mismo | real) +p (falsa alarma | real, pred, diff) p (diff | real), donde una falla significa si tiene el mismo tema (mismo) para el caso real (real), pero predicho (pred) como en el mismo tema. Si están en diferentes temas (DIFF), pero predichos como en el mismo tema, es una falsa alarma.5.2.2 Resultados del experimento Los resultados se muestran en la Tabla 3. Si la mayoría de los documentos tienen temas diferentes, en WMIL, la estimación de los pesos de los términos en la ecuación (3) no es correcta. Por lo tanto, no se espera que WMIL tenga un mejor rendimiento que MIL, cuando la mayoría de los documentos tienen temas diferentes. Cuando hay menos documentos en un subconjunto con el mismo número de temas, más documentos tienen diferentes temas, por lo que WMIL es más peor que MIL. Podemos ver que para la mayoría de los casos MIL tiene un rendimiento mejor (o al menos similar) que LDA. Después de la detección de temas compartidos, se puede ejecutar la segmentación de documentos de documentos múltiples con los temas compartidos.5.3 Segmentación de documentos múltiples 5.3.1 Datos de prueba y evaluación para la segmentación y alineación de múltiples documentos, nuestro objetivo es identificar estos segmentos sobre el mismo tema entre múltiples documentos similares con temas compartidos. Se espera que el uso de IW funcione mejor que yo, ya que sin pesos de término, el resultado se ve afectado seriamente por las palabras de parada dependientes del documento y las palabras ruidosas que depende del estilo de escritura personal. Es más probable que trate los mismos segmentos de diferentes documentos que diferentes segmentos bajo el efecto de las palabras de parada dependientes del documento y las palabras ruidosas. Los pesos de términos pueden reducir el efecto de las palabras de detención dependientes del documento y las palabras ruidosas al dar más pesos a los términos de la señal. El conjunto de datos para la segmentación y alineación de varios documentos tiene 102 muestras y 2264 oraciones totalmente. Cada uno es la parte de introducción de un informe de laboratorio seleccionado desde el curso de Biol 240W, Universidad Estatal de Pensilvania. Cada muestra tiene dos segmentos, la introducción de las hormonas vegetales y el contenido en el laboratorio. El rango de longitud de las muestras es de dos a 56 oraciones. Algunas muestras solo tienen una parte y otras tienen un orden inverso de estos dos segmentos. No es difícil identificar el límite entre dos segmentos para humanos. Etiquetamos cada oración manualmente para su evaluación. El criterio de la evaluación es solo utilizar la proporción del número de oraciones con etiquetas de segmento predichas predichas incorrectas en el número total de oraciones en toda la Tabla de entrenamiento 4: tasas de error promedio de la segmentación de múltiples documentos dados los números de segmento conocidosWMIK 102 3.14% 2.78% 300 4.68% 6.58% 51 4.17% 3.63% 300 17.83% 22.84% 34 5.06% 4.12% 300 18.75% 20.95% 20 7.08% 5.42% 250 20.40% 21.83% 10 10.38% 7.89)% 5 15.77% 11.64% 250 21.89% 22.59% 2 25.90% 23.18% 50 25.44% 25.49% 1 23.90% 24.82% 25 25.75% 26.15% Tabla 5: segmentación de múltiples documentos: p-Valores de Test Tasales de error para tasas de error para tasas de errorMil y Wmil #DOC 51 34 20 10 5 2 2 P-Valor 0.19 0.101 0.025 0.001 0.000 0.002 Conjunto como la tasa de error: P (Error | Predicción, real) = D∈D S∈Sd 1 (predicción = Reals)/ D∈D nd. Para mostrar los beneficios de la segmentación y alineación de varios documentos, comparamos nuestro método con diferentes parámetros en diferentes particiones del mismo conjunto de capacitación. Excepto los casos de que el número de documentos es 102 y uno (son casos especiales de uso de todo el conjunto y la segmentación pura de un solo documento), dividimos aleatoriamente el conjunto de entrenamiento en particiones m, y cada uno tiene 51, 34, 20,10, 5 y 2 muestras de documentos. Luego aplicamos nuestros métodos en cada partición y calculamos la tasa de error de todo el conjunto de entrenamiento. Cada caso se repitió por 10 veces para calcular las tasas de error promedio. Para diferentes particiones del conjunto de entrenamiento, se utilizan diferentes valores de K, ya que el número de términos aumenta cuando aumenta el número de documento en cada partición.5.3.2 Resultados del experimento de los resultados del experimento en la Tabla 4, podemos ver las siguientes observaciones: (1) Cuando aumenta el número de documentos, todos los métodos tienen mejores rendimientos. Solo de uno a dos documentos, MIL ha disminuido un poco. Podemos observar esto de la Figura 3 en el punto del número de documento = 2. La mayoría de las curvas incluso tienen los peores resultados en este momento. Hay dos razones. Primero, debido a que las muestras votan por la mejor segmentación y alineación de múltiples documentos, pero si solo se comparan dos documentos entre sí, el que tiene segmentos faltantes o una secuencia totalmente diferente afectará la segmentación y la alineación correcta del otro. En segundo lugar, como se señaló al comienzo de esta sección, si dos documentos tienen más palabras de parada dependientes del documento o palabras ruidosas que las palabras de referencia, entonces el algoritmo puede verlos como dos segmentos diferentes y falta el otro segmento. En general, solo podemos esperar un mejor rendimiento cuando el número de documentos es mayor que el número de segmentos.(2) Excepto la segmentación de un solo documento, WMIL siempre es mejor que MIL, y cuando el número de documentos alcanza uno o aumenta a un número muy grande, sus actuaciones se vuelven más cercanas. La Tabla 5 muestra los valores P de la prueba t unilateral entre MIL y WMIL. También podemos ver esta tendencia de los valores P. Cuando el número de documento = 5, alcanzamos el valor p más pequeño y la mayor diferencia entre las tasas de error de MIL y WMIL. Para un solo documento Tabla 6: Segmentación de documentos múltiples: tasa de error promedio para el número de documento = 5 en cada subconjunto con un número diferente de clústeres de término #Cluster 75 100 150 250 L Mik 24.67% 24.54% 23.91% 22.59% 15.77% Segmentación, WMIL, WMILes incluso un poco peor que MIL, que es similar a los resultados de la segmentación de un solo documento en el primer conjunto de datos. La razón es que para la segmentación de SingledOcument, no podemos estimar los pesos de los términos con precisión, ya que múltiples documentos no están disponibles.(3) El uso de la agrupación de términos generalmente aumenta los resultados que MIL y WMIL.(4) El uso de la agrupación de términos en WMIK es aún peor que en Mik, ya que en WMIK los clústeres de término se encuentran primero usando I antes de usar IW. Si los clústeres de término no son correctos, los pesos del término se estiman peor, lo que puede engañar al algoritmo para alcanzar resultados aún peores. De los resultados también encontramos que en la segmentación y alineación de varios documentos, la mayoría de los documentos con segmentos faltantes y un orden inverso se identifican correctamente. La Tabla 6 ilustra los resultados del experimento para el caso de 20 particiones (cada una tiene cinco muestras de documentos) del conjunto de capacitación y la segmentación y alineación de temas utilizando MIK con diferentes números de grupos de término k.Observe que cuando aumenta el número de grupos de término, la tasa de error se vuelve más pequeña. Sin la agrupación de términos, tenemos el mejor resultado. No mostramos resultados para WMIK con la agrupación de términos, pero los resultados son similares. También probamos WMIL con diferentes hiper parámetros de A y B para ajustar los pesos de los términos. Los resultados se presentan en la Figura 3. Se demostró que el caso predeterminado WMIL: A = 1, B = 1 dio los mejores resultados para diferentes particiones del conjunto de entrenamiento. Podemos ver la tendencia de que cuando el número de documento es muy pequeño o grande, la diferencia entre mil: a = 0, b = 0 y wmil: a = 1, b = 1 se vuelve bastante pequeña. Cuando el número de documento no es grande (aproximadamente de 2 a 10), todos los casos que usan pesos de términos tienen mejores rendimientos que MIL: A = 0, B = 0 sin pesos de término, pero cuando el número de documento se hace más grande, los casos WMIL:a = 1, b = 0 y wmil: a = 2, b = 1 empeoran que mil: a = 0, b = 0. Cuando el número de documento se vuelve muy grande, son aún peores que los casos con pequeños números de documentos. Esto significa que es muy importante una forma adecuada de estimar los pesos de términos para el criterio de WMI. La Figura 4 muestra el término pesos aprendidos de todo el conjunto de entrenamiento. Cuatro tipos de palabras se clasifican aproximadamente a pesar de que la transición entre ellas es sutil. La Figura 5 ilustra el cambio en la información mutua (ponderada) para MIL y WMIL. Como se esperaba, la información mutua para MIL aumenta monotónicamente con el número de pasos, mientras que WMIL no. Finalmente, MIL y WMIL son escalables, con la complejidad computacional que se muestra en la Figura 6. Una ventaja para nuestro enfoque basado en MI es que no se requiere eliminar las palabras de detención. Otra ventaja importante es que no hay hiper parámetros necesarios para ajustar. En la segmentación de un solo documento, el rendimiento basado en MI es aún mejor para eso basado en WMI, por lo que no se requiere un hiper parámetro adicional. En la segmentación de varios documentos, mostramos en el experimento, A = 1 y B = 1 es el mejor. Nuestro método ofrece más pesos a los términos de la señal. Sin embargo, por lo general, los términos o oraciones de Cue aparecen al comienzo de un segmento, mientras que el final del segmento puede ser 1 2 5 10 20 20 34 51 102 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de documento Errorrate MIL: A = 0, B =0 WMI L: A = 1, B = 1 WMI L: A = 1, B = 0 WMI L: A = 2, B = 1 Figura 3: Tasas de error para diferentes parámetros hiper de pesos de términos.0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Entropía de documento normalizado Segmentalentropy Palabras ruidosas Cue palabras de parada común0 100 200 300 400 500 600 0.06 0.08 0.1 0.12 0.14 0.16 0.18 Número de pasos (ponderados) MI L MI L WMI L Figura 5: Cambio en (ponderado) MI para MIL y WMIL.0 20 40 60 80 100 120 0 200 400 600 800 1000 1200 1400 1600 1800 2000 Número de documento TimetoConverge (SEC) MI L WMI L Figura 6: Tiempo para converger para MIL y WMIL.Mucho ruidoso. Una posible solución es dar más pesos al comienzo de cada segmento. Además, cuando la duración de los segmentos es bastante diferente, los segmentos largos tienen frecuencias a término mucho más altas, por lo que pueden dominar los límites de segmentación. La normalización de las frecuencias de términos versus la longitud del segmento puede ser útil.6. Conclusiones y trabajos futuros propusimos un método novedoso para la segmentación y alineación de temas multi-documentos basados en información mutua ponderada, que también puede manejar casos de un solo documento. Utilizamos una programación dinámica para optimizar nuestro algoritmo. Nuestro enfoque supera a todos los métodos anteriores en casos de colocación de solteres. Además, también demostramos que hacer segmentación entre múltiples documentos puede mejorar enormemente el rendimiento. Nuestros resultados también ilustraron que el uso de información mutua ponderada puede utilizar la información de múltiples documentos para alcanzar un mejor rendimiento. Solo probamos nuestro método en conjuntos de datos limitados. Se deben probar más conjuntos de datos especialmente complicados. Se deben comparar más métodos anteriores con. Además, las segmentos naturales como los párrafos son sugerencias que se pueden usar para encontrar los límites óptimos. El aprendizaje supervisado también puede considerarse.7. Agradecimientos Los autores quieren agradecer a Xiang Ji y al Prof. J. Scott Payne por su ayuda.8. Referencias [1] A. Banerjee, I. Ghillon, J. Ghosh, S. Merugu y D. Modha. Un enfoque generalizado de entropía máxima para la coincidencia de combate y aproximación de matriz de Bregman. En Actas de Sigkdd, 2004. [2] R. Bekkerman, R. El-Yaniv y A. McCallum. Agrupación de distribución múltiple a través de interacciones por pares. En Actas de ICML, 2005. [3] D. M. Blei y P. J. Moreno. Segmentación de temas con un aspecto oculto de Markov. En Actas de Sigir, 2001. [4] D. M. Blei, A. Ng y M. Jordan. Asignación latente de Dirichlet. Journal of Machine Learning Research, 3: 993-1022, 2003. [5] T. Brants, F. Chen e I. Tsochantaridis. Segmentación de documentos basada en temas con análisis semántico latente probabilístico. En Actas de CIKM, 2002. [6] F. Choi. Avances en la segmentación de texto lineal de dominio independiente. En Actas de la Naacl, 2000. [7] H. Christensen, B. Kolluru, Y. Gotoh y S. Renals. Segmentación máxima de entropía de noticias de transmisión. En Actas de ICASSP, 2005. [8] T. Cover y J. Thomas. Elementos de la teoría de la información. John Wiley and Sons, Nueva York, EE. UU., 1991. [9] S. Deerwester, S. Dumais, G. Furnes, T. Landauer y R. Harshman. Indexación por análisis semántico latente. Journal of the American Society for Information Systems, 1990. [10] I. Dhillon, S. Mallela y D. Modha. Información-co-agrupación teórica. En Actas de Sigkdd, 2003. [11] M. Hajime, H. Takeo y O. Manabu. Segmentación de texto con múltiples señales lingüísticas de superficie. En Actas de Coling-ACL, 1998. [12] T. K. Ho. Detener la ubicación de la palabra e identificación para el reconocimiento de texto adaptativo. Revista Internacional de Análisis y Reconocimiento de Documentos, 3 (1), agosto de 2000. [13] T. Hofmann. Análisis semántico latente probabilístico. En Actas del UAI99, 1999. [14] X. Ji y H. Zha. Correlacionar la resumen de un par de documentos multilingües. En Proceedings of Ride, 2003. [15] X. Ji y H. Zha. Segmentación de texto independiente del dominio utilizando difusión anisotrópica y programación dinámica. En Actas de Sigir, 2003. [16] X. Ji y H. Zha. Extracción de temas compartidos de múltiples documentos. En Actas del 7º Pakdd, 2003. [17] J. Lafferty, A. McCallum y F. Pereira. Campos aleatorios condicionales: modelos probabilísticos para datos de secuencia de segmentación y etiquetado. En Actas de ICML, 2001. [18] T. Li, S. Ma y M. Ogihara. Criterio basado en entropía en la agrupación categórica. En Actas de ICML, 2004. [19] A. McCallum, D. Freitag y F. Pereira. Modelos máximos de entropía Markov para extracción de información y segmentación. En Actas de ICML, 2000. [20] L. Pevzner y M. Hearst. Una crítica y mejora de una métrica de evaluación para la segmentación de texto. Computational Linguistic, 28 (1): 19-36, 2002. [21] J. C. Reynar. Modelos estadísticos para la segmentación de temas. En Actas de ACL, 1999. [22] G. Salton y M. McGill. Introducción a la recuperación de información moderna. McGraw Hill, 1983. [23] B. Sun, Q. Tan, P. Mitra y C. L. Giles. Extracción y búsqueda de fórmulas químicas en documentos de texto en la web. En Actas de www, 2007. [24] B. Sun, D. Zhou, H. Zha y J. Yen. Segmentación y alineación de texto de tareas múltiples basadas en información mutua ponderada. En Actas de CIKM, 2006. [25] M. Utiyama y H. Isahara. Un modelo estadístico para la segmentación de texto independiente del dominio. En Actas de la 39a ACL, 1999. [26] C. Wayne. Detección y seguimiento de temas multilingües: investigación exitosa habilitada por corpus y evaluación. En Actas de LREC, 2000. [27] J. Yamron, I. Carp, L. Gillick, S. Lowe y P. van Mulbregt. Un enfoque de modelo de Markov oculto para la segmentación de texto y el seguimiento de eventos. En Actas de ICASSP, 1998. [28] H. Zha y X. Ji. Correlacionamiento de documentos multilingües a través del modelado de gráficos bipartito. En Actas de Sigir, 2002.