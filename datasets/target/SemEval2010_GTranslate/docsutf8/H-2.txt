Expansión de consulta personalizada para la web Paul - Alexandru Chirita L3s Research Center ∗ Appelstr. 9A 30167 Hannover, Alemania chirita@l3s.de Claudiu S. Firan L3s Research Center Appelstr.9A 30167 Hannover, Alemania Firan@l3s.de Wolfgang Nejdl L3s Research Center Appelstr.9A 30167 Hannover, Alemania nejdl@l3s.de Resumen La ambigüedad inherente de las consultas de palabras clave cortas demandas de métodos mejorados para la recuperación web. En este documento, proponemos mejorar tales consultas web expandiéndolas con los términos recopilados del repositorio de información personal de cada usuarios, personalizando por lo tanto implícitamente la salida de búsqueda. Introducimos cinco técnicas amplias para generar las palabras clave de consulta adicionales mediante el análisis de los datos del usuario al aumento de los niveles de granularidad, que van desde el análisis a nivel de término y compuesto hasta las estadísticas de concurrencia global, así como hasta el uso de dicios de vía externas. Nuestro extenso análisis empírico en cuatro escenarios diferentes muestra algunos de estos enfoques para funcionar muy bien, especialmente en consultas ambiguas, produciendo un aumento muy fuerte en la calidad de las clasificaciones de salida. Posteriormente, movemos este marco de búsqueda personalizado un paso más allá y proponemos que el proceso de expansión sea adaptable a varias características de cada consulta. Un conjunto separado de experimentos indica los algoritmos adaptativos para brindar una mejora estadísticamente significativa adicional sobre el mejor enfoque de expansión estática. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información;H.3.5 [almacenamiento y recuperación de información]: Servicios de información en línea Servicios basados en Web Algoritmos de términos generales, experimentación, medición 1. Introducción La popularidad en auge de los motores de búsqueda ha determinado la búsqueda simple de palabras clave para convertirse en la única interfaz de usuario ampliamente aceptada para buscar información en la web. Sin embargo, las consultas de palabras clave son inherentemente ambiguas. El libro de consulta Canon, por ejemplo, cubre varias áreas diferentes de interés: religión, fotografía, literatura y música. Claramente, uno preferiría que la salida de búsqueda se alinee con los temas de interés de los usuarios, en lugar de mostrar una selección de URL populares de cada categoría. Los estudios han demostrado que más del 80% de los usuarios preferirían recibir tales resultados de búsqueda personalizados [33] en lugar de los actualmente genéricos. La expansión de la consulta ayuda al usuario a formular una mejor consulta, al agregar palabras clave adicionales a la solicitud de búsqueda inicial para encapsular sus intereses allí, así como para enfocar la salida de búsqueda web en consecuencia. Se ha demostrado que funciona muy bien en grandes conjuntos de datos, especialmente con consultas de entrada cortas (ver, por ejemplo, [19, 3]). ¡Este es exactamente el escenario de búsqueda web! En este documento, proponemos mejorar la reformulación de consultas web explotando el repositorio de información personal de los usuarios (PIR), es decir, la colección personal de documentos de texto, correos electrónicos, páginas web en caché, etc. Surgen varias ventajas al mover la personalización de la búsqueda web hasta el nivel de escritorio (tenga en cuenta que por escritorio nos referimos a PIR, y usamos los dos términos indistintamente). Primero es, por supuesto, la calidad de la personalización: el escritorio local es un rico repositorio de información, que describe con precisión la mayoría, si no todos los intereses del usuario. En segundo lugar, como toda la información del perfil se almacena y explota localmente, en la máquina personal, otro beneficio muy importante es la privacidad. Los motores de búsqueda no deben poder conocer los intereses de una persona, es decir, no deberían poder conectar a una persona específica con las consultas que emitió, o peor, con las URL de salida que hizo clic dentro de la interfaz de búsqueda1 (ver Volokh [35]para una discusión sobre cuestiones de privacidad relacionadas con la búsqueda web personalizada). Nuestros algoritmos expanden consultas web con palabras clave extraídas de los usuarios PIR, personalizando implícitamente la salida de búsqueda. Después de una discusión de los trabajos anteriores en la Sección 2, primero investigamos el análisis del contexto de consulta de escritorio local en la Sección 3.1.1. Proponemos varias técnicas de palabras clave, expresión y resumen para determinar los términos de expansión de aquellos documentos personales que coinciden mejor con la consulta web. En la Sección 3.1.2 movemos nuestro análisis a la colección de escritorio global e investigamos expansiones basadas en métricas de concurrencia y dicios externos. Los experimentos presentados en la Sección 3.2 muestran muchos de estos enfoques para funcionar muy bien, especialmente en consultas ambiguas, produciendo mejoras de NDCG [15] de hasta 51.28%. En la Sección 4, movemos este marco algorítmico aún más y proponemos que el proceso de expansión sea adaptable al nivel de claridad de la consulta. Esto produce una mejora adicional de 8.47% sobre el mejor algoritmo previamente identificado. Concluimos y discutimos más trabajo en la Sección 5. 1 Los motores de búsqueda pueden mapear consultas al menos a las direcciones IP, por ejemplo, utilizando cookies y minando los registros de consultas. Sin embargo, al mover el perfil de usuario a nivel de escritorio, nos aseguramos de que dicha información no esté explícitamente asociada a un usuario en particular y se almacene en el lado del motor de búsqueda.2. Trabajo anterior Este documento reúne dos áreas IR: personalización de búsqueda y expansión automática de consultas. Existe una gran cantidad de algoritmos para ambos dominios. Sin embargo, no se ha hecho mucho específicamente dirigido a combinarlos. Por lo tanto, en esta sección presentamos un análisis separado, primero introducimos algunos enfoques para personalizar la búsqueda, ya que este representa el objetivo principal de nuestra investigación, y luego discutiendo varias técnicas de expansión de consultas y su relación con nuestros algoritmos.2.1 Búsqueda personalizada La búsqueda personalizada comprende dos componentes principales: (1) Perfiles de usuario y (2) el algoritmo de búsqueda real. Esta sección divide los antecedentes relevantes de acuerdo con el enfoque de cada artículo en cualquiera de estos elementos. Enfoques centrados en el perfil de usuario. Sugiyama et al.[32] analizó el comportamiento de surf y generó perfiles de usuario como características (términos) de las páginas visitadas. Al emitir una nueva consulta, los resultados de búsqueda se clasificaron en función de la similitud entre cada URL y el perfil de usuario. Qiu y Cho [26] utilizaron el aprendizaje automático en el historial de clics pasado del usuario para determinar los vectores de preferencia de tema y luego aplicar PageRank sensible al tema [13]. El perfil de usuario basado en el historial de navegación tiene la ventaja de ser bastante fácil de obtener y procesar. Esta es probablemente la razón por la que también es empleado por varios motores de búsqueda industrial (por ejemplo, Yahoo! Myweb2). Sin embargo, definitivamente no es suficiente para reunir una visión exhaustiva de los intereses de los usuarios. Más, requiere almacenar toda la información personal en el lado del servidor, lo que plantea importantes problemas de privacidad. Solo otros dos enfoques mejoraron la búsqueda web utilizando datos de escritorio, pero ambos usaron diferentes ideas centrales: (1) Teevan et al.[34] modificó los pesos del término de consulta del esquema de ponderación BM25 para incorporar los intereses de los usuarios como capturados por sus índices de escritorio;(2) En Chirita et al.[6], nos centramos en volver a clasificar la salida de búsqueda web de acuerdo con la distancia coseno entre cada URL y un conjunto de términos de escritorio que describen los intereses de los usuarios. Además, ninguno de estos investigó la aplicación adaptativa de la personalización. Enfoques centrados en el algoritmo de personalización. Construir efectivamente el aspecto de personalización directamente en PageRank [25] (es decir, sesgarlo en un conjunto objetivo de páginas) ha recibido mucha atención recientemente. Haveliwala [13] calculó un PageRank atacado, en el que 16 vectores de PageRank sesgados en cada uno de los temas principales del directorio abierto se calcularon inicialmente fuera de línea, y luego se combinaron en el tiempo de ejecución en función de la similitud entre la consulta del usuario y cada uno de los de cada uno de los de cada uno deLos 16 temas. Más recientemente, Nie et al.[24] modificó la idea distribuyendo el PageRank de una página en los temas que contiene para generar clasificaciones orientadas a temas. JEH y Widom [16] propusieron un algoritmo que evita los recursos masivos necesarios para almacenar un Vector PageRank personalizado (PPV) por usuario mediante la precomputación de PPV solo para un pequeño conjunto de páginas y luego aplicar combinación lineal. Como el cálculo de los PPV para conjuntos de páginas más grandes aún era bastante costoso, se han investigado varias soluciones, las más importantes son las de Fogaras y Racz [12], y Sarlos et al.[30], este último usando redondeo y boceto de minuto de recuento para obtener rápidamente las aproximaciones precisas de las puntuaciones personalizadas.2.2 Expansión de consulta automática La expansión de consulta automática tiene como objetivo derivar una mejor formulación de la consulta de usuario para mejorar la recuperación. Se basa en explotar varias características sociales o específicas de la colección para generar términos adicionales, que se adjuntan al IN2 http://myweb2.search.yahoo.com. En esta sección, encuestamos algunos de los trabajos de expansión de consultas representativas agrupados de acuerdo con la fuente empleada para generar términos adicionales: (1) Comentarios de relevancia, (2) estadísticas de co-ocurrencia basadas en la recopilación y (3) información del teso. Algunos otros enfoques también se abordan al final de la sección. Técnicas de retroalimentación de relevancia. La idea principal de retroalimentación de relevancia (RF) es que se puede extraer información útil de los documentos relevantes devueltos para la consulta inicial. Los primeros enfoques fueron manuales [28] en el sentido de que el usuario era el que eligió los resultados relevantes, y luego se aplicaron varios métodos para extraer nuevos términos, relacionados con la consulta y los documentos seleccionados. Efthimiadis [11] presentó una revisión integral de la literatura y propuso varios métodos simples para extraer tales palabras clave nuevas basadas en la frecuencia del término, la frecuencia de los documentos, etc. Utilizamos algunos de estos como inspiración para nuestras técnicas específicas de escritorio. Chang y HSU [5] pidieron a los usuarios que elijan grupos relevantes, en lugar de documentos, reduciendo así la cantidad de interacción necesaria. También se ha demostrado que RF se automatizan efectivamente considerando los documentos mejor clasificados como relevantes [37] (esto se conoce como pseudo RF). Lam y Jones [21] utilizaron el resumen para extraer oraciones informativas de los documentos mejor clasificados y las agregaron a la consulta del usuario. Carpineto et al.[4] maximizó la divergencia entre el modelo de idioma definido por los documentos recuperados superiores y el definido por toda la colección. Finalmente, Yu et al.[38] seleccionó los términos de expansión de segmentos de páginas web basados en la visión para hacer frente a los múltiples temas que residen en él. Técnicas basadas en concurrencia. Se ha demostrado que los términos altamente concurrentes con las palabras clave emitidas aumentan la precisión cuando se agrega a la consulta [17]. Se han desarrollado muchas medidas estadísticas para evaluar mejor los niveles de relación de términos, ya sea analizando documentos completos [27], relaciones de afinidad léxica [3] (es decir, pares de palabras estrechamente relacionadas que contienen exactamente uno de los términos de consulta iniciales), etc. También hemos investigado tres enfoques de este tipo para identificar palabras clave relevantes de consulta del repositorio de información personal rico pero bastante complejo. Técnicas basadas en el tesauro. Un método ampliamente explorado es expandir la consulta del usuario con nuevos términos, cuyo significado está estrechamente relacionado con las palabras clave de entrada. Dichas relaciones generalmente se extraen de los dicios de sinónimos a gran escala, como WordNet [23], en los que se predefinen varios conjuntos de sinónimos, hipernyms, etc. Al igual que para los métodos de concurrencia, los experimentos iniciales con este enfoque fueron controvertidos, ya sea mejoras de informes o incluso reducciones en la calidad de la producción [36]. Recientemente, a medida que las colecciones experimentales se hicieron más grandes, y a medida que los algoritmos empleados se volvieron más complejos, se han obtenido mejores resultados [31, 18, 22]. También usamos términos de expansión basados en WordNet. Sin embargo, basamos este proceso en analizar la relación de nivel de escritorio entre la consulta original y las nuevas palabras clave propuestas. Otras técnicas. Hay muchos otros intentos de extraer términos de expansión. Aunque ortogonal a nuestro enfoque, dos obras son muy relevantes para el entorno web: Cui et al.[8] generaron correlaciones de palabras que utilizan la probabilidad de que los términos de consulta aparezcan en cada documento, según lo calculado en los registros del motor de búsqueda. Kraft y Zien [19] mostraron que el texto de anclaje es muy similar a las consultas de los usuarios y, por lo tanto, lo explotó para adquirir palabras clave adicionales.3. La expansión de la consulta utilizando datos de escritorio de escritorio representa un repositorio muy rico de información de perfiles. Sin embargo, esta información viene de una manera muy no estructurada, que cubre documentos que son muy diversos en formato, contenido e incluso características del lenguaje. En esta sección, primero abordamos este problema proponiendo varios algoritmos de análisis léxico que explotan a los usuarios PIR para extraer términos de expansión de palabras clave en diversas granularidades, que van desde la frecuencia de término dentro de los documentos de escritorio hasta la utilización de estadísticas de concurrencia global sobre el repositorio de información personal. Luego, en la segunda parte de la sección analizamos empíricamente el rendimiento de cada enfoque.3.1 Algoritmos Esta sección presenta los cinco enfoques genéricos para analizar los datos de escritorio de los usuarios para proporcionar términos de expansión para la búsqueda web. En los algoritmos propuestos aumentamos gradualmente la cantidad de información personal utilizada. Por lo tanto, en la primera parte investigamos tres técnicas de análisis locales centradas solo en aquellos documentos de escritorio que coinciden con la consulta de los usuarios. Agradecemos a la consulta web los términos, compuestos y resúmenes de oraciones más relevantes de estos documentos. En la segunda parte de la sección avanzamos hacia un análisis global de escritorio, proponiendo investigar las concurrencias de términos, así como los tesauros, en el proceso de expansión.3.1.1 Expansión con el análisis local de escritorio de escritorio El análisis de escritorio local está relacionado con la mejora de la retroalimentación de pseudo relevancia para generar palabras clave de expansión de consulta de los mejores éxitos para la consulta web de los usuarios, en lugar de los resultados de búsqueda web mejor clasificados. Distinguemos tres niveles de granularidad para este proceso e investigamos cada uno de ellos por separado. Término y frecuencia de documentos. Como las medidas más simples posibles, TF y DF tienen la ventaja de ser muy rápido para calcular. Experimentos anteriores con pequeños conjuntos de datos han demostrado que producen muy buenos resultados [11]. Por lo tanto, asociamos de forma independiente una puntuación con cada término, basado en cada una de las dos estadísticas. El basado en TF se obtiene multiplicando la frecuencia real de un término con un puntaje de posición descendente ya que el término aparece primero más cerca del final del documento. Esto es necesario, especialmente para documentos más largos, porque los términos más informativos tienden a aparecer hacia su comienzo [10]. La fórmula completa de extracción de palabras clave basada en TF es la siguiente: TermScore = 1 2 + 1 2 · Nrwords - Pos Nrwords!· Log (1 + tf) (1) donde NRWords es el número total de términos en el documento y POS es la posición de la primera aparición del término;TF representa la frecuencia de cada término en el documento de escritorio que coincide con la consulta web de los usuarios. La identificación de términos de expansión adecuados es aún más simple cuando se usa DF: dado el conjunto de documentos de escritorio relevantes de Top-K, genere sus fragmentos enfocados en la solicitud de búsqueda original. Esta orientación de consulta es necesaria, ya que los puntajes DF se calculan a nivel de todo el PIR y de lo contrario producirían sugerencias demasiado ruidosas. Una vez que se ha identificado el conjunto de términos candidatos, la selección se realiza ordenándoles de acuerdo con los puntajes de DF con los que están asociados. Los lazos se resuelven utilizando los puntajes de TF correspondientes. Tenga en cuenta que un enfoque HFXIDF híbrido no es necesariamente eficiente, ya que un término de escritorio podría tener un DF alto en el escritorio, mientras que es bastante raro en la web. Por ejemplo, el término PageRank sería bastante frecuente en el escritorio de un científico IR, logrando así una puntuación baja con TFXIDF. Sin embargo, como es bastante raro en la web, sería una buena resolución de la consulta hacia el tema correcto. Compuestos léxicos. Anick y Tipirneni [2] definieron la hipótesis de dispersión léxica, según la cual una expresión de dispersión léxica (es decir, el número de compuestos diferentes en los que aparece dentro de un documento o grupo de documentos) puede usarse automáticamente conceptos clave sobre el documento de entrada sobre el documento de entradacolocar. Aunque hay varias expresiones compuestas posibles disponibles, se ha demostrado que los enfoques simples basados en el análisis de sustantivos son casi tan buenos como los algoritmos de identificación de patrones de voz altamente complejos [1]. Por lo tanto, inspeccionamos los documentos de escritorio coincidentes para todos sus compuestos léxicos de la siguiente forma: {¿Adjetivo?sustantivo+} Todos estos compuestos podrían generarse fácilmente fuera de línea, en el momento de la indexación, para todos los documentos en el repositorio local. Además, una vez identificados, se pueden clasificar más dependiendo de su dispersión dentro de cada documento para facilitar la recuperación rápida de los compuestos más frecuentes en el tiempo de ejecución. Selección de oraciones. Esta técnica se basa en el resumen de documentos orientados a las oraciones: primero, se identifica el conjunto de documentos de escritorio relevantes;Luego, un resumen que contiene sus oraciones más importantes se genera como salida. La selección de oraciones es el enfoque de análisis local más completo, ya que produce las expansiones más detalladas (es decir, oraciones). Su desventaja es que, a diferencia de los dos primeros algoritmos, su salida no se puede almacenar de manera eficiente y, en consecuencia, no se puede calcular fuera de línea. Generamos resúmenes basados en oraciones clasificando las oraciones del documento de acuerdo con su puntaje de relevancia, de la siguiente manera [21]: Sentencescore = SW2 TW + PS + TQ2 NQ El primer término es la relación entre la cantidad cuadrada de palabras significativas dentro de la oración y el totalnúmero de palabras en ellas. Una palabra es significativa en un documento si su frecuencia está por encima de un umbral de la siguiente manera: tf> ms = v `x 7 - 0.1 ∗ (25 - ns), si ns <25 7, si ns ∈ [25, 40] 7 +0.1 ∗ (NS - 40), si NS> 40 con NS es el número total de oraciones en el documento (ver [21] para más detalles). El segundo término es una puntuación de posición establecida en (AVG (NS) - SentenceIndex)/AVG2 (NS) para las primeras diez oraciones, y a 0 de lo contrario, AVG (NS) es el número promedio de oraciones sobre todos los elementos de escritorio. De esta manera, los documentos breves como los correos electrónicos no se ven afectados, lo cual es correcto, ya que generalmente no contienen un resumen al principio. Sin embargo, como los documentos más largos generalmente incluyen oraciones descriptivas generales al principio [10], es más probable que estas oraciones sean relevantes. El término final sesga el resumen hacia la consulta. Es la relación entre el número cuadrado de términos de consulta presentes en la oración y el número total de términos de la consulta. Se basa en la creencia de que cuantos más términos de consulta contenidos en una oración, más probable es que esa oración transmitiera información altamente relacionada con la consulta.3.1.2 Expansión con el análisis global de escritorio en contraste con el enfoque presentado anteriormente, el análisis global se basa en información de todo el escritorio personal para inferir los nuevos términos de consulta relevantes. En esta sección proponemos dos de estas técnicas, a saber, estadísticas de coincidencia de término, y filtrando la salida de un tesauro externo. Estadísticas de coincidencia de término. Para cada término, podemos calcular fácilmente fuera de línea aquellos términos que concurren con él con mayor frecuencia en una colección dada (es decir, PIR en nuestro caso), y luego explotar esta información en el tiempo de ejecución para inferir palabras clave altamente correlacionadas conla consulta de usuario. Nuestro algoritmo genérico de expansión de consultas basado en la concurrencia es el siguiente: Algoritmo 3.1.2.1. Seguimiento de similitud de palabras clave basada en concurrencia. Computación fuera de línea: 1: Filtro de palabras clave potenciales k con df ∈ [10 ,..., 20% · n] 2: para cada palabra clave Ki 3: para cada palabra clave KJ 4: Compute scki, kj, el coeficiente de similitud de (ki, kj) cálculo en línea: 1: Sea s el conjunto de palabras clave, potencialmenteSimilar a una expresión de entrada E. 2: para cada palabra clave K de E: 3: S ← S ∪ TSC (k), donde TSC (k) contiene los términos más importantes de K más similares a K 4: para cada término T de S: 5A: Sea la puntuación (t) ← Q k∈E (0.01 + sct, k) 5b: STORT (T) ← #DesktoPhits (E | T) 6: Seleccione los términos Top-K de S con los puntajes más altos. El cálculo fuera de línea necesita una fase de recorte inicial (paso 1) para fines de optimización. Además, también restringimos el algoritmo para calcular los niveles de concurrencia solo entre los sustantivos, ya que contienen con mucho la mayor cantidad de información conceptual, y a medida que este enfoque reduce considerablemente el tamaño de la matriz de concurrencia. Durante la fase de tiempo de ejecución, con los términos más correlacionados con cada palabra clave de consulta en particular ya identificada, es necesaria una operación más, es decir, calcular la correlación de cada término de salida con toda la consulta. Son posibles dos enfoques: (1) utilizando un producto de la correlación entre el término y todas las palabras clave en la expresión original (paso 5a), o (2) simplemente contando el número de documentos en los que el término propuesto coopera con todaConsulta de usuario (Paso 5B). Consideramos las siguientes fórmulas para los coeficientes de similitud [17]: • La similitud cosena, definida como: cs = dfx, y pdfx · dfy (2) • información mutua, definida como: mi = log n · dfx, y dfx · dfy (3 (3) • Ratio de probabilidad, definida en los párrafos a continuación. DFX es la frecuencia de documento del término X y DFX, y es el número de documentos que contienen X e Y. Para aumentar aún más la calidad de las puntuaciones generadas, limitamos el último indicador a las coincidencias dentro de una ventana de los términos W. Establecemos W como lo mismo que la cantidad máxima de palabras clave de expansión deseadas. La relación de probabilidad de Dunnings λ [9] es una métrica basada en la concurrencia similar a χ2. Comienza intentando rechazar la hipótesis nula, según la cual dos términos A y B aparecerían en texto independientemente el uno del otro. Esto significa que p (a b) = p (a¬b) = p (a), donde p (a-b) es la probabilidad de que el término a no sea seguido por el término B. en consecuencia, la prueba de independencia de A y Bse puede realizar mirando si la distribución de un dado que B está presente es la misma que la distribución de un dado que B no está presente. Por supuesto, en realidad sabemos que estos términos no son independientes en el texto, y solo usamos las métricas estadísticas para resaltar los términos que aparecen con frecuencia juntos. Comparamos los dos procesos binomiales utilizando las relaciones de probabilidad de sus hipótesis asociadas. Primero, definamos la relación de probabilidad para una hipótesis: λ = maxω∈ω0 H (Ω; k) maxω∈ω H (Ω; k) (4) donde Ω es un punto en el espacio de parámetros ω, ω0 es el particularLa hipótesis que se está probando, y K es un punto en el espacio de observaciones K. Si suponemos que dos distribuciones binomiales tienen el mismo parámetro subyacente, es decir, {(p1, p2) |p1 = p2}, podemos escribir: λ = maxp h (p, p; k1, k2, n1, n2) maxp1, p2 h (p1, p2; k1, k2, n1, n2) (5) donde h (p1 (p1, p2; k1, k2, n1, n2) = pk1 1 · (1 - p1) (n1 - k1) · n1 k1 ¡· pk2 2 · (1 - p2) (n2 - k2) · n2 k2 ¡. Dado que los máximos se obtienen con p1 = k1 n1, p2 = k2 n2 y p = k1+k2 n1+n2, tenemos: λ = maxp l (p, k1, n1) l (p, k2, n2) maxp1,P2 L (P1, K1, N1) L (P2, K2, N2) (6) donde L (P, K, N) = Pk · (1 - P) N - K. Tomando el logaritmo de la probabilidad, obtenemos: −2 · log λ = 2 · [log l (p1, k1, n1) + log l (p2, k2, n2) - log l (p, k1, n1) - logL (P, K2, N2)] Donde log L (P, K, N) = K · log P + (N - K) · log (1 - p). Finalmente, si escribimos O11 = P (A B), O12 = P (¬A B), O21 = P (A ¬B) y O22 = P (¬A¬B), entonces la probabilidad de concurrencia de los términos A yB se convierte en: −2 · log λ = 2 · [o11 · log p1 + o12 · log (1 - p1) + o21 · log p2 + o22 · log (1 - p2) - (o11 + o21) · log p - ((O12+o22) · log (1 - p)] donde p1 = k1 n1 = o11 o11+o12, p2 = k2 n2 = o21 o21+o22, y p = k1+k2 n1+n2 expansión basada en el teso. Los tesauros a gran escala encapsulan el conocimiento global sobre las relaciones de términos. Por lo tanto, primero identificamos el conjunto de términos estrechamente relacionados con cada palabra clave de consulta, y luego calculamos el nivel de concurrencia de escritorio de cada uno de estos posibles términos de expansión con toda la solicitud de búsqueda inicial. Al final, se mantienen esas sugerencias con las frecuencias más altas. El algoritmo es el siguiente: Algoritmo 3.1.2.2. Expansión de consulta basada en el tesauro filtrado.1: para cada palabra clave k de una consulta de entrada Q: 2: Seleccione los siguientes conjuntos de términos relacionados usando WordNet: 2a: Syn: Todos los sinónimos 2B: Sub: Todos los subconceptos que residen en un nivel por debajo de K 2C: Super: Todos los super-conceptos que residen un nivel por encima de K 3: para cada conjunto SI de los conjuntos mencionados anteriormente: 4: para cada término t de Si: 5: Busque el PIR con (Q | T), es decir, la consulta original, como se expandió con T 6: Sea h el número de éxitos de la búsqueda anterior (es decir, el nivel de concurencia de t con Q) 7: devuelve los términos Top-K según lo ordenado por sus valores H. Observamos tres tipos de relaciones a términos (pasos 2a-2c): (1) sinónimos, (2) subconceptos, a saber, hiponomas (es decir, subclases) y mierymes (es decir, subpartes) y (3) Super-conceptos, a saber, hipernyms (es decir, súper clases) y holónimos (es decir, súper partes). Como representan tipos de asociación bastante diferentes, los investigamos por separado. Limitamos el conjunto de expansión de salida (Paso 7) para contener solo términos que aparecen al menos t veces en el escritorio, para evitar sugerencias ruidosas, con t = min (n docsepertópico, mindocs). Establecimos DocSpertopic = 2, 500 y Mindocs = 5, el último que está afrontando el caso de pequeños pirs.3.2 Experimentos 3.2.1 Configuración experimental Evaluamos nuestros algoritmos con 18 materias (Ph.D. y Postdoc. Estudiantes en diferentes áreas de informática y educación). Primero, instalaron nuestro motor de búsqueda basado en Lucene3 y 3 claramente, si uno ya hubiera instalado una aplicación de búsqueda de escritorio, entonces esta sobrecarga no estaría presente.indexado todo su contenido almacenado localmente: archivos dentro de rutas, correos electrónicos y caché web seleccionados por el usuario. Sin pérdida de generalidad, centramos los experimentos en máquinas de un solo usuario. Luego, eligieron 4 consultas relacionadas con sus actividades cotidianas, de la siguiente manera: • Una consulta de Altavista muy frecuente, como se extrae de las consultas más importantes del 2% más emitidas al motor de búsqueda dentro de un registro de 7.2 millones de entradas a partir de octubre de 2001. Para conectar dicha consulta a los intereses de cada usuarios, agregamos una fase de preprocesamiento fuera de línea: generamos las solicitudes de búsqueda más frecuentes y luego seleccionamos aleatoriamente una consulta con al menos 10 golpes en el escritorio de cada sujeto. Para garantizar aún más un escenario de la vida real, a los usuarios se les permitió rechazar la consulta propuesta y solicitar una nueva, si lo consideraban totalmente fuera de sus áreas de interés.• Una consulta de registro seleccionada al azar, filtrada utilizando el mismo procedimiento que anteriormente.• Una consulta específica autoseleccionada, que pensaron que solo tenía un significado.• Una consulta ambigua autoseleccionada, que pensaron que tenían al menos tres significados. Las longitudes de consulta promedio fueron de 2.0 y 2.3 términos para las consultas de registro, así como 2.9 y 1.8 para los autoseleccionados. A pesar de que nuestros algoritmos están destinados principalmente a mejorar la búsqueda cuando utilizan palabras clave de consulta ambigua, elegimos investigar su rendimiento en un amplio lapso de tipos de consultas, para ver cómo funcionan en todas las situaciones. Las consultas de registro evalúan las solicitudes de la vida real, en contraste con las auto-seleccionadas, que se dirigen a la identificación de actuaciones superior e inferior. Tenga en cuenta que los primeros estaban un poco más lejos del interés de cada sujeto, por lo que también fueron más difíciles de personalizar. Para obtener una visión de la relación entre cada tipo de consulta y los intereses de los usuarios, le pedimos a cada persona que califique la consulta en sí misma con un puntaje de 1 a 5, con las siguientes interpretaciones: (1) nunca ha oído hablar de ella, (2) noConozca, pero escuché de él, (3) lo sepan parcialmente, (4) lo sepan bien, (5) gran interés. Los grados obtenidos fueron 3.11 para las consultas de registro más importantes, 3.72 para las seleccionadas al azar, 4.45 para las específicas auto-seleccionadas y 4.39 para las ambiguas autoseleccionadas. Para cada consulta, recolectamos las 5 URL principales generadas por 20 versiones de los algoritmos4 presentados en la Sección 3.1. Estos resultados se arrastraron en un conjunto que generalmente contenía entre 70 y 90 URL. Por lo tanto, cada sujeto tuvo que evaluar unos 325 documentos para las cuatro consultas, ya que ni al tanto del algoritmo, ni de la clasificación de cada URL evaluada. En general, se emitieron 72 consultas y se evaluaron más de 6,000 URL durante el experimento. Para cada una de estas URL, los evaluadores tuvieron que dar una calificación de 0 a 2, dividiendo los resultados relevantes en dos categorías, (1) relevante y (2) altamente relevante. Finalmente, la calidad de cada clasificación se evaluó utilizando la versión normalizada de ganancia acumulativa con descuento (DCG) [15]. DCG es una medida rica, ya que da más peso a documentos altamente calificados, al tiempo que incorpora diferentes niveles de relevancia al darles diferentes valores de ganancia: DCG (i) = & g (1), si i = 1 DCG (i - 1)+ G (i)/log (i), de lo contrario. Usamos g (i) = 1 para resultados relevantes, y g (i) = 2 para los altamente relevantes. Como las consultas que tienen documentos de salida más relevantes tendrán un DCG más alto, también normalizamos su valor a un puntaje entre 0 (el peor DCG posible dadas las clasificaciones) y 1 (la mejor DCG posible dadas las calificaciones) para facilitar el promedio de las consultas. Todos los resultados fueron probados para determinar la significación estadística utilizando pruebas t.4 Tenga en cuenta que todas las partes de nivel de escritorio de nuestros algoritmos se realizaron con Lucene utilizando sus funciones de búsqueda y clasificación predefinidas. Aspectos específicos algorítmicos. El parámetro principal de nuestros algoritmos es el número de palabras clave de expansión generadas. Para este experimento, lo establecemos en 4 términos para todas las técnicas, dejando un análisis en este nivel para una investigación posterior. Para optimizar la velocidad de cálculo del tiempo de ejecución, elegimos limitar el número de palabras clave de salida por documento de escritorio al número de palabras clave de expansión deseadas (es decir, cuatro). Para todos los algoritmos también investigamos mayores limitaciones. Esto nos permitió observar que el método de compuestos léxicos funcionaría mejor si solo se seleccionara un compuesto por documento. Por lo tanto, elegimos experimentar con este nuevo enfoque también. Para todas las demás técnicas, considerar menos de cuatro términos por documento no parecía producir constantemente ninguna ganancia cualitativa adicional. Etiquetamos los algoritmos que evaluamos de la siguiente manera: 0. Google: La salida real de Google Consult, según lo devuelve la API de Google;1. TF, DF: frecuencia de término y documento;2. LC, LC [O]: regular y optimizado (considerando solo un compuesto superior por documento) compuestos léxicos;3. SS: selección de oraciones;4. TC [CS], TC [MI], TC [LR]: estadísticas de concurrencia de término utilizando similitudes de coseno respectivamente, información mutua y relación de probabilidad como coeficientes de similitud;5. Wn [Syn], Wn [Sub], Wn [Sup]: expansión basada en WordNet con sinónimos, subconceptos y superconceptos, respectivamente. A excepción de la expansión basada en el tesauro, en todos los casos también investigamos el rendimiento de nuestros algoritmos al explotar solo el caché del navegador web para representar la información personal de los usuarios. Esto está motivado por el hecho de que otros documentos personales, como por ejemplo, se sabe que los correos electrónicos tienen un lenguaje algo diferente al que reside en la World Wide Web [34]. Sin embargo, a medida que este enfoque funcionó visiblemente más pobre que el uso de los datos de escritorio completos, lo omitimos del análisis posterior.3.2.2 Consultas de registro de resultados. Evaluamos todas las variantes de nuestros algoritmos usando NDCG. Para las consultas de registro, el mejor rendimiento se logró con TF, LC [O] y TC [LR]. Las mejoras que trajeron fueron de hasta 5.2% para consultas superiores (P = 0.14) y 13.8% para consultas seleccionadas al azar (P = 0.01, estadísticamente significativas), ambas obtenidas con LC [O]. Un resumen de todos los resultados se muestra en la Tabla 1. Tanto TF como LC [O] arrojaron muy buenos resultados, lo que indica que los enfoques simples de palabras clave y orientados a la expresión podrían ser suficientes para la tarea de expansión de consultas basada en el escritorio. LC [O] fue mucho mejor que LC, mejorando su calidad con hasta el 25.8% en el caso de consultas log de registro seleccionadas al azar, mejoría que también fue significativa con p = 0.04. Por lo tanto, una selección de compuestos que abarcan varios documentos de escritorio es más informativa sobre los intereses de los usuarios que el enfoque general, en el que no hay restricción en el número de compuestos producidos a partir de cada elemento personal. Los enfoques orientados al escritorio más complejos, a saber, la selección de oraciones y los algoritmos basados en la concurrencia de todo el término, mostraron un rendimiento bastante promedio, sin mejoras visibles, excepto TC [LR]. Además, la expansión basada en el tesauro generalmente producía muy pocas sugerencias, posiblemente debido a las muchas consultas técnicas empleadas por nuestros sujetos. Sin embargo, observamos que expandirse con subconceptos es muy bueno para los términos de la vida cotidiana (por ejemplo, CAR), mientras que el uso de superconceptos es valioso para compuestos que tienen al menos un término con bajo tecnicismo (por ejemplo, agrupación de documentos). Como se esperaba, la expansión basada en el sinónimo funcionó generalmente bien, aunque en algunos algoritmo NDCG significativo. NDCG significado. Arriba vs. Google Random vs. Google Google 0.42 - 0.40tf 0.43 p = 0.32 0.43 p = 0.04 df 0.17 - 0.23LC 0.39 - 0.36lc [o] 0.44 p = 0.14 0.45 p = 0.01 ss 0.33 - 0.36tc [CS] 0.37- 0.35tc [MI] 0.40 - 0.36tc [LR] 0.41 - 0.42 p = 0.06 WN [SYN] 0.42 - 0.38WN [SUB] 0.28 - 0.33WN [SUP] 0.26 - 0.26 Tabla 1: ganancia cumulativa con descuento normalizada a la primera5 Resultados al buscar consultas de registro superior (izquierda) y aleatoria (derecha). Algoritmo NDCG significado. NDCG significado. Clear vs. Google Ambiguo vs. Google Google 0.71 - 0.39TF 0.66 - 0.52 P 0.01 DF 0.37 - 0.31LC 0.65 - 0.54 P 0.01 LC [O] 0.69 - 0.59 P 0.01 SS 0.56 - 0.52 P 0.01 TC [CS] 0.60 - 0.50p = 0.01 tc [mi] 0.60 - 0.47 p = 0.02 tc [LR] 0.56 - 0.47 p = 0.03 wn [syn] 0.70 - 0.36wnObtenga los primeros 5 resultados al buscar consultas de Clear (izquierda) y ambiguas (derecha) seleccionadas.casos técnicos produjo sugerencias bastante generales. Finalmente, notamos que Google estaba muy optimizado para algunas consultas frecuentes superiores. Sin embargo, incluso dentro de este escenario más difícil, algunos de nuestros algoritmos de personalización produjeron mejoras estadísticamente significativas sobre la búsqueda regular (es decir, TF y LC [O]). Consultas autoseleccionadas. Los valores de NDCG obtenidos con consultas autoelectadas se representan en la Tabla 2. Si bien nuestros algoritmos no mejoraron Google para las tareas de búsqueda claras, produjeron fuertes mejoras de hasta 52.9% (que, por supuesto, también fueron muy significativas con P 0.01) cuando se utilizaron con consultas ambiguas. De hecho, casi todos nuestros algoritmos dieron como resultado mejoras estadísticamente significativas sobre Google para este tipo de consulta. En general, las diferencias relativas entre nuestros algoritmos fueron similares a las observadas para las consultas basadas en log. Como en el análisis anterior, la frecuencia de término basada en escritorio simple y las métricas de compuestos léxicos funcionaban mejor. Sin embargo, también se obtuvo un muy buen resultado para la selección de oraciones basada en el escritorio y métricas de concurrencia de todo el término. No hubo diferencias visibles entre el comportamiento de los tres enfoques diferentes para el cálculo de la coincurrencia. Finalmente, para el caso de consultas claras, notamos que menos términos de expansión que 4 podrían ser menos ruidosos y, por lo tanto, útiles para lograr mejoras adicionales. Por lo tanto, seguimos esta idea con los algoritmos adaptativos presentados en la siguiente sección.4. Introducción de la adaptación en la sección anterior Hemos investigado el comportamiento de cada técnica al agregar un número fijo de palabras clave a la consulta del usuario. Sin embargo, un algoritmo óptimo de expansión de consulta personalizada debe adaptarse automáticamente a varios aspectos de cada consulta, así como a las particularidades de la persona que lo usa. En esta sección discutimos los factores que influyen en el comportamiento de nuestros algoritmos de expansión, que podrían usarse como entrada para el proceso de adaptación. Luego, en la segunda parte presentamos algunos experimentos iniciales con uno de ellos, a saber, la claridad de consulta.4.1 Factores de adaptación Varios indicadores podrían ayudar al algoritmo a sintonizar automáticamente el número de términos de expansión. Comenzamos discutiendo la adaptación analizando el nivel de claridad de consulta. Luego, presentamos brevemente un enfoque para modelar el proceso de formulación de consultas genéricas para adaptar automáticamente el algoritmo de búsqueda y discutir algunos otros factores posibles que podrían ser útiles para esta tarea. Claridad de consulta. El interés por analizar la dificultad de consultas ha aumentado solo recientemente, y no hay muchos documentos que aborden este tema. Sin embargo, ha sabido hace mucho tiempo que la desambiguación de la consulta tiene un alto potencial de mejorar la efectividad de la recuperación para búsquedas de bajo retiro con consultas muy cortas [20], que es exactamente nuestro escenario específico. Además, el éxito de los sistemas IR claramente varía en diferentes temas. Por lo tanto, proponemos utilizar un número de estimación que exprese el nivel calculado de claridad de consulta para ajustar automáticamente la cantidad de personalización alimentada en el algoritmo. Las siguientes métricas están disponibles: • La longitud de la consulta se expresa simplemente por el número de palabras en la consulta del usuario. La solución es bastante ineficiente, según lo informado por él y Ounis [14].• El alcance de la consulta se relaciona con las FDI de toda la consulta, como en: c1 = log (#Documentsincollection #hits (consulta)) (7) Esta métrica funciona bien cuando se usa con colecciones de documentos que cubren un solo tema, pero de lo contrario [7 de lo contrario [7, 14].• La claridad de la consulta [7] parece ser la mejor, así como la técnica más aplicada hasta ahora. Mide la divergencia entre el modelo de idioma asociado a la consulta de usuario y el modelo de idioma asociado a la colección. En una versión simplificada (es decir, sin suavizar los términos que no están presentes en la consulta), se puede expresar de la siguiente manera: c2 = w∈Query pml (w | consulta) · log pml (w | consulta) pcoll (w) (8) donde pml (w | consulta) es la probabilidad de la palabra w dentro de la consulta enviada, y pcoll (w) es la probabilidad de w dentro de toda la colección de documentos. Existen otras soluciones, pero creemos que son demasiado costosas computacionalmente para la gran cantidad de datos que deben procesarse dentro de las aplicaciones web. Por lo tanto, decidimos investigar solo C1 y C2. Primero, analizamos su rendimiento en un gran conjunto de consultas y dividimos sus predicciones de claridad en tres categorías: • Pequeño alcance / consulta clara: C1 ∈ [0, 12], C2 ∈ [4, ∞).• Medio alcance / consulta semi-ambigua: c1 ∈ [12, 17), c2 ∈ [2.5, 4).• Alcance grande / consulta ambigua: c1 ∈ [17, ∞), c2 ∈ [0, 2.5]. Para limitar la cantidad de experimentos, analizamos solo los resultados producidos al emplear C1 para el PIR y C2 para la web. Como base algorítmica, utilizamos LC [O], es decir, compuestos léxicos optimizados, que fue claramente el método ganador en el análisis anterior. Como la investigación manual mostró que se sobreportó ligeramente los términos de expansión para consultas claras, utilizamos un sustituto de este caso particular. Se consideraron dos candidatos: (1) TF, es decir, el segundo mejor enfoque, y (2) Wn [Syn], como observamos que sus términos de expansión primero y segundo a menudo eran muy buenos. Escopio de escritorio Claridad web No. de Algoritmo de términos Grande ambiguo 4 lc [o] Gran semi-ambig.3 lc [o] grande transparente 2 lc [o] medio ambiguo 3 lc [o] medio ambig medio.2 lc [o] medio claro 1 tf / wn [syn] pequeño ambiguo 2 tf / wn [syn] pequeño semi-ambig.1 tf / wn [syn] pequeño transparente 0 table 3: expansión de consulta personalizada adaptativa. Dados los algoritmos y las medidas de claridad, implementamos el procedimiento de adaptación adaptando la cantidad de términos de expansión agregados a la consulta original, en función de su ambigüedad en la web, así como dentro de los usuarios PIR. Tenga en cuenta que el nivel de ambigüedad está relacionado con el número de documentos que cubren una determinada consulta. Por lo tanto, hasta cierto punto, tiene diferentes significados en la web y dentro de PIRS. Si bien una consulta considerada ambigua en una gran colección, como la web, muy probablemente tendrá una gran cantidad de significados, este puede no ser el caso del escritorio. Tome, por ejemplo, el PageRank de consulta. Si el usuario es un experto en análisis de enlaces, muchos de sus documentos podrían coincidir con este término y, por lo tanto, la consulta se clasificaría como ambigua. Sin embargo, cuando se analiza contra la web, esta es definitivamente una consulta clara. En consecuencia, empleamos más términos adicionales, cuando la consulta era más ambigua en la web, pero también en el escritorio. Dicho de otra manera, las consultas consideradas claras en el escritorio inherentemente no estaban bien cubiertas dentro de los usuarios PIR y, por lo tanto, tenían menos palabras clave adjuntas. El número de términos de expansión que utilizamos para cada combinación de niveles de alcance y claridad se representa en la Tabla 3. Proceso de formulación de consultas. La expansión de consulta interactiva tiene un alto potencial para mejorar la búsqueda [29]. Creemos que modelar su proceso subyacente sería muy útil para producir algoritmos de búsqueda web adaptativos cualitativos. Por ejemplo, cuando el usuario está agregando un nuevo término a su consulta emitida anteriormente, básicamente está reformulando su solicitud original. Por lo tanto, es más probable que los términos recién agregados transmitan información sobre sus objetivos de búsqueda. Para un motor de recuperación general no personalizado, esto podría corresponder a dar más peso a estas nuevas palabras clave. Dentro de nuestro escenario personalizado, las expansiones generadas pueden ser sesgadas de manera similar hacia estos términos. Sin embargo, se necesitan más investigaciones para resolver los desafíos que plantea este enfoque. Otras características. La idea de adaptar el proceso de recuperación a varios aspectos de la consulta, del propio usuario e incluso del algoritmo empleado ha recibido solo poca atención en la literatura. Solo se han investigado algunos enfoques, generalmente indirectamente. Existen estudios de comportamientos de consulta en diferentes momentos del día, o de los temas abarcados por las consultas de varias clases de usuarios, etc. Sin embargo, generalmente no discuten cómo estas características pueden incorporarse realmente en el proceso de búsqueda en sí y casi nunca se han relacionado con la tarea de personalización web.4.2 Experimentos Utilizamos exactamente la misma configuración experimental que para nuestro análisis anterior, con dos consultas basadas en registros y dos autoseleccionadas (todos diferentes de antes, para asegurarse de que no haya sesgo en los nuevos enfoques), evaluado conNDCG sobre la salida de resultados de los 5 mejores por cada algoritmo. Los algoritmos de expansión de consultas personalizados adaptativos recientemente propuestos se denotan como un [LCO/TF] para el enfoque utilizando TF con las consultas de escritorio claras y como [LCO/WN] cuando se utilizó WN [SYN] en lugar de TF. Los resultados generales fueron al menos similares o mejores que Google para todo tipo de consultas de registro (ver Tabla 4). Para las consultas frecuentes superiores, el algoritmo NDCG significado. NDCG significado. Top vs. Google Random vs. Google Google 0.51 - 0.45tf 0.51 - 0.48 P = 0.04 LC [O] 0.53 P = 0.09 0.52 P <0.01 WN [SYN] 0.51 - 0.45A [LCO/TF] 0.56 P <0.01 0.49 P <= 0.04 A [LCO/WN] 0.55 P = 0.01 0.44Table 4: ganancia acumulativa con descuento normalizada en los primeros 5 resultados cuando se usa nuestros algoritmos de búsqueda personalizados adaptativos en las consultas de registro de la parte superior (izquierda) y aleatoria (derecha). Algoritmo NDCG significado. NDCG significado. Clear vs. Google Ambiguo vs. Google Google 0.81 - 0.46TF 0.76 - 0.54 P = 0.03 LC [O] 0.77 - 0.59 P 0.01 WN [SYN] 0.79 - 0.44a [LCO/TF] 0.81 - 0.64 P 0.01 A [LCO//WN] 0.81 - 0.63 P 0.01 Tabla 5: Ganancia acumulativa con descuento normalizada en los primeros 5 resultados cuando se usa nuestros algoritmos de búsqueda personalizados adaptativos en consultas de Clear (izquierda) y ambiguas (derecha) seleccionadas.Ambos algoritmos adaptativos, A [LCO/TF] y A [LCO/WN], mejoran con 10.8% y 7.9% respectivamente, ambas diferencias también son estadísticamente significativas con P ≤ 0.01. También logran una mejora de hasta 6.62% sobre el algoritmo estático de mejor rendimiento, LC [O] (P = 0.07). Para consultas seleccionadas al azar, a pesar de que A [LCO/TF] produce resultados significativamente mejores que Google (P = 0.04), ambos enfoques adaptativos quedan detrás de los algoritmos estáticos. La razón principal parece ser la selección imperfecta del número de términos de expansión, en función de la claridad de consulta. Por lo tanto, se necesitan más experimentos para determinar el número óptimo de palabras clave de expansión generadas, en función del nivel de ambigüedad de consulta. El análisis de las consultas autoseleccionadas muestra que la adaptación puede traer aún más mejoras a la personalización de la búsqueda web (ver Tabla 5). Para consultas ambiguas, los puntajes dados a la búsqueda de Google se mejoran en un 40,6% a través de un [LCO/TF] y en un 35,2% a través de un [LCO/WN], ambos muy significativos con P 0,01. La adaptación también trae otra mejora del 8,9% sobre la personalización estática de LC [O] (p = 0,05). Incluso para consultas claras, los algoritmos flexibles recientemente propuestos funcionan ligeramente mejor, mejorando con 0.4% y 1.0% respectivamente. Todos los resultados se representan gráficamente en la Figura 1. Notamos que un [LCO/TF] es el mejor algoritmo general, que funciona mejor que Google para todo tipo de consultas, ya sea extraída del registro del motor de búsqueda o autoseleccionada. Los experimentos presentados en esta sección confirman claramente que la adaptación es un paso más necesario para tomar la personalización de la búsqueda web.5. Conclusiones y trabajo adicional En este documento propusimos expandir las consultas de búsqueda web explotando el repositorio de información personal de los usuarios para extraer automáticamente palabras clave adicionales relacionadas tanto con la consulta en sí como a los intereses de los usuarios, personalizando la salida de búsqueda. En este contexto, el documento incluye las siguientes contribuciones: • Propusimos cinco técnicas para determinar los términos de expansión de los documentos personales. Cada uno de ellos produce palabras clave de consulta adicionales mediante el análisis de los usuarios de escritorio al aumento de los niveles de granularidad, que van desde el análisis del nivel de término y de expresión hasta las estadísticas de co-ocurrencia globales y los tesauros externos. Figura 1: ganancia relativa de NDCG (en %) para cada algoritmo en general, así como por categoría de consulta separada.• Proporcionamos un análisis empírico exhaustivo de varias variantes de nuestros enfoques, en cuatro escenarios diferentes. Mostramos algunos de estos enfoques para funcionar muy bien, produciendo mejoras de NDCG de hasta 51.28%.• Movimos este marco de búsqueda personalizado y propusimos para que el proceso de expansión sea adaptable a las características de cada consulta, un fuerte enfoque en su nivel de claridad.• Dentro de un conjunto separado de experimentos, mostramos que nuestros algoritmos adaptativos proporcionan una mejora adicional del 8,47% sobre el mejor enfoque previamente identificado. Actualmente estamos realizando investigaciones sobre la dependencia entre varias características de consulta y el número óptimo de términos de expansión. También estamos analizando otros tipos de enfoques para identificar sugerencias de expansión de consultas, como la aplicación de análisis semántico latente en los datos de escritorio. Finalmente, estamos diseñando un conjunto de combinaciones más complejas de estas métricas para proporcionar una mejor adaptación a nuestros algoritmos.6. Agradecimientos Agradecemos a Ricardo Baeza-Yates, Vassilis Plachouras, Carlos Castillo y Vanessa Murdock de Yahoo!Para las interesantes discusiones sobre la configuración experimental y los algoritmos que presentamos. Agradecemos a Fabrizio Silvestri de CNR y a Ronny Lempel de IBM por proporcionarnos el registro de consultas de Altavista. Finalmente, agradecemos a nuestros colegas de L3 por participar en los experimentos que realizamos el tiempo que realizamos, así como a la Comisión Europea por el apoyo de financiación (Project Nepomuk, 6to Programa Marco, IST Contract no. 027705).7. Referencias [1] J. Allan y H. Raghavan. Uso de patrones de parte de voz para reducir la ambigüedad de la consulta. En Proc.del 25 ° Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 2002. [2] P. G. Anick y S. Tipirneni. El Asistente de búsqueda de paráfrasis: Comentarios terminológicos para la búsqueda de información iterativa. En Proc.del 22º Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 1999. [3] D. Carmel, E. Farchi, Y. Petruschka y A. Soffer. Weinse de consulta automática utilizando afinidades léxicas con máxima ganancia de información. En Proc.del 25 ° Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 283-290, 2002. [4] C. Carpineto, R. de Mori, G. Romano y B. Bigi. Un enfoque teórico de información para la expansión automática de consultas. ACM TOIS, 19 (1): 1-27, 2001. [5] C.-H.Chang y C.-C.HSU. Integrando la expansión de la consulta y la retroalimentación de relevancia conceptual para la recuperación de información web personalizada. En Proc.del séptimo intl. Conf.En World Wide Web, 1998. [6] P. A. Chirita, C. Firan y W. Nejdl. Resumiendo el contexto local para personalizar la búsqueda web global. En Proc.del 15 ° Intl. CIKM Conf.Sobre la gestión de la información y el conocimiento, 2006. [7] S. Cronen-Townsend, Y. Zhou y W. B. Croft. Predecir el rendimiento de la consulta. En Proc.del 25 ° Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 2002. [8] H. Cui, J.-R.Wen, J.-Y. Nie y W.-Y. Mamá. Expansión de consultas probabilísticas utilizando registros de consulta. En Proc.del 11 ° Intl. Conf.En World Wide Web, 2002. [9] T. Dunning. Métodos precisos para las estadísticas de sorpresa y coincidencia. Computational Linguistics, 19: 61-74, 1993. [10] H. P. Edmundson. Nuevos métodos en extracción automática. Journal of the ACM, 16 (2): 264-285, 1969. [11] E. N. Efthimiadis. Opciones de usuario: un nuevo criterio para la evaluación de algoritmos de clasificación para la expansión de consultas interactivas. Procesamiento y gestión de la información, 31 (4): 605-620, 1995. [12] D. Fogaras y B. Racz. Búsqueda de similitud basada en el enlace de escala. En Proc.del 14º intl. World Wide Web Conf., 2005. [13] T. Haveliwala. PageRank sensible al tema. En Proc.del 11 ° Intl. World Wide Web Conf., Honolulu, Hawai, mayo de 2002. [14] B. Él y yo. Ousis. Inferir el rendimiento de la consulta utilizando predictores pre-retrievales. En Proc.del 11 ° Intl. Spire Conf.Sobre el procesamiento de cadenas y la recuperación de información, 2004. [15] K. J¨arvelin y J. Keklinen. IR Métodos de evaluación para recuperar documentos altamente relevantes. En Proc.del 23 ° intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 2000. [16] G. Jeh y J. Widom. Escala de búsqueda web personalizada. En Proc.del 12º intl. Conferencia World Wide Web, 2003. [17] M.-C.Kim y K.-S.Choi. Una comparación de las medidas de similitud basadas en colocación en la expansión de la consulta. Inf. Proc.y Mgmt., 35 (1): 19-30, 1999. [18] S.-B. Kim, H.-C.SEO y H.-C.Borde. Recuperación de información utilizando los sentidos de las palabras: enfoque de etiquetado de sentido raíz. En Proc.del 27 ° Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 2004. [19] R. Kraft y J. Zien. Texto de anclaje de minería para el refinamiento de la consulta. En Proc.del 13 ° Intl. Conf.En World Wide Web, 2004. [20] R. Krovetz y W. B. Croft. Ambigüedad léxica y recuperación de información. ACM Trans. Inf. Syst., 10 (2), 1992. [21] A. M. Lam-Ladesina y G. J. F. Jones. Aplicar técnicas de resumen para la selección de términos en retroalimentación de relevancia. En Proc.del 24 ° Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 2001. [22] S. Liu, F. Liu, C. Yu y W. Meng. Un enfoque efectivo para la recuperación de documentos mediante la utilización de WordNet y el reconocimiento de frases. En Proc.del 27 ° Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 2004. [23] G. Miller. WordNet: una base de datos léxica electrónica. Comunicaciones de la ACM, 38 (11): 39-41, 1995. [24] L. Nie, B. Davison y X. Qi. Análisis de enlaces tópicos para la búsqueda web. En Proc.del 29 ° intl. Conferencia ACM Sigir.en res.y desarrollo en Inf. Retr., 2006. [25] L. Page, S. Brin, R. Motwani y T. Winograd. Ranking de citas de PageRank: traer orden a la web. Informe técnico, Stanford Univ., 1998. [26] F. Qiu y J. Cho. Identificación automática del interés del usuario para la búsqueda personalizada. En Proc.del 15 ° Intl. WWW Conf., 2006. [27] Y. Qiu y H.-P.Frei. Expansión de consultas basada en el concepto. En Proc.del 16 ° Intl. Conferencia ACM Sigir.sobre investigación y desarrollo en Inf. Retr., 1993. [28] J. Rocchio. Comentarios de relevancia en la recuperación de información. El sistema de recuperación inteligente: experimentos en el procesamiento automático de documentos, páginas 313-323, 1971. [29] I. Ruthven. Reexaminando la efectividad potencial de la expansión de consulta interactiva. En Proc.del 26 ° Intl. ACM Sigir Conf., 2003. [30] T. Sarlos, A. A. Benczur, K. Csalogany, D. Fogaras y B. Racz. Para aleatorizar o no aleatorizar: Resúmenes óptimos de espacio para el análisis de hipervínculos. En Proc.del 15 ° Intl. Www conf., 2006. [31] C. Shah y W. B. Croft. Evaluación de técnicas de recuperación de alta precisión. En Proc.del 27 ° Intl. Conferencia ACM Sigir.sobre investigación y desarrollo en recuperación de información, páginas 2-9, 2004. [32] K. Sugiyama, K. Hatano y M. Yoshikawa. Búsqueda web adaptativa basada en el perfil de usuario construido sin ningún esfuerzo de los usuarios. En Proc.del 13 ° Intl. World Wide Web Conf., 2004. [33] D. Sullivan. Cuanto más viejo sea, más querrá una búsqueda personalizada, 2004. http://searchenginewatch.com/searchday/article.php/3385131.[34] J. Teevan, S. Dumais y E. Horvitz. Personalizar la búsqueda a través del análisis automatizado de intereses y actividades. En Proc.del 28 ° Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 2005. [35] E. Volokh. Personalización y privacidad. Comun. ACM, 43 (8), 2000. [36] E. M. Voorhees. Expansión de consulta utilizando relaciones léxicas semánticas. En Proc.del 17 ° intl. Conferencia ACM Sigir.en res.y desarrollo en Inf. Retr., 1994. [37] J. Xu y W. B. Croft. Expansión de consulta utilizando análisis de documentos locales y globales. En Proc.del 19 ° Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, 1996. [38] S. Yu, D. Cai, J.-R.Wen y W.-Y. Mamá. Mejora de la retroalimentación de pseudo-relevancia en la recuperación de información web utilizando la segmentación de la página web. En Proc.del 12º intl. Conf.En World Wide Web, 2003.