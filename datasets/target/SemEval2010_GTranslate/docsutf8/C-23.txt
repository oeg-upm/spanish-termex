Implementación de un mecanismo de ajuste dinámico con una selección de réplica eficiente en entornos de cuadrícula de datos Chao-tung yang i-hsien yang chun-hsiang chen shih-yu wang de informática de alto rendimiento Departamento de informática e ingeniería de la información Universidad de Tunghai City, 40704, TaiwanR.O.C. ctyang@thu.edu.tw g932813@thu.edu.tw Resumen La arquitectura de co-asignación se desarrolló para permitir la descarga paralela de conjuntos de datos de múltiples servidores. Varias estrategias de co-asignación se han acoplado y utilizado para explotar las diferencias de velocidad entre varios enlaces del servidor del cliente y para abordar las fluctuaciones de la velocidad dinámica dividiendo archivos en múltiples bloques de igualdad de tamaños. Sin embargo, un obstáculo importante, el tiempo de inactividad de los servidores más rápidos que tienen que esperar a que el servidor más lento entregue el bloque final, hace que sea importante reducir las diferencias en el tiempo de finalización entre los servidores de réplicas. En este documento, proponemos un esquema de coaclada dinámica, a saber, el esquema de co-asignación de ajuste recursivo, para mejorar el rendimiento de la transferencia de datos en las redes de datos. Nuestro enfoque reduce el tiempo de inactividad dedicado a esperar el servidor más lento y disminuye el tiempo de finalización de la transferencia de datos. También proporcionamos un esquema efectivo para reducir el costo de volver a armar los bloques de datos. Categorías y descriptores de sujetos C.2.4 [Sistemas distribuidos]: aplicaciones distribuidas. H.3.5 [Servicios de información en línea]: intercambio de datos, servicios basados en la web. Gestión de términos generales, rendimiento, diseño, experimentación.1. INTRODUCCIÓN Redes de datos Recursos distribuidos agregados para resolver problemas de gestión de conjuntos de datos de gran tamaño. La mayoría de las aplicaciones de cuadrícula de datos se ejecutan simultáneamente y acceden a grandes números de archivos de datos en el entorno de la red. Ciertas aplicaciones científicas intensivas en datos, como física de alta energía, aplicaciones bioinformáticas y observatorios astrofísicos virtuales, implican grandes cantidades de datos que requieren sistemas de administración de archivos de datos para replicar archivos y administrar transferencias de datos y acceso a datos distribuidos. La infraestructura de la cuadrícula de datos integra dispositivos de almacenamiento de datos y servicios de gestión de datos en el entorno de la red, que consiste en recursos de computación y almacenamiento dispersos, tal vez ubicados en diferentes países/regiones aún accesibles para los usuarios [12]. La replicación del contenido popular en los servidores distribuidos se usa ampliamente en la práctica [14, 17, 19]. Recientemente, las comunidades científicas de intercambio de datos a gran escala, como las descritas en [1, 5], utilizaron esta tecnología para replicar sus grandes conjuntos de datos en varios sitios. La descarga de conjuntos de datos grandes de varias ubicaciones de réplicas puede dar como resultado tasas de rendimiento variadas, porque los sitios de réplica pueden tener diferentes arquitecturas, cargas del sistema y conectividad de red. La calidad del ancho de banda es el factor más importante que afecta las transferencias entre clientes y servidores, ya que las velocidades de descarga están limitadas por la congestión del tráfico de ancho de banda en los enlaces que conectan los servidores con los clientes. Una forma de mejorar las velocidades de descarga es determinar las mejores ubicaciones de réplicas utilizando técnicas de selección de réplicas [19]. Este método selecciona los mejores servidores para proporcionar tasas de transferencia óptimas porque la calidad del ancho de banda puede variar de manera impredecible debido a la naturaleza compartida de Internet. Otra forma es utilizar la tecnología de co-asignación [17] para descargar datos. La co-asignación de transferencias de datos permite a los clientes descargar datos de múltiples ubicaciones estableciendo múltiples conexiones en paralelo. Esto puede mejorar el rendimiento en comparación con los casos de servidor único y aliviar el problema de congestión de Internet [17]. Se proporcionaron varias estrategias de co-asignación en trabajos anteriores [17]. Queda un inconveniente del tiempo de inactividad ya que los servidores más rápidos deben esperar a que el servidor más lento entregue su bloque final. Por lo tanto, es importante reducir las diferencias en el tiempo de finalización entre los servidores de réplicas. En este documento, proponemos un esquema dinámico de co-asignación basado en la arquitectura de transferencia de datos de cuadrícula de co-asignación llamado esquema de co-asignación de recursos. Los resultados experimentales muestran que nuestro enfoque es superior a los métodos anteriores y logró el mejor rendimiento general. También discutimos el costo de la combinación y proporcionamos un esquema efectivo para reducirlo. El resto de este documento está organizado de la siguiente manera. La revisión y los estudios de antecedentes relacionados se presentan en la Sección 2 y la arquitectura de co-asignación y el trabajo relacionado se introducen en la Sección 3. En la Sección 4, nosotros propone un servicio de selección de réplica eficiente. Nuestros enfoques de investigación se describen en la Sección 5, y los resultados experimentales y una evaluación del rendimiento de nuestro esquema se presentan en la Sección 6. La Sección 7 concluye este trabajo de investigación.2. Antecedentes 2.1 Red de datos Las cuadrículas de datos permiten el intercambio, la selección y la conexión de una amplia variedad de recursos computacionales y de almacenamiento distribuidos geográficamente para resolver aplicaciones científicas intensivas de datos a gran escala (por ejemplo, física de alta energía, aplicaciones bioinformáticas y observatorio virtual astrofísico). El término cuadrícula de datos representa tradicionalmente la red de recursos de almacenamiento distribuidos, desde sistemas de archivo hasta cachés y bases de datos, que se vinculan utilizando un espacio de nombres lógico para crear identificadores globales y persistentes y proporcionar mecanismos de acceso uniformes [4]. Las cuadrículas de datos [1, 2, 16] federan muchos recursos de almacenamiento. Grandes colecciones de datos medidos o calculados están surgiendo como recursos importantes en muchas aplicaciones intensivas en datos.2.1.1 Gestión de réplicas La gestión de réplicas implica crear o eliminar réplicas en un sitio de cuadrícula de datos [19]. En otras palabras, el papel de un administrador de réplica es crear o eliminar réplicas, dentro de los sistemas de almacenamiento especificados. La mayoría de las veces, estas réplicas son copias exactas de los archivos originales, creadas solo para aprovechar ciertos beneficios de rendimiento. Un administrador de réplica generalmente mantiene un catálogo de réplica que contiene direcciones de sitio de réplica y las instancias de archivo. El servicio de gestión de réplicas es responsable de administrar la replicación de copias completas y parciales de conjuntos de datos, definidas como colecciones de archivos. El servicio de gestión de réplicas es solo un componente en un entorno de cuadrícula de datos que proporciona soporte para aplicaciones de alto rendimiento e intensivas en datos. Una réplica o ubicación es un subconjunto de una colección que se almacena en un sistema de almacenamiento físico particular. Puede haber múltiples subconjuntos posiblemente superpuestos de una colección almacenada en múltiples sistemas de almacenamiento en una cuadrícula de datos. Estos sistemas de almacenamiento de cuadrícula pueden usar una variedad de tecnologías de almacenamiento subyacentes y protocolos de movimiento de datos, que son independientes de la gestión de réplicas.2.1.2 Catálogo de réplicas Como se mencionó anteriormente, el propósito del catálogo de réplicas es proporcionar asignaciones entre nombres lógicos para archivos o colecciones y una o más copias de los objetos en sistemas de almacenamiento físico. El catálogo de réplica incluye entradas opcionales que describen archivos lógicos individuales. Los archivos lógicos son entidades con nombres globalmente únicos que pueden tener una o más instancias físicas. El catálogo puede contener opcionalmente una entrada lógica de archivo en el catálogo de réplicas para cada archivo lógico en una colección. Una cuadrícula de datos puede contener múltiples catálogos de réplicas. Por ejemplo, una comunidad de investigadores interesados en un tema de investigación particular podría mantener un catálogo de réplicas para una recopilación de conjuntos de datos de interés mutuo. Es posible crear jerarquías de catálogos de réplicas para imponer una estructura similar a un directorio en colecciones lógicas relacionadas. Además, el Administrador de réplicas puede realizar el control de acceso en catálogos completos, así como en archivos lógicos individuales.2.1.3 Selección de réplica El propósito de la selección de réplicas [16] es seleccionar una réplica de entre los sitios que constituyen una cuadrícula de datos [19]. Los criterios de selección dependen de las características de la aplicación. Al usar este mecanismo, los usuarios de la red de datos pueden administrar fácilmente réplicas de conjuntos de datos en sus sitios, con un mejor rendimiento. Se ha dedicado mucho esfuerzo previo al problema de selección de réplicas. El proceso común de selección de réplicas consta de tres pasos: preparación de datos, preprocesamiento y predicción. Luego, las aplicaciones pueden seleccionar una réplica de acuerdo con sus atributos específicos. La selección de réplicas es importante para las aplicaciones intensivas en datos, y puede proporcionar transparencia de ubicación. Cuando un usuario solicita acceder a un conjunto de datos, el sistema determina una forma apropiada de entregar la réplica al usuario.2.2 Globus Toolkit y GridftP El proyecto Globus [9, 11, 16] proporciona herramientas de software llamadas colectivamente el kit de herramientas Globus que facilita la creación de cuadrículas computacionales y aplicaciones basadas en la red. Muchas organizaciones usan el juego de herramientas Globus para construir cuadrículas computacionales para respaldar sus aplicaciones. La composición del kit de herramientas Globus se puede representar como tres pilares: gestión de recursos, servicios de información y gestión de datos. Cada pilar representa un componente primario del kit de herramientas Globus y utiliza una base común de seguridad. GRAM implementa un protocolo de gestión de recursos, MDS implementa un protocolo de servicios de información y GRIDFTP implementa un protocolo de transferencia de datos. Todos usan el protocolo de seguridad GSI en la capa de conexión [10, 11, 16, 13]. La Alianza de Globus propuso un protocolo de transferencia de datos y acceso común llamado GridftP que proporciona un movimiento de datos seguro y eficiente en entornos de cuadrícula [3]. Este protocolo, que extiende el protocolo FTP estándar, proporciona un superconjunto de las características ofrecidas por los diversos sistemas de almacenamiento de cuadrícula actualmente en uso. Para resolver los problemas de aparición, la comunidad de la red de datos intenta desarrollar un mecanismo de transporte de datos seguro y eficiente y servicios de gestión de réplicas. GRIDFTP es un protocolo confiable, seguro y eficiente de transporte de datos que se desarrolla como parte del proyecto Globus. Existe otra tecnología clave del Proyecto Globus, llamado Réplica Catálogo [16] que se utiliza para registrar y administrar copias completas y parciales de conjuntos de datos. El catálogo de réplica contiene la información de mapeo de un archivo o colección lógica a uno o más archivos físicos.2.3 Servicio meteorológico de red El Servicio Meteorológico de la Red (NWS) [22] es un sistema de monitoreo generalizado y distribuido para producir pronósticos de rendimiento a corto plazo basados en mediciones de rendimiento histórico. El objetivo del sistema es caracterizar y pronosticar dinámicamente la entrega de rendimiento a nivel de aplicación desde un conjunto de recursos de red y computación. Una instalación típica implica un NWS_NAMESERVER, uno o más NWS_Memory (que puede residir en diferentes máquinas) y un NWS_Sensor que se ejecuta en cada máquina con recursos que se deben monitorear. El sistema incluye sensores para el rendimiento TCP/IP de extremo a extremo (ancho de banda y latencia), porcentaje de CPU disponible y memoria disponible no apagada.798 2.4 Sysstat Utilidades Las utilidades sysstat [15] son una colección de herramientas de monitoreo de rendimiento para el sistema operativo Linux. El paquete SysStat incorpora los comandos SAR, MPSTAT e IOSTAT. El comando SAR recopila e informa la información de actividad del sistema, que también se puede guardar en un archivo de actividad del sistema para una inspección futura. El comando iostat informa estadísticas de CPU y estadísticas de E/S para dispositivos y discos TTY. Las estadísticas reportadas por las tasas de transferencia de E/S de E/S, actividad de paginación, actividades relacionadas con el proceso, interrupciones, actividad de red, memoria y uso de espacio de intercambio, utilización de CPU, actividades del núcleo y estadísticas TTY, entre otras. Las máquinas uniprocesador (UP) y multiprocesador simétrico (SMP) son totalmente compatibles.3. Arquitectura de co-asignación y trabajo relacionado La arquitectura de co-asignación propuesta en [17] consta de tres componentes principales: un servicio de información, un corredor/co-alocador y sistemas de almacenamiento locales. La Figura 1 muestra la co-asignación de transferencias de datos de la red, que es una extensión de la plantilla básica para la gestión de recursos [7] proporcionadas por Globus Toolkit. Las aplicaciones especifican las características de los datos deseados y pasan la descripción del atributo a un corredor. El corredor consulta recursos disponibles y obtiene ubicaciones de réplicas de los servicios de información [6] y los servicios de gestión de réplicas [19], y luego obtiene una lista de ubicaciones físicas para los archivos deseados. Figura 1. Arquitectura de co-asignación de la cuadrícula de datos [17] Las ubicaciones de réplicas de candidatos se pasan a un servicio de selección de réplica [19], que se presentó en un trabajo anterior [23]. Este servicio de selección de réplica proporciona estimaciones del rendimiento de transferencia de candidatos en función de un modelo de costo y elige los montos apropiados para solicitar las mejores ubicaciones. El agente de co-asignación luego descarga los datos en paralelo de los servidores seleccionados. En estas investigaciones, se usó GRIDFTP [1, 11, 16] para habilitar transferencias de datos paralelas. GRIDFTP es un protocolo de transferencia de datos de alto rendimiento, seguro y confiable optimizado para redes de ancho de ancho de banda alto. Entre sus muchas características se encuentran la seguridad, las secuencias paralelas, las transferencias de archivos parciales, las transferencias de terceros y los canales de datos reutilizables. Su capacidad de transferencia de archivos parcial permite que los archivos se recuperen de los servidores de datos especificando las compensaciones de inicio y finalización de las secciones de archivos. Las redes de datos consisten en recursos de computación y almacenamiento dispersos ubicados en diferentes países/regiones, pero accesibles para los usuarios [8]. En este estudio utilizamos el kit de herramientas de globo de middleware de la cuadrícula [16] como la infraestructura de la cuadrícula de datos. El Globus Toolkit proporciona soluciones para consideraciones como la seguridad, la gestión de recursos, la gestión de datos y los servicios de información. Uno de sus componentes principales es MDS [6, 11, 16, 25], que está diseñado para proporcionar un mecanismo estándar para descubrir y publicar el estado de los recursos y la información de configuración. Proporciona una interfaz uniforme y flexible para los datos recopilados por proveedores de información de nivel inferior en dos modos: estática (por ejemplo, OS, tipos de CPU y arquitecturas del sistema) y datos dinámicos (por ejemplo, disponibilidad de disco, disponibilidad de memoria y carga). Y utiliza GridFTP [1, 11, 16], un protocolo de transporte de datos confiable, seguro y eficiente para proporcionar una gestión eficiente y transferencia de terabytes o petabytes de datos en un entorno de recursos distribuidos de área amplia. Como los conjuntos de datos se replican dentro de entornos de cuadrícula para su confiabilidad y rendimiento, los clientes requieren las habilidades para descubrir las réplicas de datos existentes y crear y registrar nuevas réplicas. Un servicio de ubicación de réplica (RLS) [4] proporciona un mecanismo para descubrir y registrar las réplicas existentes. Se han desarrollado varias métricas de predicción para ayudar a la selección de réplicas. Por ejemplo, Vazhkudai y Schopf [18, 20, 21] utilizaron los historiales de transferencia de datos anteriores para estimar los rendimientos de transferencia de datos actuales. En nuestro trabajo anterior [23, 24], propusimos un modelo de costo de selección de réplica y un servicio de selección de réplica para realizar la selección de réplicas. En [17], el autor propone una arquitectura de co-asignación para co-asignar transferencias de datos de cuadrícula a través de múltiples conexiones explotando la función de copia parcial de GRIDFTP. También proporciona equilibrio de carga bruta, fuerza de historia y carga dinámica para asignar el bloqueo de datos. La co-asignación de la fuerza bruta: la co-asignación de fuerza bruta funciona dividiendo el tamaño del archivo por igual entre los flujos disponibles. No aborda las diferencias de ancho de banda entre los diversos enlaces de cliente cliente. La co-asignación basada en la historia: el esquema de coalgación basado en la historia mantiene los tamaños de bloqueo por flujo proporcional a las tasas de transferencia predichas. Equilibrio de carga conservadora: una de sus coalocaciones dinámicas es el equilibrio de carga conservadora. La estrategia de co-asignación dinámica de equilibrio de carga conservadora divide los conjuntos de datos solicitados en k bloques disjuntos de igual tamaño. Los servidores disponibles se asignan bloques únicos para entregar en paralelo. Cuando un servidor termina entregando un bloque, se solicita otro, y así sucesivamente, hasta que se descarga todo el archivo. Las cargas en los flujos co-asignados se ajustan automáticamente porque los servidores más rápidos entregarán más rápidamente proporcionando porciones más grandes del archivo. Equilibrio agresivo de carga: otra estrategia de coalgación dinámica, presentada en [17], es el equilibrio de carga agresivo. La estrategia de co-asignación dinámica agresiva de equilibrio de carga presentada en [17] agrega funciones que cambian el tamaño del bloque de las livieces al: (1) aumentando progresivamente las cantidades de datos solicitados de servidores más rápidos, y (2) reduciendo las cantidades de datos solicitadas deservidores más lentos o dejar de solicitar datos de ellos por completo. Las estrategias de co-asignación descritas anteriormente no manejan la deficiencia de servidores más rápidos que tienen que esperar a que el servidor más lento entregue su bloque final. En la mayoría de los casos, esto desperdicia mucho tiempo y disminuye el rendimiento general. Por lo tanto, proponemos un enfoque eficiente llamado co-asignación de ajuste recursivo y basado en 799 en una arquitectura de co-asignación. Mejora la co-asignación dinámica y reduce el tiempo de espera, lo que mejora el rendimiento general de la transferencia.4. Un servicio de selección de réplica eficiente construimos un servicio de selección de réplica para permitir a los clientes seleccionar los mejores servidores de réplicas en entornos de cuadrícula de datos. Consulte a continuación una descripción detallada.4.1 Escenario de selección de réplicas Nuestro modelo de selección de réplica propuesto se ilustra en [23], que muestra cómo un cliente identifica la mejor ubicación para una transferencia de réplica deseada. El cliente inicia sesión primero en un sitio local y ejecuta la aplicación de la plataforma de cuadrícula de datos, que verifica si los archivos están disponibles en el sitio local. Si están presentes en el sitio local, la aplicación los accede de inmediato;De lo contrario, pasa los nombres de archivos lógicos al servidor de catálogo de réplica, que devuelve una lista de ubicaciones físicas para todas las copias registradas. La aplicación pasa esta lista de ubicaciones de réplicas a un servidor de selección de réplica, que identifica las ubicaciones de destino del sistema de almacenamiento para todas las operaciones de transferencia de datos candidatos. El servidor de selección de réplica envía las posibles ubicaciones de destino al servidor de información, que proporciona mediciones de rendimiento y predicciones de los tres factores del sistema que se describen a continuación. El servidor de selección de réplica elige mejores ubicaciones de réplicas de acuerdo con estas estimaciones y devuelve información de ubicación a la aplicación de transferencia, que recibe la réplica a través de GridFTP. Cuando finaliza la aplicación, devuelve los resultados al usuario.4.2 Factores del sistema Determinar la mejor base de datos de muchos con las mismas replicaciones es un problema significativo. En nuestro modelo, consideramos tres factores del sistema que afectan la selección de réplicas: ancho de banda de red: este es uno de los factores de cuadrícula de datos más significativos, ya que los archivos de datos en los entornos de la red de datos suelen ser muy grandes. En otras palabras, los tiempos de transferencia de archivos de datos dependen estrechamente de situaciones de ancho de banda de red. Debido a que el ancho de banda de la red es un factor dinámico inestable, debemos medirlo con frecuencia y predecirlo con la mayor precisión posible. El Servicio Meteorológico de la Red (NWS) es un poderoso conjunto de herramientas para este propósito. Carga de CPU: las plataformas de cuadrícula consisten en números de sistemas heterogéneos, construidos con diferentes arquitecturas de sistemas, por ejemplo, plataformas de clúster, supercomputadoras, PC. La carga de CPU es un factor de sistema dinámico, y una carga de CPU de sistema pesado ciertamente afectará el proceso de descargas de archivos de datos desde el sitio. La medición de TI es realizada por Globus Toolkit / MDS. Estado de E/S: los nodos de la cuadrícula de datos consisten en diferentes sistemas de almacenamiento heterogéneos. Los archivos de datos en las redes de datos son enormes. Si el estado de E/S de un sitio del que deseamos descargar archivos está muy ocupado, afectará directamente el rendimiento de la transferencia de datos. Medimos los estados de E/S usando utilidades sysstat [15].4.3 Nuestro modelo de costo de selección de réplica La función objetivo de un modelo de costo para el almacenamiento de datos distribuido y replicado es la puntuación de información del servicio de información. Enumeramos algunos factores influyentes para nuestro modelo de costos en la sección anterior. Sin embargo, debemos expresar estos factores en notación matemática para un análisis posterior. Suponemos que el nodo I es el sitio local en el que el usuario o la aplicación inician sesión, y el nodo J posee la réplica que desean el usuario o la aplicación. Los siete parámetros del sistema que considera nuestro modelo de costo de selección de réplica son: Score-J: el valor de puntaje representa cuán eficientemente un usuario o aplicación en el nodo puedo adquirir una réplica del nodo J BW JIP: Porcentaje de ancho de banda disponible desde el nodo I al nodo J;Ancho de banda actual dividido por el mayor ancho de banda teórico BBW: peso de ancho de banda de red definido por el administrador de la cuadrícula de datos CPU JP: porcentaje de nodo J CPU Estados inactivos WCPU: peso de carga de CPU definido por el administrador de la cuadrícula de datos OI JP /: porcentual de nodo J I / OEstados inactivos WI/O: Peso de estado de E/S definido por el administrador de la red de datos Definimos la siguiente fórmula general utilizando estos factores del sistema. Oioi j cpucpu j bwbw jiji wpwpwpwpscore // (1) Los tres factores influyentes en esta fórmula: WBW, WCPU y WI/o describen los pesos de CPU, E/S y de ancho de banda de red, que pueden determinarse mediante administradores de la organización de cuadrícula de datos de acuerdoA los diversos atributos de los sistemas de almacenamiento en los nodos de la cuadrícula de datos, ya que algunos equipos de almacenamiento no afectan la carga de la CPU. Después de varias mediciones experimentales, determinamos que el ancho de banda de la red es el factor más significativo que influye directamente en los tiempos de transferencia de datos. Cuando realizamos transferencias de datos utilizando el protocolo GRIDFTP, descubrimos que la CPU y los estados de E/S afectan ligeramente el rendimiento de la transferencia de datos. Sus valores respectivos en nuestro entorno de cuadrícula de datos son 80%, 10%y 10%.4.4 Análisis de costos de co-asignación Cuando los clientes descargan conjuntos de datos utilizando la tecnología de co-asignación de gridftp, se incurren tres costos de tiempo: el tiempo requerido para la autenticación del cliente en el servidor GRIDFTP, el tiempo de transmisión de datos real y el tiempo de reensamblaje del bloque de datos. Tiempo de autenticación: antes de una transferencia, el cliente debe cargar un proxy de Globus y autenticarse al servidor GridFTP con credenciales de usuario especificadas. Luego, el cliente establece un canal de control, establece los parámetros de transferencia y solicita la creación del canal de datos. Cuando se ha establecido el canal, los datos comienzan a fluir. Tiempo de transmisión: el tiempo de transmisión se mide desde el momento en que el cliente comienza a transferirse al momento en que todos los trabajos de transmisión están terminados, e incluye el tiempo 800 requerido para restablecer los canales de datos entre las solicitudes de transferencia. Las vías de datos deben abrirse solo una vez y pueden manejar muchas transferencias antes de cerrarse. Esto permite que las mismas vías de datos se usen para transferencias de múltiples archivos. Sin embargo, los canales de datos deben restablecerse explícitamente entre las solicitudes de transferencia. Esto es menos costoso. Tiempo de combinación: la arquitectura de co-asignación explota la característica de copia parcial de la herramienta de movimiento de datos GRIDFTP para habilitar las transferencias de datos a través de múltiples conexiones. Con la transferencia de archivos parcial, las secciones de archivos se pueden recuperar de los servidores de datos especificando solo la sección Inicio y finalización de compensaciones. Cuando se entregan estas secciones de archivos, es posible que necesiten ser reensamblados;La operación de reensamblaje incurre en un costo de tiempo adicional.5. Estrategia de co-asignación dinámica La co-asignación dinámica, descrita anteriormente, es el enfoque más eficiente para reducir la influencia de las variaciones de red entre clientes y servidores. Sin embargo, el tiempo de inactividad de los servidores más rápidos que esperan el servidor más lento para entregar el último bloque sigue siendo un factor importante que afecta la eficiencia general, que el equilibrio de carga conservadora y el equilibrio de carga agresivo [17] no pueden evitar efectivamente. El enfoque propuesto en el presente documento, un mecanismo de asignación dinámica llamado coalgación de ajuste recursivo puede superar esto y, por lo tanto, mejorar el rendimiento de la transferencia de datos.5.1 La co-asignación recursiva de ajuste de ajuste recursivo ajustando continuamente cada carga de trabajo de los servidores de réplicas para corresponder a su ancho de banda en tiempo real durante las transferencias de archivos. El objetivo es hacer que el tiempo de finalización esperado de todos los servidores sea igual. Como muestra la Figura 2, cuando se selecciona una sección de archivo apropiada por primera vez, se divide en los tamaños de bloque adecuados de acuerdo con los respectivos anchos de banda del servidor. El co-alocador asigna los bloques a los servidores para la transferencia. En este momento, se espera que el tiempo de finalización de transferencia sea consistente en E (T1). Sin embargo, dado que los anchos de banda del servidor pueden fluctuar durante las entregas del segmento, el tiempo de finalización real puede ser diferente (línea continua, en la Figura 2). Una vez que el servidor más rápido termina su trabajo en el tiempo T1, la siguiente sección se asigna nuevamente a los servidores. Esto permite que cada servidor finalice su carga de trabajo asignada por el tiempo esperado en E (T2). Estos ajustes se repiten hasta que se termina toda la transferencia del archivo. Server 1 Server 2 Server 3 Ronda 1 Ronda 2 E (T1) E (T2) T1 Archivo A Sección 1 Sección 2 ... ... ... Figura 2. El proceso de ajuste del proceso de co-asignación de ajuste recursivo se ilustra en la Figura 3. Cuando un usuario solicita el archivo A, el servicio de selección de réplica responde con el subconjunto de todos los servidores disponibles definidos por la matriz de rendimiento máximo. El servicio de co-asignación obtiene esta lista de servidores de réplicas seleccionados. Suponiendo que se seleccionan los servidores de n réplicas, SI denota servidor i tal que 1 i n.Luego se crea una conexión para la descarga de archivos en cada servidor. El proceso de co-asignación de recursos es el siguiente. Primero se define una nueva sección de un archivo para asignar. El tamaño de la sección, SEJ, es: SEJ = UnasignedFilesize, (0 <<1) (2) donde SEJ denota la Sección J de tal manera que 1 J K, suponiendo que asignemos k Times para el proceso de descarga. Y por lo tanto, hay k secciones, mientras que TJ denota la sección de tiempo J asignada. UnassignedFilesize es la parte del archivo que aún no se ha distribuido para descargar;Inicialmente, UnsignedFilesize es igual al tamaño total del archivo A. es la tasa que determina cuánto de la sección queda por asignar. Figura 3. El proceso de co-asignación de ajuste recursivo. En el siguiente paso, SEJ se divide en varios bloques y se asigna a N servidores. Cada servidor tiene una tasa de transferencia en tiempo real al cliente de BI, que mide el Servicio Meteorológico de la Red (NWS) [18]. El tamaño del bloque por flujo de SEJ para cada servidor i en el momento TJ es: I n i ii n i iji zeunfinishsibbzzeunfinishsisises -) (11 (3) donde inquebrantable denota el tamaño de los bloques de transferencia inacabados que se asigna en rondas anteriores en el servidor i. Undinishsizei es igual a igual a iguala cero en primera ronda. Idealmente, dependiendo del ancho de banda en tiempo real en el momento en que TJ, se espera que cada flujo termine su carga de trabajo en el futuro. Esto cumple con nuestro requisito de minimizar el tiempo que los servidores más rápidos deben esperar a que el servidor más lento finalice. Si, en algunos casos, las variaciones de red degradan en gran medida las tasas de transferencia, inquebrantable puede exceder n i ii n i ij bbzeunfinissise 11 *) (, que es el tamaño total del bloque que se espera transferir después de TJ. En tales casos, el co-alocador elimina los servidores por adelantado y asigna SEJ a otros servidores. Después de la asignación, todos los canales continúan transfiriendo bloques de datos. Cuando un canal más rápido finaliza sus bloques de datos asignados, el co-alocador comienza a asignar una sección no asignada del archivo A nuevamente. El proceso de asignación de datos 801 bloqueos para ajustar el tiempo de finalización de flujo esperado continúa hasta que se haya asignado todo el archivo.5.2 Determinar cuándo detener el ajuste continuo Nuestro enfoque obtiene nuevas secciones de archivos completos dividiendo rangos de archivos no asignados en cada ronda de asignación. Estas porciones no asignadas de los rangos de archivo se vuelven más pequeñas después de cada asignación. Dado que el ajuste es continuo, se ejecutaría como un bucle interminable si no está limitado por una condición de parada. Sin embargo, ¿cuándo es apropiado detener el ajuste continuo? Proporcionamos dos criterios de monitoreo, de tamaño mínimo y esperado en tiempo de Finished, para permitir a los usuarios definir los umbrales de parada. Cuando se alcanza un umbral, el servidor de co-asignación dejó de dividir el resto del archivo y asigna ese resto como la sección final. El criterio de menor tamaño especifica el archivo más pequeño que queremos procesar, y cuando la porción no asignada de UnsignedFilesize cae por debajo de la especificación de menor tamaño, la división se detiene. El criterio de tiempo expectativo especifica la transferencia de tiempo restante que se espera que tome. Cuando el tiempo de transferencia esperado de la porción no asignada de un archivo cae por debajo del tiempo especificado por ExpectFinededTime, la división de archivos se detiene. El valor de tiempo de descanso esperado se determina por: 1 N I IbFilesizeUnassigned (4) Estos dos criterios determinan el tamaño de sección final asignado. Los valores de umbral más altos inducirán menos divisiones y producirán costos de co-asignación más bajos, que incluyen establecer conexiones, negociación, reensamblaje, etc. Sin embargo, aunque el tiempo de ajuste total de coalocación puede ser más bajo, las variaciones de ancho de banda también pueden ejercer más influencia. Por el contrario, los valores de umbral más bajos inducirán ajustes de carga de trabajo de servidor dinámico más frecuentes y, en el caso de mayores fluctuaciones de la red, darán lugar a menos diferencias en el tiempo de finalización de transferencia del servidor. Sin embargo, los valores más bajos también aumentarán los tiempos de co-asignación y, por lo tanto, aumentarán los costos de co-asignación. Por lo tanto, el entorno de Internet, los tamaños de archivo transferidos y los costos de asignación de conjuntos deben considerarse para determinar los umbrales óptimos.5.3 Reducción de la sobrecarga de reensamblaje El proceso de reensamblaje de bloques después de las transferencias de datos utilizando la tecnología de coalgación en gastos generales adicionales y disminuye el rendimiento general. La sobrecarga de reensamblaje está relacionada con el tamaño total del bloque, y podría reducirse actualizando las capacidades de hardware o utilizando mejores algoritmos de software. Proponemos un mecanismo de reensamblaje alternativo eficiente para reducir la sobrecarga de combinación adicional después de que se terminen todas las transmisiones de bloque. Se diferencia del método convencional en el que el software comienza el ensamblaje después de que todos los bloques se han entregado comenzando a ensamblar bloques una vez que terminan las primeras entregas. Por supuesto, esto hace necesario mantener el orden de división original. Las estrategias de co-asignación de co-asignación, como el equilibrio conservador de carga y la co-asignación de ajuste recursivo, producen bloques adicionales durante las transferencias de archivos y pueden beneficiarse de habilitar el reensamblaje durante las transferencias de datos. Si algunos bloques se ensamblan por adelantado, el costo de tiempo para ensamblar los bloques restantes después de todas las transferencias, se puede reducir.6. Resultados y análisis experimentales En esta sección, discutimos el desempeño de nuestra estrategia de co-asignación de recursos recursos. Evaluamos cuatro esquemas de coacallozización: (1) fuerza bruta (bruta), (2) basada en la historia (historia), (3) equilibrio de carga conservadora (conservador) y (4) co-asignación de ajuste recursivo (recursivo). Analizamos el rendimiento de cada esquema comparando su tiempo de finalización de transferencia, y el tiempo de inactividad total de los servidores más rápidos pasó esperando que el servidor más lento finalice de entregar el último bloque. También analizamos el rendimiento general en los diversos casos. Realizamos experimentos de transferencia de datos de área de amplio área utilizando nuestra herramienta de cliente GUI GRIDFTP. Ejecutamos nuestra herramienta de cliente de co-asignación en nuestro Bed de prueba en la Universidad de Tunghai (Thu), Taichung City, Taiwán, y obtuvimos archivos de cuatro servidores de réplicas seleccionados: uno en la Universidad de Providence (PU), uno en Li-Zen High School (LZ), uno en Hsiuping Institute of Technology School (HIT), y otro en Da-Li High School (DL). Todas estas instituciones están en Taiwán, y cada una está al menos a 10 km de jueves. La Figura 4 muestra nuestro lecho de prueba de cuadrícula de datos. Nuestros servidores tienen Globus 3.0.2 o más arriba instalado. Internet Thu Li-Zen High School (LZ) HITCELERON 900 MHz 256 MB RAM 60 GB HD AMD ATLON (TM) XP 2400+ 1024 MB RAM 120 GB HD Pentium 4 2.8 GHz 512 MB RAM 80 GB HD PU DA-LI High School ((DL) ATHLON MP 2000 MHz *2 1 GB RAM 60 GB HD Pentium 4 1.8 GHz 128 MB RAM 40 GB HD Pentium 4 2.5 GHz 512 MB RAM 80 GB HD Figura 4. Nuestra cuadrícula de datos se lleva a cabo en los siguientes experimentos, establecemos = 0.5, el umbral de mínimo tamaño a 10 MB, y experimentamos con tamaños de archivo de 10 MB, 50 MB, 100 MB, 500MB, 1000MB, 2000MB y 4000MB. A modo de comparación, medimos el rendimiento del equilibrio de carga conservadora en cada tamaño utilizando los mismos números de bloque. La Figura 5 muestra una instantánea de nuestra herramienta de cliente GridFTP. Esta herramienta de cliente se desarrolla utilizando Java COG. Permite un desarrollo de aplicaciones más fácil y más rápido al alentar la reutilización del código colaborativo y evitar la duplicación del esfuerzo entre los entornos de resolución de problemas, los portales de ciencias, el middleware de la cuadrícula y los pilotos colaborativos. La Tabla 1 muestra las tasas de transmisión promedio entre Thu y cada servidor de réplica. Estos números se obtuvieron transfiriendo archivos de 500 MB, 1000 MB y 2000 MB de un solo servidor de réplica utilizando nuestra herramienta de cliente GridFTP, y cada número es un promedio en varias ejecuciones. Tabla 1. La tasa de transmisión de extremo a extremo GRIDFTP de la tasa de transmisión promedio del servidor de varios servidores alcanzó 61.5 Mbps LZ 59.5 Mbps DL 32.1 Mbps PU 26.7 Mbps 802 Figura 5. Nuestra herramienta de cliente GRIDFTP analizamos el efecto de los servidores más rápidos que esperan que el servidor más lento entregue el último bloque para cada esquema. La Figura 6 (a) muestra el tiempo de inactividad total para varios tamaños de archivo. Tenga en cuenta que nuestro esquema de co-asignación de recursos logró mejoras de rendimiento significativas sobre otros esquemas para cada tamaño de archivo. Estos resultados demuestran que nuestro enfoque reduce eficientemente las diferencias en los tiempos de finalización de los servidores. Los resultados experimentales que se muestran en la Figura 6 (b) indican que nuestro esquema comienza el reensamblaje del bloqueo tan pronto como los primeros bloques se han entregado por completo reducen el tiempo de combinación, lo que ayuda a las estrategias de co-asignación como el equilibrio de carga conservadora y la co-asignación de Justificación recursiva que producen más bloques.Durante las transferencias de datos. La Figura 7 muestra los resultados experimentales del tiempo de finalización total en una vista detallada de la estructura de costos. Los servidores estaban en PU, DL y golpean, con el cliente en Thu. Las primeras tres barras para cada tamaño de archivo denotan el tiempo para descargar todo el archivo del servidor único, mientras que las otras barras muestran descargas co-asignadas utilizando los tres servidores. Nuestro esquema de co-asignación terminó el trabajo más rápido que las otras estrategias de co-asignación. Por lo tanto, podemos inferir que las principales ganancias que ofrecen la tecnología son tiempos de transmisión y combinación más bajos que otras estrategias de co-asignación.0 20 40 60 80 100 120 140 160 180 200 100 500 1000 1500 2000 Tamaño del archivo (MB) Waittime (SEC) Brute3 History3 Conservativo3 Recursivo3 0 10 20 30 40 50 60 70 80 90 100 500 1000 1500 Tamaño de archivo 2000 (MB) Combinación Tiempo de combinación(Sec) Brute3 History3 Conservative3 Recursivo3 Figura 6. (a) Tiempos de inactividad para varios métodos;Los servidores están en PU, DL y golpean.(b) tiempos de combinación para varios métodos;Los servidores están en PU, DL y golpean. En el siguiente experimento, utilizamos la estrategia de coalgación de ajuste recursivo-ajuste con varios conjuntos de servidores de réplicas y actuaciones generales medidas, donde el rendimiento general es: rendimiento total = tamaño de archivo/tiempo de finalización total (5) Tabla 2 Listas de todos los experimentos que realizamos y elconjuntos de servidores de réplica utilizados. Los resultados en la Figura 8 (a) muestran que el uso de tecnologías de coalgación no produjo una mejora para tamaños de archivos más pequeños como 10 MB. También muestran que en la mayoría de los casos, el rendimiento general aumentó a medida que aumentó el número de flujos co-asignados. Observamos que para nuestro Testbed y nuestra tecnología de co-asignación, el rendimiento general alcanzó su valor más alto en el caso Rec3_2. Sin embargo, en el caso REC4, cuando agregamos un flujo al conjunto de servidores de réplicas, el rendimiento no aumentó. Por el contrario, disminuyó. Podemos inferir que la eficiencia de co-asignación alcanzó la saturación en el caso Rec3_2, y que los flujos adicionales causaron sobrecarga adicional y un rendimiento general reducido. Esto significa que más flujos de descarga no necesariamente resultan en un mayor rendimiento. Debemos elegir números apropiados de flujos para lograr un rendimiento óptimo. Mostramos la vista detallada de la estructura de costos para el caso de REC3_2 y el caso de REC4 en la Figura 8 (b). El costo detallado consiste en tiempo de autenticación, tiempo de transferencia y tiempo de combinación.0 100 200 300 400 500 600 PU1 DL1 HIT1 BRU3 HIS3 CON3 REC3 PU1 DL1 HIT1 BRU3 HIS3 CON3 REC3 PU1 PU1 HIT1Tiempo de transmisión Tiempo de combinación Figura 7. Tiempos de finalización para varios métodos;Los servidores están en PU, DL y golpean. Tabla 2. Los conjuntos de servidores de réplicas para todos los casos de servidores de casos PU1 PU DL1 DL REC2 PU, DL rec3_1 PU, DL, LZ Rec3_2 PU, DL, HIT REC4 PU, DL, HIT, LZ 0 10 20 30 30 50 60 70 10 50 500 5001000 1500 2000 Tamaño del archivo (MB) General Performance (MBITS) PU1 DL1 REC2 REC3_1 REC3_2 REC4 0 10 20 20 30 40 50 60 70 REC3_2 REC4 REC3_2 REC4 REC3_2 REC4 REC3_2 REC4 REC4 REC3_2 REC4 REC3_2 REC4 REC3_2 REC4 10 50 100 500 1000 1500 2000 Tamaño de archivo ((((MB) General Performance (MBITS) Tiempo de autenticación Tiempo de transmisión Tiempo de combinación Figura 8. (a) Actuaciones generales para varios conjuntos de servidores.(b) Vista de estructura de costo detallada para el caso de REC3_2 y el caso de REC4.7. Conclusiones La arquitectura de co-asignación proporciona un agente coordinado para asignar bloques de datos. Un trabajo anterior mostró que el esquema dinámico de co-asignación conduce a mejoras de rendimiento. Sin embargo, no puede manejar el tiempo de inactividad de los servidores más rápidos, lo que debe esperar a que el servidor más lento entregue su bloque final. Propusimos el esquema de co-asignación de ajuste recursivo para mejorar el rendimiento de la transferencia de datos utilizando la arquitectura de co-asignación en [17]. En este enfoque, las cargas de trabajo de los servidores de réplica seleccionados se ajustan continuamente durante las transferencias de datos, y proporcionamos una función que permite a los usuarios definir un umbral de bloque 803 final, de acuerdo con su entorno de red de datos. Los resultados experimentales muestran la efectividad de nuestra técnica propuesta para mejorar el tiempo de transferencia y reducir el tiempo de inactividad general dedicado al servidor más lento. También discutimos el costo de re-combinación y proporcionamos un esquema efectivo para reducirlo.8. Referencias [1] B. Allcock, J. Bester, J. Bresnahan, A. Chervenak, I. Foster, C. Kesselman, S. Meder, V. Nefedova, D. Quesnel y S. Tuecke, Gestión de datos y transferencia en entornos de cuadrícula computacional de alto rendimiento, Computación Paralela, 28 (5): 749-771, mayo de 2002. [2] B. Allcock, J. Bester, J. Bresnahan, A. Chervenak, I. Foster, C. Kesselman, S. Meder, V. Nefedova, D. Quesnel y S. Tuecke, Transporte de datos seguro y eficiente y gestión de réplicas para la computación intensiva de datos de alto rendimiento, Proc.del decimoctavo Simposio IEEE sobre sistemas y tecnologías de almacenamiento de masas, pp. 13-28, 2001. [3] B. Allcock, S. Tuecke, I. Foster, A. Chervenak y C. Kesselman. Protocolos y servicios para la ciencia dataintensiva distribuida. Actat2000 Proceedings, pp. 161-163, 2000. [4] A. Chervenak, E. Deelman, I. Foster, L. Guy, W. Hoschek, A. Iamnitchi, C. Kesselman, P. Kunszt y M. Ripeanu, Risigro: un marco para construir servicios de ubicación de réplica escalable, Proc.de SC 2002, Baltimore, MD, 2002. [5] A. Chervenak, I. Foster, C. Kesselman, C. Salisbury y S. Tuecke, The Data Grid: Hacia una arquitectura para la gestión y análisis distribuidos de grandes conjuntos de datos científicos, Journal of Network and Computer Applications, 23: 187-200, 2001. [6] K. Czajkowski, S. Fitzgerald, I. Foster y C. Kesselman, Servicios de información de cuadrícula para el intercambio de recursos distribuidos, Proc.del décimo Simposio Internacional IEEE sobre computación distribuida de alto rendimiento (HPDC-1001), 181-194, agosto de 2001. [7] K. Czajkowski, I. Foster y C. Kesselman. Coacleización de recursos en cuadrículas computacionales, Proc.del octavo Simposio Internacional IEEE sobre computación distribuida de alto rendimiento (HPDC-899), agosto de 1999. [8] F. Donno, L. Gaido, A. Ghiselli, F. Prelz y M. Sgaravatto, prototipo datagríConferencia, http://www.terena.nl/conferences/tnc2002/papers/p5a2ghiselli.pdf, junio de 2002, [9] I. Foster, C. Kesselman y S. Tuecke. La anatomía de la cuadrícula: habilitando organizaciones virtuales escalables. En t. J. de aplicaciones de supercomputador y computación de alto rendimiento, 15 (3), pp. 200-222, 2001. [10] I. Foster y C. Kesselman, Globus: un kit de herramientas de infraestructura metacomputación, Intl J. SuperComiter Applications, 11 (2), pp. 115-128, 1997. [11] Global Grid Forum, http://www.ggf.org/ [12] W. Hoschek, J. Jaen-Martinez, A. Samar, H. Stockinger y K. Stockinger, Gestión de datos en un proyecto internacional de redes de datos, Proc.de First IEEE/ACM International Workshop on Grid Computing - Grid 2000, Bangalore, India, diciembre de 2000. [13] IBM Red Books, Introducción a la computación de la red con Globus, IBM Press, www.redbooks.ibm.com/redbooks/pdfs/SG246895.pdf [14] H. Stockinger, A. Samar, B. Allcock, I. Foster, K. Holtman y B. Tierney, Replicación de archivos y objetos en cuadrículas de datos, Journal of Cluster Computing, 5 (3): 305-314, 2002. [15] Página de inicio de Sysstat Utilities, http: //perso.wanadoo.Fr/Sebastien.Godard/[16] The Globus Alliance, http://www.globus.org/ [17] S. Vazhkudai, que permite la co-asignación de transferencias de datos de cuadrícula, Proc.de Fourth International Workshop on Grid Computing, págs. 41-51, noviembre de 2003. [18] S. Vazhkudai y J. Schopf, utilizando técnicas de regresión para predecir grandes transferencias de datos, International Journal of High Performance Computing Aplications (IJHPCA), 17:249-268, agosto de 2003. [19] S. Vazhkudai, S. Tuecke e I. Foster, selección de réplicas en la cuadrícula de datos del globo, Proc.del 1er Simposio Internacional sobre Computación de Clúster y la Grid (CCGRID 2001), pp. 106-113, mayo de 2001. [20] S. Vazhkudai, J. Schopf, Predicción de transferencias de datos de cuadrícula esporádica, Proc.del 11º Simposio Internacional IEEE sobre computación distribuida de alto rendimiento (HPDC-11 02), pp. 188-196, julio de 2002. [21] S. Vazhkudai, J. Schopf e I. Foster, prediciendo el rendimiento de las transferencias de datos de área amplia, Proc.del 16º Simposio internacional de procesamiento paralelo y distribuido (IPDPS 2002), pp.34-43, abril de 2002, pp. 34 - 43. [22] R. Wolski, N. Spring y J. Hayes, The Network Weather Service:Un servicio de pronóstico de rendimiento de recursos distribuido para Metacomputación, Sistemas de Computación de Generación Futada, 15 (5-6): 757-768, 1999. [23] Chao-Tung Yang, Chun-Hsiang Chen, Kuan-Ching Li y Ching-Hsien Hsu Hsu, Análisis de rendimiento de la aplicación de la tecnología de selección de réplicas para entornos de cuadrícula de datos, PACT 2005, Notas de conferencias en informática, vol.3603, pp. 278-287, Springer-Verlag, septiembre de 2005. [24] Chao-Tung Yang, I-Hsien Yang, Kuan-Ching Li y Chinghsien Hsu un esquema de co-asignación de ajuste recursivo en entornos de cuadrícula de datos, ICA3PPAlgoritmo y arquitectura 2005 para procesamiento paralelo, Notas de conferencias en informática, vol.3719, pp. 40-49, Springer-Verlag, octubre de 2005. [25] X. Zhang, J. Freschl y J. Schopf, Un estudio de rendimiento de monitoreo y servicios de información para sistemas distribuidos, Proc.del 12º Simposio Internacional IEEE sobre computación distribuida de alto rendimiento (HPDC-12 03), pp. 270-282, agosto de 2003. 804