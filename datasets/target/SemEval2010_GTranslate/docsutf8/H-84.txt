Enhebrado de eventos dentro de los temas de noticias Ramesh Nallapati, Ao Feng, Fuchun Peng, Centro James Allan para la recuperación de información inteligente Departamento de Ciencias de la Computación Universidad de Massachusetts Amherst, MA 01003 Nmramesh, Aofeng, Fuchun, Allan @Cs.UMass.Edu Resumen con el volumen abrumadorDe las noticias en línea disponibles hoy, existe una creciente necesidad de técnicas automáticas para analizar y presentar noticias al usuario de manera significativa y eficiente. Investigaciones anteriores se centraron solo en organizar noticias de sus temas en una jerarquía plana. Creemos que ver un tema de noticias como una colección plana de historias es demasiado restrictivo e ineficiente para que un usuario comprenda el tema rápidamente. En este trabajo, intentamos capturar la rica estructura de los eventos y sus dependencias en un tema de noticias a través de nuestros modelos de eventos. Llamamos al proceso de reconocimiento de eventos y sus dependencias. Creemos que nuestra perspectiva de modelar la estructura de un tema es más efectiva para capturar su semántica que una lista plana de historias sobre el tema. Definimos formalmente el nuevo problema, sugerimos métricas de evaluación y presentamos algunas técnicas para resolver el problema. Además de las características estándar basadas en palabras, nuestros enfoques tienen en cuenta características novedosas, como la localidad temporal de historias para el reconocimiento de eventos y el pedido de tiempo para capturar dependencias. Nuestros experimentos en un conjunto de datos etiquetados manualmente muestran que nuestros modelos identifican efectivamente los eventos y capturan las dependencias entre ellos. Categorías y descriptores de sujetos H.3.3 [Búsqueda y recuperación de información]: algoritmos de términos generales de agrupación, experimentación, medición 1. Introducción Las noticias forman una parte importante de la información difundida en el mundo todos los días. Las personas comunes y los analistas de noticias están muy interesados en mantenerse al tanto de las cosas nuevas que suceden en las noticias, pero se está volviendo muy difícil hacer frente a los enormes volúmenes de información que llega cada día. Por lo tanto, existe una creciente necesidad de técnicas automáticas para organizar las noticias de una manera que ayude a los usuarios a interpretarlas y analizarlas rápidamente. Este problema es abordado por un programa de investigación llamado Topic Detection and Tracking (TDT) [3] que ejecuta una competencia anual abierta en tareas estandarizadas de organización de noticias. Una de las deficiencias de la evaluación actual de TDT es su visión de los temas de noticias como una colección plana de historias. Por ejemplo, la tarea de detección de TDT es organizar una colección de noticias en grupos de temas. Sin embargo, un tema en las noticias es más que una mera colección de historias: se caracteriza por una estructura definitiva de eventos interrelacionados. De hecho, esto es reconocido por TDT, que define un tema como un conjunto de noticias que están fuertemente relacionadas con algún evento seminal del mundo real donde un evento se define como algo que ocurre en un momento y ubicación específicos [3]. Por ejemplo, cuando una bomba explota en un edificio, ese es el evento seminal que desencadena el tema. Otros eventos en el tema pueden incluir los intentos de rescate, la búsqueda de perpetradores, arrestos y juicios, etc. Vemos que hay un patrón de dependencias entre pares de eventos en el tema. En el ejemplo anterior, el evento de intentos de rescate está influenciado por el evento de bombardeo y también lo es el evento de búsqueda de perpetradores. En este trabajo investigamos métodos para modelar la estructura de un tema en términos de sus eventos. Por estructura, nos referimos a no solo identificar los eventos que conforman un tema, sino también establecer dependencias generalmente causales. Llamamos al proceso de reconocer eventos e identificar las dependencias entre ellos, una analogía con el subproceso de correo electrónico que muestra conexiones entre mensajes de correo electrónico relacionados. Nos referimos a la estructura de eventos interconectada resultante como el modelo de evento del tema. Aunque este documento se centra en los eventos de enhebrado dentro de un tema de noticias existente, esperamos que dicha estructura de dependencia basada en eventos refleje con mayor precisión la estructura de las noticias que los temas estrictamente limitados. Desde la perspectiva de los usuarios, creemos que nuestra visión de un tema de noticias como un conjunto de eventos interconectados lo ayuda a obtener una visión general rápida del tema y también le permite navegar a través del tema más rápido. El resto del documento está organizado de la siguiente manera. En la Sección 2, discutimos el trabajo relacionado. En la Sección 3, definimos el problema y usamos un ejemplo para ilustrar el enhebrado de los eventos dentro de un tema de noticias. En la Sección 4, describimos cómo construimos el corpus para nuestro problema. La Sección 5 presenta nuestras técnicas de evaluación, mientras que la Sección 6 describe las técnicas que utilizamos para la estructura de eventos de modelado. En la Sección 7 presentamos nuestros experimentos y resultados. La Sección 8 concluye el documento con algunas observaciones sobre nuestros resultados y comentarios sobre el trabajo futuro.446 2. Trabajo relacionado El proceso de enhebramiento de eventos juntos está relacionado con el enhebrado del correo electrónico solo por nombre en su mayor parte. El correo electrónico generalmente incorpora una fuerte estructura de mensajes referenciados y encabezados de temas formateados constantemente, aunque las técnicas de recuperación de información son útiles cuando la estructura se rompe [7]. El subproceso de correo electrónico captura dependencias de referencia entre mensajes y no intenta reflejar ninguna estructura subyacente del mundo del mundo en discusión. Otra área de investigación que analiza la estructura dentro de un tema es la clasificación de temas de texto jerárquico [9, 6]. La jerarquía dentro de un tema impone una estructura sobre el tema, pero no sabemos de un esfuerzo por explorar hasta qué punto esa estructura refleja las relaciones de eventos subyacentes. Barzilay y Lee [5] propusieron una técnica de modelado de estructura de contenido donde los temas dentro del texto se aprenden utilizando métodos no supervisados, y un orden lineal de estos temas se modela utilizando modelos ocultos de Markov. Nuestro trabajo difiere del suyo, ya que no limitamos la dependencia para ser lineal. Además, sus algoritmos están sintonizados para trabajar en géneros específicos de temas como terremotos, accidentes, etc., mientras esperamos que nuestros algoritmos se generalicen sobre cualquier tema. En TDT, los investigadores han considerado tradicionalmente temas como planos planos [1]. Sin embargo, en TDT-2003, se ha propuesto una estructura jerárquica de la detección de temas y [2] realizó intentos útiles para adoptar la nueva estructura. Sin embargo, esta estructura todavía no modeló explícitamente ninguna dependencia entre los eventos. En una obra más cercana a la nuestra, Makkonen [8] sugirió modelar temas de noticias en términos de sus eventos en evolución. Sin embargo, el documento no se detuvo en proponer cualquier modelo al problema. Otro trabajo relacionado que se ocupó del análisis dentro de un tema de noticias incluye resumen temporal de temas de noticias [4].3. Definición y notación del problema En este trabajo, nos hemos adherido a la definición de evento y tema tal como se define en TDT. Presentamos algunas definiciones (en cursiva) y nuestras interpretaciones (de cara regular) a continuación para mayor claridad.1. Historia: Una historia es un artículo de noticias que entrega información a los usuarios. En TDT, se supone que una historia se refiere a un solo tema. En este trabajo, también suponemos que cada historia discute un solo evento. En otras palabras, una historia es la unidad atómica más pequeña de la jerarquía (historia del evento del tema). Claramente, ambos supuestos no son necesariamente verdaderos en la realidad, pero los aceptamos por simplicidad en el modelado.2. Evento: un evento es algo que sucede en algún momento y lugar específico [10]. En nuestro trabajo, representamos un evento de un conjunto de historias que lo discuten. Después de la suposición de atomicidad de una historia, esto significa que cualquier conjunto de eventos distintos puede estar representado por un conjunto de grupos no superpuestos de noticias.3. Tema: Un conjunto de noticias fuertemente conectadas por un evento seminal. Ampliamos esta definición e interpretamos un tema como una serie de eventos relacionados. Por lo tanto, un tema puede ser representado por grupos de historias, cada uno que representa un evento y un conjunto de bordes (dirigidos o no dirigidos) entre pares de estos grupos que representan las dependencias entre estos eventos. Describiremos esta representación de un tema con más detalle en la siguiente sección.4. Detección y seguimiento de temas (TDT): la detección de temas detecta grupos de historias que discuten el mismo tema;El seguimiento del tema detecta historias que discuten un tema previamente conocido [3]. Por lo tanto, TDT se refiere principalmente a las historias de agrupación en temas que los discuten.5. Enhebrado de eventos: el hilo de eventos detecta eventos dentro de un tema, y también captura las dependencias entre los eventos. Por lo tanto, la principal diferencia entre el enhebrado de eventos y el TDT es que centramos nuestro esfuerzo de modelado en eventos microscópicos en lugar de temas más grandes. Además, el enhebrado de eventos modela la relación o las dependencias entre pares de eventos en un tema, mientras que TDT modela temas como grupos de historias no relacionados. Primero definimos nuestro problema y representación de nuestro modelo formalmente y luego ilustramos con la ayuda de un ejemplo. Se nos da un conjunto de noticias de ò ë × ½ ¡¡¡¡× ò sobre un tema determinado y su tiempo de publicación. Definimos un conjunto de eventos ½ ¡¡Ñ con las siguientes restricciones: ¾ ¾ ë (1) × Ø (2) × ¾ × Ø × ¾ (3) mientras que la primera restricción dice que cada evento es un elemento en la potencia del poderConjunto de S, la segunda restricción asegura que cada historia pueda pertenecer como máximo un evento. La última restricción nos dice que cada historia pertenece a uno de los eventos en. De hecho, esto nos permite definir una función de mapeo de historias a eventos de la siguiente manera: ´ × µ IFF × ¾ (4) Además, también definimos un conjunto de bordes dirigidos ´ µ que denotan dependencias entre eventos. Es importante explicar lo que queremos decir con esta dependencia direccional: mientras que la existencia de un borde en sí representa la relación de dos eventos, la dirección podría implicar la causalidad o el orden temporal. Por dependencia causal queremos decir que la aparición del evento B está relacionada y es una consecuencia de la ocurrencia del evento A. Por orden temporal, queremos decir que el evento B ocurrió después del evento A y está relacionado con A pero no es necesariamente una consecuencia de A. Por ejemplo, considere los siguientes dos eventos: accidente aéreo (evento A) e investigaciones posteriores (Evento B) en un tema sobre un incidente de accidente aéreo. Claramente, las investigaciones son el resultado del accidente. Por lo tanto, una flecha de A a B se encuentra en la categoría de dependencia causal. Ahora considere el par de eventos que Pope llega a Cuba (Evento A) y Pope se encuentra con Castro (Evento B) en un tema que discute la visita de los papas a Cuba. Ahora los eventos A y B están estrechamente relacionados a través de su asociación con el Papa y Cuba, pero el evento B no es necesariamente una consecuencia de la ocurrencia del evento A. Una flecha en este escenario captura lo que llamamos ordenar tiempo. En este trabajo, no intentamos distinguir entre estos dos tipos de dependencias y nuestros modelos los tratan como idénticos. Una elección más simple (y por lo tanto menos controvertida) sería ignorar la dirección en las dependencias por completo y considerar solo bordes no dirigidos. Esta elección definitivamente tiene sentido como un primer paso, pero elegimos el primero, ya que creemos que los bordes direccionales tienen más sentido para el usuario, ya que proporcionan una perspectiva más ilustrativa de la tabla de flujo para el tema. Para que la idea de que el evento sea más concreto, considere el ejemplo del tema TDT3 30005, titulado Osama bin Ladens acusación (en las noticias de 1998). Este tema tiene 23 historias que forman 5 eventos. Un modelo de evento de este tema puede representarse como en la Figura 1. Cada cuadro de la figura indica un evento en el tema de la acusación de Osamas. La aparición del evento 2, a saber, el juicio y la acusación de Osama depende del evento de evidencia reunida por la CIA, es decir, el evento 1. Del mismo modo, el evento 2 influye en las ocurrencias de los eventos 3, 4 y 5, a saber, amenazas de militantes, reacciones 447 del mundo musulmán y el anuncio de la recompensa. Por lo tanto, todas las dependencias en el ejemplo son causales. Extendiendo aún más nuestra notación, llamamos a un evento a un padre de B y B el hijo de A, si ´ µ ¾. Definimos un modelo de evento Å ´ µ para ser una tupla del conjunto de eventos y un conjunto de dependencias. El juicio y (5) (3) (4) CIA anuncia la recompensa de las reacciones del mundo musulmán de las amenazas de militantes islámicos de (2) (1) acusación de Osama de la CIA reunida por evidencia Figura 1: Un modelo de evento del tema TDT Osama bin Ladens acusación. El enhebrado de eventos está fuertemente relacionado con la detección y el seguimiento de temas, pero también es diferente de él significativamente. Va más allá de los temas y modela las relaciones entre los eventos. Por lo tanto, el enhebrado de eventos puede considerarse como una extensión adicional de la detección y el seguimiento de los temas y es más desafiante debido a al menos las siguientes dificultades.1. Se desconoce el número de eventos.2. La granularidad de los eventos es difícil de definir.3. Las dependencias entre los eventos son difíciles de modelar.4. Dado que es un área de investigación nueva, no hay métricas de evaluación estándar y datos de referencia disponibles. En las próximas secciones, describiremos nuestros intentos de abordar estos problemas.4. Datos etiquetados Elegimos 28 temas del Corpus TDT2 y 25 temas del Corpus TDT3. El criterio que utilizamos para seleccionar un tema es que debe contener al menos 15 historias en el tema de CNN Headline News. Si el tema contenía más de 30 historias de CNN, elegimos solo las primeras 30 historias para mantener el tema lo suficientemente corto para los anotadores. La razón para elegir solo CNN como fuente es que las historias de esta fuente tienden a ser cortas y precisas y no tienden a desviarse o desviarse demasiado del tema central. Creemos que modelar tales historias sería un primer paso útil antes de tratar con conjuntos de datos más complejos. Contratamos a un anotador para crear datos de verdad. La anotación incluye definir la membresía del evento para cada historia y también las dependencias. Supervisamos al anotador en un conjunto de tres temas en los que hicimos nuestras propias anotaciones y luego le pedimos que anotara los 28 temas de TDT2 y 25 temas de TDT3. Al identificar los eventos en un tema, se le pidió al anotador que siguiera ampliamente la definición de TDT de un evento, es decir, algo que ocurre en un momento y ubicación específicos. Se alentó al anotador a fusionar dos eventos A y B en un solo evento C si alguna de las historias discute tanto A como B. Esto es para satisfacer nuestra suposición de que cada historia corresponde a un evento único. También se alentó al anotador a evitar eventos de singleton, eventos que contienen una sola noticia, si es posible. Nos dimos cuenta de nuestra propia experiencia que las personas difieren en su percepción de un evento, especialmente cuando el número de historias en ese evento es pequeña. Como parte de las pautas, instruimos al anotador que asigne títulos a todos los eventos en cada tema. Creemos que esto ayudaría a que su comprensión de los eventos sea más concreta. Sin embargo, no usamos ni modelamos estos títulos en nuestros algoritmos. Al definir las dependencias entre eventos, no impusimos restricciones en la estructura del gráfico. Cada evento podría tener padres solteros, múltiples o nulos. Además, el gráfico podría tener ciclos o huérfanas. Sin embargo, el anotador recibió instrucciones de asignar una dependencia del evento A al evento B si y solo si la ocurrencia de B está influenciada causalmente por A o está estrechamente relacionada con A y sigue a A tiempo. A partir de los temas anotados, creamos un conjunto de entrenamiento de 26 temas y un conjunto de pruebas de 27 temas fusionando los 28 temas de TDT2 y 25 de TDT3 y dividiéndolos al azar. La Tabla 1 muestra que los conjuntos de capacitación y prueba tienen estadísticas bastante similares. Testamento de capacitación de características Conjunto de prueba Num.Temas 26 27 AVG. Numer Historias/Tema 28.69 26.74 AVG. Doc. Len.64.60 64.04 avg. Numer Historias/Evento 5.65 6.22 AVG. Numer Eventos/Tema 5.07 4.29 AVG. Numer Dependencias/Tema 3.07 2.92 AVG. Numer Dependencias/Evento 0.61 0.68 AVG. Numer Días/Tema 30.65 34.48 Tabla 1: Estadísticas de datos anotados 5. Evaluación Un sistema puede generar algún modelo de evento Å¼ ´ ¼ ¼ µ usando ciertos algoritmos, que generalmente es diferente del modelo de verdad Å ´ µ (suponemos que el anotador no cometió ningún error). Comparar un evento de evento del sistema Å¼ con el verdadero modelo Å requiere comparar todos los modelos de eventos, incluida su estructura de dependencia. Y diferentes granularidades de eventos pueden traer una gran discrepancia entre Å¼ y Å. Esto ciertamente no es trivial, ya que incluso prueba si dos gráficos son isomórficos no tienen una solución de tiempo polinomial conocida. Por lo tanto, en lugar de comparar la estructura real, examinamos un par de historias a la vez y verificamos si el sistema y las etiquetas verdaderas acuerdan sus membresías y dependencias de eventos. Específicamente, comparamos dos tipos de pares de historias: ¯ pares de clúster (´åµ): estos son el conjunto completo de pares no ordenados ´ × × µ de historias × y × que caen dentro del mismo evento dado un modelo Å. Formalmente, ´åµ ´ × × µ × × ¾ ë ´ × µ ´ × µ (5) donde está la función en Å que mapea las historias a los eventos definidos en la ecuación 4. ¯ Pares de dependencia (´åµ): estos son el conjuntoDe todos los pares ordenados de historias ´ × × µ, de modo que hay una dependencia desde el evento de × hasta el evento de × en el modelo Å.´åµ ´ × × µ ´ ´ × µ ´ × µ ¾ (6) Tenga en cuenta que el par de la historia se ordena aquí, por lo que ´ × × µ no es equivalente a ´ × × µ. En nuestra evaluación, un par correcto con pares de dependencia de clúster 448 (b-> d) incorrecto (a, c) (a-> b) (c-> b) (b-> d) d, e d, e (d, E) (d, e) (a-> c) (a-> e) (b-> c) (b-> e) (b-> e) precisión del clúster: 1/2 recuerdo del clúster: 1/2Recuerdo de dependencia: 2/6 Precisión de dependencia: 2/4 (A-> D) True Model Sistema de eventos Modelo de evento A, B C A, C B Pares de clúster (A, B) Pares de dependencia Figura 2: La dirección de medidas de evaluación se considerará un error. Como mencionamos anteriormente en la Sección 3, ignorar la dirección puede simplificar el problema, pero perderemos la expresividad de nuestra representación. Dados estos dos conjuntos de pares de historias correspondientes al verdadero Modelo de eventos Å y al Modelo de eventos del sistema Å¼, definimos el recuerdo y la precisión para cada categoría de la siguiente manera.¯ Precisión de clúster (CP): es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento verdadero dado que están en el mismo evento del sistema. È è´ ´ × µ ´ × µ ¼´ × µ ¼´ × µ ´åµ ´å¼µ ´å¼µ (7) donde ¼ es la función de mapeo de eventos de la historia correspondiente al modelo Å¼.¯ Recuerdo del clúster (CR): es la probabilidad de que dos historias seleccionadas al azar × y × estén en el mismo evento del sistema dado que están en el mismo verdadero evento. Ê è´ ¼´ × µ ¼´ × µ ´ × µ ´ × µ ´åµ ´å¼µ ´åµ (8) ¯ Precisión de dependencia (DP): es la probabilidad de que haya una dependencia entre los eventos de dos historias seleccionadas aleatoriamente× y × en el verdadero modelo Å dado que tienen una dependencia en el modelo del sistema Å¼. Tenga en cuenta que la dirección de dependencia es importante en comparación. È´´´ ´ × µ ´ × µµ ¾ ´ ¼´ × µ ¼´ × µµ ¾ ¼ ´åµ ´å¼µ ´å¼a (9) ¯ RECUERDO DE DEPENENCIA (DR): es la probabilidad de que haya una dependencia entre los eventos entre los eventosDe dos historias seleccionadas al azar × y × en el modelo del sistema Å¼, dado que tienen una dependencia en el verdadero modelo Å. Nuevamente, se tiene en cuenta la dirección de dependencia. Ê è´´ ¼´ × µ ¼´ × µo ¾ ¼ ´ ´ × µ ´ × µµ ¾ µ ´åµ ´å¼µ ´åµ (10) Las medidas se ilustran mediante un ejemplo en la Figura 2. También combinamos estas medidas utilizando la conocida medida F1 comúnmente utilizada en la clasificación de texto y otras áreas de investigación como se muestra a continuación.¾ ¢ è ¢ ê è · ê ¾ ¢ è ¢ ê è · ê â ¾ ¢ ¢ · (11) donde y son las medidas de clúster y dependencia F1 respectivamente y es la medida F1 conjunta (â) que usamosMida el rendimiento general.6. Técnicas La tarea del modelado de eventos se puede dividir en dos partes: agrupar las historias en eventos únicos en el tema y construir dependencias entre ellas. En las siguientes subsecciones, describimos las técnicas que desarrollamos para cada una de estas subasinas.6.1 Agrupación de cada tema se compone de múltiples eventos, por lo que las historias deben agruparse en eventos antes de que podamos modelar las dependencias entre ellos. Para simplificar, se supone que todas las historias en el mismo tema están disponibles al mismo tiempo, en lugar de entrar en un flujo de texto. Esta tarea es similar a la agrupación tradicional, pero las características distintas a las distribuciones de palabras también pueden ser críticas en nuestra aplicación. En muchos sistemas de agrupación de texto, la similitud entre dos historias es el producto interno de sus vectores TF-IDF, por lo tanto, lo usamos como una de nuestras características. Las historias en el mismo evento tienden a seguir la localidad temporal, por lo que la marca de tiempo de cada historia puede ser una característica útil. Además, las entidades con nombre, como los nombres de la persona y la ubicación, son otra característica obvia al formar eventos. Las historias en el mismo evento tienden a estar relacionadas con las mismas personas y ubicaciones. En esta subsección, presentamos un algoritmo de agrupamiento aglomerativo que combina todas estas características. Sin embargo, en nuestros experimentos, estudiamos el efecto de cada característica en el rendimiento por separado utilizando versiones modificadas de este algoritmo.6.1. Entonces, la similitud entre dos eventos, para empezar, es exactamente la similitud entre las historias correspondientes. La similitud û × ùñ´ × ½ × ¾µ entre dos pisos × ½ y × ¾ viene dada por la siguiente fórmula: × × ùñ´ × ½ × ¾µ ½ Ó × ´ × ½ × ¾µ · ¾äó ´ × ½ × ¾µ · ¿È Ö´ × ½ × ¾µ (12) Aquí ½, ¾, ¿son los pesos en diferentes características. En este trabajo, los determinamos empíricamente, pero en el futuro, uno puede considerar técnicas de aprendizaje más sofisticadas para determinarlas. Ó × ´ × ½ × ¾µ es la similitud cosena de los vectores térmicos. Äó ´ × ½ × ¾µ es 1 si hay alguna ubicación que aparece en ambas historias, de lo contrario es 0. È Ö´ × ½ × ¾µ se define de manera similar para el nombre de la persona. Usamos la descomposición del tiempo al calcular la similitud de los pares de historias, es decir, la mayor diferencia de tiempo entre dos historias, menores son sus similitudes. El período de tiempo de cada tema difiere mucho, de unos pocos días a unos pocos meses. Por lo tanto, normalizamos la diferencia de tiempo utilizando toda la duración de ese tema. La similitud ajustada por desintegración de tiempo 449 × ñ´ × ½ × ¾ µ se da por × ñ´ × ½ × ¾µ × × × × ½ × ¾µ «Ø½ Ø¾ ì (13) donde Ø½ y Ø¾ son las sellos de tiempo para la historia 1 y2 respectivamente. T es la diferencia horaria entre la historia más temprana y la última en el tema dado.«Es el factor de descomposición de tiempo. En cada iteración, encontramos el par de eventos más similar y fusionamos. Tenemos tres formas diferentes de calcular la similitud entre dos eventos ù y Ú: ¯ Enlace promedio: en este caso, la similitud es el promedio de las similitudes de todos los pares de historias entre ù y Ú como se muestra a continuación: × ñ´ ù Ú µÈ × ù¾ ù è × ú¾ × × × ù × ú µ ù Ú (14) ¯ Enlace completo: la similitud entre dos eventos viene dada por las similitudes más pequeñas de las parejas.× ñ´ ù ú µ ñ ò × ù¾ ù × ú¾ ú × ñ´ × ù × ú µ (15) ¯ enlace único: Aquí la similitud está dada por la mejor similitud entre todos los pares de historias.× ñ´ ù Ú µ ñ ü × ù¾ ù × ú¾ ú × ñ´ × ù × ú µ (16) Este proceso continúa hasta que la similitud máxima cae por debajo del umbral o el número de clústeres es menor que un número dado.6.2 Modelado de dependencia La captura de dependencias es un problema extremadamente difícil porque puede requerir una comprensión más profunda de los eventos en cuestión. Un anotador humano decide las dependencias no solo en función de la información en los eventos, sino también en su base de su vasto repertorio de conocimiento de dominio y comprensión general de cómo funcionan las cosas en el mundo. Por ejemplo, en la Figura 1, un humano conoce el juicio y la acusación de Osama está influenciada por la evidencia reunida por la CIA porque él/ella comprende el proceso de derecho en general. Creemos que un modelo robusto debería incorporar dicho conocimiento del dominio en la captura de dependencias, pero en este trabajo, como primer paso, confiaremos en las características de la superficie, como la orden del tiempo de las noticias y las distribuciones de palabras para modelarlas. Nuestros experimentos en secciones posteriores demuestran que tales características son útiles para capturar en gran medida las dependencias. En esta subsección, describimos los modelos que consideramos para capturar dependencias. En el resto de la discusión en esta subsección, suponemos que ya nos dan el mapeo ¼ ë y solo nos centramos en modelar los bordes ¼. Primero definimos un par de características que emplearán los siguientes modelos. Primero definimos una función de pedido de tiempo 1-1 Ø ë ½ ¡¡¡¡¡¡'s que clasifica historias en orden ascendente por su tiempo de publicación. Ahora, la función de pedido en el tiempo de evento Ø se define de la siguiente manera. Ø ½ ¡¡¡¡Ñ × Ø ù ú ¾ Ø ´ ùµ Ø ´ Úµ ´µ ñ × × ù¾ Ø × × ùµ × × × Ú¾ ú Ø´ × × ÚN (17) En otras palabras, Ø TimeDers Based Based Based Based Based Baseders Baseders basadosen el pedido de tiempo de sus respectivas primeras historias. También utilizaremos la similitud de coseno promedio entre dos eventos como una característica y se define de la siguiente manera. Ú ë ñ´ ù ú µ è × ù¾ ù è × ú¾ ú Ó × ´ × ù × ú µ ù Ú (18) 6.2.1 Modelo de enlace completo En este modelo, asumimos que hay dependencias entre todos los pares de eventos de eventos. La dirección de dependencia se determina por el pedido de tiempo de las primeras historias en los eventos respectivos. Formalmente, los bordes del sistema se definen de la siguiente manera.¼ ´ ù ú µ Ø ´ ùµ Ø ´ Ú µ (19) donde Ø es la función de orden del tiempo de evento. En otras palabras, la ventaja de dependencia se dirige desde el evento ù hasta el evento Ú, si la primera historia en evento ù es anterior a la primera historia en el evento Ú. Señalamos que esto no debe confundirse con el algoritmo de enlace completo en la agrupación. Aunque usamos los mismos nombres, será claro en el contexto a cuál nos referimos.6.2.2 umbral simple Este modelo es una extensión del modelo de enlace completo con una restricción adicional de que existe una dependencia entre dos eventos ù y Ú solo si la similitud de coseno promedio entre el evento y el evento Ú es mayor que un umbral ì. Formalmente, ¼ ´ ù ú µ ú ë ñ´ ù ú µ ì Ø ´ ùµ Ø ´ ú µ (20) 6.2.3 Modelo principal más cercano en este modelo, suponemos que cada evento puede tener como máximo uno padre. Definimos el conjunto de dependencias de la siguiente manera.¼ ´ ù ú µ ë Ñ´ ù ú µ ì Ø ´ ú Ø ´ ùµ · ½ (21) Por lo tanto, para cada evento, el modelo principal más cercano considera solo el evento que precede como definido por Ø como un candidato potencial. El candidato se asigna como padre solo si la similitud promedio excede un umbral predefinido ì.6.2.4 Best Simility Model Este modelo también supone que cada evento puede tener como máximo padre. A un evento se asigna a un padre ù si y solo si ù es el evento anterior más similar a Ú y la similitud excede un umbral ì. Matemáticamente, esto se puede expresar como: ¼ ´ ù ú µ ú ë ñ´ ù ú µ ù Ö ü ü û Ø ´ ´µ Ø ´ ú µ ú ë ñ´ û Ú µ (22) 6.2.5 Modelo de árbol de expansión máxima en estoModelo, primero construimos un árbol de expansión máximo (MST) utilizando un algoritmo codicioso en el siguiente gráfico pesado totalmente conectado y no dirigido cuyos vértices son los eventos y cuyos bordes se definen como los siguientes: ´ ù Ú µ µ û ù Ú µ ú ë ë ë ë ë ë ë ë ë ë ë´ ù ú µ (23) Sea Åëì´ µ el conjunto de bordes en el árbol de expansión máximo de ¼. Ahora nuestros bordes de dependencia dirigidos se definen de la siguiente manera.¼ ´ ù ú µ ´ ù Ú µ ¾ Åëì´ µ Ø ´ ùµ Ø ´ úµ ú ë ñ ù ú µ ì (24) 450 Así en este modelo, asignamos dependencias entre los eventos más similares en el tema.7. Experimentos Nuestros experimentos constan de tres partes. Primero modelamos solo la parte de agrupación de eventos (definiendo la función de mapeo ¼) utilizando algoritmos de agrupación descritos en la Sección 6.1. Luego modelamos solo las dependencias al proporcionar al sistema los clústeres verdaderos y ejecutar solo los algoritmos de dependencia de la Sección 6.2. Finalmente, experimentamos con combinaciones de algoritmos de agrupación y dependencia para producir el modelo de evento completo. Esta forma de experimentación nos permite comparar el rendimiento de nuestros algoritmos de forma aislada y en asociación con otros componentes. Las siguientes subsecciones presentan las tres partes de nuestra experimentación.7.1 Agrupación Hemos probado varias variaciones del algoritmo ì para estudiar los efectos de varias características en el rendimiento de la agrupación. Todos los parámetros se aprenden sintonizar en el conjunto de entrenamiento. También probamos los algoritmos en el conjunto de pruebas con parámetros fijados en sus valores óptimos aprendidos de la capacitación. Usamos clusmodel aglomerativo mejor t cp cr cf p-valor p cos+1-lnk 0.15 0.41 0.56 0.43cos+all-lnk 0.00 0.40 0.62 0.45cos+LOC+AVG-LNK 0.07 0.37 0.74 0.45cos+PER+AVG-LNK 0.07 0.390.70 0.46cos+TD+AVG-LNK 0.04 0.45 0.70 0.53 2.9E-4* COS+N (T)+AVG-LNK-0.41 0.62 0.48 7.5E-2 Cos+N (T)+T+AVG-LNK 0.03 0.42 0.420.62 0.49 2.4e-2* cos+td+n (t)+avg-lnk-0.44 0.66 0.52 7.0e-3* cos+td+n (t)+t+avg-lnk 0.03 0.47 0.64 0.53 1.1e-3* Línea de base (COS+AVG-LNK) 0.05 0.39 0.67 0.46Table 2: Comparación de algoritmos de agrupación aglomerativa (conjunto de entrenamiento) basado solo en similitud de coseno como nuestra línea de base de agrupación. Los resultados en los conjuntos de entrenamiento y prueba se encuentran en las Tabas 2 y 3 respectivamente. Utilizamos el clúster F1-Masure (CF) promediado sobre todos los temas como nuestro criterio de evaluación. Modelo CP CR CF P-VALUE Value cos+1-LNK 0.43 0.49 0.39cos+all-lnk 0.43 0.62 0.47cos+loc+avg-lnk 0.37 0.73 0.45cos+per+avg-lnk 0.44 0.62 0.45cos+td+avg-lnk0.48 0.70 0.54 0.014* cos+n (t)+avg-lnk 0.41 0.71 0.51 0.31 cos+n (t)+t+avg-lnk 0.43 0.69* 0.52 0.14 cos+td+n (t)+avg-lnk 0.43 0.760.54 0.025* cos+td+n (t)+t+avg-lnk 0.47 0.69 0.54 0.0095* línea de referencia (cos+avg-lnk) 0.44 0.67 0.50Table 3: comparación de algoritmos de agrupamiento aglomerativo (conjunto de top) marcado conA £ significa que es una mejora estadísticamente significativa sobre la línea de base (nivel de confianza del 95%, una prueba t de cola). Los métodos que se muestran en la Tabla 2 y 3 son: ¯ Basora: peso del vector TF-IDF, similitud de coseno, enlace promedio en la agrupación. En la ecuación 12, ½ ½, ¾ ¿¼. Y «¼ en la ecuación 13. Este valor F es el máximo obtenido ajustando el umbral.¯ COS+1-LNK: Se utiliza la comparación de enlaces individuales (ver la ecuación 16) donde la similitud de dos grupos es el máximo de todos los pares de historias, otras configuraciones son las mismas que la ejecución de la línea de base.¯ Cos+All-Lnk: se utiliza el algoritmo de enlace completo de la ecuación 15. Similar al enlace único, pero toma la similitud mínima de todos los pares de historias.¯ COS+LOC+AVG-LNK: Los nombres de ubicación se utilizan al calcular la similitud.¾ ¼ ¼ en la ecuación 12. Todos los algoritmos a partir de este usan el enlace promedio (Ecuación 14), ya que el enlace único y el enlace completo no muestran ninguna mejora del rendimiento.¯ cos+per+avg-lnk: ¿¼ ¼ en la ecuación 12, es decir, ponemos algo de peso en los nombres de las personas en la similitud.¯ COS+TD+AVG-LNK: Coeficiente de descomposición de tiempo «½ en la ecuación 13, lo que significa que la similitud entre dos historias se detendrá a ½ si están en diferentes extremos del tema.¯ COS+N (T)+AVG-LNK: Use el número de eventos verdaderos para controlar el algoritmo de agrupación aglomerativa. Cuando el número de grupos es menos que el de los eventos de la verdad, deje de fusionar grupos.¯ cos+n (t)+t+avg-lnk: similar a n (t) pero también detiene la aglomeración si la similitud máxima está por debajo del umbral ì.¯ cos+td:+n (t)+avg-lnk: similar a n (t) pero las similitudes se descomponen, «½ en la ecuación 13. ¯ cos+td+n (t)+t+avg-lnk: similara TD+N (verdad) pero el cálculo se detiene cuando la similitud máxima es menor que el umbral ì. Nuestros experimentos demuestran que las similitudes de enlace único y el enlace completo funcionan peor que el enlace promedio, lo cual es razonable ya que el enlace promedio es menos sensible a uno o dos pares de pisos. Esperábamos que las ubicaciones y los nombres de las personas mejorara el resultado, pero no es el caso. El análisis de los temas muestra que muchas historias en el tema comparten los mismos lugares o personas, independientemente del evento al que pertenecen, por lo que estas características pueden ser más útiles para identificar temas en lugar de eventos. La descomposición del tiempo es exitosa porque los eventos están localizados temporalmente, es decir, las historias que discuten el mismo evento tienden a ser adyacentes entre sí en términos de tiempo. También notamos que proporcionar el número de eventos verdaderos mejora el rendimiento, ya que guía el algoritmo de agrupación para obtener una granularidad correcta. Sin embargo, para la mayoría de las aplicaciones, no está disponible. Lo usamos solo como un experimento de trucos para comparar con otros algoritmos. En general, la descomposición del tiempo resultó a la característica más poderosa además de la similitud de coseno tanto en los conjuntos de entrenamiento como en los conjuntos de pruebas.7.2 Dependencias En esta subsección, nuestro objetivo es modelar solo dependencias. Utilizamos la verdadera función de mapeo y, por implicación, los verdaderos eventos î. Construimos nuestra estructura de dependencia ¼ utilizando los cinco modelos descritos en la Sección 6.2. Primero entrenamos a nuestros modelos en los 26 temas de entrenamiento. La capacitación implica aprender el mejor umbral ì para cada uno de los modelos. Luego probamos el rendimiento de todos los modelos entrenados en los 27 temas de prueba. Evaluamos nuestro rendimiento 451 utilizando los valores promedio de precisión de dependencia (DP), recuerdo de dependencia (DR) y dependencia de la medida F (DF). Consideramos que el modelo de enlace completo es nuestra línea de base ya que para cada evento considera trivialmente que todos los eventos anteriores son padres. La Tabla 4 enumera los resultados en el conjunto de capacitación. Vemos que si bien todos los algoritmos, excepto MST, superan el algoritmo de enlace completo de línea de base, el algoritmo principal más cercano es estadísticamente significativo desde la línea de base en términos de su valor DF utilizando una prueba T emparejada con un nivel de confianza del 95%. Modelo mejor ì DP DR DF P-Valor P Strenom más cercano 0.025 0.55 0.62 0.56 0.04* Mejor similitud 0.02 0.51 0.62 0.53 0.24 MST 0.0 0.46 0.58 0.48 Tresh inmediato.0.045 0.45 0.76 0.52 0.14 enlace completo - 0.36 0.93 0.48 Tabla 4: Resultados en el conjunto de entrenamiento: El mejor ì es el valor óptimo del umbral ì.* Indica que el modelo correspondiente es estadísticamente significativo en comparación con la línea de base que usa una prueba t de una cola y un nivel de confianza del 95%. En la Tabla 5 presentamos la comparación de los modelos en el conjunto de pruebas. Aquí, no usamos ningún ajuste, pero establecemos el umbral en los valores óptimos correspondientes aprendidos del conjunto de entrenamiento. Los resultados arrojan algunas sorpresas: el modelo principal más cercano, que fue significativamente mejor que la línea de base en el conjunto de entrenamiento, resulta peor que la línea de base en el conjunto de pruebas. Sin embargo, todos los demás modelos son mejores que la línea de base, incluida la mejor similitud que es estadísticamente significativa. Observe que todos los modelos que funcionan mejor que la línea de base en términos de DF, en realidad sacrifican su rendimiento de recuperación en comparación con la línea de base, pero mejoran su precisión sustancialmente, mejorando así su rendimiento en la medida de DF. Notamos que tanto el umbral simple como la mejor similitud son mejores que la línea de base tanto en los conjuntos de entrenamiento como de prueba, aunque la mejora no es significativa. En general, observamos que las características de nivel de superficie que utilizamos capturan las dependencias a un nivel razonable que alcanza un mejor valor de 0.72 df en el conjunto de pruebas. Aunque hay mucho margen de mejora, creemos que este es un buen primer paso. Modelo DP DR DF P-Valor Patrio más cercano 0.61 0.60 0.60 Best Similitud 0.71 0.74 0.72 0.04* MST 0.70 0.68 0.69 0.22 Thresh simple.0.57 0.75 0.64 0.24 línea de base (enlace completo) 0.50 0.94 0.63Table 5: Resultados en el conjunto de pruebas 7.3 Combinando la agrupación y dependencias Ahora que hemos estudiado los algoritmos de agrupación y dependencia de forma aislada, combinamos los algoritmos de mejor rendimiento y construimos los eventos completos de los eventos completosmodelo. Dado que no se ha demostrado que ninguno de los algoritmos de dependencia sea consistente y significativamente mejor que los demás, los usamos todos en nuestra experimentación. Desde las técnicas de agrupación, elegimos el costoso TD de mejor rendimiento. Como línea de base, utilizamos una combinación de las líneas de base en cada componentes, es decir, COS para agrupación y enlace completo para dependencias. Tenga en cuenta que necesitamos volver a entrenar todos los algoritmos en el conjunto de capacitación porque nuestra función objetivo para optimizar ahora es JF, la medida F conjunta. Para cada algoritmo, necesitamos optimizar tanto el umbral de agrupación como el umbral de dependencia. Hicimos esto empíricamente en el conjunto de entrenamiento y los valores óptimos se enumeran en la Tabla 6. Los resultados en el conjunto de entrenamiento, también presentados en la Tabla 6, indican que el umbral simple COS+TD+es significativamente mejor que la línea de base en términos de la JF de valor F conjunto, utilizando un TTest emparejado de una cola al nivel de confianza del 95%. En general, notamos que si bien el rendimiento de la agrupación es comparable a los experimentos en la Sección 7.1, el rendimiento general se ve socavado por el rendimiento de bajo dependencia. A diferencia de nuestros experimentos en la Sección 7.2, donde habíamos proporcionado los verdaderos grupos al sistema, en este caso, el sistema tiene que lidiar con el deterioro en la calidad del clúster. Por lo tanto, el rendimiento de los algoritmos de dependencia ha sufrido sustancialmente, lo que reduce el rendimiento general. Los resultados en el conjunto de pruebas presentan una historia muy similar a la de la Tabla 7. También notamos una buena cantidad de consistencia en el rendimiento de los algoritmos de combinación.COS+TD+umbral simple supera significativamente la línea de base. Los resultados del conjunto de pruebas también apuntan al hecho de que el componente de agrupación sigue siendo un cuello de botella para lograr un buen rendimiento general.8. Discusión y conclusiones En este documento, hemos presentado una nueva perspectiva de los temas de modelado de noticias. Al contrario de la visión de TDT de los temas como una colección plana de noticias, vemos un tema de noticias como una estructura relacional de eventos interconectados por las dependencias. En este artículo, también propusimos algunos enfoques para las historias de agrupación en eventos y construir dependencias entre ellos. Desarrollamos un enfoque de agrupación basado en Timedecay que aprovecha la temporalocalización de las noticias sobre el mismo evento y demostramos que funciona significativamente mejor que el enfoque de referencia basado en la similitud de coseno. Nuestros experimentos también muestran que podemos hacerlo bastante bien en las dependencias utilizando solo las características de la superficie, como la cosinesimilaridad y los sellos de tiempo de las noticias, siempre que se proporcionen verdaderos eventos al sistema. Sin embargo, el rendimiento se deteriora rápidamente si el sistema tiene que descubrir los eventos por sí solo. A pesar de ese resultado desalentador, hemos demostrado que nuestros algoritmos combinados funcionan significativamente mejor que las líneas de base. Nuestros resultados indican que las dependencias de modelado pueden ser un problema muy difícil, especialmente cuando el rendimiento de la agrupación está por debajo del nivel ideal. Los errores en la agrupación tienen un efecto de aumento en los errores en las dependencias como hemos visto en nuestros experimentos. Por lo tanto, debemos centrarnos no solo en mejorar las dependencias sino también en la agrupación al mismo tiempo. Como parte de nuestro trabajo futuro, planeamos investigar más a los datos y descubrir nuevas características que influyen en la agrupación y las dependencias. Y para las dependencias de modelado, un marco probabilístico debería ser una mejor opción ya que no hay una respuesta definitiva de sí/no para las relaciones causales entre algunos eventos. También esperamos diseñar un algoritmo iterativo que pueda mejorar el rendimiento de la agrupación y la dependencia alternativamente como lo sugiere uno de los revisores. También esperamos expandir nuestro corpus etiquetado aún más para incluir fuentes de noticias más diversas y estructuras de eventos más grandes y complejas. Agradecimientos Nos gustaría agradecer a los tres revisores anónimos por sus valiosos comentarios. Este trabajo fue apoyado en parte por el Centro 452 Modelo Cluster T Dep. T CP CR CF DP DR DF JF P-VALUE POS+TD+PARADA más cercana 0.055 0.02 0.51 0.53 0.49 0.21 0.19 0.19 0.27cos+TD+Best-Simility 0.04 0.02 0.45 0.70 0.53 0.21 0.33 0.23 0.32cos+TD+MST 0.04 0.00 0.000.45 0.70 0.53 0.22 0.35 0.25 0.33cos+TD+umbral simple 0.065 0.02 0.56 0.47 0.48 0.23 0.61 0.32 0.38 0.0004* Base (cos+de enlace completo) 0.10-0.58 0.31 0.38 0.20 0.67 0.3033TableEstablecer modelo CP CR CF DP DR DF JF P-Value POS+TD+Padre más cercano 0.57 0.50 0.50 0.27 0.19 0.21 0.30cos+TD+Mejor similitud 0.48 0.70 0.54 0.31 0.27 0.26 0.35cos+TD+MST 0.48 0.70 0.54 0.330 0.28 0.37cos+td+umbral simple 0.60 0.39 0.44 0.32 0.66 0.42 0.43 0.0081* línea de base (cos+enlace completo) 0.66 0.27 0.36 0.30 0.72 0.43 0.39Table 7: Resultados combinados en el conjunto de prueba para la recuperación de información inteligente y en parte por el número de concesión SpawarsyScensdN66001-02-1-8903. Cualquier opinión, hallazgos y conclusiones o recomendaciones expresadas en este material son los autores y no reflejan necesariamente las del patrocinador.9. Referencias [1] J. Allan, J. Carbonell, G. Doddington, J. Yamron e Y. Yang. Estudio piloto de detección y seguimiento de temas: informe final. En Actas del Taller de transcripción y comprensión de Noticias de Broadcast DARPA, páginas 194-218, 1998. [2] J. Allan, A. Feng y A. Bolívar. Evaluación intrínseca flexible de la agrupación jerárquica para TDT.Volumen en el proceso.de la Duodécima Conferencia Internacional de ACM sobre Gestión de Información y Conocimiento, páginas 263-270, noviembre de 2003. [3] James Allan, editor. Detección y seguimiento de temas: Organización de información basada en eventos. Kluwer Academic Publishers, 2000. [4] James Allan, Rahul Gupta y Vikas Khandelwal. Resúmenes temporales de nuevos temas. En Actas de la 24ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 10-18. ACM Press, 2001. [5] Regina Barzilay y Lillian Lee. Captura de la deriva: modelos de contenido probabilístico, con aplicaciones a la generación y resumen. En Actas de la Conferencia de Tecnología del Lenguaje Humano y el Capítulo de América del Norte de la Asociación de Lingüística Computacional (HLT-NAACL), páginas 113-120, 2004. [6] D. Lawrie y W. B. Croft. Descubrir y comparar jerarquías de temas. En Actas de la Conferencia RIAO 2000, páginas 314-330, 1999. [7] David D. Lewis y Kimberly A. Knowles. Paso de correo electrónico: un estudio preliminar. Inf. Proceso. Manag., 33 (2): 209-217, 1997. [8] Juha Makkonen. Investigaciones sobre evolución del evento en TDT. En Actas del Taller de Estudiantes HLT-NAACL 2003, páginas 43-48, 2004. [9] Aixin Sun y Ee-Peng Lim. Clasificación y evaluación de texto jerárquico. En Actas de la Conferencia Internacional IEEE de 2001 sobre minería de datos, páginas 521-528. IEEE Computer Society, 2001. [10] Yiming Yang, Jaime Carbonell, Ralf Brown, Thomas Pierce, Brian T. Archibald y Xin Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En IEEE Intelligent Systems, número especial sobre aplicaciones de recuperación de información inteligente, volumen 14 (4), páginas 32-43, 1999. 453