Aplicaciones autoadaptativas en la cuadrícula Gosia Wrzesinska Jason Maassen Henri E. Bal Dept. de los sistemas informáticos, Vrije Universiteit Amsterdam {Gosia, Jason, balth@cs.vu.nl Las cuadrículas abstractas son inherentemente heterogéneas y dinámicas. Un problema importante en la informática de la red es la selección de recursos, es decir, encontrar un conjunto de recursos apropiado para la aplicación. Otro problema es la adaptación a las características cambiantes del entorno de la cuadrícula. Las soluciones existentes a estos dos problemas requieren que se conozca un modelo de rendimiento para una aplicación. Sin embargo, construir tales modelos es una tarea compleja. En este artículo, investigamos un enfoque que no requiere modelos de rendimiento. Comenzamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la solicitud, periódicamente recopilamos las estadísticas sobre la ejecución de la aplicación y deducimos los requisitos de la aplicación de estas estadísticas. Luego, ajustamos el conjunto de recursos para ajustar mejor las necesidades de la aplicación. Este enfoque nos permite evitar cuellos de botella de rendimiento, como enlaces WAN sobrecargados o procesadores muy lentos y, por lo tanto, puede producir mejoras significativas de rendimiento. Evaluamos nuestro enfoque en varios escenarios típicos de la cuadrícula. Categorías y descriptores de sujetos C.2.4 [Redes de comunicación informática]: aplicaciones distribuidas de sistemas distribuidos;C.4 [rendimiento de los sistemas]: técnicas de medición, técnicas de modelado algoritmos de términos generales, medición, rendimiento, experimentación 1. Introducción En los últimos años, la informática de la red se ha convertido en una alternativa real a la informática paralela tradicional. Una cuadrícula proporciona mucha potencia computacional y, por lo tanto, ofrece la posibilidad de resolver problemas muy grandes, especialmente si las aplicaciones pueden ejecutarse en múltiples sitios al mismo tiempo (7; 15; 20). Sin embargo, la complejidad de los entornos de la cuadrícula también es muchas veces mayor que la de las máquinas paralelas tradicionales como grupos y supercomputadoras. Un problema importante es la selección de recursos: seleccionar un conjunto de nodos de cómputo de modo que la aplicación logre un buen rendimiento. Incluso en entornos paralelos tradicionales y homogéneos, encontrar el número óptimo de nodos es un problema difícil y a menudo se resuelve de manera de prueba y error. En un entorno de la cuadrícula, este problema es aún más difícil, debido a la heterogeneidad de los recursos: los nodos de cómputo tienen varias velocidades y la calidad de las conexiones de red entre ellos varía desde redes de área local de baja latencia y alto ancho de banda (LAN) hasta altas-Latencia y posiblemente redes de área ancha de ancho de banda bajo (WAN). Otro problema importante es que el rendimiento y la disponibilidad de los recursos de la cuadrícula varían con el tiempo: los enlaces de red o los nodos de cómputo pueden sobrecargarse, o los nodos de cálculo pueden no estar disponibles debido a los bloqueos o porque han sido reclamados por una aplicación de mayor prioridad. Además, pueden estar disponibles nuevos y mejores recursos. Para mantener un nivel de rendimiento razonable, la aplicación debe adaptarse a las condiciones cambiantes. El problema de adaptación se puede reducir al problema de selección de recursos: la fase de selección de recursos se puede repetir durante la ejecución de la aplicación, ya sea a intervalos regulares o cuando se detecta un problema de rendimiento, o cuando se dispone de nuevos recursos. Este enfoque ha sido adoptado por varios sistemas (5; 14; 18). Para la selección de recursos, el tiempo de ejecución de la aplicación se estima para algunos conjuntos de recursos y el conjunto que produce el tiempo de ejecución más corto se selecciona para la ejecución. Sin embargo, predecir el tiempo de ejecución de la aplicación en un conjunto de recursos determinado requiere conocimiento sobre la aplicación. Por lo general, se utiliza un modelo de rendimiento analítico, pero construir dicho modelo es inherentemente difícil y requiere una experiencia que los programadores de aplicaciones puedan no tener. En este documento, presentamos y evaluamos un enfoque alternativo para la adaptación de la aplicación y la selección de recursos que no necesita un modelo de rendimiento. Comenzamos una aplicación en cualquier conjunto de recursos. Durante la ejecución de la aplicación, periódicamente recopilamos información sobre los tiempos de comunicación y los tiempos de inactividad de los procesadores. Utilizamos estas estadísticas para estimar automáticamente los requisitos de recursos de la aplicación. A continuación, ajustamos el conjunto de recursos que la aplicación se ejecuta agregando o eliminando nodos de cómputo o incluso grupos completos. Nuestra estrategia de adaptación utiliza el trabajo de Anic et al.(10) para determinar la eficiencia y los intentos de mantener la eficiencia de la aplicación entre un umbral inferior y superior derivado de su teoría. Los procesadores se agregan o eliminan para permanecer entre los umbrales, adaptándose automáticamente al entorno cambiante. Una ventaja importante de nuestro enfoque es que mejora el rendimiento de la aplicación en muchas situaciones diferentes que son típicas para la computación de la red. Maneja todos los siguientes casos: • Adaptando automáticamente el número de procesadores al grado de paralelismo en la aplicación, incluso cuando este grado cambia dinámicamente durante el cálculo • migrar (parte de) un cálculo lejos de los recursos sobrecargados • Eliminar recursos con pobresLos enlaces de comunicación que ralentizan el cálculo • Agregar nuevos recursos para reemplazar los recursos que han bloqueado nuestro trabajo supone que la aplicación es maleable y puede ejecutarse (de manera eficiente) en múltiples sitios de una cuadrícula (es decir, usar co-asignación (15)). No debe usar el equilibrio de carga estática o ser muy sensible a las latencias de área Wide121. Hemos aplicado nuestras ideas para dividir y vencer aplicaciones, que satisfacen estos requisitos. Se ha demostrado que Divide-and-Conquer es un paradigma atractivo para la programación de aplicaciones de cuadrícula (4; 20). Creemos que nuestro enfoque puede extenderse a otras clases de aplicaciones con los supuestos dados. Implementamos nuestra estrategia en Satin, que es un marco centrado en Java para escribir aplicaciones divididas y conquistar habilitadas para la cuadrícula (20). Evaluamos el rendimiento de nuestro enfoque en el sistema de área amplia DAS-2 y mostraremos que nuestro enfoque produce principales mejoras de rendimiento (aproximadamente 10-60 %) en los escenarios anteriores. El resto del artículo se estructura de la siguiente manera. En la Sección 2, explicamos qué suposiciones estamos haciendo sobre las aplicaciones y los recursos de la red. En la Sección 3, presentamos nuestra estrategia de selección y adaptación de recursos. En la Sección 4, describimos su implementación en el marco satinado. En la Sección 5, evaluamos nuestro enfoque en varios escenarios de cuadrícula. En la Sección 6, comparamos nuestro enfoque con el trabajo relacionado. Finalmente, en la Sección 7, concluimos y describimos el trabajo futuro.2. Antecedentes y supuestos En esta sección, describimos nuestras suposiciones sobre las aplicaciones y sus recursos. Asumimos el siguiente modelo de recursos. Las aplicaciones se ejecutan en varios sitios al mismo tiempo, donde los sitios son grupos o supercomputadoras. También suponemos que se pueden acceder a los procesadores de los sitios utilizando un sistema de programación de cuadrícula, como Koala (15), Zorilla (9) o GRMS (3). Los procesadores que pertenecen a un sitio están conectados por una LAN rápida con una baja latencia y un alto ancho de banda. Los diferentes sitios están conectados por una WAN. La comunicación entre sitios sufre de altas latencias. Suponemos que los enlaces que conectan los sitios con la red troncal de Internet podrían convertirse en cuellos de botella que hacen que la comunicación entre sitios sufra de bajos anchos de banda. Estudiamos el problema de adaptación en el contexto de aplicaciones de divide y conquistar. Sin embargo, creemos que nuestra metodología también puede usarse para otros tipos de aplicaciones. En esta sección resumimos los supuestos sobre aplicaciones que son importantes para nuestro enfoque. La primera suposición que hacemos es que la aplicación es maleable, es decir, es capaz de manejar procesadores que se unen y dejan el cálculo continuo. En (23), mostramos cómo las aplicaciones de divide y conquistar pueden ser tolerantes y maleables. Los procesadores se pueden agregar o eliminar en cualquier punto del cálculo con poca sobrecarga. La segunda suposición es que la aplicación puede ejecutarse de manera eficiente en procesadores con diferentes velocidades. Esto se puede lograr utilizando una estrategia de equilibrio de carga dinámica, como el robo del trabajo utilizado por aplicaciones divididas y conquistadoras (19). Además, las aplicaciones de trabajadores maestros generalmente utilizan estrategias dinámicas de equilibrio de carga (por ejemplo, MW, un marco para escribir aplicaciones de trabajadores maestros en cuadrícula (12)). Encontramos una suposición razonable para una aplicación de la red, ya que las aplicaciones para la cual el procesador más lento se convierte en un cuello de botella no podrán utilizar de manera eficiente los recursos de la red. Finalmente, la aplicación debe ser insensible a las latencias de área ancha, por lo que puede funcionar de manera eficiente en una cuadrícula de Widearea (16; 17).3. Autoadaptación en esta sección Explicaremos cómo utilizamos la maleabilidad de la aplicación para encontrar un conjunto adecuado de recursos para una aplicación determinada y para adaptarnos a las condiciones cambiantes en el entorno de la red. Para monitorear el rendimiento de la aplicación y guiar la adaptación, agregamos un proceso adicional al cálculo que llamamos coordinador de adaptación. El coordinador de adaptación recopila periódicamente estadísticas de rendimiento de los procesadores de solicitudes. Introducimos una nueva métrica de rendimiento de la aplicación: eficiencia promedio ponderada que describe el rendimiento de la aplicación en un conjunto heterogéneo de recursos. El coordinador utiliza estadísticas de procesadores de aplicación para calcular la eficiencia promedio ponderada. Si la eficiencia cae por encima o por debajo de ciertos umbrales, el coordinador decide agregar o eliminar procesadores. Se utiliza una fórmula heurística para decidir qué procesadores deben eliminarse. Durante este proceso, el coordinador aprende los requisitos de la aplicación al recordar las características de los procesadores eliminados. Estos requisitos se utilizan para guiar la adición de nuevos procesadores.3.1 Eficiencia promedio ponderada en la computación paralela tradicional, una métrica estándar que describe el rendimiento de una aplicación paralela es la eficiencia. La eficiencia se define como la utilización promedio de los procesadores, es decir, la fracción de tiempo que los procesadores pasan haciendo un trabajo útil en lugar de estar inactivo o comunicarse con otros procesadores (10).Eficiencia = 1 n ∗ n i = 0 (1 - sobrecarga) donde n es el número de procesadores y la sobrecarga es la fracción de tiempo que el procesador ésimo gasta en inactivo o comunicando. La eficiencia indica el beneficio de usar múltiples procesadores. Por lo general, la eficiencia cae a medida que se agregan nuevos procesadores al cálculo. Por lo tanto, lograr una alta velocidad (y, por lo tanto, un tiempo de ejecución bajo) y lograr una alta utilización del sistema son objetivos conflictivos (10). El número óptimo de procesadores es el número para el cual se maximiza la relación de eficiencia y el tiempo de ejecución. Agregar procesadores más allá de este número produce poco beneficio. Este número es típicamente difícil de encontrar, pero en (10) se demostró teóricamente que si se usa el número óptimo de procesadores, la eficiencia es al menos 50%. Por lo tanto, agregar procesadores cuando la eficiencia es menor o igual al 50% solo disminuirá la utilización del sistema sin ganancias de rendimiento significativas. Para entornos heterogéneos con diferentes velocidades de procesador, ampliamos la noción de eficiencia e introdujimos la eficiencia promedio ponderada.WA Eficiencia = 1 N ∗ N I = 0 Speedi ∗ (1 - Sobrevei) El trabajo útil realizado por un procesador (1 - Sobrevei) se pondera multiplicándolo por la velocidad de este procesador en relación con el procesador más rápido. El procesador más rápido tiene velocidad = 1, para otros se mantiene: 0 <velocidad ≤ 1. Por lo tanto, los procesadores más lentos se modelan como los rápidos que pasan una gran fracción del tiempo que está inactivo. La eficiencia promedio ponderada refleja el hecho de que agregar procesadores lentos produce menos beneficio que agregar procesadores rápidos. En el mundo heterogéneo, no es beneficioso agregar procesadores si la eficiencia es inferior al 50% a menos que el procesador agregado sea más rápido que algunos de los procesadores utilizados actualmente. Agregar procesadores más rápidos puede ser beneficioso independientemente de la eficiencia.3.2 Monitoreo de la aplicación Cada procesador mide el tiempo que pasa comunicando o está inactivo. El cálculo se divide en períodos de monitoreo. Después de cada período de monitoreo, los procesadores calculan su sobrecarga durante este período como el porcentaje del tiempo que pasaron en inactivo o comunicándose en este período. Además de la sobrecarga total, cada procesador también calcula la sobrecarga de la comunicación entre grupos e intracluster. Para calcular la eficiencia promedio ponderada, necesitamos conocer las velocidades relativas de los procesadores, que dependen de la aplicación y el tamaño del problema utilizado. Dado que no es práctico ejecutar la aplicación completa 122 en cada procesador por separado, utilizamos los puntos de referencia específicos de aplicaciones. Actualmente usamos la misma aplicación con un pequeño tamaño de problema como punto de referencia y requerimos que el programador de la aplicación especifique este tamaño de problema. Este enfoque requiere un esfuerzo adicional del programador para encontrar el tamaño del problema correcto y posiblemente para producir archivos de entrada para este tamaño de problema, lo que puede ser difícil. En el futuro, estamos planeando generar puntos de referencia automáticamente eligiendo un subconjunto aleatorio del gráfico de tareas de la aplicación original. Los puntos de referencia deben volver a ejecutar periódicamente porque la velocidad de un procesador podría cambiar si se sobrecarga por otra aplicación (para máquinas compartidas). Existe una compensación entre la precisión de las mediciones de velocidad y la sobrecarga en la que incurre. Cuanto más tiempo sea el punto de referencia, mayor será la precisión de la medición. Cuanto más a menudo se ejecuta, se detectan cambios más rápidos en la velocidad del procesador. En nuestra implementación actual, el programador de aplicaciones especifica la longitud del punto de referencia (al especificar su tamaño de problema) y la sobrecarga máxima que puede causar. Los procesadores ejecutan el punto de referencia a tal frecuencia para no exceder la sobrecarga especificada. En el futuro, planeamos combinar la evaluación comparativa con el monitoreo de la carga del procesador que nos permitiría evitar ejecutar el punto de referencia si no se detecta ningún cambio en la carga del procesador. Esta optimización reducirá aún más la sobrecarga de evaluación comparativa. Tenga en cuenta que la sobrecarga de evaluación comparativa podría evitarse por completo para aplicaciones más regulares, por ejemplo, para aplicaciones de trabajadores maestros con tareas de tamaño igual o similar. La velocidad del procesador podría medirse contando las tareas procesadas por este procesador dentro de un período de monitoreo. Desafortunadamente, las aplicaciones de división y conquista generalmente exhiben una estructura muy irregular. Los tamaños de las tareas pueden variar según muchos órdenes de magnitud. Al final de cada período de monitoreo, los procesadores envían las estadísticas de sobrecarga y las velocidades del procesador al coordinador. Periódicamente, el coordinador calcula la eficiencia promedio ponderada y otras estadísticas, como los gastos generales o gastos generales entre clúster promedio en cada clúster. Los relojes de los procesadores no están sincronizados entre sí o con el reloj del coordinador. Cada procesador decide por separado cuando es hora de enviar datos. Ocasionalmente, el coordinador puede perder datos al final de un período de monitoreo, por lo que tiene que usar datos del período de monitoreo anterior para estos procesadores. Esto causa pequeñas inexactitudes en los cálculos del coordinador, pero no influye en el rendimiento de la adaptación.3.3 Estrategia de adaptación El coordinador de adaptación intenta mantener la eficiencia promedio ponderada entre Emin y Emax. Cuando excede EMAX, el coordinador solicita nuevos procesadores del planificador. El número de procesadores solicitados depende de la eficiencia actual: cuanto mayor sea la eficiencia, más procesadores se solicitan. El coordinador comienza a eliminar procesadores cuando la eficiencia promedio ponderada cae por debajo de Emin. El número de nodos que se eliminan nuevamente depende de la eficiencia promedio ponderada. Cuanto menor sea la eficiencia, más nodos se eliminan. Los umbrales que usamos son EMAX = 50%, porque sabemos que agregar procesadores cuando la eficiencia es menor no tiene sentido, y emin = 30%. La eficiencia del 30% o menos puede indicar problemas de rendimiento, como procesadores de bajo ancho de banda o sobrecarga. En ese caso, la eliminación de procesadores malos será beneficioso para la aplicación. Tal baja eficiencia también podría indicar que simplemente tenemos demasiados procesadores. En ese caso, eliminar algunos procesadores puede no ser beneficioso, pero no dañará la aplicación. El coordinador siempre intenta eliminar los peores procesadores. La maldad de un procesador está determinada por la siguiente fórmula: PROC Badnessi = α ∗ 1 Speedi + β ∗ IC Overheadi + γ ∗ InW Orstcluster (i) El procesador se considera malo si tiene baja velocidad (1 velocidad es grande) y altaOverhead entre clúster (sobrecarga IC). La sobrecarga de alta intergrupa indica que el ancho de banda de este clúster de procesadores es insuficiente. La eliminación de procesadores ubicados en un solo grupo es deseable ya que disminuye la cantidad de comunicación de área ancha. Por lo tanto, se prefieren los procesadores que pertenecen al peor grupo. La función inW OrstCluster (i) devuelve 1 para procesadores que pertenecen al peor clúster y 0 de lo contrario. La maldad de los clústeres se calcula de manera similar a la maldad de los procesadores: la mala mala calidad del clúster = α ∗ 1 Speedi + β β IC Sobre la velocidad de un clúster es la suma de las velocidades del procesador normalizadas a la velocidad del grupo más rápido. La sobrecarga de IC de un clúster es un promedio de sobrecargas entre grupos del procesador. Los coeficientes α, β y γ determinan la importancia relativa de los términos. Esos coeficientes se establecen empíricamente. Actualmente estamos utilizando los siguientes valores: α = 1, β = 100 y γ = 10, según la observación de que la sobrecarga de IC> 0.2 indica problemas de ancho de banda y procesadores con velocidad <0.05 no contribuyen al cálculo. Además, cuando uno de los clústeres tiene una sobrecarga entre clúster excepcionalmente alta (más de 0.25), concluimos que el ancho de banda en el enlace entre este clúster y la red troncal de Internet es insuficiente para la aplicación. En ese caso, simplemente eliminamos todo el clúster en lugar de calcular la maldad del nodo y eliminar los peores nodos. Después de decidir qué nodos se eliminan, el coordinador envía un mensaje a estos nodos y los nodos dejan el cálculo. La Figura 1 muestra una visión esquemática de la estrategia de adaptación. Las líneas discontinuas indican una parte que aún no es compatible, como se explicará a continuación. Esta estrategia de adaptación simple nos permite mejorar el rendimiento de la aplicación en varias situaciones típicas de la red: • Si se inicia una aplicación en menos procesadores que su grado de paralelismo, se expandirá automáticamente a más procesadores (tan pronto como hay recursos adicionales disponibles.). Por el contrario, si se inicia una aplicación en más procesadores de los que puede usar de manera eficiente, se lanzará una parte de los procesadores.• Si una aplicación se ejecuta en un conjunto apropiado de recursos, pero después de un tiempo, algunos de los recursos (procesadores y/o enlaces de red) se sobrecargan y ralentizan el cálculo, se eliminarán los recursos sobrecargados. Después de eliminar los recursos sobrecargados, la eficiencia promedio ponderada aumentará por encima del umbral Emax y el Coordinador de adaptación intentará agregar nuevos recursos. Por lo tanto, la aplicación se migrará de los recursos sobrecargados.• Si algunos de los recursos originales elegidos por el usuario son inapropiados para la aplicación, por ejemplo, el ancho de banda de uno de los clústeres es demasiado pequeño, los recursos inapropiados se eliminarán. Si es necesario, el componente de adaptación intentará agregar otros recursos.• Si durante el cálculo se bloqueará una parte sustancial de los procesadores, el componente de adaptación intentará agregar nuevos recursos para reemplazar los procesadores bloqueados.123 0 2000 4000 6000 de ejecución (secs.) Escenario 0 A B C Escenario 1 Escenario 2 Escenario 3 Escenario 4 Escenario 5 sin monitoreo y adaptación (tiempo de ejecución 1) con monitoreo y adaptación (tiempo de ejecución 2) con monitoreo pero sin adaptación (tiempo de ejecución 3) Figura 2. Los tiempos de ejecución de la aplicación Barnes-Hut, los escenarios 0-5 Agregar nodos nodos más rápidos disponibles si calculan la eficiencia promedio ponderada e WA Wa Wait y recolectan los nodos de rango de rango Elimine los peores nodos wae ewa y n y arriba si es abajo si emin maxe figura 1. Estrategia de adaptación • Si el grado de aplicación de paralelismo está cambiando durante el cálculo, el número de nodos en los que se ejecuta la aplicación se ajustará automáticamente. Son posibles mejoras adicionales, pero requieren una funcionalidad adicional del programador de la red y/o integración con servicios de monitoreo como NWS (22). Por ejemplo, se puede mejorar los nodos a un cálculo. Actualmente, agregamos cualquier nodo que nos brinde el programador. Sin embargo, sería más eficiente pedir los procesadores más rápidos entre los disponibles. Esto podría hacerse, por ejemplo, al pasar un punto de referencia al planificador de la cuadrícula, para que pueda medir las velocidades del procesador de una manera específica de la aplicación. Por lo general, sería suficiente medir la velocidad de un procesador por sitio, ya que los grupos y las supercomputadoras son generalmente homogéneas. Un enfoque alternativo sería clasificar los procesadores en función de parámetros como la velocidad del reloj y el tamaño de la memoria caché. Este enfoque a veces se utiliza para la selección de recursos para aplicaciones secuenciales (14). Sin embargo, es menos preciso que usar un punto de referencia específico de la aplicación. Además, durante la ejecución de la aplicación, podemos aprender algunos requisitos de aplicación y pasarlos al planificador. Un ejemplo es el ancho de banda mínimo requerido por la aplicación. El límite inferior en el ancho de banda mínimo requerido se aprieta cada vez que se elimina un clúster con alto nivel entre clúster. El ancho de banda entre cada par de grupos se estima durante el cálculo midiendo los tiempos de transferencia de datos, y el ancho de banda al clúster eliminado se establece como un mínimo. Alternativamente, se puede utilizar información de un sistema de monitoreo de cuadrícula. Dichos límites se pueden pasar al planificador para evitar agregar recursos inapropiados. Es especialmente importante cuando migra de los recursos que causan problemas de rendimiento: debemos tener cuidado de no agregar los recursos que acabamos de eliminar. Actualmente usamos Blacklisting: simplemente no permitimos agregar recursos que eliminamos antes. Esto significa, sin embargo, que no podemos usar estos recursos, incluso si la causa del problema de rendimiento desaparece, p.El ancho de banda de un enlace podría mejorar si el tráfico de fondo disminuye. Actualmente no podemos realizar una migración oportunista, migrando a mejores recursos cuando se descubren. Si una aplicación se ejecuta con eficiencia entre Emin y Emax, el componente de adaptación no realizará ninguna acción, incluso si hay mejores recursos disponibles. Habilitar la migración oportunista requiere, nuevamente, la capacidad de especificar al planificador qué mejores recursos son (más rápido, con un cierto ancho de banda mínimo) y recibir notificaciones cuando dichos recursos están disponibles. Los programadores de cuadrícula existentes como el Gram del Kit de herramientas Globus (11) no admiten dicha funcionalidad. Los desarrolladores del Koala Metascheduler (15) han comenzado recientemente un proyecto cuyo objetivo es brindar apoyo para aplicaciones adaptativas. Actualmente estamos discutiendo con ellos la posibilidad de proporcionar las funcionalidades requeridas por nosotros, con el objetivo de extender nuestra adaptividad Strat124 Egy para apoyar la migración oportunista y mejorar la selección inicial de recursos.4. Implementación Incorporamos nuestro mecanismo de adaptación en Satin, un marco Java para crear aplicaciones divididas y conquistar habilitadas para la red. Con el satén, el programador anota el código secuencial con primitivas divididas y conquistas y compila el código anotado con un compilador de satén especial que genera la comunicación necesaria y el código de equilibrio de carga. El satén utiliza un algoritmo de equilibrio de carga de carga muy eficiente y consciente de la cuadrícula-Robado aleatorio con consumo de clúster (CRS) (19), que oculta latencias de área ancha superponiendo el robo local y remoto. El satén también proporciona tolerancia a fallas transparente y maleabilidad (23). Con satén, eliminar y agregar procesadores de/a un cálculo continuo incurre en poca sobrecarga. Instrumentamos el sistema de tiempo de ejecución de satén para recopilar estadísticas de tiempo de ejecución y enviarlas al coordinador de adaptación. El coordinador se implementa como un proceso separado. Tanto el coordinador como el satén se implementan completamente en Java sobre la Biblioteca de Comunicación IBIS (21). El núcleo de IBIS también se implementa en Java. Por lo tanto, el sistema resultante es altamente portátil (debido a la escritura de Javas una vez, ejecuta la propiedad en cualquier lugar), lo que permite que el software se ejecute sin modificar en una cuadrícula heterogénea. IBIS también proporciona el registro de IBIS. El registro proporciona, entre otros, un servicio de membresía a los procesadores que participan en el cálculo. El Coordinador de adaptación utiliza el registro para descubrir los procesos de solicitud, y los procesos de solicitud usan este servicio para descubrir entre sí. El registro también ofrece detección de fallas (adicional a la detección de fallas proporcionada por los canales de comunicación). Finalmente, el registro proporciona la posibilidad de enviar señales a los procesos de solicitud. El coordinador utiliza esta funcionalidad para notificar a los procesadores que necesitan para dejar el cálculo. Actualmente, el registro se implementa como un servidor centralizado. Para solicitar nuevos nodos, se utiliza el sistema Zorilla (9), un middleware de supercomputación entre pares que permite una asignación directa de procesadores en múltiples grupos y/o supercomputadoras. Zorilla proporciona la programación de la localidad, que intenta asignar procesadores que se encuentran cerca entre sí en términos de latencia de comunicación. En el futuro, Zorilla también admitirá la programación del ancho de banda, lo que trata de maximizar el ancho de banda total en el sistema. El zorilla se puede reemplazar fácilmente con otro planificador de cuadrícula. En el futuro, estamos planeando integrar nuestro componente de adaptación con GAT (3) que se está convirtiendo en un estándar en la comunidad de la red y koala (15) un programador que proporciona co-asignación sobre el middleware de la red estándar, como el kit de herramientas Globus(11).5. Evaluación del desempeño En esta sección, evaluaremos nuestro enfoque. Demostraremos el rendimiento de nuestro mecanismo en algunos escenarios. El primer escenario es una situación ideal: la aplicación se ejecuta en un conjunto razonable de nodos (es decir, de modo que la eficiencia es de alrededor del 50%) y no se producen problemas como redes y procesadores sobrecargados, procesadores de bloqueo, etc. Este escenario nos permite medir la sobrecarga del soporte de adaptación. Los escenarios restantes son típicos para los entornos de la red y demuestran que con nuestro soporte de adaptación, la aplicación puede evitar cuellos de botella de rendimiento serios, como procesadores sobrecargados o enlaces de red. Para cada escenario, comparamos el rendimiento de una aplicación con soporte de adaptación con una versión no adaptativa. En la versión no adaptativa, el coordinador no recopila estadísticas y no se realiza la evaluación comparativa (para medir velocidades del procesador). En el escenario ideal, 0 5 10 15 Número de iteración 0 200 400 600 iteración Duración (secs.) Comenzando en 8 nodos que comienzan en 16 nodos que comienzan en 24 nodos que comienzan en 8 nodos que comienzan en 16 nodos que comienzan en 24 nodos} sin adaptación} con adaptación con adaptaciónFigura 3. Duraciones de iteración de Barnes-Hut con/sin adaptación, muy pocos procesadores 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (SECS). Sin adaptación con adaptación la carga de la CPU introducida los nodos sobrecargados eliminados comenzó a agregar nodos 36 nodos alcanzados en la Figura 4. Duraciones de iteración de Barnes-Hut con/sin adaptación, CPU sobrecargadas, además, medimos el rendimiento de una aplicación con la recopilación de estadísticas y la evaluación comparativa activada pero sin hacer la adaptación, es decir, sin permitir que cambie el número de nodos. Esto nos permite medir la sobrecarga de la evaluación comparativa y la recolección de estadísticas. En todos los experimentos utilizamos un período de monitoreo de 3 minutos para las versiones adaptativas de las aplicaciones. Todos los experimentos se llevaron a cabo en el sistema de área ancha DAS-2 (8), que consta de cinco grupos ubicados en cinco versidades holandesas UNI125. Uno de los grupos consta de 72 nodos, los otros de 32 nodos. Cada nodo contiene dos procesadores Pentium de 1 GHz. Dentro de un clúster, los nodos están conectados por Fast Ethernet. Los grupos están conectados por la columna vertebral de Internet de la Universidad holandesa. En nuestros experimentos, utilizamos la simulación Barnes-Hut N-Body. Barneshut simula la evolución de un gran conjunto de cuerpos bajo la influencia de las fuerzas (gravitacionales o electrostáticas). La evolución de N organismos se simula en iteraciones de pasos de tiempo discretos.5.1 Escenario 0: Sobre la superación de adaptación En este escenario, la aplicación se inicia en 36 nodos. Los nodos están igualmente divididos en 3 grupos (12 nodos en cada clúster). En este número de nodos, la aplicación se ejecuta con un 50% de eficiencia, por lo que lo consideramos un número razonable de nodos. Como se mencionó anteriormente, en este escenario medimos tres tiempos de ejecución: el tiempo de ejecución de la aplicación sin soporte de adaptación (tiempo de ejecución 1), el tiempo de ejecución con soporte de adaptación (tiempo de ejecución 2) y el tiempo de ejecución con monitoreo (es decir, colección de estadísticas y benchmarking) se enciendepero sin permitir que cambie el número de nodos (tiempo de ejecución 3). Esos tiempos de ejecución se muestran en la Figura 2, primer grupo de barras. La comparación entre el tiempo de ejecución 3 y 1 muestra la sobrecarga del soporte de adaptación. En este experimento es alrededor del 15%. Casi todo lo alto proviene de la evaluación comparativa. El punto de referencia se ejecuta 1-2 veces por período de monitoreo. Esta sobrecarga se puede hacer más pequeña aumentando la longitud del período de monitoreo y disminuyendo la frecuencia de evaluación comparativa. El período de monitoreo que utilizamos (3 minutos) es relativamente corto, porque el tiempo de ejecución de la aplicación también fue relativamente corto (30-60 minutos). El uso de aplicaciones de ejecución más larga no nos permitiría terminar la experimentación en un tiempo razonable. Sin embargo, las aplicaciones de cuadrícula del mundo real generalmente necesitan horas, días o incluso semanas para completar. Para tales aplicaciones, se puede usar un período de monitoreo mucho más largo y la sobrecarga de adaptación puede mantenerse mucho más baja. Por ejemplo, con la aplicación Barnes-Hut, si el período de monitoreo se extiende a 10 minutos, la sobrecarga cae al 6%. Tenga en cuenta que combinar la evaluación comparativa con la carga del procesador de monitoreo (como se describe en la Sección 3.2) reduciría la sobrecarga de evaluación comparativa a casi cero: dado que la carga del procesador no está cambiando, los puntos de referencia solo deberían ejecutarse al comienzo del cálculo.5.2 Escenario 1: Al expandirse a más nodos en este escenario, la aplicación se inicia en menos nodos de los que la aplicación puede usar de manera eficiente. Esto puede suceder porque el usuario no conoce el número correcto de nodos o porque los nodos insuficientes estaban disponibles en el momento en que se inició la aplicación. Probamos 3 números iniciales de nodos: 8 (Escenario 1A), 16 (Escenario 1B) y 24 (Escenario 1C). Los nodos se ubicaron en 1 o 2 grupos. En cada uno de los tres sub-escenarios, la aplicación se expandió gradualmente a 36-40 nodos ubicados en 4 grupos. Esto permitió reducir los tiempos de ejecución de la aplicación en un 50% (escenario 1A), 35% (escenario 1b) y 12% (escenario 1c) con respecto a la versión no adaptativa. Esos tiempos de ejecución se muestran en la Figura 2. Dado que Barnes-Hut es una aplicación iterativa, también medimos el tiempo de cada iteración, como se muestra en la Figura 3. La adaptación reduce el tiempo de iteración en un factor de 3 (escenario 1a), 1.7 (escenario 1b) y 1.2 (escenario 1c) que nos permite concluir que las ganancias en el tiempo de ejecución total serían aún mayores si la aplicación se ejecutara más larga que para15 iteraciones.5.3 Escenario 2: procesadores sobrecargados En este escenario, comenzamos la aplicación en 36 nodos en 3 grupos. Después de 200 segundos, presentamos una carga pesada y artificial en los procesadores en uno de los grupos. Tal situación puede ocurrir cuando se inicia una aplicación con una prioridad más alta en algunos de los recursos. La Figura 4 muestra las duraciones de iteración de las versiones adaptativas y no adaptativas. Después de introducir la carga, la iteración 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (SECS.) Sin adaptación con adaptación Un clúster está mal conectado mal conectado Cluster eliminado Comenzó a agregar nodos 36 nodos alcanzados a la Figura 5. Duraciones de iteración de Barnes-Hut con/sin adaptación, enlace de red sobrecargado 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (Secs.) Sin adaptación con adaptación Un clúster está mal conectado 12 nodos ligeramente sobrecargados eliminados mal connected 2 Lightly 2 Lightly Lightly LightlyNodos sobrecargados Figura 6. Las duraciones de la iteración de Barnes-Hut con/sin adaptación, CPU sobrecargadas y una duración de enlace de red sobrecargada aumentó en un factor de 2 a 3. Además, los tiempos de iteración se volvieron muy variables. La versión adaptativa reaccionó eliminando los nodos sobrecargados. Después de eliminar estos nodos, la eficiencia promedio ponderada aumentó a alrededor del 35%, lo que activó agregar nuevos nodos y la aplicación se expandió a 38 nodos. Entonces, los nodos sobrecargados fueron reemplazados por mejores nodos, lo que llevó la duración de la iteración a los valores iniciales. Esto redujo el tiempo de ejecución total en un 14%. Los tiempos de ejecución se muestran en la Figura 2. 126 5.4 Escenario 3: Enlace de red sobrecargado En este escenario, ejecutamos la aplicación en 36 nodos en 3 clústeres. Simulamos que el enlace ascendente a uno de los grupos estaba sobrecargado y el ancho de banda en este enlace ascendente se redujo a aproximadamente 100 kb/s. Para simular un bajo ancho de banda, utilizamos las técnicas de forma de tráfico descritas en (6). Las duraciones de la iteración en este experimento se muestran en la Figura 5. Las duraciones de iteración de la versión no adaptativa exhiben una enorme variación: de 170 a 890 segundos. La versión adaptativa eliminó el clúster mal conectado después del primer período de monitoreo. Como resultado, la eficiencia promedio ponderada aumentó a alrededor del 35% y los nodos nuevos se agregaron gradualmente hasta que su número alcanzó 38. Esto redujo los tiempos de iteración a alrededor de 100 segundos. El tiempo de ejecución total se redujo en un 60% (Figura 2).5.5 Escenario 4: procesadores sobrecargados y un enlace de red sobrecargado En este escenario, ejecutamos la aplicación en 36 nodos en 3 clústeres. Nuevamente, simulamos un enlace ascendente sobrecargado a uno de los grupos. Además, simulamos procesadores con velocidades heterogéneas insertando una carga artificial relativamente ligera en los procesadores en uno de los grupos restantes. Las duraciones de la iteración se muestran en la Figura 6. Nuevamente, la versión no adaptativa exhibe una gran variación en la duración de la iteración: de 200 a 1150 segundos. La versión adaptativa elimina el clúster mal conectado después del primer período de monitoreo, lo que reduce la duración de la iteración a 210 segundos en promedio. Después de eliminar uno de los grupos, ya que algunos de los procesadores son más lentos (aproximadamente 5 veces), la eficiencia promedio ponderada aumenta solo a alrededor del 40%. Dado que este valor se encuentra entre Emin y Emax, no se agregan ni se eliminan nodos. Este ejemplo ilustra cuáles serían las ventajas de la migración oportunista. Había nodos más rápidos disponibles en el sistema. Si estos nodos se agregaran a la aplicación (que podría activar la eliminación de los nodos más lentos), la duración de la iteración podría reducirse aún más. Aún así, la adaptación redujo el tiempo de ejecución total en un 30% (Figura 2).5.6 Escenario 5: Nodos bloqueados En el último escenario, también ejecutamos la aplicación en 36 nodos en 3 grupos. Después de 500 segundos, 2 de 3 clústeres se bloquean. Las duraciones de la iteración se muestran en la Figura 7. Después del accidente, la duración de la iteración aumentó de 100 a 200 segundos. La eficiencia ponderada aumentó a alrededor del 30%, lo que desencadenó agregar nuevos nodos en la versión adaptativa. El número de nodos volvió gradualmente a 35, lo que llevó la duración de la iteración a alrededor de 100 segundos. El tiempo de ejecución total se redujo en el 13% (Figura 2).6. Trabajo relacionado Varios proyectos de cuadrícula abordan la cuestión de la selección y adaptación de recursos. En Grads (18) y Assist (1), la selección y adaptación de recursos requiere un modelo de rendimiento que permita predecir los tiempos de ejecución de la aplicación. En la fase de selección de recursos, se examinan varios conjuntos de recursos posibles y se selecciona el conjunto de recursos con el tiempo de ejecución predicho más corto. Si se detecta la degradación del rendimiento durante el cálculo, se repite la fase de selección de recursos. Grads utiliza la relación de los tiempos de ejecución predichos (de ciertas fases de aplicación) a los tiempos de ejecución reales como un indicador del rendimiento de la aplicación. Assist utiliza el número de iteraciones por unidad de tiempo (para aplicaciones iterativas) o el número de tareas por unidad de tiempo (para aplicaciones regulares de trabajadores maestros) como indicador de rendimiento. La principal diferencia entre estos enfoques y nuestro enfoque es el uso de modelos de rendimiento. La principal ventaja es que una vez que se conoce el modelo de rendimiento, el sistema puede tomar decisiones de migración más precisas que con nuestro enfoque. Sin embargo, incluso si el rendimiento 0 5 10 15 Número de iteración 0 200 400 600 800 1000 Duración de iteración (SECS.) Sin adaptación con la adaptación 2 de 3 clústeres, el bloqueo comenzó a agregar nodos 36 nodos alcanzados en la Figura 7. Duraciones de iteración de Barnes-Hut con/sin adaptación, se conoce el modelo de CPU de bloqueo, el problema de encontrar un conjunto de recursos óptimo (es decir, el conjunto de recursos con el tiempo de ejecución mínimo) es NP-Complete. Actualmente, tanto los graduados como la asistencia examinan solo un subconjunto de todos los conjuntos de recursos posibles y, por lo tanto, no hay garantía de que el conjunto de recursos resultante sea óptimo. A medida que aumenta el número de recursos de la cuadrícula disponibles, la precisión de este enfoque disminuye, ya que el subconjunto de posibles conjuntos de recursos que se puede examinar en un tiempo razonable se vuelve más pequeño. Otra desventaja de estos sistemas es que la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas o regulares. El cactus (2) y la red de cuadrícula (14) no usan modelos de rendimiento. Sin embargo, estos marcos solo son adecuados para aplicaciones secuenciales (reducción de cuadrícula) o de un solo sitio (cactus). En ese caso, el problema de selección de recursos se reduce a seleccionar la máquina o clúster más rápido. La velocidad del reloj del procesador, la carga promedio y varios procesadores en un clúster (cactus) se utilizan para clasificar los recursos y se selecciona el recurso con el rango más alto. La aplicación se migra si se detecta la degradación del rendimiento o se descubren mejores recursos. Tanto el cactus como la red utilizan el número de iteraciones por unidad de tiempo como indicador de rendimiento. La principal limitación de esta metodología es que es adecuada solo para aplicaciones secuenciales o de un solo sitio. Además, la selección de recursos basada en la velocidad del reloj no siempre es precisa. Finalmente, la detección de degradación del rendimiento es adecuada solo para aplicaciones iterativas y no puede usarse para cálculos irregulares como problemas de búsqueda y optimización. El problema de selección de recursos también fue estudiado por el Proyecto Apple (5). En el contexto de este proyecto, se estudiaron varias aplicaciones y se crearon modelos de rendimiento para estas aplicaciones. Basado en dicho modelo, se crea un agente de programación que utiliza el modelo de rendimiento para seleccionar el mejor conjunto de recursos y el mejor programa de aplicaciones en este conjunto. Los agentes de programación de manzanas se escriben caso por caso y no se pueden reutilizar para otra solicitud. También se desarrollaron dos plantillas reutilizables para clases específicas de aplicaciones, a saber, las aplicaciones maestras (plantilla AMWAT) y barrido de parámetros (plantilla APST). La migración no es compatible con el software de manzanas.127 En (13), se estudia el problema de programar aplicaciones de trabajadores maestros. Los autores asumen procesadores homogéneos (es decir, con la misma velocidad) y no tienen en cuenta los costos de comunicación. Por lo tanto, el problema se reduce a encontrar el número correcto de trabajadores. El enfoque aquí es similar al nuestro en que no se utiliza ningún modelo de rendimiento. En cambio, el sistema intenta deducir los requisitos de aplicación en tiempo de ejecución y ajusta el número de trabajadores para abordar el número ideal.7. Conclusiones y trabajo futuro En este documento, investigamos el problema de la selección y adaptación de recursos en entornos de cuadrícula. Los enfoques existentes de estos problemas generalmente asumen la existencia de un modelo de rendimiento que permite predecir los tiempos de ejecución de la aplicación en varios conjuntos de recursos. Sin embargo, crear modelos de rendimiento es inherentemente difícil y requiere conocimiento sobre la aplicación. Proponemos un enfoque que no requiere un conocimiento profundo sobre la aplicación. Comenzamos la aplicación en un conjunto arbitrario de recursos y monitoreamos su rendimiento. El monitoreo del rendimiento nos permite aprender ciertos requisitos de aplicación, como el número de procesadores que necesitan la aplicación o los requisitos de ancho de banda de aplicaciones. Utilizamos este conocimiento para refinar gradualmente el conjunto de recursos eliminando nodos inadecuados o agregando nuevos nodos si es necesario. Este enfoque no da como resultado el conjunto de recursos óptimo, sino en un conjunto de recursos razonable, es decir, un conjunto libre de varios cuellos de botella de rendimiento, como conexiones de red lentas o procesadores sobrecargados. Nuestro enfoque también permite que la aplicación se adapte a las condiciones cambiantes de la red. Las decisiones de adaptación se basan en la eficiencia promedio ponderada: una extensión del concepto de eficiencia paralela definida para máquinas paralelas homogéneas tradicionales. Si la eficiencia promedio ponderada cae por debajo de un cierto nivel, el coordinador de adaptación comienza a eliminar los peores nodos. La maldad de los nodos se define por una fórmula heurística. Si la eficiencia promedio ponderada aumenta por encima de un cierto nivel, se agregan nuevos nodos. Nuestra estrategia de adaptación simple nos permite manejar múltiples escenarios típicos de entornos de cuadrícula: expandirse a más nodos o encoger a menos nodos si la aplicación se inició en una cantidad inapropiada de procesadores, elimine los nodos inadecuados y los reemplace con mejores, reemplace procesadores bloqueados,etc. La aplicación se adapta completamente automáticamente a las condiciones cambiantes. Implementamos nuestro enfoque en el marco de división y conquista satinada y lo evaluamos en la supercomputadora distribuida DAS-2 y demostramos que nuestro enfoque puede producir mejoras de rendimiento significativas (hasta el 60% en nuestros experimentos). El trabajo futuro implicará extender nuestra estrategia de adaptación para apoyar la migración oportunista. Esto, sin embargo, requiere programadores de cuadrícula con una funcionalidad más sofisticada de lo que existe actualmente. También se necesita más investigación para disminuir la sobrecarga de evaluación comparativa. Por ejemplo, la información sobre la carga de la CPU podría usarse para disminuir la frecuencia de evaluación comparativa. Otra línea de investigación que deseamos investigar es utilizar el control de retroalimentación para refinar la estrategia de adaptación durante la ejecución de la aplicación. Por ejemplo, la fórmula de la mala gala de nodos podría refinarse en el tiempo de ejecución en función de la efectividad de las decisiones de adaptación anteriores. Finalmente, la implementación centralizada del coordinador de adaptación podría convertirse en un cuello de botella para aplicaciones que se ejecutan en grandes cantidades de nodos (cientos o miles). Este problema se puede resolver implementando una jerarquía de coordinadores: un subcoordinador por grupo que recopila y procesa estadísticas de su grupo y un coordinador principal que recopila la información de los sub-coordinadores. Agradecimientos Este trabajo se llevó a cabo en el contexto del Laboratorio Virtual para el Proyecto E-Science (ww.vl-e.nl). Este proyecto cuenta con el apoyo de una subvención BSIK del Ministerio de Educación, Cultura y Ciencias holandeses (OC&W) y es parte del Programa de Innovación de TIC del Ministerio de Asuntos Económicos (EZ). Referencias [1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola, M. Danelutto y C. Zoccolo. Gestión de adaptividad de programa/componente paralelo. En Parco 2005, septiembre de 2005. [2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu, T. Radke, E. Seidel y J. Shalf. El gusano Cactus: experimentos con descubrimiento de recursos y asignación en un entorno de cuadrícula. Intl Journal of High Performance Computing Applications, 15 (4): 345-358, 2001. [3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale, T. Kielmann, A. Merzky, J.Nabrzyski, J. Pukacki, T. Radke, M. Russell, E. Seidel, J. Shalf e I. Taylor. Habilitando aplicaciones en la cuadrícula: una descripción general de GridLab. Intl Journal of High-Performance Computing Applications, 17 (4): 449-466, agosto de 2003. [4] J. E. Baldeschwieler, R. D. Blumafe y E. A. Atlas: una infraestructura para la informática global. En el 7º Taller Europeo de Sigops Sigops sobre soporte del sistema para aplicaciones mundiales, páginas 165-172, septiembre de 1996. [5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail, M. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf, G. Shao, S. Smallen, N. Spring, A. Su y D. Zagorodnov. Computación adaptativa en la cuadrícula usando manzanas. IEEE Trans.en sistemas paralelos y distribuidos, 14 (4): 369-382, abril de 2003. [6] D.-M.Chiu, M. Kadansky, J. Provino y J. Wesley. Experiencias en la programación de un shaper de tráfico. En 5to IEEE Symp.En computadoras y comunicaciones, páginas 470-476, 2000. [7] W. Chrabakh y R. Wolski. Gridsat: un solucionador SAT distribuido a base de paja para la cuadrícula. En la Conferencia ACM/IEEE de 2003 sobre Supercomputación, página 37, 2003. [8] La supercomputadora ASCI distribuida (DAS).http://www.cs.vu.nl/das2/.[9] N. Drost, R. V. Van Nieuwport y H. E. Bal. CO-asignación de localidad simple en supercomputación entre pares. En el 6to Taller INTL sobre Computación Global Peer-2-Peer, mayo de 2005. [10] D. L. Eazing, J. Zahorjan y E. D. Lazowska. Aceleración versus eficiencia en sistemas paralelos. Transacciones IEEE en computadoras, 38 (3): 408-423, marzo de 1989. [11] I. Globus Toolkit Versión 4: Software para sistemas orientados al servicio. En la Conferencia Internacional de IFIP sobre red y computación paralela, páginas 2-13. Springer-Verlag LNCS 3779, 2005. [12] J.-P.Goux, S. Kulkarni, M. Yoder y J. Linderoth. Un marco habilitador para aplicaciones de trabajadores maestros en la cuadrícula computacional. En el noveno IEEE INTL Symp.En computación distribuida de alto rendimiento, páginas 43-50, agosto de 2000. [13] E. Heymann, M. A. Senar, E. Luque y M. Livny. Programación adaptativa para aplicaciones de trabajadores maestros en la red computacional. En el primer taller internacional IEEE/ACM sobre computación en la red, páginas 214-227. Springer Verlag Lncs 1971, 2000. 128 [14] E. Huedo, R. S. Montero e I. M. Llorente. Un marco para la ejecución adaptativa en cuadrículas. Software - Práctica y experiencia, 34 (7): 631-651, 2004. [15] H. H. Mohamed y D. H. Epema. Experiencias con el programador de co-asignación de Koala en multiclusters. En 5º IEEE/ACM INTL Symp.En Cluster Computing y The Grid, páginas 640-650, mayo de 2005. [16] A. Plaat, H. E. Bal y R. F. H. Hofman. Sensibilidad de aplicaciones paralelas a grandes diferencias en el ancho de banda y la latencia en las interconexiones de dos capas. Sobre la arquitectura informática de alto rendimiento, páginas 244-253, enero de 1999. [17] J. W. Romein, H. E. Bal, J. Schaeffer y A. Plaat. Un análisis de rendimiento de la programación de trabajo impulsada por la tabla de transposición en la búsqueda distribuida. IEEE Trans.en Sistemas Paralelos y Distribuidos, 13 (5): 447-459, mayo de 2002. [18] S. S. Vadhiyar y J. J. Dongarra. Auto adaptabilidad en la informática de la cuadrícula. Concurrencia y cálculo: Práctica y experiencia, 17 (2-4): 235-257, 2005. [19] R. V. Van Nieuwpoort, T. Kielmann y H. E. Bal. Equilibrio eficiente de carga para aplicaciones de división y conquista de área amplia. En el octavo ACM Sigplan Symp.Sobre principios y prácticas de programación paralela, páginas 34-43, 2001. [20] R. V. Van Nieuwpoort, J. Maassen, T. Kielmann y H. E. Bal. Satinado: programación de cuadrícula basada en Java simple y eficiente. Computación escalable: Práctica y experiencia, 6 (3): 19-32, septiembre de 2004. [21] R. V. Van Nieuwpoort, J. Maassen, G. Wrzesinska, R. Hofman, C. Jacobs, T. Kielmann y H. E. Bal. IBIS: un entorno de programación de cuadrícula flexible y eficiente basado en Java. Concurrencia y computación: Práctica y experiencia, 17 (78): 1079-1107, 2005. [22] R. Wolski, N. Spring y J. Hayes. El servicio meteorológico de la red: un servicio de pronóstico de rendimiento de recursos distribuido para metacomputación. Journal of Future Generation Computing Systems, 15 (5-6): 757-768, octubre de 1999. [23] G. Wrzesinska, R. V. Van Nieuwport, J. Maassen y H. E. Bal. Tolerancia a fallas, maleabilidad y migración para aplicaciones conquistadoras de divididos en la red. En INTL Paralelo y Simposio de procesamiento distribuido, abril de 2005. 129