Diseño del mecanismo empírico: Métodos, con la aplicación a un escenario de cadena de suministro Yevgeniy Vorobeychik, Christopher Kiekintveld y Michael P. Wellman University of Michigan Informática e Ingeniería Ann Arbor, Mi 48109-2121 USA {Yvorobey, Ckiekint, Wellman} @umich.Resumen EDU Nuestros métodos propuestos emplean técnicas de aprendizaje y búsqueda para estimar las características de los resultados de interés en función de la configuración de los parámetros del mecanismo. Ilustramos nuestro enfoque con una tarea de diseño de una competencia de comercio de cadena de suministro. Los diseñadores adoptaron varios cambios en las reglas para disuadir el comportamiento de adquisición particular, pero las medidas resultaron insuficientes. Nuestro análisis de mecanismo empírico modela la relación entre un parámetro de diseño clave y los resultados, confirmando el comportamiento observado e indicando que no se hubiera podido lograr una configuración de parámetros razonable el efecto deseado. En términos más generales, mostramos que bajo ciertas condiciones, el estimador de la configuración de parámetros de mecanismo óptimo basado en datos empíricos es consistente. Categorías y descriptores de sujetos I.6 [Metodologías de computación]: simulación y modelado;J.4 [Aplicaciones informáticas]: Ciencias sociales y conductuales-economía Algoritmos de términos generales, Economía, Diseño 1. Motivación. Ilustramos nuestro problema con una anécdota de un ejercicio de investigación de la cadena de suministro: el juego de la Cadena de Suministros de la Competencia de Agentes Comerciales de 2003 y 2004 (TAC) (SCM). TAC/SCM [1] define un escenario en el que los agentes compitan para maximizar sus ganancias como fabricantes en una cadena de suministro. Los agentes obtienen componentes de los diversos proveedores y ensamblan productos terminados para la venta a los clientes, repetidamente durante un año simulado. Como sucedió, el comportamiento de negociación especificado de los proveedores proporcionó un gran incentivo para que los agentes obtuvieran grandes cantidades de componentes el día 0: el comienzo de la simulación. Durante las primeras rondas de la competencia SCM 2003, varios desarrolladores de agentes descubrieron esto, y el aparente éxito llevó a la mayoría de los agentes a realizar la mayoría de sus compras el día 0. Aunque la adquisición de la adquisición de Day-0 resultó ser un problema estratégico interesante en sí mismo [19], el fenómeno le resta valor a otros problemas interesantes, como adaptar los niveles de producción a la demanda variable (ya que los costos de los componentes ya estaban hundidos) y la gestión dinámica deproducción, ventas e inventario. Varios participantes señalaron que el predominio de la adquisición del día 0 eclipsó otros problemas de investigación clave, como la programación de fábricas [2] y la optimización de ofertas para los pedidos de los clientes [13]. Después del torneo de 2003, hubo un consenso general en la comunidad de TAC de que las reglas deberían cambiarse para disuadir a las grandes adquisiciones de día 0. La tarea que enfrenta los organizadores del juego puede verse como un problema en el diseño del mecanismo. Los diseñadores tienen ciertas características del juego bajo su control y un conjunto de objetivos con respecto a los resultados del juego. A diferencia de la mayoría de los tratamientos académicos del diseño del mecanismo, el objetivo es una característica de comportamiento (adquisición moderada del día 0) en lugar de una característica de asignación como la eficiencia económica, y los mecanismos permitidos están restringidos a aquellos que se consideran solo una modificación incremental del juego actual. Reemplazar los procedimientos de negociación de la cadena de suministro con un mecanismo directo de un solo disparo, por ejemplo, no era una opción. Creemos que tales restricciones operativas y objetivos idiosincráticos son en realidad bastante típicos de la configuración de diseño de mecanismo práctico, donde quizás se caracterizan más comúnmente como problemas de ingeniería de incentivos. En respuesta al problema, los diseñadores de TAC/SCM adoptaron varios cambios de reglas destinados a penalizar grandes órdenes de día 0. Estos incluyeron modificaciones a las políticas de precios de proveedores e introducción de los costos de almacenamiento evaluados en inventarios de componentes y productos terminados. A pesar de los cambios, la adquisición del día 0 fue muy alta en las primeras rondas de la competencia de 2004. En una medida drástica, el Gamemaster impuso un aumento de cinco veces de los costos de almacenamiento a mitad del torneo. Incluso esto no detuvo la marea, y la adquisición del día 0 en las rondas finales en realidad aumentó (por algunas medidas) desde 2003 [9]. La aparente dificultad para identificar las modificaciones de las reglas que afectan la moderación en la adquisición del día 0 es bastante sorprendente. Aunque los diseños se discutieron ampliamente, las predicciones para los efectos de varias propuestas fueron respaldadas principalmente por argumentos intuitivos o, en el mejor de los casos, por cálculos de retroceso. Gran parte de la dificultad, por supuesto, anticipa las respuestas de los agentes (y sus desarrolladores) sin esencialmente ejecutar un ejercicio de juego para este propósito. El episodio nos hizo considerar si los nuevos proaches o herramientas AP306 podrían permitir un análisis más sistemático de las opciones de diseño. Los métodos estándar de diseño teórico y de mecanismo del juego son claramente relevantes, aunque la falta de una descripción analítica del juego parece ser un impedimento. Bajo el supuesto de que el simulador en sí es la única fuente confiable de cálculo de resultados, nos referimos a nuestra tarea como diseño de mecanismo empírico. En la secuela, desarrollamos algunos métodos generales para el diseño del mecanismo empírico y los aplicamos al problema de rediseño TAC/SCM. Nuestro análisis se centra en la configuración de los costos de almacenamiento (tomando otras modificaciones del juego como fijas), ya que este es el elemento disuasorio más directo para las adquisiciones tempranas adoptadas. Nuestros resultados confirman la intuición básica de que los incentivos para la disminución de la compra del día 0 a medida que aumentan los costos de almacenamiento. También confirmamos que la adquisición alta del día 0 observada en el torneo de 2004 es una respuesta racional al establecimiento de los costos de almacenamiento utilizados. Finalmente, concluimos de nuestros datos que es muy poco probable que cualquier configuración razonable de los costos de almacenamiento resulte en niveles aceptables de adquisición del día 0, por lo que se habría requerido un enfoque de diseño diferente para eliminar este problema. En general, contribuimos con un marco formal y un conjunto de métodos para abordar problemas de diseño de mecanismo indirecto en la configuración donde solo hay disponible una descripción de la caja negra de los utilidades de los jugadores. Nuestros métodos incorporan la estimación de conjuntos de equilibrios NASH y equilibrios de NASH de muestra, utilizados en conjunción para respaldar afirmaciones generales sobre la estructura de la utilidad de los diseñadores de mecanismos, así como un análisis probabilístico restringido para evaluar la probabilidad de conclusiones. Creemos que los problemas más realistas son demasiado complejos para ser susceptibles al análisis exacto. En consecuencia, abogamos por el enfoque de reunir evidencia para proporcionar apoyo indirecto de hipótesis específicas.2. Preliminarios Un juego de forma normal2 se denota por [i, {ri}, {ui (r)}], donde me refiere al conjunto de jugadores y m = | i |es el número de jugadores. RI es el conjunto de estrategias disponibles para el jugador I ∈ I, con R = R1 ×... × RM que representa el conjunto de estrategias conjuntas de todos los jugadores. Designamos el conjunto de estrategias puras disponibles para el jugador I por IA, y denotamos el conjunto conjunto de estrategias puras de todos los jugadores por A = A1 ×... × AM. A menudo es conveniente referirse a una estrategia del jugador que estoy por separado de la de los jugadores restantes. Para acomodar esto, usamos A - I para denotar la estrategia conjunta de todos los jugadores que no sean el jugador i. Sea Si el conjunto de todas las distribuciones de probabilidad (mezclas) sobre IA y, de manera similar, es el conjunto de todas las distribuciones sobre A. Un s ∈ S se llama perfil de estrategia mixta. Cuando el juego es finito (es decir, A e I son finitos), la probabilidad de que A ∈ A se juegue bajo S (A) = S (Ai, A - I). Cuando la distribución no está correlacionada, simplemente podemos decir SI (AI) al referirnos al jugador de probabilidad que toca AI bajo s.A continuación, definimos la función de pago (utilidad) de cada jugador I por ui: a1 × · · · × am → r, donde ui (ai, a - i) indica la recompensa al jugador I para jugar a la estrategia pura cuando el restoLos jugadores juegan A - I. Podemos extender esta definición a las estrategias mixtas suponiendo que UI son von Neumann-Morgenstern (VNM) Utilidades de la siguiente manera: UI (S) = ES [UI], donde ES es la expectativa tomada con respecto a la distribución de probabilidad de juego inducida porLos jugadores mezclan estrategias s.2 Al emplear la forma normal, modelamos a los agentes como una sola acción, con decisiones tomadas simultáneamente. Esto es apropiado para nuestro estudio actual, que trata las estrategias (programas de agentes) como acciones atómicas. Podríamos capturar decisiones de grano más fino sobre la acción a lo largo del tiempo en la forma extensa. Aunque cualquier juego extenso puede ser refundido en forma normal, hacerlo puede sacrificar la compacidad y difuminar las distinciones relevantes (por ejemplo, la perfección subjama). Ocasionalmente, escribimos UI (x, y) para significar que x ∈ Ai o Si e Y ∈ A - I o S - I dependiendo del contexto. También expresamos el conjunto de funciones de utilidad de todos los jugadores como u (·) = {u1 (·) ,..., um (·)}. Definimos una función: R → R, interpretada como el máximo beneficio que cualquier jugador puede obtener al desviarse de su estrategia en el perfil especificado.(r) = max i∈I max ai∈Ai [ui (ai, r - i) - ui (r)], (1) donde r pertenece a algún conjunto de estrategias, r, de estrategias puras o mixtas. Ante un juego, un agente idealmente jugaría su mejor estrategia dada las que juegan los otros agentes. Una configuración en la que todos los agentes juegan estrategias que son las mejores respuestas a las demás constituye un equilibrio de Nash. Definición 1. Un perfil de estrategia r = (r1, ..., rm) constituye un equilibrio NASH de juego [i, {ri}, {ui (r)}] si por cada i ∈ I, ri ∈ Ri, ui (ri, r, r−i) ≥ ui (ri, r - i). Cuando r ∈ A, lo anterior define una estrategia pura Nash Equilibrio;De lo contrario, la definición describe un equilibrio de estrategia mixta Nash. A menudo apelamos al concepto de un equilibrio aproximado o -nash, donde es el beneficio máximo para cualquier agente para desviarse de la estrategia prescrita. Por lo tanto, (r) como se define anteriormente (1) es tal que el perfil r es un equilibrio de noh iff (r) ≤. En este estudio dedicamos especial atención a los juegos que exhiben simetría con respecto a los pagos, lo que hace que los agentes estratégicamente sean idénticos. Definición 2. Un juego [i, {ri}, {ui (r)}] es simétrico si para todo i, j ∈ I, (a) ri = rj y (b) ui (ri, r - i) = uJ (rj,r - j) cada vez que ri = rj y r - i = r - j 3. El modelo que modelamos las interacciones estratégicas entre el diseñador del mecanismo y sus participantes como un juego de dos etapas. El diseñador se mueve primero seleccionando un valor, θ, de un conjunto de configuraciones de mecanismo permitido, θ. Todos los agentes participantes observan el parámetro del mecanismo θ y se mueven simultáneamente a partir de entonces. Por ejemplo, el diseñador podría estar decidiendo entre un primer precio y los mecanismos de subasta de la chica sellada de primer precio, con la presunción de que después de que se haya tomado la elección, los postores participarán con plena conciencia de las reglas de subasta. Dado que los participantes juegan con pleno conocimiento del parámetro del mecanismo, definimos un juego entre ellos en la segunda etapa como γθ = [i, {ri}, {ui (r, θ)}]. Nos referimos a γθ como un juego inducido por θ. Sea n (θ) el conjunto de perfiles de estrategia considerados soluciones del juego γθ.3 Suponga que el objetivo del diseñador es optimizar el valor de alguna función de bienestar, w (r, θ), dependiente del parámetro de mecanismo y resultantejugar, r.Definimos una medida pesimista, w (ˆr, θ) = inf {w (r, θ): r ∈ ˆr}, representando el peor bienestar del juego inducido por θ, suponiendo que los agentes jueguen una estrategia conjunta en ˆr. Por lo general, nos importa W (n (θ), θ), el peor resultado de la que jugará alguna solución.4 En algunos problemas podemos obtener una ventaja considerable mediante el uso de una función de agregación para asignar el resultado del bienestar de un Juego 3 que generalmente adoptamosEl equilibrio de NASH como concepto de solución, y por lo tanto tomar N (θ) como el conjunto de equilibrios. Sin embargo, gran parte de la metodología desarrollada aquí podría emplearse con criterios alternativos para derivar el comportamiento de los agentes de una definición del juego.4 Nuevamente, las alternativas están disponibles. Por ejemplo, si uno tiene una distribución de probabilidad sobre el conjunto de soluciones N (θ), sería natural tomar la expectativa de W (R, θ) en su lugar.307 especificado en términos de estrategias de agente a un resultado de bienestar equivalente especificado en términos de un resumen de baja dimensión. Definición 3. Una función φ: R1 × · · · × RM → RQ es una función de agregación si M ≥ Q y W (R, θ) = V (φ (R), θ) para alguna función v. Sobrecargamos el símbolo de la función para aplicar a los conjuntos de perfiles de estrategia: φ (ˆr) = {φ (r): r ∈ ˆr}. Para conveniencia de la exposición, escribimos φ ∗ (θ) para medir φ (n (θ)). El uso de una función de agregación produce una representación más compacta de los perfiles de estrategia. Por ejemplo, suponga: AS en nuestra aplicación debajo, que una estrategia de agentes se define por un parámetro numérico. Si todo lo que nos importa es el valor total jugado, podemos tomar φ (a) = pm i = 1 ai. Si hemos elegido nuestro agregador con cuidado, también podemos capturar la estructura no obvia de lo contrario. Por ejemplo, φ ∗ (θ) podría estar disminuyendo en θ, mientras que N (θ) podría tener una estructura más compleja. Dada una descripción de la correspondencia de la solución n (θ) (de manera equivalente, φ ∗ (θ)), el diseñador enfrenta un problema de optimización estándar. Alternativamente, dado un simulador que podría producir una muestra imparcial a partir de la distribución de W (N (θ), θ) para cualquier θ, el diseñador se enfrentaría a otro problema muy apreciado en la literatura: la optimización de la simulación [12]. Sin embargo, incluso para un juego γθ con pagos conocidos, puede ser computacionalmente intratable resolver los equilibrios de Nash, particularmente si el juego tiene conjuntos de estrategias grandes o infinitos. Además, deseamos estudiar juegos donde los pagos no se dan explícitamente, pero deben determinarse a partir de la simulación u otra experiencia con el juego.5 En consecuencia, suponemos que se nos da un conjunto de datos (posiblemente ruidoso) de realizaciones de pago: do = = do = ={(θ1, a1, u1) ,..., (θk, AK, Reino Unido)}, donde para cada punto de datos θi es la configuración de parámetros del mecanismo observado, la IA es el perfil de estrategia pura observado de los participantes y la interfaz de usuario es la realización correspondiente de los pagos del agente. También podemos tener datos adicionales generados por un simulador (posiblemente ruidoso): ds = {(θk+1, AK+1, Reino Unido+1) ,..., (θk+L, Ak+L, Reino Unido+L)}. Sea d = {do, ds} el conjunto de datos combinado.(O DO o DS pueden ser nulos para un problema particular). En el resto de este documento, aplicamos nuestro enfoque de modelado, junto con varios métodos teóricos empíricos del juego, para responder preguntas sobre el diseño del escenario TAC/SCM.4. Análisis de diseño empírico Dado que nuestros datos vienen en forma de experiencia de pago y no como el valor de una función objetivo para la configuración dada de la variable de control, ya no podemos confiar en los métodos para optimizar las funciones utilizando simulaciones. De hecho, un aspecto fundamental de nuestro problema de diseño implica estimar la correspondencia de equilibrio de Nash. Además, no podemos confiar directamente en los resultados de convergencia que abundan en la literatura de optimización de simulación, y debemos establecer métodos de análisis probabilísticos adaptados para nuestra configuración de problemas.4.1 Problema de diseño TAC/SCM Describimos nuestros métodos de análisis de diseño empírico presentando una aplicación detallada al escenario TAC/SCM introducido anteriormente. Recuerde que durante el torneo de 2004, los diseñadores del juego SupplyChain decidieron aumentar drásticamente los costos de almacenamiento como una medida destinada a frenar la adquisición del día 0, a poco en vano. Aquí exploramos sistemáticamente la relación entre los costos de almacenamiento y 5 Este es a menudo el caso de los juegos reales de interés, donde el lenguaje natural o las descripciones algorítmicas pueden sustituir una especificación formal de la estrategia y las funciones de pago.La cantidad agregada de componentes adquiridos el día 0 en equilibrio. Al hacerlo, consideramos varias preguntas planteadas durante y después del torneo. Primero, ¿el aumento de los costos de almacenamiento en realidad reduce la adquisición de día 0? En segundo lugar, ¿fue la adquisición excesiva del día 0 que se observó durante el torneo racional de 2004? Y tercero, ¿podrían aumentar los costos de almacenamiento suficientemente haber reducido la adquisición de día 0 a un nivel aceptable, y de ser así, ¿cuál debería haber sido la configuración de los costos de almacenamiento? Es esta tercera pregunta la que define el aspecto del diseño del mecanismo de nuestro análisis.6 Para aplicar nuestros métodos, debemos especificar los conjuntos de estrategias de agentes, la función de bienestar de los diseñadores, el espacio de los parámetros del mecanismo y la fuente de datos. Restringimos que las estrategias del agente sean un multiplicador en la cantidad de las solicitudes del día 0 de uno de los finalistas, el maíz profundo, en el torneo TAC/SCM 2004. Además, lo restringimos al conjunto [0,1.5], ya que cualquier estrategia por debajo de 0 es ilegal y las estrategias superiores a 1.5 son extremadamente agresivas (por lo tanto, es poco probable que proporcione desviaciones de refutación más allá de las disponibles de las estrategias incluidas, y ciertamente no parte de ningún equilibrio deseable). Todo otro comportamiento se basa en el comportamiento del maíz profundo y es idéntico para todos los agentes. Esta elección solo puede proporcionar una estimación del comportamiento real del torneo de un agente típico. Sin embargo, creemos que la forma general de los resultados debería ser robusta a los cambios en el comportamiento del agente completo. Modelamos la función de bienestar de los diseñadores como un umbral en la suma de las compras del día 0. Sea φ (a) = p6 i = 1 ai la función de agregación que representa la suma de la adquisición del día 0 de los seis agentes que participan en un juego de cadena de suministro particular (para perfiles de estrategia mixta, esperamos φ con respecto ala mezcla). La función de bienestar de los diseñadores w (n (θ), θ) es dada por I {sup {φ ∗ (θ)} ≤ α}, donde α es el nivel máximo aceptable de la adquisición del día 0 e I es la función indicadora. El diseñador selecciona un valor θ de los costos de almacenamiento, expresado como un porcentaje anual del valor de referencia de los componentes en el inventario (cargado diariamente), del conjunto θ = R+. Dado que la decisión de los diseñadores depende solo de φ ∗ (θ), presentamos todos nuestros resultados en términos del valor de la función de agregación.4.2 Estimación del equilibrio de NASH El objetivo de los agentes TAC/SCM es maximizar las ganancias realizadas en una instancia del juego. Por lo tanto, si fijamos una estrategia para cada agente al comienzo de la simulación y registramos las ganancias correspondientes al final, habremos obtenido un punto de datos en la forma (a, u (a)). Si también hemos arreglado el parámetro θ del simulador, el punto de datos resultante se convierte en parte de nuestro conjunto de datos D. Este conjunto de datos, entonces, contiene datos solo en forma de estrategias puras de los jugadores y sus pagos correspondientes y, en consecuencia,Para formular el problema de los diseñadores como optimización, primero debemos determinar o aproximar el conjunto de equilibrios NASH de cada juego γθ. Por lo tanto, necesitamos métodos para aproximar los equilibrios de Nash para juegos infinitos. A continuación, describimos los dos métodos que utilizamos en nuestro estudio. El primero se ha explorado empíricamente antes, mientras que el segundo se introduce aquí como el método diseñado específicamente para aproximar un conjunto de equilibrios NASH.4.2.1 Aproximación de la función de pago El primer método para estimar los equilibrios de NASH basados en datos utiliza el aprendizaje supervisado para aproximar las funciones de pago de MECH6 No abordamos si otras medidas (por ejemplo, restringir la adquisición directamente) podrían haber logrado objetivos de diseño. Nuestro enfoque se toma como un conjunto de opciones de diseño, en este caso definido por el parámetro de costo de almacenamiento. En principio, nuestros métodos podrían aplicarse a un espacio de diseño diferente o más grande, aunque con el crecimiento de la complejidad correspondiente.308 participantes de anismo de un conjunto de datos de experiencia en el juego [17]. Una vez que las funciones de pago aproximadas están disponibles para todos los jugadores, los equilibrios NASH pueden encontrarse analíticamente o aproximarse utilizando técnicas numéricas, dependiendo del modelo de aprendizaje. En lo que sigue, estimamos solo un equilibrio de NASH de muestra utilizando esta técnica, aunque esta restricción se puede eliminar a expensas del tiempo de cálculo adicional. Una ventaja de este método es que se puede aplicar a cualquier conjunto de datos y no requiere el uso de un simulador. Por lo tanto, podemos aplicarlo cuando ds = ∅. Si hay un simulador disponible, podemos generar datos adicionales para generar confianza en nuestras estimaciones iniciales.7 Intentamos los siguientes métodos para aproximar las funciones de pago: regresión cuadrática (QR), promedio ponderado localmente (LWA) y regresión lineal ponderada localmente (LWLR). También utilizamos variaciones de control para reducir la varianza de las estimaciones de pago, como en nuestro análisis teórico de juego empírico anterior de TAC/SCM-03 [19]. El modelo de regresión cuadrática permite calcular los equilibrios del juego aprendido analíticamente. Para los otros métodos, aplicamos la dinámica de replicador [7] a una aproximación discreta del juego aprendido. La adquisición total esperada del día 0 en equilibrio se tomó como la estimación de un resultado.4.2.2 Búsqueda en el espacio de perfil de estrategia Cuando tenemos acceso a un simulador, también podemos usar la búsqueda dirigida a través del espacio de perfil para estimar el conjunto de equilibrios NASH, que describimos aquí después de presentar alguna notación adicional. Definición 4. Un vecino estratégico de un perfil de estrategia puro es un perfil que es idéntico a una estrategia en toda la estrategia. Definimos SNB (a, d) como el conjunto de todos los vecinos estratégicos de un disponible en el conjunto de datos D. De manera similar, definimos SNB (a, ˜d) como todos vecinos estratégicos de un no en D. Finalmente, para cualquieraa ∈ Snb (a, d) Definimos el agente desviado como yo (a, a). Definición 5. El -bound, ˆ, de un perfil de estrategia puro a se define como maxa ∈Snb (a, d) max {ui (a, a) (a) −ui (a, a) (a), 0}. Decimos que A es un equilibrio δ candidato para δ ≥ ˆ. Cuando SNB (a, ˜d) = ∅ (es decir, todos los vecinos estratégicos están representados en los datos), A se confirma como un equilibrio de la red. Nuestro método de búsqueda funciona explorando las desviaciones de los equilibrios candidatos. Nos referimos a ello como BestIrstSearch, ya que selecciona con probabilidad uno de un perfil de estrategia a ∈ Snb (a, ˜d) que tiene el más pequeño D. Finalmente definimos un estimador para un conjunto de equilibrios Nash. Definición 6. Para un conjunto k, define Co (k) como el casco convexo de K. Sea Bδ el conjunto de candidatos en el nivel δ. Definimos ˆφ ∗ (θ) = Co ({φ (a): a ∈ Bδ}) para que un δ fijo sea un estimador de φ ∗ (θ). En palabras, la estimación de un conjunto de resultados de equilibrio es el casco convexo de todos los perfiles de estrategia agregados con -bound debajo de algunos δ fijos. Esta definición nos permite explotar la estructura que surge de la función de agregación. Si dos perfiles están cercanos en términos de valores de agregación, es probable que tengan fusiones similares. En particular, si uno es un equilibrio, el otro también puede ser. Presentamos cierto apoyo teórico para este método para estimar el conjunto de equilibrios NASH a continuación. Dado que el juego que nos interesa es infinito, es necesario terminar BestIrstSearch antes de explorar todo el espacio de Strat7, por ejemplo, podemos usar técnicas de aprendizaje activas [5] para mejorar la calidad de la aproximación de la función de pago. En este trabajo, en su lugar nos concentramos en la búsqueda en el espacio de perfil de estrategia.Perfiles de Egy. Actualmente determinamos el tiempo de terminación de una manera algo ad-hoc, basada en observaciones sobre el conjunto actual de equilibrios candidatos.8 4.3 Generación de datos Nuestros datos se recopilaron simulando juegos TAC/SCM en una versión local del servidor TAC/SCM 2004,que tiene una configuración de configuración para el costo de almacenamiento. Las estrategias de agente en juegos simulados se seleccionaron del conjunto {0, 0.3, 0.6 ,..., 1.5} Para tener una probabilidad positiva de generar vecinos estratégicos.9 Se generó un conjunto de datos de línea de base al muestreo 10 perfiles de estrategia generados aleatoriamente para cada θ ∈ {0, 50, 100, 150, 200}. Entre 5 y 10 juegos se ejecutaron para cada perfil después de descartar juegos que tenían varias fallas.10 Utilizamos la búsqueda para generar un conjunto de datos simulado DS, realizando entre 12 y 32 iteraciones de BestFirstSearch para cada una de las configuraciones anteriores de θ. Dado que el costo de simulación es extremadamente alto (un juego tarda casi 1 hora en correr), pudimos ejecutar un total de 2670 juegos en el lapso de más de seis meses. A modo de comparación, obtener la descripción completa de un juego empírico definido por el espacio de estrategia conjunta finita restringida para cada valor de θ ∈ {0, 50, 100, 150, 200} habría requerido al menos 23100 juegos (muestreando cada perfil 10 veces 10 veces).4.4 Resultados 4.4.1 Análisis del conjunto de datos de línea de base Aplicamos los tres métodos de aprendizaje descritos anteriormente al conjunto de datos de línea de base Do. Además, generamos una estimación de la correspondencia de equilibrio de Nash, ˆφ ∗ (θ), aplicando la definición 6 con δ = 2.5E6. Los resultados se muestran en la Figura 1. Como podemos ver, la correspondencia ˆφ ∗ (θ) tiene poco poder predictivo basado en DO, y no revela una estructura interesante sobre el juego. Por el contrario, los tres métodos de aprendizaje sugieren que la adquisición total del día 0 es una función decreciente de los costos de almacenamiento.0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 Costo de almacenamiento Totalday-0 Procurement LWA LWLR QR Baselinemin Baselinemax Figura 1: Estimaciones de adquisiciones de día-0 agregadas basadas en Do. La correspondencia ˆφ ∗ (θ) es el intervalo entre Baselinemin y Baselinemax.8 En general, la búsqueda termina una vez que el conjunto de equilibrios candidatos es lo suficientemente pequeño como para sacar conclusiones útiles sobre el rango probable de estrategias de equilibrio en el juego.9 Por supuesto, no restringimos nuestras estimaciones de equilibrio de Nash para permanecer en este subconjunto discreto de [0,1.5].10 Por ejemplo, si detectamos que algún agente falló durante el juego (las fallas incluyeron bloqueos, problemas de conectividad de red y otras anomalías obvias), el juego se expulsaría.309 4.4.2 Análisis de datos de búsqueda para corroborar la evidencia inicial de los métodos de aprendizaje, estimamos ˆφ ∗ (θ) (nuevamente, usando Δ = 2.5e6) en el conjunto de datos d = {do, ds}, donde ds es datosGenerado a través de la aplicación de BestFirstSearch. Los resultados de esta estimación se trazan contra los resultados de los métodos de aprendizaje entrenados en DO 11 en la Figura 2. Primero, observamos que la adición de los datos de búsqueda reduce el rango de equilibrios potenciales sustancialmente. Además, las predicciones puntuales reales de los métodos de aprendizaje y las basadas en los fondos después de la búsqueda son razonablemente cercanos. La combinación de la evidencia reunida de estos dos enfoques muy diferentes para estimar la correspondencia de resultados produce una imagen mucho más convincente de la relación entre los costos de almacenamiento y la adquisición del día 0 que cualquier método utilizado de forma aislada.0 1 2 3 4 5 6 7 8 9 10 0 50 100 150 200 200 Costo de almacenamiento TOTAYDAY-0PROCURIMENTO LWA LWLR QR Searchmin Searchmax Figura 2: Estimaciones de adquisición de día-0 agregadas basadas en la búsqueda en el espacio de perfil de estrategia en comparación con las técnicas de aproximación de función capacitadas. La correspondencia ˆφ ∗ (θ) para d = {do, ds} es el intervalo entre Searchmin y Searchmax. Esta evidencia respalda la intuición inicial que la adquisición del día 0 debería ser disminuir con los costos de almacenamiento. También confirma que los altos niveles de adquisición del día 0 son una respuesta racional a la configuración del torneo 2004 del costo de almacenamiento promedio, que corresponde a θ = 100. La predicción mínima para la adquisición agregada a este nivel de costos de almacenamiento dados por cualquier método experimental es de aproximadamente 3. Esto es bastante alto, ya que corresponde a un compromiso esperado de 1/3 de la capacidad total del proveedor para todo el juego. La predicción máxima es considerablemente mayor en 4.5. En la competencia real de 2004, la adquisición agregada del día 0 fue equivalente a 5.71 en la escala utilizada aquí [9]. Nuestras predicciones subestiman este resultado hasta cierto punto, pero demuestran que cualquier resultado racional probablemente tuviera una alta adquisición del día 0.4.4.3 Extrapolar la correspondencia de la solución Tenemos evidencia razonablemente fuerte de que la correspondencia de resultado está disminuyendo. Sin embargo, el objetivo final es poder establecer el parámetro de costo de almacenamiento en un valor que frenaría la adquisición de día 0 en equilibrio o concluir que esto no es posible. Para responder a esta pregunta directamente, supongamos que establecemos un umbral conservador α = 2 en la adquisición agregada del día-0.12 lineal 11 No está claro cuán significativos serían los resultados del aprendizaje si se agregaran DS al conjunto de datos de entrenamiento. De hecho, los datos adicionales en realidad pueden aumentar la varianza de aprendizaje.12 Recuerde que el objetivo de los diseñadores es incentivar la adquisición de Aggergate Day-0 que está por debajo del umbral α. Nuestro umbral aquí todavía representa un compromiso de más del 20% de la capacidad de los proveedores para la extrapolación del máximo de la correspondencia de resultado estimada a partir de los rendimientos D θ = 320. Los datos para θ = 320 se recopilaron de la misma manera que para otras configuraciones de costos de almacenamiento, con 10 perfiles generados aleatoriamente seguidos de 33 iteraciones de Best FirstSearch. La Figura 3 muestra los bounds detallados para todos los perfiles en términos de sus valores correspondientes de φ.0.00E+00 5.00E+06 1.00E+07 1.50E+07 2.00E+07 2.50E+07 3.00E+07 3.50E+07 4.00E+07 4.50E+07 5.00E+07 2.1 2.4 2.7 3 3.3 3.63.9 4.2 4.5 4.8 5.1 5.4 5.7 6 6.3 6.6 6.9 7.2 Total Día-0 Adquisición ε-Figura 3: Valores de ˆ para perfiles explorados usando búsqueda cuando θ = 320. Los perfiles de estrategia explorados se presentan en términos de los valores correspondientes de φ (a). La región gris corresponde a ˆφ ∗ (320) con δ = 2.5m. El conjunto estimado de resultados agregados del Día-0 es muy cercano a θ = 200, lo que indica que hay poco beneficio adicional para aumentar los costos de almacenamiento por encima de 200. Observe que incluso el límite inferior de nuestro conjunto estimado de equilibrios Nash está muy por encima de la adquisición objetivo de 2 de 2. Además, los pagos a los agentes casi siempre son negativos en θ = 320. En consecuencia, aumentar aún más los costos sería indeseable incluso si la adquisición del día 0 pudiera ser frenada. Dado que estamos razonablemente seguros de que φ ∗ (θ) está disminuyendo en θ, tampoco esperamos que la configuración θ en algún lugar entre 200 y 320 alcance el resultado deseado. Llegamos a la conclusión de que es poco probable que la adquisición de día 0 pueda reducirse a un nivel deseable utilizando cualquier configuración razonable del parámetro de costo de almacenamiento. Que nuestras predicciones tienden a subestimar los resultados del torneo refuerzan esta conclusión. Para lograr la reducción deseada en la adquisición del día 0 requiere rediseñar otros aspectos del mecanismo.4.5 Análisis probabilístico Nuestro análisis empírico ha producido evidencia en apoyo de la conclusión de que no es probable que ningún ajuste razonable de costo de almacenamiento frenara suficientemente la adquisición excesiva de día 0 en TAC/SCM 04. Toda esta evidencia ha sido en forma de interpolación simple y extrapolación de estimaciones de la correspondencia de equilibrio de Nash. Estas estimaciones se basan en la simulación de instancias del juego, y están sujetas al ruido de muestreo aportado por los diversos elementos estocásticos del juego. En esta sección, desarrollamos y aplicamos métodos para evaluar la sensibilidad de nuestros cálculos unidos a tales efectos estocásticos. Supongamos que todos los agentes tienen conjuntos de estrategias puras finitas (y pequeñas), A. Por lo tanto, es factible probar toda la matriz de pago del juego. Además, suponga que el ruido es aditivo con cero medio todo el juego en promedio, por lo que en la práctica probablemente quisiéramos que el umbral sea aún más bajo.310 y varianza finita, es decir, ui (a) = ui (a) + ˜ξi (a), donde ui (a) es la recompensa observada a i cuando a se jugó, ui (a) es el pago correspondiente real,y ˜ξi (a) es una variable aleatoria normal de cero cero. Designamos la varianza conocida de ˜ξi (a) por σ2 I (a). Por lo tanto, suponemos que ˜ξi (a) es normal con la distribución n (0, σ2 i (a)). Tomamos que ¯Ui (a) sea la media de la muestra sobre toda la interfaz de usuario (a) en D, y seguimos a Chang y Huang [3] para asumir que tenemos un prior inadecuado sobre los pagos reales UI (a) y el muestreo fue independiente paraTodos yo y a. También confiamos en su resultado de que Ui (a) | ¯ui (a) = ¯ui (a) −zi (a)/ [σi (a)/ p ni (a)] son independientes con distribuciones posteriores n (¯ui(a), σ2 I (a)/ni (a)), donde Ni (a) es el número de muestras tomadas de pagos a I para el perfil puro a, y zi (a) ∼ n (0, 1). Ahora derivamos un límite probabilístico genérico de que un perfil a ∈ A es un equilibrio -nash. Si ui (·) | ¯ui (·) son independientes para todos los i ∈ I y a ∈ A, tenemos el siguiente resultado (desde este punto en omitir el acondicionamiento en ¯Ui (·) para la brevedad): Proposición 1. Pr „max i∈I max b∈Ai ui (b, a - i) - ui (a) ≤« = = y i∈I z r y b∈Ai \ ai pr (ui (b, a - i) ≤ u +)fui (a) (u) du, (2) donde fui (a) (u) es el pdf de n (¯ui (a), σi (a)). Las pruebas de esto y todos los resultados posteriores están en el apéndice. La distribución posterior de la media óptima de las muestras de N, derivada por Chang y Huang [3], es PR (UI (A) ≤ C) = 1 - φ P Ni (A) (¯Ui (A) - C) σi (a) #, (3) donde a ∈ A y φ (·) es la función de distribución n (0, 1). Combinando los resultados (2) y (3), obtenemos un límite de confianza probabilística que (a) ≤ γ para un γ dado. Ahora, consideramos casos de datos incompletos y usamos los resultados que acabamos de obtener para construir un límite superior (restringido a perfiles representados en datos) sobre la distribución de sup {φ ∗ (θ)} e inf {φ ∗ (θ)}(Suponiendo que ambos sean alcanzables): PR {sup {φ ∗ (θ)} ≤ x} ≤d pr {∃a ∈ D: φ (a) ≤ x ∧ a ∈ N (θ)} ≤ x a∈D:φ (a) ≤x pr {a ∈ N (θ)} = x a∈D: φ (a) ≤x pr {(a) = 0}, donde x es un número real y ≤d indica que el límite superiorCuentas solo de estrategias que aparecen en el conjunto de datos D. Dado que los eventos {∃a ∈ D: φ (a) ≤ x ∧ a ∈ N (θ)} y {inf {φ ∗ (θ)} ≤ x} son equivalentes, esto también define un límite superior en la probabilidad de {inf {φ ∗ (θ)} ≤ x}. Los valores así derivados comprenden las Tablas 1 y 2. φ ∗ (θ) θ = 0 θ = 50 θ = 100 <2.7 0.00000098 0 0.146 <3 0.158 0.0511 0.146 <3.9 0.536 0.163 1 <4.5 1 1 1 1 Tabla 1: límites superioresEn la distribución de inf {φ ∗ (θ)} restringida a D para θ ∈ {0, 50, 100} cuando n (θ) es un conjunto de equilibrios Nash.φ ∗ (θ) θ = 150 θ = 200 θ = 320 <2.7 0 0 0.00132 <3 0.0363 0.141 1 <3.9 1 1 1 <4.5 1 1 Tabla 2: límites superiores en la distribución de INF {φ ∗ (θ)} restringido a D para θ ∈ {150, 200, 320} cuando n (θ) es un conjunto de equilibrios NASH. Las tablas 1 y 2 sugieren que la existencia de cualquier equilibrio con φ (a) <2.7 es poco probable para cualquier θ para los que tenemos datos, aunque este juicio, como mencionamos, es solo con respecto a los perfiles que realmente hemos probado. Entonces podemos aceptar esto como otra evidencia de que el diseñador no pudo encontrar una configuración adecuada de θ para lograr sus objetivos, de hecho, ¡el diseñador parece poco probable que logre su objetivo incluso si pudiera persuadir a los participantes para que jueguen un equilibrio deseable! La Tabla 1 también proporciona evidencia adicional de que los agentes en el torneo TAC/SCM 2004 eran racionales para adquirir un gran número de componentes al principio del juego. Si miramos la tercera columna de esta tabla, que corresponde a θ = 100, podemos recopilar que no hay perfil A en nuestros datos con φ (a) <3 es muy probable que se juegue en equilibrio. Los límites anteriores proporcionan alguna evidencia general, pero en última instancia estamos interesados en una evaluación probabilística concreta de nuestra conclusión con respecto a los datos que hemos probado. Particularmente, nos gustaría decir algo sobre lo que sucede para la configuración de θ para la cual no tenemos datos. Para derivar un límite probabilístico aproximado de la probabilidad de que no θ ∈ θ podría haber logrado el objetivo de los diseñadores, que ∪j j = 1θj, sea una partición de θ, y suponga que la función sup {φ ∗ (θ)} satisface los Lipschitzzcondición con Lipschitz constante AJ en cada subconjunto θj.13 Dado que hemos determinado que aumentar el costo de almacenamiento por encima de 320 es indeseable debido a consideraciones secundarias, restringimos la atención a θ = [0, 320]. Ahora definimos que cada subconjunto J es el intervalo entre dos puntos para los cuales hemos producido datos. Por lo tanto, θ = [0, 50] [(50, 100] [(100, 150] [(150, 200] [(200, 320], con J en ejecución entre 1 y 5, correspondiente a los subintervalos anteriores. Denotaremos cada vez cada θj por (AJ, BJ] .14 Entonces, la siguiente proposición nos da un límite superior aproximado15 sobre la probabilidad de que sup {φ ∗ (θ)} ≤ α. Proposición 2. PR {_ θ∈θ Sup {φ (θ)} ≤ α} ≤d 5x J = 1 x y, z∈D: y+z≤cj 0 @ x a: φ (a) = z pr {(a)= 0} 1 a × × 0 @ x a: φ (a) = y pr {(a) = 0} 1 a, donde cj = 2α + aj (bj - aj) y ≤d indica que el límite superior solo explicaPara las estrategias que aparecen en el conjunto de datos D. 13 Una función que satisface la condición de Lipschitz se llama Lipschitz continuo.14 El tratamiento para el intervalo [0,50] es idéntico.15 Es aproximado en cierto sentido que solo tenemos en cuenta las estrategias que están presentes en los datos.311 Debido al hecho de que nuestros límites son aproximados, no podemos usarlos como una evaluación probabilística concluyente. En cambio, tomamos esto como otra evidencia para complementar nuestros hallazgos. Incluso si podemos suponer que una función que aproximamos de los datos es Lipschitz continuo, rara vez conocemos el Lipschitz constante para cualquier subconjunto de θ. Por lo tanto, nos enfrentamos a la tarea de estimarlo a partir de datos. Aquí, probamos tres métodos para hacer esto. El primero simplemente toma la pendiente más alta que la función alcanza dentro de los datos disponibles y utiliza este valor constante para cada subinterval. Esto produce el límite más conservador, y en muchas situaciones es poco probable que sea informativo. Un método alternativo es tomar un límite superior en la pendiente obtenido dentro de cada subintervalo utilizando los datos disponibles. Esto produce un límite superior mucho menos conservador en las probabilidades. Sin embargo, dado que el límite superior real es generalmente mayor para cada subintervalo, el límite probabilístico resultante puede ser engañoso. Un método final que probamos es un compromiso entre los dos anteriores. En lugar de tomar el límite superior conservador en función de los datos en todo el dominio de la función θ, tomamos el promedio de los límites superiores obtenidos en cada θj. El límite en un intervalo se considera el máximo del límite superior para este intervalo y el límite superior promedio para todos los intervalos. Los resultados de evaluar la expresión para Pr {_ θ∈θ sup {φ ∗ (θ)} ≤ α} cuando α = 2 se presentan en la Tabla 3. En términos de nuestras afirmaciones en Maxj AJ AJ Max {AJ, Ave (AJ)} 1 0.00772 0.00791 Tabla 3: Aproximadamente un límite superior en la probabilidad de que alguna configuración de θ ∈ [0, 320] satisfaga el objetivo del diseñador con el objetivo α = 2 [0. Se utilizan diferentes métodos para aproximar el límite superior en la pendiente en cada subinterval. J se utilizan.Este trabajo, la expresión da un límite superior en la probabilidad de que una configuración de θ (es decir, el costo de almacenamiento) en el intervalo [0,320] dará como resultado una adquisición total del día 0 que no es mayor en ningún equilibrio que el objetivo especificado por αy tomado aquí para ser 2. Como habíamos sospechado, el enfoque más conservador para estimar el límite superior en la pendiente, presentado en la primera columna de la tabla, nos proporciona poca información aquí. Sin embargo, los otros dos enfoques de estimación, que se encuentran en las columnas dos y tres de la Tabla 3, sugieren que estamos bastante seguros de que ninguna configuración razonable de θ ∈ [0, 320] habría hecho el trabajo. Dada la tremenda dificultad del problema, este resultado es muy fuerte.16 Aún así, debemos ser muy cautelosos al sacar una conclusión demasiado heroica basada en esta evidencia. Ciertamente, no hemos revisado todos los perfiles, sino solo una pequeña proporción de ellos (infinitesimal, si consideramos todo el dominio continuo de θ y conjuntos de estrategias). Tampoco podemos esperar que obtenga suficiente evidencia para llegar a conclusiones completamente objetivas. En cambio, el enfoque que abogamos aquí es recopilar tanta evidencia como sea factible dadas las limitaciones de recursos, y hacer el juicio más convincente basado en esta evidencia, si es posible.5. Resultados de convergencia En este punto, exploramos de manera abstracta si una elección de parámetros de diseño basada en datos de pago puede ser asintóticamente confiable.16 Dado que no teníamos todas las desviaciones posibles para ningún perfil disponible en los datos, los límites superiores verdaderos pueden ser aún más bajos. Como cuestión de conveniencia, usaremos la notación un, I (a) para referirnos a una función de pago del jugador I basándose en un promedio sobre n i.i.d.Muestras de la distribución de pagos. También suponemos que Un, I (a) son independientes para todos A ∈ A e I ∈ I. Usaremos la notación γn para referirnos al juego [i, r, {ui, n (·)}], mientras que γ denotará el juego subyacente, [i, r, {ui (·)}]. Del mismo modo, definimos que N (R) sea (R) con respecto al juego γn. En esta sección, mostramos que n (s) → (s) A.S.Uniformemente en el espacio de estrategia mixta para cualquier juego finito y, además, que todos los equilibrios de Nash de estrategia mixta en juegos empíricos eventualmente se vuelven arbitrariamente cercanos a algunas estrategias de equilibrio de Nash en el juego subyacente. Utilizamos estos resultados para mostrar que, bajo ciertas condiciones, la elección óptima del parámetro de diseño basado en datos empíricos converge casi seguramente con el óptimo real. Teorema 3. Supongamos que | i |<∞, | a |<∞. Entonces n (s) → (s) a.s.Uniformemente en S. Recuerde que N es un conjunto de todos los equilibrios Nash de γ. Si definimos nn, γ = {s ∈ S: n (s) ≤ γ}, tenemos el siguiente corolario al teorema 3: corolario 4. Para cada γ> 0, hay m tal que ∀n ≥ m, n ⊂ nn, γ a.s. PRUEBA. Dado que (s) = 0 para cada s ∈ N, podemos encontrar m lo suficientemente grande como para pr {supn≥m sups∈N n (s) <γ} = 1. Por el corolario, para cualquier juego con un conjunto finito de estrategias puras y para cualquier> 0, todos los equilibrios de Nash se encuentran en el conjunto de equilibrios empíricos -nash si se han tomado suficientes muestras. Como ahora mostramos, esto proporciona cierta justificación para nuestro uso de un conjunto de perfiles con un no distinto de cero como una estimación del conjunto de equilibrios Nash. Primero, supongamos que concluimos que para una configuración particular de θ, sup {ˆφ ∗ (θ)} ≤ α. Luego, dado que para cualquier fijo> 0, n (θ) ⊂ nn, (θ) cuando n es lo suficientemente grande, sup {φ ∗ (θ)} = sup s∈N (θ) φ (s) ≤ sup s∈Nn, (θ) φ (s) = sup {ˆφ ∗ (θ)} ≤ α para cualquier n.Por lo tanto, dado que definimos la función de bienestar del diseñador como i {sup {φ ∗ (θ)} ≤ α} En nuestro dominio de interés, la elección empírica de θ satisface el objetivo de los diseñadores, maximizando así su función de bienestar. Alternativamente, supongamos que concluimos que inf {ˆφ ∗ (θ)}> α para cada θ en el dominio. Entonces, α <inf {ˆφ ∗ (θ)} = inf S∈Nn, (θ) φ (s) ≤ inf s∈N (θ) φ (s) ≤ ≤ sup s∈N (θ) φ (s)= sup {φ ∗ (θ)}, para cada θ, y podemos concluir que ninguna configuración de θ satisfará el objetivo de los diseñadores. Ahora, mostraremos que cuando el número de muestras es lo suficientemente grande, cada equilibrio de Nash de γn está cerca de algún equilibrio de Nash del juego subyacente. Este resultado nos llevará a considerar la convergencia de optimizadores basados en datos empíricos a la configuración de los parámetros de mecanismo óptimo real. Primero observamos que las funciones (s) son continuas en un juego finito. Lema 5. Sea s un conjunto de estrategias mixtas definidas en un juego finito. Entonces: S → R es continuo.312 Para la exposición que sigue, necesitamos un poco de notación adicional. Primero, Sea (z, d) un espacio métrico, y x, y ⊂ z y defina la distancia de Hausdorff dirigida de x a y para ser h (x, y) = sup x∈X inf y∈Y d (x, y). Observe que u ⊂ x ⇒ h (u, y) ≤ h (x, y). Además, defina BS (x, δ) para que sea una bola abierta en S ⊂ Z con el centro x ∈ S y Radius δ. Ahora, deje que Nn denote todos los equilibrios NASH del juego γn y deje nδ = [x∈N BS (x, δ), es decir, la unión de bolas abiertas de radio δ con centros en equilibrios NASH de γ. Tenga en cuenta que h (nδ, n) = δ. Luego podemos probar el siguiente resultado general. Teorema 6. Supongamos | i |<∞ y | a |<∞. Entonces casi seguramente h (nn, n) converge a 0. Ahora mostraremos que en el caso especial cuando θ y A son finitos y cada γθ tiene un equilibrio NASH único, las estimaciones ˆθ del parámetro de diseñador óptimo convergen a un optimizador real casi seguramente. Sea ˆθ = arg maxθ∈θ W (nn (θ), θ), donde n es el número de veces que cada perfil puro se muestreó en γθ para cada θ, y vamos θ ∗ = arg maxθ∈θ W (n (θ), θ). Teorema 7. Supongamos | n (θ) |= 1 para todos θ ∈ θ y suponga que θ y A son finitos. Sea W (s, θ) continuo en el único S ∗ (θ) ∈ N (θ) para cada θ ∈ θ. Entonces ˆθ es un estimador consistente de θ ∗ si W (n (θ), θ) se define como un supremum, infimum o expectativa sobre el conjunto de equilibrios Nash. De hecho, ˆθ → θ ∗ a.s.en cada uno de estos casos. La deficiencia del resultado anterior es que, dentro de nuestro marco, el diseñador no tiene forma de saber o garantizar que γθ haga, de hecho, tenga equilibrios únicos. Sin embargo, presta alguna justificación teórica para perseguir el diseño de esta manera y, tal vez, servirá como una guía para resultados más generales en el futuro.6. Trabajo relacionado La literatura de diseño del mecanismo en economía ha explorado típicamente la existencia de un mecanismo que implementa una función de elección social en equilibrio [10]. Además, hay una extensa literatura sobre el diseño de subasta óptimo [10], de la cual el trabajo de Roger Myerson [11] es, quizás, el más relevante. En gran parte de este trabajo, los resultados analíticos se presentan con respecto a funciones de utilidad específicas y contabilidad de restricciones como la compatibilidad de incentivos y la racionalidad individual. Varios enfoques relacionados para buscar el mejor mecanismo existen en la literatura de informática. Conitzer y Sandholm [6] desarrollaron un algoritmo de búsqueda cuando todos los parámetros del juego relevantes son de conocimiento común. Cuando se desconocen las funciones de pago de los jugadores, se ha explorado una búsqueda que usa simulaciones como alternativa. Un enfoque en esa dirección, tomado en [4] y [15], es co-evolucionar los parámetros del mecanismo y las estrategias de agentes, utilizando alguna noción de utilidad social y pagos de agentes como criterios de aptitud física. Una alternativa a la coevolución explorada en [16] fue optimizar una función de bienestar bien definida del diseñador utilizando programación genética. En este trabajo, los autores utilizaron una estrategia de aprendizaje común para todos los agentes y definieron el resultado de un juego inducido por un parámetro de mecanismo como resultado del aprendizaje de agentes conjuntos. Más recientemente, Phelps et al.[14] comparó dos mecanismos basados en la utilidad social esperada con la expectativa tomada sobre una distribución empírica de equilibrios en los juegos definidos por estrategias heurísticas, como en [18].7. Conclusión En este trabajo gastamos un esfuerzo considerable en desarrollar tácticas generales para el diseño del mecanismo empírico. Definimos un modelo de interacción gametheorético formal entre el diseñador y los participantes del mecanismo como un juego de dos etapas. También describimos en cierta generalidad los métodos para estimar una función de equilibrio NASH de muestra cuando los datos son extremadamente escasos, o una correspondencia de equilibrio de Nash cuando hay más datos disponibles. Nuestras técnicas están diseñadas específicamente para tratar problemas en los que tanto el espacio de parámetros del mecanismo como los conjuntos de estrategias de agente son infinitos y solo se puede adquirir un conjunto de datos relativamente pequeño. Un problema de diseño difícil en el juego TAC/SCM que la comunidad TAC ha estado ansiosa por abordar nos proporciona una configuración para probar nuestros métodos. Al aplicar el análisis de juegos empíricos al problema en cuestión, somos plenamente conscientes de que nuestros resultados son inherentemente inexactos. Por lo tanto, nos concentramos en recopilar evidencia sobre la estructura de la correspondencia de equilibrio de Nash. Al final, podemos tratar de proporcionar suficiente evidencia para prescribir una configuración de parámetros o sugerir que no es posible una configuración que satisfaga al diseñador. En el caso de TAC/SCM, nuestra evidencia sugiere con bastante fuerza que el costo de almacenamiento no podría haberse ajustado de manera efectiva en el torneo de 2004 para frenar la adquisición excesiva de día 0 sin efectos perjudiciales en la rentabilidad general. El éxito de nuestro análisis en este entorno extremadamente complejo con altos costos de simulación nos hace optimistas de que nuestros métodos pueden proporcionar orientación para tomar decisiones de diseño del mecanismo en otros dominios desafiantes. Los resultados teóricos confirman algunas intuiciones detrás de los métodos de diseño de mecanismo empírico que hemos introducido, y aumenta nuestra confianza de que nuestro marco puede ser efectivo para estimar la mejor opción de parámetros de mecanismo en entornos relativamente generales. Agradecimientos Agradecemos a Terence Kelly, Matthew Rudary y Satinder Singh por sus útiles comentarios sobre borradores anteriores de este trabajo. Este trabajo fue apoyado en parte por NSF Grant IIS-0205435 y el programa de razonamiento estratégico Real DARPA.8. Referencias [1] R. Arunachalam y N. M. Sadeh. La competencia de agentes comerciales de la cadena de suministro. Investigación y aplicaciones de comercio electrónico, 4: 63-81, 2005. [2] M. Benisch, A. Greenwald, V. Naroditskiy y M. Tschantz. Un enfoque de programación estocástica para la programación en TAC SCM. En la Quinta Conferencia ACM sobre Comercio Electrónico, páginas 152-159, Nueva York, 2004. [3] Y.-P.Chang y W.-T.Huang. Intervalos de confianza generalizados para el mayor valor de algunas funciones de parámetros bajo normalidad. Statistica Sinica, 10: 1369-1383, 2000. [4] D. Cliff. Evolución del mecanismo de mercado a través de un espacio continuo de tipos de subastas. En el Congreso sobre Computación Evolutiva, 2002. [5] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Journal of Artificial Intelligence Research, 4: 129-145, 1996. [6] V. Conitzer y T. Sandholm. Un algoritmo para diseñar automáticamente mecanismos deterministas sin pagos. En 313 Tercera Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas de Multi-Agentes, páginas 128-135, 2004. [7] D. Friedman. Juegos evolutivos en economía. Econometrica, 59 (3): 637-666, mayo de 1991. [8] R. Keener. Teoría estadística: una mezcla de temas centrales. Departamento de Estadísticas de la Universidad de Michigan, 2004. [9] C. Kiekintveld, Y. Vorobeychik y M. P. Wellman. Un análisis de la competencia de agentes comerciales de gestión de la cadena de suministro de 2004. En el taller IJCAI-05 sobre el diseño y el análisis del agente comercial, Edimburgo, 2005. [10] A. Mas-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [11] R. B. Myerson. Diseño de subasta óptimo. Matemáticas de la investigación de operaciones, 6 (1): 58-73, febrero de 1981. [12] S. Olafsson y J. Kim. Optimización de simulación. En E. Yucesano, C.-H.Chen, J. Snowdon y J. Charnes, editores, 2002 Winter Simulation Conference, 2002. [13] D. Pardoe y P. Stone. TACTEX-03: Un agente de gestión de la cadena de suministro. Exchanges de Sigecom, 4 (3): 19-28, 2004. [14] S. Phelps, S. Parsons y P. McBurney. Agentes automatizados versus humanos virtuales: una comparación teórica evolutiva del juego de dos diseños de mercado de doble subasta. En Taller sobre el Comercio Electrónico Mediado por el Agente VI, 2004. [15] S. Phelps, S. Parsons, P. McBurney y E. Sklar. Coevolución de los mecanismos de subastas y estrategias comerciales: hacia un enfoque novedoso para el diseño microeconómico. En Ecomas 2002 Workshop, 2002. [16] S. Phelps, S. Parsons, E. Sklar y P. McBurney. Uso de la programación genética para optimizar las reglas de precios para un mercado de doble subasta. En Taller sobre Agentes para Comercio Electrónico, 2003. [17] Y. Vorobeychik, M. P. Wellman y S. Singh. Aprender funciones de pago en juegos infinitos. En la decimocoria Conferencia Conjunta Internacional sobre Inteligencia Artificial, páginas 977-982, 2005. [18] W. E. Walsh, R. Das, G. Tesauro y J. O. Kephart. Análisis de interacciones estratégicas complejas en sistemas de múltiples agentes. En el taller de AAAI-02 sobre los agentes teóricos y teóricos de la decisión del juego, 2002. [19] M. P. Wellman, J. J. Estelle, S. Singh, Y. Vorobeychik, C. Kiekintveld y V. Soni. Interacciones estratégicas en un juego de cadena de suministro. Inteligencia computacional, 21 (1): 1-26, febrero de 2005. APÉNDICE A. Pruebas A.1 Prueba de la proposición 1 Pr „max i∈I max b∈Ai \ ai ui (b, a - i) - ui (a) ≤« = y i∈I eui (a) »pr (max b (max b (max b)∈Ai \ ai ui (b, a - i) - ui (a) ≤ | ui (a)) = = y i∈I z r y b∈Ai \ ai pr (ui (b, a - i) ≤ u +) fui(a) (u) du. A.2 Prueba de la Proposición 2 Primero, supongamos que algún funcionamiento, F (x) definido en [AI, BI], satisface la condición de Lipschitz en (Ai, BI] con Lipschitz constante Ai. Entonces la siguiente afirmación es válida: afirmación: infx∈ (ai, bi] f (x) ≥ 0.5 (f (ai) + f (bi) - ai (bi - ai). Para probar esta afirmación, tenga en cuenta que la intersección de líneas en F (ai) y F (bi) con pendientes −a y ai respectivamente determinará el límite inferior en el mínimo de f (x) en [ai, bi] (que esun límite inferior en infimum de f (x) en (ai, bj]). La línea en f (ai) está determinada por f (ai) = −aiai + cl y la línea en f (bi) está determinada por f (bi) = aibi + cr. Por lo tanto, las intercepciones son cl = f (ai) + aiai y cr = f (bi) + aibi respectivamente. Sea x ∗ el punto en el que estas líneas se cruzan. Entonces, x ∗ = - f (x ∗) - cr a = f (x ∗) - cl a. Al sustituir las expresiones por CR y CL, obtenemos el resultado deseado. Ahora, la subadditividad nos da pr {_ θ∈θ sup {φ ∗ (θ)} ≤ α} ≤ 5x j = 1 pr {_ θ∈θj sup {φ ∗ (θ)} ≤ α} y, por la afirmación, Pr {_ θ∈θj sup {φ ∗ (θ)} ≤ α} = 1 - Pr {inf θ∈θj sup {φ ∗ (θ)}> α} ≤ pr {sup {φ ∗ (aj)} +sup {φ ∗ (bj)} ≤ 2α + aj (bj - aj)}. Dado que tenemos un número finito de puntos en el conjunto de datos para cada θ, podemos obtener la siguiente expresión: PR {sup {φ ∗ (aj)} + sup {φ ∗ (bj)} ≤ cj} = d x y, z∈D: y+z≤cj pr {sup {φ ∗ (bj)} = y} pr {sup {φ ∗ (aj)} = z}. Ahora podemos restringir la atención a derivar un límite superior en PR {sup {φ ∗ (θ)} = y} para un θ fijo. Para hacer esto, observe que Pr {sup {φ ∗ (θ)} = y} ≤d pr {_ a∈D: φ (a) = y (a) = 0} ≤ x a∈D: φ (a)= y Pr {(a) = 0} por subadditividad y el hecho de que un perfil a es un equilibrio Nash si y solo si (a) = 0. Poner todo juntos produce el resultado deseado. A.3 Prueba del teorema 3 Primero, necesitaremos el siguiente hecho: Reclamación: Dada una función fi (x) y un conjunto x, |maxx∈X f1 (x) - maxx∈X f2 (x) |≤ maxx∈X | f1 (x) - f2 (x) |. Para probar esta afirmación, observe que |max x∈X f1 (x) - max x∈X f2 (x) |=  maxx f1 (x) - maxx f2 (x) si maxx f1 (x) ≥ maxx f2 (x) maxx f2 (x) - maxx f1 (x) si maxx f2 (x) ≥ maxx f1 (x) en elPrimer caso, max x∈X f1 (x) - max x∈X f2 (x) ≤ max x∈X (f1 (x) - f2 (x)) ≤ ≤ max x∈X | f1 (x) - f2 (x) |.314 Del mismo modo, en el segundo caso, max x∈X f2 (x) - max x∈X f1 (x) ≤ max x∈X (f2 (x) - f1 (x)) ≤ ≤ max x∈X | f2 (x) - f1 (x) |= max x∈X | f1 (x) - f2 (x) |. Por lo tanto, la afirmación se mantiene. Por la fuerte ley de grandes números, un, i (a) → ui (a) a.s.Para todos los i ∈ I, a ∈ A. Es decir, pr {lim n → ∞ un, i (a) = ui (a)} = 1, o, de manera equivalente [8], para cualquier α> 0 y δ> 0, hay m (i, a)>>0 tal que pr {sup n≥m (i, a) | un, i (a) - ui (a) |<Δ 2 | a |} ≥ 1 - α. Al tomar m = maxi∈I maxa∈A m (i, a), tenemos pr {max i∈I max a∈A sup n≥m | un, i (a) - ui (a) |<Δ 2 | a |} ≥ 1 - α. Por lo tanto, por el reclamo, para cualquier n ≥ m, sup n≥m |n (s) - (s) |≤ max i∈I max ai∈Ai sup n≥m | un, i (ai, s - i) - ui (ai, s - i) | + + sup n≥m max i∈I | un, i (s) - ui (s) |≤ max i∈I max ai∈Ai x b∈A - i sup n≥m | un, i (ai, b) - ui (ai, b) | s - i (b) + + max i∈I x b∈A Sup n≥m | un, i (b) - ui (b) | s (b) ≤ max i∈I max ai∈Ai x b∈A - i sup n≥m | un, i (ai, b)- ui (ai, b) | + + max i∈I x b∈A sup n≥m | un, i (b) - ui (b) |<max i∈I max ai∈Ai x b∈A - i (Δ 2 | a |) + max i∈I x b∈A (Δ 2 | a |) ≤ δ con probabilidad al menos 1 - α. Tenga en cuenta que dado que S - I (a) y S (a) están limitados entre 0 y 1, pudimos dejarlas de las expresiones anteriores para obtener un límite que será válido independiente de la elección particular de s.Además, dado que el resultado anterior se puede obtener para un α> 0 y Δ> 0 arbitrario, tenemos PR {Limn → ∞ n (s) = (s)} = 1 uniformemente en S. A.4 Prueba de Lemma 5 Probamos el resultadoutilizando continuidad uniforme de UI (s) y preservación de la continuidad al máximo. Reclamación: una función f: rk → r definida por f (t) = pk i = 1 ziti, donde zi son constantes en r, es uniformemente continuo en t.La afirmación sigue porque | f (t) −f (t) |= |Pk I = 1 Zi (ti - ti) |≤ Pk i = 1 | zi || ti - ti |. Un resultado inmediato de esto para nuestros propósitos es que UI (S) es uniformemente continuo en S y UI (Ai, S - I) es uniformemente continuo en S - I. Reclamación: Sea f (a, b) ser uniformemente continuo en b ∈ B por cada a ∈ A, con | a |<∞. Entonces V (b) = maxa∈A f (a, b) es uniformemente continuo en b. Para mostrar esto, tome γ> 0 y deje b, b ∈ B tal que b - b <δ (a) ⇒ | f (a, b) - f (a, b) |<γ. Ahora tome δ = mina∈A δ (a). Luego, siempre que b - b <δ, | V (b) - V (b) |= |max a∈A f (a, b) - max a∈A f (a, b) |≤ max a∈A | f (a, b) - f (a, b) |<γ. Ahora, recuerde que (s) = maxi [maxai∈Ai ui (ai, s - i) - ui (s)]. Según las afirmaciones anteriores, maxai∈Ai ui (ai, s - i) es uniformemente continuo en s - i y ui (s) es uniformemente continuo en s.Dado que la diferencia de dos funciones uniformemente continuas es uniformemente continua, y dado que esta continuidad se conserva al máximo por nuestro segundo reclamo, tenemos el resultado deseado. A.5 Prueba del teorema 6 Elija δ> 0. Primero, debemos determinar que la siguiente afirmación es contenida: afirma: ¯ = mins∈S \ nδ (s) existe y ¯> 0. Dado que Nδ es un subconjunto abierto de S compacto, se deduce que S \ Nδ es compacto. Como también habíamos demostrado en Lemma 5 que (s) es continua, la existencia se deriva del teorema de Weierstrass. Que ¯> 0 está claro ya que (s) = 0 si y solo si s es un equilibrio NASH de γ. Ahora, por el Teorema 3, para cualquier α> 0 hay M tal que Pr {sup n≥m sup s∈S |n (s) - (s) |<¯} ≥ 1 - α.En consecuencia, para cualquier δ> 0, PR {sup n≥m h (nn, nΔ) <Δ} ≥ pr {∀n ≥ m nn ⊂ nδ} ≥ pr {sup n≥m sup s∈N (s) <¯} ≥ pr {sup n≥m sup s∈S |n (s) - (s) |<¯} ≥ 1 - α. Dado que esto es válido para un α> 0 y δ> 0 arbitrario, el resultado deseado sigue. A.6 Prueba del teorema 7 FIJA θ y elija δ> 0. Dado que w (s, θ) es continuo en s ∗ (θ), dado> 0 hay δ> 0 tal que para cada s que está dentro de δ de s ∗ (θ), | w (s, θ) - w (S ∗ (θ), θ) |<. Por el Teorema 6, podemos encontrar m (θ) lo suficientemente grande como para que todos los s ∈ Nn estén dentro de δ de S ∗ (θ) para todos n ≥ m (θ) con probabilidad 1. En consecuencia, para cualquier> 0 podemos encontrar m (θ) lo suficientemente grande como para que con la probabilidad 1 tengamos supn≥m (θ) sups ∈Nn | w (s, θ) - w (s ∗ (θ), θ) |<. Supongamos sin pérdida de generalidad que existe una elección óptima única de θ. Ahora, dado que el conjunto θ es finito, también existe la segunda mejor opción de θ (si solo hay una θ ∈ θ esta discusión es discutible de todos modos): θ ∗∗ = arg max θ \ θ ∗ w (s ∗ ((θ), θ). Supongamos que W.L.O.G.que θ ∗∗ también es único y deje ∆ = w (s ∗ (θ ∗), θ ∗) - w (s ∗ (θ ∗∗), θ ∗∗). Entonces, si dejamos <∆/2 y M = maxθ∈θ m (θ), donde cada m (θ) es lo suficientemente grande como como supn≥m (θ) sups ∈Nn | w (s, θ) - w (S ∗ (θ), θ) |<A.S., la elección óptima de θ basada en cualquier equilibrio empírico será θ ∗ con probabilidad 1. Por lo tanto, en particular, dada cualquier distribución de probabilidad sobre los equilibrios empíricos, la mejor opción de θ será θ ∗ con probabilidad 1 (de manera similar, si tomamos supremum o infimum de w (nn (θ), θ) sobre el conjunto de equilibrios empíricosal construir la función objetivo).315