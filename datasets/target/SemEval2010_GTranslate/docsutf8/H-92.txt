Mejora de la clasificación de búsqueda web mediante la incorporación de información de comportamiento del usuario Eugene Agichtein Microsoft Research eugeneag@microsoft.com Eric Brill Microsoft Research Brill@microsoft.com Susan Dumais Microsoft Research sdumais@microsoft.com Resumen que la incorporación de datos de comportamiento del usuario puede mejorar significativamente la orden de la orden de arribaResultados en una configuración de búsqueda web real. Examinamos alternativas para incorporar comentarios en el proceso de clasificación y explorar las contribuciones de los comentarios de los usuarios en comparación con otras características de búsqueda web comunes. Reportamos los resultados de una evaluación a gran escala más de 3.000 consultas y 12 millones de interacciones de usuario con un popular motor de búsqueda web. Mostramos que la incorporación de retroalimentación implícita puede aumentar otras características, mejorando la precisión de un algoritmos competitivos de clasificación de búsqueda web hasta un 31% en relación con el rendimiento original. Categorías y descriptores de sujetos H.3.3 Búsqueda y recuperación de información - Comentarios de relevancia, proceso de búsqueda;H.3.5 Servicios de información en línea - Servicios basados en la web. Algoritmos de términos generales, medición, experimentación 1. Introducción millones de usuarios interactúan diariamente con los motores de búsqueda. Emiten consultas, siguen algunos de los enlaces en los resultados, hacen clic en anuncios, pasan tiempo en páginas, reforman sus consultas y realizan otras acciones. Estas interacciones pueden servir como una fuente valiosa de información para ajustar y mejorar la clasificación de los resultados de la búsqueda web y pueden complementar juicios explícitos más costosos. La retroalimentación de relevancia implícita para la clasificación y la personalización se ha convertido en un área activa de investigación. El trabajo reciente de Joachims y otros que exploran la retroalimentación implícita en entornos controlados han demostrado el valor de incorporar la retroalimentación implícita en el proceso de clasificación. Nuestra motivación para este trabajo es comprender cómo se puede utilizar la retroalimentación implícita en un entorno operativo a gran escala para mejorar la recuperación. ¿Cómo se compara y complementa la evidencia del contenido de la página, el texto de anclaje o las características basadas en enlaces como Inlinks o PageRank? Si bien es intuitivo que las interacciones del usuario con el motor de búsqueda web revelen al menos alguna información que podría usarse para la clasificación, estimar las preferencias de los usuarios en la configuración de búsqueda web real es un problema desafiante, ya que las interacciones reales del usuario tienden a ser más ruidosas de lo que comúnmente se supone.En los entornos controlados de estudios anteriores. Nuestro artículo explora si la retroalimentación implícita puede ser útil en entornos realistas, donde la retroalimentación de los usuarios puede ser ruidosa (o adversa) y un motor de búsqueda web ya usa cientos de características y está muy sintonizado. Con este fin, exploramos diferentes enfoques para clasificar los resultados de búsqueda web utilizando el comportamiento real del usuario obtenido como parte de las interacciones normales con el motor de búsqueda web. Las contribuciones específicas de este documento incluyen: • Análisis de alternativas para incorporar el comportamiento del usuario en la clasificación de búsqueda web (Sección 3).• Una aplicación de un modelo de retroalimentación implícita robusto derivado de la extracción de millones de interacciones del usuario con un importante motor de búsqueda web (Sección 4).• Una evaluación a gran escala sobre consultas reales de usuario y resultados de búsqueda, que muestra mejoras significativas derivadas de la incorporación de comentarios de los usuarios (Sección 6). Resumimos nuestros hallazgos y discutimos extensiones al trabajo actual en la Sección 7, lo que concluye el documento.2. Antecedentes y resultados de búsqueda de clasificación de trabajo relacionados es un problema fundamental en la recuperación de la información. Los enfoques más comunes se centran principalmente en la similitud de la consulta y una página, así como en la calidad general de la página [3,4,24]. Sin embargo, con la creciente popularidad de los motores de búsqueda, los comentarios implícitos (es decir, las acciones que toman los usuarios al interactuar con el motor de búsqueda) se pueden usar para mejorar las clasificaciones. Las medidas de relevancia implícita han sido estudiadas por varios grupos de investigación. Una descripción general de las medidas implícitas se compila en Kelly y Teevan [14]. Esta investigación, mientras desarrollaba información valiosa sobre medidas de relevancia implícitas, no se aplicó para mejorar la clasificación de los resultados de búsqueda web en entornos realistas. Estrechamente relacionado con nuestro trabajo, Joachims [11] recopilaron medidas implícitas en lugar de medidas explícitas, introduciendo una técnica basada completamente en datos de clic para aprender funciones de clasificación. Fox et al.[8] exploró la relación entre las medidas implícitas y explícitas en la búsqueda web, y desarrolló modelos bayesianos para correlacionar las medidas implícitas y los juicios de relevancia explícita para consultas individuales y sesiones de búsqueda. Este trabajo consideró una amplia gama de comportamientos del usuario (por ejemplo, tiempo de permanencia, tiempo de desplazamiento, patrones de reformulación) además del popular comportamiento de clics. Sin embargo, el esfuerzo de modelado tenía como objetivo predecir juicios de relevancia explícita de las acciones implícitas del usuario y no específicamente en las funciones de clasificación de aprendizaje. Otros estudios del comportamiento del usuario en la búsqueda web incluyen Pharo y Järvelin [19], pero no se aplicaron directamente para mejorar la clasificación. Más recientemente, Joachims et al.[12] presentó una evaluación empírica de la interpretación de la evidencia de clics. Al realizar estudios de seguimiento ocular y correlacionar predicciones de sus estrategias con calificaciones explícitas, los autores mostraron que es posible interpretar con precisión los clics en un entorno de laboratorio controlado. Desafortunadamente, la medida en que la investigación anterior se aplica a la búsqueda web del mundo real no está claro. Al mismo tiempo, si bien el trabajo reciente (por ejemplo, [26]) sobre el uso de información de clics para mejorar la clasificación de búsqueda web es prometedor, solo captura un aspecto de las interacciones del usuario con los motores de búsqueda web. Construimos una investigación existente para desarrollar técnicas sólidas de interpretación del comportamiento del usuario para la configuración de búsqueda web real. En lugar de tratar a cada usuario como un experto confiable, agregamos información de trazas de sesión de búsqueda de usuarios múltiples, poco confiables, como describimos en las siguientes dos secciones.3. Incorporando la retroalimentación implícita, consideramos dos enfoques complementarios para la clasificación con la retroalimentación implícita: (1) Tratar la retroalimentación implícita como evidencia independiente para los resultados de clasificación y (2) integrar las características de retroalimentación implícita directamente en el algoritmo de clasificación. Describimos los dos enfoques de clasificación general a continuación. Las características de retroalimentación implícita específicas se describen en la Sección 4, y los algoritmos para interpretar e incorporar la retroalimentación implícita se describen en la Sección 5. 3.1 Comentarios implícitos como evidencia independiente El enfoque general es volver a clasificar los resultados obtenidos por un motor de búsqueda web de acuerdo conClickthrough observado y otras interacciones de usuario para la consulta en sesiones de búsqueda anteriores. A cada resultado se le asigna una puntuación de acuerdo con la relevancia esperada/satisfacción del usuario basada en interacciones anteriores, lo que resulta en un orden de preferencia basado solo en las interacciones del usuario. Si bien ha habido un trabajo significativo para fusionar múltiples clasificaciones, adaptamos un enfoque simple y robusto de ignorar los puntajes originales de Rankers, y simplemente fusionar las órdenes de rango. La razón principal para ignorar los puntajes originales es que, dado que los espacios de características y los algoritmos de aprendizaje son diferentes, las puntuaciones no son directamente comparables y la re-normalización tiende a eliminar el beneficio de incorporar las puntuaciones del clasificador. Experimentamos con una variedad de funciones de fusión en el conjunto de consultas de desarrollo (y utilizando un conjunto de interacciones desde un período de tiempo diferente a partir de conjuntos de evaluación final). Descubrimos que un rango simple que fusiona la combinación heurística funciona bien, y es robusto a las variaciones en los valores de puntaje de los rankers originales. Para una consulta dada Q, el puntaje implícito ISD se calcula para cada resultado D de las características de interacción del usuario disponibles, lo que resulta en la ID de rango implícita para cada resultado. Calculamos una puntuación fusionada SM (D) para D combinando los rangos obtenidos de la retroalimentación implícita, ID con el rango original de D, OD: ¡¢ £ + + + + = de lo contrario o DforexistsFeedBackimpliCitif oi W Woids D DD I IDDM 1 1 1 11 1 1 1) ,,, (donde el peso WI es un factor de escala heurísticamente sintonizado que representa la importancia relativa de la retroalimentación implícita. Los resultados de la consulta se ordenan disminuyendo los valores de SM para producir la clasificación final. Un caso especial de este modelo surge al establecer WI en un valor muy grande, forzando efectivamente los resultados de los clics para clasificarse más altos que los resultados no haciendo clic, una heurística intuitiva y efectiva que usaremos como línea de base. La aplicación de algoritmos de combinación de clasificadores y ranker más sofisticados puede dar lugar a mejoras adicionales, y es una dirección prometedora para el trabajo futuro. El enfoque anterior supone que no hay interacciones entre las características subyacentes que producen la clasificación de búsqueda web original y las características de retroalimentación implícitas. Ahora relajamos esta suposición integrando las características de retroalimentación implícita directamente en el proceso de clasificación.3.2 Clasificación con características de retroalimentación implícita Los motores de búsqueda web modernos Los resultados de clasificación en función de una gran cantidad de características, incluidas las características basadas en el contenido (es decir, cuán de cerca una consulta coincide con el texto o el título o el texto de anclaje del documento), y la página independiente de la consultaCaracterísticas de calidad (por ejemplo, PageRank del documento o el dominio). En la mayoría de los casos, se desarrollan métodos automáticos (o semiautomáticos) para ajustar la función de clasificación específica que combina estos valores de características. Por lo tanto, un enfoque natural es incorporar características de retroalimentación implícita directamente como características para el algoritmo de clasificación. Durante el entrenamiento o el ajuste, el ranker se puede ajustar como antes pero con características adicionales. En tiempo de ejecución, el motor de búsqueda obtendría las características de retroalimentación implícita asociadas con cada par de URL de resistencia de consulta. Este modelo requiere que un algoritmo de clasificación sea robusto para los valores faltantes: más del 50% de las consultas a los motores de búsqueda web son únicos, sin comentarios implícitos previos disponibles. Ahora describimos un ranker de este tipo que solíamos aprender sobre los conjuntos de características combinadas, incluidos los comentarios implícitos.3.3 Aprender a clasificar los resultados de la búsqueda web Un aspecto clave de nuestro enfoque es explotar los avances recientes en el aprendizaje automático, a saber, los algoritmos de clasificación capacitables para la búsqueda en la web y la recuperación de información (por ejemplo, [5, 11] y resultados clásicos revisados en [3]). En nuestro entorno, los juicios explícitos de relevancia humana (etiquetas) están disponibles para un conjunto de consultas y resultados de búsqueda web. Por lo tanto, una opción atractiva para usar es una técnica de aprendizaje automático supervisado para aprender una función de clasificación que mejor predice juicios de relevancia. RankNet es uno de esos algoritmo. Es un algoritmo de ajuste de red neuronal que optimiza los pesos de las características para que mejor coincida explícitamente las preferencias de usuario proporcionadas por pares. Si bien los algoritmos de entrenamiento específicos utilizados por RankNet están más allá del alcance de este documento, se describe en detalle en [5] e incluye una evaluación extensa y comparación con otros métodos de clasificación. Una característica atractiva de RankNet es la eficiencia del tiempo de ejecución y el tiempo de ejecución: la clasificación de tiempo de ejecución se puede calcular rápidamente y puede escalar a la web, y la capacitación se puede realizar durante miles de consultas y resultados juzgados asociados. Utilizamos una implementación de 2 capas de RankNet para modelar relaciones no lineales entre características. Además, RankNet puede aprender con muchas funciones de costos (diferenciables) y, por lo tanto, puede aprender automáticamente una función de clasificación de etiquetas proporcionadas por humanos, una alternativa atractiva a las técnicas de combinación de características heurísticas. Por lo tanto, también usaremos RankNet como un ranker genérico para explorar la contribución de la retroalimentación implícita para diferentes alternativas de clasificación.4. Modelo de retroalimentación de usuarios implícito Nuestro objetivo es interpretar con precisión la retroalimentación de los usuarios ruidosas obtenidas como rastrear las interacciones del usuario con el motor de búsqueda. La interpretación de comentarios implícitos en la configuración de búsqueda web real no es una tarea fácil. Caracterizamos este problema en detalle en [1], donde motivamos y evaluamos una amplia variedad de modelos de actividades de usuario implícitas. El enfoque general es representar las acciones del usuario para cada resultado de la búsqueda como un vector de características, y luego capacitar a un ranker en estas características para descubrir valores de características indicativos de resultados de búsqueda relevantes (y no relevantes). Primero resumimos brevemente nuestras características y modelo, y el enfoque de aprendizaje (Sección 4.2) para proporcionar información suficiente para replicar nuestros métodos de clasificación y los experimentos posteriores.4.1 Representación de las acciones del usuario como características modelamos los comportamientos de búsqueda web observados como una combinación de un componente de fondo `` (es decir, ruido independiente de la consulta y relevancia en el comportamiento del usuario, incluidos los sesgos posicionales con interacciones de resultados) y un componente de relevancia `` ((es decir, comportamiento específico de consulta indicativo de relevancia de un resultado a una consulta). Diseñamos nuestras características para aprovechar el comportamiento agregado del usuario. El conjunto de características se compone de características observadas directamente (calculadas directamente a partir de observaciones para cada consulta), así como características derivadas de consulta, calculadas como la desviación de la distribución general independiente de la consulta de los valores para los valores de características observados directamente correspondientes. Las características utilizadas para representar las interacciones del usuario con los resultados de búsqueda web se resumen en la Tabla 4.1. Esta información se obtuvo a través de la instrumentación del lado del cliente de los usuarios de un importante motor de búsqueda web. Incluimos las características tradicionales de retroalimentación implícita, como los recuentos de clics para los resultados, así como nuestras nuevas características derivadas, como la desviación del número de clics observado para un par de consulta dada del número esperado de clics en un resultado en el resultado dado.posición. También modelamos el comportamiento de navegación después de que se hizo clic en un resultado, por ejemplo, el tiempo promedio de permanencia de la página para un par de consulta -URL dada, así como su desviación del tiempo de permanencia esperado (promedio). Además, el conjunto de características fue diseñado para proporcionar información esencial sobre la experiencia del usuario para hacer que la interpretación de comentarios sea robusta. Por ejemplo, los usuarios de búsqueda web a menudo pueden determinar si un resultado es relevante al observar el título de los resultados, la URL y el resumen; en muchos casos, no es necesario mirar el documento original. Para modelar este aspecto de la experiencia del usuario, incluimos características como superposición en palabras en título y palabras en consulta (titeoverlap) y la fracción de palabras compartidas por la consulta y el resumen de resultados. Haga clic en las características de la posición Posición de la URL en la clasificación actual El número de clics de la frecuencia de consecuencia de los clics para esta consulta, el par de la URL Click -Probability Probabilidad de un clic para esta consulta y la desviación de la URL ClickDeviation Desviándose de la probabilidad de clic esperadaEn la posición anterior, 0 de lo contrario IsClickABove 1 Si hay un clic arriba, 0 de lo contrario ISCLICKBELOW 1 Si hay clic a continuación, 0 de lo contrario las características de la página Tiempo de permanencia de la página de tiempo CumulativetimeonPage Tiempo acumulativo para todasTiempo acumulativo en el prefijo de URL, no hay parámetros ISFollowDlink 1 Si se sigue el enlace al resultado, 0 de lo contrario isExacturlMatch 0 Si se usa la normalización agresiva, 1 de lo contrario ISredirected 1 si la URL inicial es igual a la URL final, 0 de otra manera ISPATHFROMSearch 1 si solo siguió los enlaces después de la consulta, 0 de otra manera de otra manera de otra maneraClicksFromSearch Número de lúpulos para llegar a la página desde consulta el tiempo promedio de promedio de tiempo en la página para esta consulta desviación de la evitación de la evitación del tiempo promedio de permanencia en la página Desviación de evaluación acumulada por la adviación de la desviación promedio del tiempo de permanencia acumulativa del tiempo de dominio del tiempo de permanencia promedio en el dominio.Título Resumen Palabras de SummaryOverLap compartidas entre la consulta y el fragmento Palabras de consulta de consultas compartidas entre consultas y url Consulta Palabras de consulta compartidas entre la consulta y el dominio URL El número de consultas de la consulta de tokens en Query QueryExtoverlap fracción de palabras compartidas con la siguiente consulta Tabla 4.1: Algunas características utilizadas para representar la historia posterior a la búsqueda de la historia de navegación Historia de navegaciónpara una consulta dada y URL de resultado de búsqueda. Habiendo descrito nuestro conjunto de características, revisamos brevemente nuestro método general para derivar un modelo de comportamiento del usuario.4.2 Derando un modelo de retroalimentación del usuario para aprender a interpretar el comportamiento del usuario observado, correlacionamos las acciones del usuario (es decir, las características de la Tabla 4.1 que representan las acciones) con los juicios de usuario explícitos para un conjunto de consultas de capacitación. Encontramos todas las instancias en nuestros registros de sesión donde estas consultas se enviaron al motor de búsqueda y agregamos las características de comportamiento del usuario para todas las sesiones de búsqueda que involucran estas consultas. Cada par de consultas observado está representado por las características en la Tabla 4.1, con valores promediados en todas las sesiones de búsqueda, y se asigna una de las seis etiquetas de relevancia posibles, que van desde perfectas a malas, según lo asignado por juicios de relevancia explícita. Estos vectores de características etiquetadas se utilizan como entrada al algoritmo de entrenamiento RankNet (Sección 3.3) que produce un modelo de comportamiento de usuario entrenado. Este enfoque es particularmente atractivo, ya que no requiere heurística más allá de la ingeniería de características. El modelo de comportamiento del usuario resultante se utiliza para ayudar a clasificar la búsqueda de la búsqueda en la web directamente o en combinación con otras características, como se describe a continuación.5. Configuración experimental El objetivo final de incorporar la retroalimentación implícita en la clasificación es mejorar la relevancia de los resultados de búsqueda web devueltos. Por lo tanto, comparamos los métodos de clasificación con un gran conjunto de consultas juzgadas con etiquetas de relevancia explícita proporcionadas por jueces humanos. Para que la evaluación sea realista, obtuvimos una muestra aleatoria de consultas de los registros de búsqueda web de un motor de búsqueda importante, con resultados asociados y trazas para las acciones del usuario. Describimos este conjunto de datos en detalle a continuación. Nuestras métricas se describen en la Sección 5.2 que utilizamos para evaluar las alternativas de clasificación, enumeradas en la Sección 5.3 en los experimentos de la Sección 6. 5.1 conjuntos de datos comparamos nuestros métodos de clasificación con una muestra aleatoria de 3.000 consultas de los registros de consultas de motores de búsqueda. Las consultas se extrajeron de los registros de manera uniforme al azar por token sin reemplazo, lo que resultó en una muestra de consulta representativa de la distribución general de la consulta. En promedio, 30 resultados fueron etiquetados explícitamente por jueces humanos utilizando una escala de seis puntos que varía desde perfecta hasta mal. En general, hubo más de 83,000 resultados con juicios de relevancia explícita. Para calcular varias estadísticas, los documentos con la etiqueta bueno o mejor se considerarán relevantes, y con las etiquetas más bajas para no ser relevantes. Tenga en cuenta que los experimentos se realizaron sobre los resultados ya altamente clasificados por un motor de búsqueda web, que corresponde a una experiencia de usuario típica que se limita al pequeño número de resultados altamente clasificados para una consulta de búsqueda web típica. Las interacciones del usuario se recopilaron durante un período de 8 semanas utilizando información voluntaria de opción. En total, se instrumentaron más de 1.2 millones de consultas únicas, lo que resultó en más de 12 millones de interacciones individuales con el motor de búsqueda. Los datos consistieron en interacciones del usuario con el motor de búsqueda web (por ejemplo, hacer clic en un enlace de resultados, volver a los resultados de búsqueda, etc.) realizados después de que se envió una consulta. Estas acciones se agregaron entre los usuarios y las sesiones de búsqueda y se convirtieron en características en la Tabla 4.1. Para crear los conjuntos de capacitación, validación y consultas de prueba, creamos tres divisiones aleatorias diferentes de 1,500 capacitación, 500 validación y 1000 consultas de prueba. Las divisiones se hicieron al azar mediante consulta, de modo que no hubo superposición en el entrenamiento, la validación y las consultas de prueba.5.2 Métricas de evaluación Evaluamos los algoritmos de clasificación en un rango de métricas de recuperación de información aceptadas, a saber, precisión en K (p (k)), ganancia acumulativa con descuento normalizada (NDCG) y precisión promedio media (MAP). Cada métrica se centra en un aspecto deferente del rendimiento del sistema, como describimos a continuación.• Precisión en K: Como la métrica más intuitiva, P (k) informa la fracción de documentos clasificados en los resultados de K superiores que se etiquetan como relevantes. En nuestro entorno, requerimos un documento relevante para ser etiquetado como bueno o más alto. La posición de los documentos relevantes dentro de la K superior es irrelevante y, por lo tanto, esta métrica medida general de satisfacción del usuario con los resultados principales de K.• NDCG en K: NDCG es una medida de recuperación ideada específicamente para la evaluación de búsqueda web [10]. Para una consulta dada Q, los resultados clasificados se examinan desde la parte superior clasificada, y el NDCG calculado como: = + - = k j jr qq jmn 1) () 1log (/) 12 (donde MQ es una constante de normalización calculada SOque un pedido perfecto obtendría NDCG de 1; y cada R (j) es una etiqueta de relevancia entera (0 = mala y 5 = perfecta) de resultado devuelto en la posición j. Tenga en cuenta que los documentos no etiquetados y malos no contribuyen a la suma, pero reducirán NDCG para la consulta que empuja los documentos etiquetados relevantes, reduciendo sus contribuciones. NDCG es muy adecuado para la evaluación de la búsqueda web, ya que recompensa los documentos relevantes en los resultados mejor clasificados más en gran medida que los que se clasifican más bajos.• Mapa: la precisión promedio para cada consulta se define como la media de la precisión en los valores de K calculados después de que se recuperó cada documento relevante. El valor final del mapa se define como la media de las precisiones promedio de todas las consultas en el conjunto de pruebas. Esta métrica es el resumen de valor único más utilizado de una ejecución sobre un conjunto de consultas.5.3 Métodos de clasificación comparados Recuerde que nuestro objetivo es cuantificar la efectividad del comportamiento implícito para la búsqueda web real. Una dimensión es comparar la utilidad de la retroalimentación implícita con otra información disponible para un motor de búsqueda web. Específicamente, comparamos la efectividad de los comportamientos de usuario implícitos con características de calidad de página estática basadas en contenido y combinaciones de todas las características.• BM25F: como una línea de base de búsqueda web fuerte, utilizamos la puntuación BM25F, que se utilizó en uno de los sistemas de mejor rendimiento en la pista web de TREC 2004 [23,27]. BM25F y sus variantes se han descrito y evaluado ampliamente en la literatura IR y, por lo tanto, sirven como una línea de base fuerte y reproducible. La variante BM25F que utilizamos para nuestros experimentos calcula puntajes de coincidencia separados para cada campo para un documento de resultado (por ejemplo, texto del cuerpo, título y texto de anclaje), e incorpora información basada en enlaces independientes de la consulta (por ejemplo, PageRank, ClickDistance y URL Profundation). La función de puntuación y el ajuste específico de campo se describen en detalle en [23]. Tenga en cuenta que BM25F no considera directamente la retroalimentación explícita o implícita para el ajuste.• RN: la clasificación producida por un Ranker de red neuronal (RankNet, descrita en la Sección 3.3) que aprende a clasificar los resultados de búsqueda web incorporando BM25F y una gran cantidad de características estáticas y dinámicas adicionales que describen cada resultado de la búsqueda. Este sistema aprende automáticamente pesos para todas las características (incluida la puntuación BM25F para un documento) basado en etiquetas humanas explícitas para un gran conjunto de consultas. Un sistema que incorpora una implementación de RankNet está actualmente en uso por un importante motor de búsqueda y puede considerarse representativo del estado de la técnica en la búsqueda web.• BM25F-RerankCT: la clasificación producida al incorporar estadísticas de clic para reordenar los resultados de búsqueda web clasificados por BM25F anterior. Clickthrough es un caso especial particularmente importante de retroalimentación implícita, y se ha demostrado que se correlaciona con la relevancia de los resultados. Este es un caso especial del método de clasificación en la Sección 3.1, con el peso WI establecido en 1000 y la ID de clasificación es simplemente el número de clics en el resultado correspondiente a d.En efecto, esta clasificación lleva a la parte superior todos los resultados de búsqueda web devueltos con al menos un clic (y los ordena en orden decreciente por número de clics). La clasificación relativa del resto de los resultados no cambia y se insertan debajo de todos los resultados haciendo clic. Este método sirve como nuestro método de referencia de retroalimentación implícita de línea de base. BM25F-Rerankall La clasificación producida reordenando los resultados BM25F utilizando todas las características de comportamiento del usuario (Sección 4). Este método aprende un modelo de preferencias del usuario correlacionando los valores de características con etiquetas de relevancia explícita utilizando el algoritmo de red neuronal RankNet (Sección 4.2). En tiempo de ejecución, para una consulta dada, la puntuación implícita IR se calcula para cada resultado R con las características de interacción del usuario disponibles, y se produce la clasificación implícita. La clasificación fusionada se calcula como se describe en la Sección 3.1. Según los experimentos sobre el conjunto de desarrollo, fijamos el valor de WI a 3 (el efecto del parámetro WI para este ranker resultó ser insignificante).• BM25F+ALL: Ranking Derivado mediante la capacitación del alumno RankNet (Sección 3.3) sobre el conjunto de características del puntaje BM25F, así como todas las características de retroalimentación implícita (Sección 3.2). Utilizamos la implementación de 2 capas de RankNet [5] capacitada en las consultas y etiquetas en los conjuntos de capacitación y validación.• RN+ALL: Ranking derivado de la capacitación del algoritmo de clasificación RankNet de 2 capas (Sección 3.3) sobre la unión de todas las características de retroalimentación de contenido, dinámica e implícita (es decir, todas las características descritas anteriormente, así como todas las nuevas implícitas.Características de retroalimentación que presentamos). Los métodos de clasificación sobre el rango de la información utilizada para la clasificación, desde no usar la retroalimentación implícita o explícita (es decir, BM25F) hasta un motor de búsqueda web moderno que utiliza cientos de características y sintonizados en juicios explícitos (RN). Como mostraremos a continuación, la incorporación del comportamiento del usuario en estos sistemas de clasificación mejora dramáticamente la relevancia de los documentos devueltos.6. Resultados experimentales La retroalimentación implícita para la clasificación de búsqueda web se puede explotar de varias maneras. Comparamos métodos alternativos para explotar la retroalimentación implícita, tanto al volver a clasificar los resultados principales (es decir, los métodos BM25F-RerankCT y BM25F-Rerankall que reordenan los resultados de BM25F), así como integrando las características implícitas directamente en el proceso de clasificación (es decir, es decir,, el RN+All y BM25F+todos los métodos que aprenden a clasificar los resultados sobre la retroalimentación implícita y otras características). Comparamos nuestros métodos sobre líneas de base fuertes (BM25F y RN) sobre el NDCG, la precisión en K y las medidas del mapa definidas en la Sección 5.2. Los resultados se promediaron en tres divisiones aleatorias del conjunto de datos general. Cada división contenía 1500 capacitación, 500 validación y 1000 consultas de prueba, todas las consultas establecen disjuntos. Primero presentamos los resultados sobre las consultas de prueba 1000 (es decir, incluidas las consultas para las cuales no hay medidas implícitas, por lo que usamos las clasificaciones web originales). Luego profundizamos para examinar los efectos sobre la reperancia para los intentos de consultas con más detalle, analizando cuando la retroalimentación implícita resultó más beneficiosa. Primero experimentamos con diferentes métodos para volver a clasificar la salida de los resultados de búsqueda BM25F. Las Figuras 6.1 y 6.2 informan NDCG y precisión para BM25F, así como para las estrategias que vuelven a ser los resultados con los comentarios de los usuarios (Sección 3.1). La incorporación de todos los comentarios de los usuarios (ya sea en el marco de reestructura o como las características del alumno directamente) da como resultado mejoras significativas (utilizando la prueba t de dos colas con p = 0.01) tanto en la clasificación BM25F original como en exceso de rerantería con clic solo. La mejora es consistente en los 10 resultados principales y más grande para el resultado superior: NDCG en 1 para BM25F+todo es 0.622 en comparación con 0.518 de los resultados originales, y la precisión a 1 aumenta de manera similar de 0.5 a 0.63. En base a estos resultados, utilizaremos la combinación de características directas (es decir, BM25F+All) Ranker para comparaciones posteriores que implican comentarios implícitos.0.5 0.52 0.54 0.56 0.58 0.6 0.62 0.64 0.66 0.68 1 2 3 4 5 6 7 8 9 10K NDCG BM25 BM25-Rerank-CT BM25-Rerank-All BM25+Toda la Figura 6.1: NDCG en K para BM25F, BM25F-Rerankct, BM25F--------------------------------Rerank-All, y BM25F+All para variar K 0.35 0.4 0.45 0.5 0.55 0.6 0.65 1 3 5 10 10 K Precisión BM25 BM25-Rerank-CT BM25-Rerank-All BM25+Toda Figura 6.2: Precisión en K para BM25F, BM25F Rerankct-Rerankct-Rerankct-Rerankct, BM25F-Rerank-All, y BM25F+All para variar K curiosamente, usando solo hacer clic, al tiempo que brindan un beneficio significativo sobre la clasificación BM25F original, no es tan efectivo como considerando el conjunto completo de características en la Tabla 4.1. Si bien analizamos el comportamiento del usuario (y las características de componentes más efectivas) en un artículo separado [1], vale la pena dar un ejemplo concreto del tipo de ruido inherente a la retroalimentación real de los usuarios en la configuración de búsqueda web.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 2 3 5 Posición de resultado RelativeclickFrequency PTR = 2 PTR = 3 PTR = 5 Figura 6.3: Frecuencia de clic relativo para consultas con una posición variable de resultado relevante superior (PTR). Si los usuarios consideraron solo la relevancia de un resultado a su consulta, harían clic en los resultados más relevantes. Desafortunadamente, como han demostrado Joachims y otros, la presentación también influye en lo que los usuarios hacen que los usuarios hagan clic bastante dramáticamente. Los usuarios a menudo hacen clic en los resultados anteriores al relevante presumiblemente porque los resúmenes breves no proporcionan suficiente información para hacer evaluaciones de relevancia precisas y han aprendido que, en promedio, los elementos superiores son relevantes. La Figura 6.3 muestra frecuencias relativas de clic para consultas con elementos relevantes conocidos en posiciones distintas de la primera posición;La posición del resultado más relevante (PTR) varía de 2-10 en la figura. Por ejemplo, para consultas con el primer resultado relevante en la posición 5 (PTR = 5), hay más clics en los resultados no relevantes en posiciones de mayor rango que en el primer resultado relevante en la posición 5. Como veremos, aprender sobre un conjunto de características de comportamiento más ricas, resulta en una mejora de precisión sustancial solo sobre el clic. Ahora consideramos incorporar el comportamiento del usuario en un conjunto de características mucho más rico, RN (Sección 5.3) utilizado por un importante motor de búsqueda web. RN incorpora BM25F, características basadas en enlaces y cientos de otras características. La Figura 6.4 informa que NDCG en K y la Figura 6.5 informa precisión en K. Curiosamente, mientras que las clasificaciones RN originales son significativamente más precisas que BM25F solo, incorporando características de retroalimentación implícita (BM25F+ALL) da como resultado que la clasificación supera significativamente las clasificaciones RN originales. En otras palabras, la retroalimentación implícita incorpora información suficiente para reemplazar las cientos de otras características disponibles para el alumno RankNet capacitado en el conjunto de características RN.0.5 0.52 0.54 0.56 0.58 0.6 0.62 0.64 0.66 0.68 0.7 1 2 3 4 5 6 7 8 9 10K NDCG RN RN+Todos BM25 BM25+Todos Figura 6.4: NDCG en K para BM25F, BM25F+All, RN, y RN+All For For For For For For For For For For For For For For For For For For For For For para BM25F.Variando K además, enriquecer las características de RN con un conjunto de retroalimentación implícita exhibe una ganancia significativa en todas las medidas, lo que permite que RN+todos superen a todos los demás métodos. Esto demuestra la naturaleza complementaria de la retroalimentación implícita con otras características disponibles para un motor de búsqueda web de última generación.0.4 0.45 0.5 0.55 0.6 0.65 1 3 5 10 K Precisión RN RN+Todos BM25 BM25+Todas la Figura 6.5: Precisión en K para BM25F, BM25F+ALL, RN y RN+All para variando K Resumimos el rendimiento de la diferente ranuraMétodos en la Tabla 6.1. Reportamos la puntuación media de precisión promedio (MAP) para cada sistema. Si bien no es intuitivo para interpretar, MAP permite una comparación cuantitativa en una sola métrica. Las ganancias marcadas con * son significativas en el nivel p = 0.01 usando dos pruebas t de cola. Ganancia del mapa P (1) Gane BM25F 0.184-0.503bm25f-Rerank-CT 0.215 0.031* 0.577 0.073* BM25F-RerankimpliCit 0.218 0.003 0.605 0.028* BM25F+implícito 0.222 0.004 0.620 0.015* RN 0.215- 29 0.032* Tabla 6.1: Precisión promedio media (MAP) para todas las estrategias. Hasta ahora informamos que los resultados promediaron en todas las consultas en el conjunto de pruebas. Desafortunadamente, menos de la mitad tuvo interacciones suficientes para intentar el rescate. De las 1000 consultas en la prueba, entre 46% y 49%, dependiendo de la división de la prueba de tren, tenía suficiente información de interacción para hacer predicciones (es decir, hubo al menos 1 sesión de búsqueda en la que se hizo al menos 1 resultado URL de resultadospor el usuario). Esto no es sorprendente: la búsqueda web es de cola pesada, y hay muchas consultas únicas. Ahora consideramos el rendimiento en las consultas para las que estaban disponibles las interacciones del usuario. La Figura 6.6 informa NDCG para el subconjunto de las consultas de prueba con las características de retroalimentación implícita. Las ganancias en el Top 1 son dramáticas. El NDCG a 1 de BM25F+aumenta de 0.6 a 0.75 (una ganancia relativa del 31%), lo que alcanza el rendimiento comparable a RN+que operan en un conjunto de características mucho más rico.0.6 0.65 0.7 0.7 0.7 0.8 1 3 5 10k NDCG RN RN+Todos BM25 BM25+Todos Figura 6.6: NDCG en K para BM25F, BM25F+ALL, RN y RN+All en las consultas de prueba con interacciones de usuario de manera similar, se refiere a la precisión en Top en TOP1 son sustanciales (Figura 6.7), y es probable que sean evidentes para los usuarios de búsqueda web. Cuando hay una retroalimentación implícita disponible, el BM25F+All System devuelve el documento relevante en el top 1 casi el 70% del tiempo, en comparación con el 53% del tiempo cuando el sistema BM25F no considera la retroalimentación implícita.0.45 0.5 0.55 0.6 0.65 0.7 1 3 3 5 10k Precisión RN RN+Todos BM25 BM25+Todos Figura 6.7: Precisión en K NDCG en K para BM25F, BM25F+ALL, RN y RN+ALL en Probar las interacciones de los usuarios Resumimos elResultados en la medida del mapa para consultas intentadas en la Tabla 6.2. Las mejoras de los mapas son sustanciales y significativas, con mejoras sobre el ranker BM25F más pronunciado. Método Mapa ganancia P (1) Ganancia RN 0.269 0.632 Rn+All 0.321 0.051 (19%) 0.693 0.061 (10%) BM25F 0.236 0.525 BM25F+All 0.292 0.056 (24%) 0.687 0.162 (31%) Tabla 6.2: Precisión media media precisión media Precisión media media(Mapa) En las consultas intentadas para los métodos de mejor rendimiento, ahora analizamos los casos en que la retroalimentación implícita se mostró más útil. La Figura 6.8 informa las mejoras del mapa sobre la línea de base BM25F para cada consulta con MAP bajo 0.6. Tenga en cuenta que la mayor parte de la mejora es para consultas de bajo rendimiento (es decir, MAP <0.1). Curiosamente, la incorporación de la información de comportamiento del usuario degrada la precisión para consultas con una puntuación de mapa original alta. Una posible explicación es que estas consultas fáciles tienden a ser navegacionales (es decir, tener una sola respuesta más apropiada altamente clasificada), y las interacciones de los usuarios con resultados de menor clasificación pueden indicar las necesidades de información divergente que son mejor atendidas por los resultados menos populares ((con calificaciones de relevancia generales correspondientemente pobres).0 50 100 100 150 200 250 300 350 0.1 0.2 0.3 0.4 0.5 0.6 -0.4 -0.35 -0.3 -0.25 -0.2 -0.15 -0.1 -0.05 0 0.05 0.1 0.15 0.2 ganancia promedio de frecuencia Figura 6.8: ganancia de BM25F+en todo el rango de BM25F originalPara resumir nuestros resultados experimentales, la incorporación de comentarios implícitos en la configuración de búsqueda web real dio como resultado mejoras significativas sobre las clasificaciones originales, utilizando las líneas de base BM25F y RN. Nuestro rico conjunto de características implícitas, como el tiempo en la página y las desviaciones del comportamiento promedio, proporciona ventajas sobre el uso de clic solo como un indicador de interés. Además, la incorporación de características de retroalimentación implícita directamente en la función de clasificación aprendida es más efectiva que usar comentarios implícitos para el reranking. Las mejoras observadas sobre grandes conjuntos de consultas de prueba (1,000 en total, entre 466 y 495 con retroalimentación implícita disponible) son sustanciales y estadísticamente significativas.7. Conclusiones y trabajo futuro En este documento exploramos la utilidad de incorporar retroalimentación implícita ruidosas obtenidas en una configuración de búsqueda web real para mejorar la clasificación de búsqueda web. Realizamos una evaluación a gran escala de más de 3.000 consultas y más de 12 millones de interacciones de los usuarios con un importante motor de búsqueda, estableciendo la utilidad de incorporar retroalimentación implícita ruidosas para mejorar la relevancia de la búsqueda en la web. Comparamos dos alternativas para incorporar la retroalimentación implícita en el proceso de búsqueda, a saber, replicar la retroalimentación implícita e incorporar características de retroalimentación implícita directamente en la función de clasificación capacitada. Nuestros experimentos mostraron una mejora significativa sobre los métodos que no consideran la retroalimentación implícita. Las ganancias son particularmente dramáticas para el resultado de K = 1 superior en la clasificación final, con mejoras de precisión de hasta el 31%, y las ganancias son sustanciales para todos los valores de K. Nuestros experimentos mostraron que la retroalimentación implícita de los usuarios puede mejorar aún más el rendimiento de la búsqueda web., cuando se incorpora directamente con características populares basadas en contenido y enlaces. Curiosamente, la retroalimentación implícita es particularmente valiosa para consultas con una clasificación original de los resultados (por ejemplo, mapa inferior a 0.1). Una dirección prometedora para el trabajo futuro es aplicar investigaciones recientes sobre la predicción de la dificultad de consultas automáticamente, y solo intenta incorporar comentarios implícitos para las consultas difíciles. Como otra dirección de investigación, estamos explorando métodos para extender nuestras predicciones a las consultas previamente invisibles (por ejemplo, agrupación de consultas), lo que debería mejorar aún más la experiencia de búsqueda en la web de los usuarios. Agradecimientos Agradecemos a Chris Burges y Matt Richardson por una implementación de RankNet para nuestros experimentos. También agradecemos a Robert Ragno por sus valiosas sugerencias y muchas discusiones.8. Referencias [1] E. Agichtein, E. Brill, S. Dumais y R.Ragno, Aprender modelos de interacción de usuario para predecir las preferencias de los resultados de la búsqueda web. En Actas de la Conferencia de la ACM sobre Investigación y Desarrollo sobre Recuperación de Información (SIGIR), 2006 [2] J. Allan, Hard Track Descripción general en TREC 2003, Recuperación de alta precisión de los documentos, 2003 [3] R. Baeza-Yates y B.Ribeiro-Neto, Recuperación de información moderna, Addison-Wesley, 1999. [4] S. Brin y L. Page, La anatomía de un motor de búsqueda web hipertextual a gran escala, en los procedimientos de WWW, 1997 [5] C.J.C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender, Aprendiendo a clasificarse utilizando descenso de gradiente, en Actas de la Conferencia Internacional de Aprendizaje Machine, 2005 [6] D.M. Chickering, The WinMine Toolkit, Microsoft Technical Report MSR-TR-2002-103, 2002 [7] M. Claypool, D. Brown, P. Lee y M. Waseda. Inferir el interés del usuario. IEEE Internet Computing.2001 [8] S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White. Evaluar las medidas implícitas para mejorar la experiencia de búsqueda. En Transacciones ACM en Sistemas de Información, 2005 [9] J. Goecks y J. Shavlick. Aprender los intereses de los usuarios observando discretamente su comportamiento normal. En Actas del Taller IJCAI sobre aprendizaje automático para el filtrado de información.1999. [10] K Jarvelin y J. Kekalainen. IR Métodos de evaluación para recuperar documentos altamente relevantes. En Actas de la Conferencia ACM sobre Investigación y Desarrollo sobre Recuperación de Información (SIGIR), 2000 [11] T. Joachims, optimizando los motores de búsqueda utilizando datos de clics. En Actas de la Conferencia de ACM sobre Discovery y Datamining (Sigkdd), 2002 [12] T. Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay, interpretando con precisión los datos de clics como comentarios implícitos, procedimientos deLa Conferencia de ACM sobre investigación y desarrollo sobre recuperación de información (SIGIR), 2005 [13] T. Joachims, haciendo práctico el aprendizaje SVM a gran escala. Avances en los métodos del núcleo, en el aprendizaje de vectores de soporte, MIT Press, 1999 [14] D. Kelly y J. Teevan, Comentarios implícitos para inferir la preferencia del usuario: una bibliografía. En Sigir Forum, 2003 [15] J. Konstan, B. Miller, D. Maltz, J. Herlocker, L. Gordon y J. Riedl. Grouplens: aplicando filtrado colaborativo a Usenet News. En Communications of ACM, 1997. [16] M. morita e Y. shinoda, filtrado de información basado en el análisis de comportamiento del usuario y la mejor recuperación de texto de coincidencia. Actas de la Conferencia ACM sobre investigación y desarrollo sobre recuperación de información (SIGIR), 1994 [17] D. Oard y J. Kim. Comentarios implícitos para los sistemas de recomendación. En Actas del Taller AAAI sobre Sistemas de Recomendación.1998 [18] D. Oard y J. Kim. Modelado de contenido de información utilizando comportamiento observable. En Actas de la 64ª Reunión Anual de la Sociedad Americana de Ciencias y Tecnología de la Información.2001 [19] N. Pharo, N. y K. Järvelin. El método SST: una herramienta para analizar los procesos de búsqueda de información web. En Information Processing & Management, 2004 [20] P. Pirolli, El uso del aroma de información proximal para buscar contenido distal en la red mundial. Al trabajar con la tecnología en mente: Brunswikian. Recursos para la ciencia e ingeniería cognitiva, Oxford University Press, 2004 [21] F. Radlinski y T. Joachims, Cadenas de consulta: aprendiendo a clasificarse a partir de comentarios implícitos. En Actas de la Conferencia de ACM sobre descubrimiento de conocimiento y minería de datos (SIGKDD), 2005. [22] F. Radlinski y T. Joachims, evaluando la solidez del aprendizaje de los comentarios implícitos, en los procedimientos del taller ICML sobre el aprendizaje en la búsqueda en la web,2005 [23] S. E. Robertson, H. Zaragoza y M. Taylor, Extensión simple de BM25 a múltiples campos ponderados, en Actas de la Conferencia sobre Gestión de Información y Conocimiento (CIKM), 2004 [24] G. Salton y M. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, 1983 [25] E.M. Voorhees, D. Harman, Descripción general de Trec, 2001 [26] G.R. Xue, H.J. Zeng, Z. Chen, Y. Yu, W.Y. MA, W.S. XI y W.G. Fan, Optimización de la búsqueda web utilizando datos de clic en la web, en Actas de la Conferencia sobre Información y Gestión del Conocimiento (CIKM), 2004 [27] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC 13: pistas web y duras. En Actas de Trec 2004