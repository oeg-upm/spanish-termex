Control de superposición en la recuperación XML orientada al contenido Charles L. A. Clarke Escuela de Ciencias de la Computación, Universidad de Waterloo, Canadá claclark@plg.uwaterloo.ca Resumen La aplicación directa de las técnicas de clasificación estándar para recuperar elementos individuales de una colección de documentos XML a menudo produce un resultado que produce un resultado produce un resultado.establecido en el que los rangos superiores están dominados por una gran cantidad de elementos tomados de un pequeño número de documentos altamente relevantes. Este documento presenta y evalúa un algoritmo que vuelve a rangar este conjunto de resultados, con el objetivo de minimizar el contenido redundante al tiempo que preserva los beneficios de la recuperación de elementos, incluido el beneficio de identificar componentes centrados en el tema contenidos en documentos relevantes. La recopilación de pruebas desarrollada por la iniciativa para la evaluación de la recuperación de XML (INEX) forma la base de la evaluación. Categorías y descriptores de sujetos H.3.3 [Sistemas de información]: Algoritmos de Búsqueda y recuperación de información de almacenamiento de información y recuperación de términos generales, medición, rendimiento, experimentación 1. Introducción La representación de documentos en XML brinda la oportunidad de que los sistemas de recuperación de información aprovechen la estructura del documento, que devuelve los componentes de documentos individuales cuando sea apropiado, en lugar de documentos completos en todas las circunstancias. En respuesta a una consulta de usuario, un sistema de recuperación de información XML podría devolver una mezcla de párrafos, secciones, artículos, entradas bibliográficas y otros componentes. Esta instalación es de particular beneficio cuando una colección contiene documentos muy largos, como manuales o libros de productos, donde el usuario debe dirigirse a las partes más relevantes de estos documentos.<artículo> <fm> <tl> Compresión de texto para bases de datos de documentos dinámicos </ttl> <au> Alistair Moffat </au> <au> Justin Zobel </au> <au> Neil Sharman </au> <ens> <ens> <ens>P> <b> Abstract </b> para ... </p> </sbs> </fm> <bdy> <sec> <st> Introducción </st> <p1> bases de datos de documentos modernos ... </ip1> <p> Hay buenas razones para comprimir ... </p> </ec> <ec> <s> Reducción de los requisitos de memoria </st> ... <ss1> <st> 2.1 Método A <//ST> ... </ec> ... </bdy> </artículo> Figura 1: Un artículo de revista codificado en XML. La Figura 1 proporciona un ejemplo de un artículo de revista codificado en XML, que ilustra muchas de las características importantes de los documentos XML. Las etiquetas indican el principio y el final de cada elemento, con elementos que varían ampliamente en tamaño, de una palabra a miles de palabras. Algunos elementos, como párrafos y secciones, pueden presentarse razonablemente al usuario como resultados de recuperación, pero otros no son apropiados. Los elementos se superponen entre sí: los artículos contienen secciones, las secciones contienen subsecciones y las subsecciones contienen párrafos. Cada una de estas características afecta el diseño de un sistema IR XML, y cada uno conduce a problemas fundamentales que deben resolverse en un sistema exitoso. La mayoría de estos problemas fundamentales se pueden resolver a través de la cuidadosa adaptación de las técnicas IR estándar, pero los problemas causados por la superposición son exclusivos de esta área [4,11] y forman el enfoque principal de este documento. El artículo de la Figura 1 puede verse como un árbol XML, como se ilustra en la Figura 2. Formalmente, una colección de documentos XML puede representarse como un bosque de árboles ordenados y enraizados, que consiste en un conjunto de nodos N y un conjunto de bordes E dirigidos que conecta estos nodos. Para cada nodo x ∈ N, la notación X.Parent se refiere al nodo principal de X, si existe, y la notación X. Los niños se refieren al conjunto de nodos infantiles Sec Bdyfm Atl Au Au ABS P B ST IP1 SEC ST SS1ST Artículo P Figura 2: Ejemplo de árbol XML.de x. Dado que un elemento puede estar representado por el nodo en su raíz, la salida de un sistema IR XML puede verse como una lista clasificada de los nodos TOP-M. La aplicación directa de una técnica de clasificación de relevancia estándar para un conjunto de elementos XML puede producir un resultado en el que los rangos superiores están dominados por muchos elementos estructuralmente relacionados. Es probable que una sección de alta puntuación contenga varios párrafos de alta puntuación y sea contenida en un artículo de alta puntuación. Por ejemplo, muchos de los elementos en la Figura 2 recibirían una puntuación alta en los algoritmos de compresión del índice de texto de consulta clave. Si cada uno de estos elementos se presenta a un usuario como un resultado individual y separado, puede perder un tiempo considerable revisando y rechazando contenido redundante. Una posible solución es informar solo el elemento de puntuación más alto a lo largo de una ruta determinada en el árbol, y eliminar de los rangos inferiores cualquier elemento que lo contenga, o contenido dentro de él. Desafortunadamente, este enfoque destruye algunos de los posibles beneficios de XML IR. Por ejemplo, un elemento exterior puede contener una cantidad sustancial de información que no aparece en un elemento interno, pero el elemento interno puede estar muy enfocado en el tema de la consulta y proporcionar una breve descripción de los conceptos clave. En tales casos, es razonable informar elementos que contienen o están contenidos en elementos de clasificación más altos. Incluso cuando un libro completo es relevante, un usuario aún puede desear que se resalten los párrafos más importantes, para guiar su lectura y ahorrar tiempo [6]. Este artículo presenta un método para controlar la superposición. Comenzando con una clasificación de elementos iniciales, un algoritmo de reanicación ajusta los puntajes de elementos de clasificación más bajos que contienen, o están contenidos, elementos de clasificación más altos, lo que refleja el hecho de que esta información ahora puede ser redundante. Por ejemplo, una vez que aparece un elemento que representa una sección en la clasificación, los puntajes para los párrafos que contiene y el artículo que lo contiene se reduce. La inspiración para esta estrategia proviene en parte del trabajo reciente en la recuperación de documentos estructurados, donde los términos que aparecen en diferentes campos, como el título y el cuerpo, tienen diferentes pesos [20]. Al extender ese enfoque, el algoritmo de reanimiento varía los pesos dinámicamente a medida que se procesan elementos. El resto del documento se organiza de la siguiente manera: después de una discusión sobre el trabajo de antecedentes y la metodología de evaluación, se presenta un método de recuperación de línea de base en la Sección 4. Este método de referencia representa una adaptación razonable de la tecnología IR estándar a XML. La Sección 5 describe una estrategia para controlar la superposición, utilizando el método de referencia como punto de partida. En la Sección 6 se presenta un algoritmo de reanupación que implementa esta estrategia y se evalúa en la Sección 7. La Sección 8 discute una versión extendida del algoritmo.2. Antecedentes Esta sección proporciona una descripción general de la recuperación de información XML y analiza el trabajo relacionado, con énfasis en los problemas fundamentales mencionados en la introducción. Mucha investigación en el área de la recuperación de XML lo ve desde una perspectiva de base de datos tradicional, que se ocupa de problemas como la implementación de lenguajes de consulta estructurados [5] y el procesamiento de las uniones [1]. Aquí, tomamos un perceptivo IR orientado al contenido, centrándonos en documentos XML que contienen principalmente datos y consultas del lenguaje natural que se expresan principalmente en el lenguaje natural. Suponemos que estas consultas indican solo la naturaleza del contenido deseado, no su estructura, y que el papel del sistema IR es determinar qué elementos satisfacen mejor la información subyacente. Otra investigación IR ha considerado consultas mixtas, en las que se especifican tanto el contenido como los requisitos estructurales [2,6,14,17,23].2.1 Estadísticas de término y documento en aplicaciones de recuperación de información tradicional La unidad de recuperación estándar se considera el documento. Dependiendo de la aplicación, este término podría interpretarse para abarcar muchos objetos diferentes, incluidas páginas web, artículos periodísticos y mensajes de correo electrónico. Al aplicar técnicas de clasificación de relevancia estándar en el contexto de XML IR, un enfoque natural es tratar cada elemento como un documento separado, con estadísticas de término disponibles para cada uno [16]. Además, la mayoría de las técnicas de clasificación requieren estadísticas globales (por ejemplo, frecuencia inversa de documentos) calculadas sobre la colección en su conjunto. Si consideramos que esta colección incluye todos los elementos que podrían ser devueltos por el sistema, una ocurrencia específica de un término puede aparecer en varios documentos diferentes, tal vez en elementos que representan un párrafo, una subsección, una sección y un artículo. No es apropiado calcular la frecuencia del documento inverso bajo el supuesto de que el término está contenido en todos estos elementos, ya que el número de elementos que contienen un término depende completamente de la disposición estructural de los documentos [13,23].2.2 Elementos recuperables Si bien un sistema IR XML podría recuperar cualquier elemento, muchos elementos pueden no ser apropiados como resultados de recuperación. Este suele ser el caso en que los elementos contienen muy poco texto [10]. Por ejemplo, un título de sección que contiene solo los términos de consulta puede recibir una puntuación alta de un algoritmo de clasificación, pero solo sería de valor limitado para un usuario, que podría preferir la sección real en sí. Otros elementos pueden reflejar la estructura física, en lugar de lógica, física, que puede tener poco o ningún significado para un usuario. Un sistema IR XML efectivo debe devolver solo aquellos elementos que tienen suficiente contenido para ser utilizables y pueden estar solo como objetos independientes [15,18]. Los componentes estándar de documentos, como párrafos, secciones, subsecciones y resúmenes, generalmente cumplen con estos requisitos;Los títulos, frases en cursiva y campos de metadatos individuales a menudo no.2.3 Metodología de evaluación En los últimos tres años, la iniciativa para la evaluación de la recuperación de XML (INEX) ha alentado la investigación sobre la tecnología de recuperación de información XML [7,8]. INEX es una serie de conferencias experimentales, similar a TREC, con grupos de diferentes instituciones que completan una o más tareas experimentales utilizando sus propias herramientas y sistemas, y comparando sus resultados en la conferencia misma. Más de 50 grupos participaron en INEX 2004, y la conferencia se ha vuelto tan influyente en el área de XML IR como TREC está en otras áreas IR. La investigación descrita en este documento, así como en gran parte del trabajo relacionado que cita, depende de las colecciones de prueba desarrolladas por INEX. La superposición causa problemas considerables con la evaluación de la recuperación, y los organizadores e participantes de INEX han luchado con estos problemas desde el principio. Si bien se han logrado un progreso sustancial, estos problemas aún no están completamente resueltos. Kazai et al.[11] proporcionan una exposición detallada del problema de superposición en el contexto de la evaluación de recuperación de INEX y discuten las métricas de evaluación actuales y propuestas. Muchas de estas métricas se aplican para evaluar los experimentos informados en este documento, y se describen brevemente en la siguiente sección.3. Las limitaciones de espacio de INEX 2004 impiden la inclusión de más de un breve resumen de las tareas de INEX 2004 y la metodología de evaluación. Para obtener información detallada, se deben consultar los procedimientos de la conferencia en sí [8].3.1 Tareas para las principales tareas experimentales, los participantes de INEX 2004 recibieron una colección de 12,107 artículos tomados de las revistas y revistas de las Sociedades de Computación IEEE entre 1995 y 2002. Cada documento está codificado en XML utilizando un DTD común, con el documento de las Figuras 1 y 2 que proporciona un ejemplo. En INEX 2004, las dos tareas experimentales principales fueron las tareas de recuperación ADHOC, investigando el rendimiento de los sistemas que buscan una colección estática utilizando temas previamente invisibles. Las dos tareas diferían en los tipos de temas que usaron. Para una tarea, la tarea de solo contenido o CO, los temas consisten en declaraciones cortas de lenguaje natural sin referencia directa a la estructura de los documentos en la colección. Para esta tarea, se requiere el sistema IR para seleccionar los elementos que se devolverán. Para la otra tarea, la tarea de contenido y estructura o CAS, los temas se escriben en un lenguaje de consulta XML [22] y contienen referencias explícitas a la estructura de documentos, que el sistema IR debe intentar satisfacer. Dado que el trabajo descrito en este documento se dirige a la tarea de solo contenido, donde el sistema IR no recibe orientación sobre los elementos para devolver, la tarea CAS se ignora en el resto de nuestra descripción. En 2004, los organizadores de la conferencia seleccionaron 40 nuevos temas de CO de las contribuciones proporcionadas por los participantes de la conferencia. Cada tema incluye una consulta de palabras clave breve, que es ejecutada sobre la colección por cada grupo participante en su propio sistema XML IR. Cada grupo podría presentar hasta tres carreras experimentales que consisten en los elementos M = 1500 superiores para cada tema.3.2 Evaluación de relevancia Dado que XML IR se refiere a la ubicación de los elementos que proporcionan una cobertura completa de un tema al tiempo que contiene la menor cantidad de información extraña posible, los juicios simples relevantes versus no relevantes no son suficientes. En cambio, los organizadores de INEX adoptaron dos dimensiones para una evaluación de relevancia: la dimensión de agotamiento refleja el grado en que un elemento cubre el tema, y la dimensión de especificidad refleja el grado en que un elemento se centra en el tema. Se usa una escala de cuatro puntos en ambas dimensiones. Por lo tanto, un elemento (3,3) es altamente exhaustivo y altamente específico, un elemento (1,3) es marginalmente exhaustivo y altamente específico, y un elemento (0,0) no es relevante. Se puede encontrar información adicional sobre la metodología de evaluación en Piwowarski y Lalmas [19], quienes proporcionan una justificación detallada.3.3 Métricas de evaluación La métrica de evaluación principal utilizada en INEX 2004 es una versión de precisión promedio media (MAP), ajustada por varias funciones de cuantización para dar diferentes pesos a diferentes elementos, dependiendo de sus valores de agotamiento y especificidad. Una variante, la función de cuantización estricta da un peso de 1 a (3,3) elementos y un peso de 0 a todos los demás. Esta variante es esencialmente el valor de mapa familiar, con (3,3) elementos tratados como relevantes y todos los demás elementos tratados como no relevantes. Otras funciones de cuantificación están diseñadas para dar crédito parcial a los elementos que están cerca de las fallas, debido a la falta o agotación y/o especificidad. Tanto la función de cuantización generalizada como los elementos de crédito de la función de generalización orientada a la especificidad (SOG) de acuerdo con su grado de relevancia [11], con la segunda función poniendo mayor énfasis en la especificidad. Este documento informa los resultados de esta métrica utilizando las tres funciones de cuantización. Dado que esta métrica se introdujo por primera vez en INEX 2002, generalmente se conoce como la métrica INEX-2002. La métrica INEX-2002 no penaliza la superposición. En particular, tanto las funciones de cuantización generalizada como la SOG dan crédito parcial a una fallas cercanas incluso cuando un elemento (3,3) que se superpone a él se informa en un rango más alto. Para abordar este problema, Kazai et al.[11] propone una métrica de ganancia acumulada por XML, que compara la ganancia acumulada [9] de una lista clasificada con un vector de ganancia ideal. Este vector de ganancia ideal se construye a partir de los juicios de relevancia al eliminar la superposición y retener solo el mejor elemento a lo largo de una ruta determinada. Por lo tanto, la recuperación de la métrica XCG corre que evitan la superposición. Si bien XCG no se usó oficialmente en INEX 2004, es probable que se use una versión en el futuro. En INEX 2003, se introdujo otra métrica para mejorar las limitaciones percibidas de la métrica INEX-2002. Esta métrica INEX-2003 extiende las definiciones de precisión y recuerdo para considerar tanto el tamaño de los componentes informados como la superposición entre ellos. Se crearon dos versiones, una que consideró solo el tamaño del componente y otra que consideró tanto el tamaño como la superposición. Si bien la métrica INEX-2003 exhibe anomalías indeseables [11], y no se usó en 2004, los valores se informan en la sección de evaluación para proporcionar un instrumento adicional para investigar la superposición.4. Método de recuperación de línea de base Esta sección proporciona una descripción general del método de recuperación de información XML de línea de base que se utiliza actualmente en el sistema IR multitexio, desarrollado por el grupo de recuperación de información en la Universidad de Waterloo [3]. Este método de recuperación resulta de la adaptación y ajuste de la medida Okapi BM25 [21] a la tarea de recuperación de información XML. El sistema MultiText se desempeñó respetablemente en INEX 2004, colocando en los diez primeros en todas las funciones de cuantización y colocando primero cuando la función de cuantización enfatizó la agotación. Para admitir la recuperación de XML y otros tipos de documentos estructurados, el sistema proporciona consultas generalizadas de la forma: Rango X por y donde X es un subcreidor que especifica un conjunto de elementos de documentos que se clasificarán y Y es un vector de subcreperias especificandoTérminos de recuperación individuales. Para nuestras ejecuciones de INEX 2004, el Sub-Query X especificó una lista de elementos recuperables como aquellos con nombres de etiquetas de la siguiente manera: Artículo de la aplicación ABS BB BDY BM Fig FM IP1 Li P Sec SS1 SS2 VT Esta lista incluye entradas bibliográficas (BB) y figurasubtítulos (Fig), así como párrafos, secciones y subsecciones. Antes de INEX 2004, la colección INEX y los juicios de relevancia de INEX 2003 se analizaron manualmente para seleccionar estos nombres de etiquetas. Los nombres de las etiquetas se seleccionaron sobre la base de su frecuencia en la colección, el tamaño promedio de sus elementos asociados y el número relativo de juicios de relevancia positiva que recibieron. La automatización de este proceso de selección se planifica como un trabajo futuro. Para INEX 2004, el término vector Y se derivó del tema dividiendo frases en palabras individuales, eliminando las palabras de parada y los términos negativos (aquellos que comienzan con -) y aplicando un Stemmer. Por ejemplo, el campo de palabras clave del tema 166 + Distancia de edición de árbol + XML -Image se convirtió en la consulta de cuatro términos $ Tree $ Edit $ Distancia $ XML donde el operador $ dentro de una cadena citada detiene el término que lo sigue. Nuestra implementación de Okapi BM25 se deriva de la fórmula de Robertson et al.[21] estableciendo parámetros k2 = 0 y k3 = ∞. Dado un conjunto de términos Q, se le asigna a un elemento x la puntuación t∈Q w (1) Qt (k1 + 1) xt k + xt (1) donde w (1) = log ¡d - dt + 0.5 dt + 0.5 ¢D = número de documentos en el corpus dt = número de documentos que contienen t qt = frecuencia que t ocurre en el tema xt = frecuencia que t ocurre en x k = k1 ((1 - b) + b · lx/lavg) lx =Longitud de x LAVG = Promedio del documento Longitud 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0 2 4 6 6 8 10 12 14 Media MediaB = 0.75 (temas de CO INEX 2003). Antes de INEX 2004, los temas y juicios de INEX 2003 se utilizaron para sintonizar los parámetros B y K1, y el impacto de esta sintonización se discute más adelante en esta sección. A los fines de calcular estadísticas a nivel de documento (D, DT y LAV), se define un documento como un artículo. Estas estadísticas se utilizan para clasificar todos los tipos de elementos. Después de la sugerencia de Kamps et al.[10], los resultados de la recuperación se filtran para eliminar elementos muy cortos, aquellos de menos de 25 palabras de longitud. El uso de estadísticas de artículo para todos los tipos de elementos podría ser cuestionado. Este enfoque puede justificarse al ver la colección como un conjunto de artículos que se buscarán utilizando técnicas estándar orientadas a documentos, donde solo se pueden devolver artículos. El puntaje calculado para un elemento es esencialmente el puntaje que recibiría si se agregara a la colección como un nuevo documento, ignorando los ajustes menores necesarios para las estadísticas a nivel de documento. No obstante, planeamos examinar este problema nuevamente en el futuro. En nuestra experiencia, el rendimiento de BM25 generalmente se beneficia de ajustar los parámetros B y K1 a la colección, siempre que las consultas de capacitación estén disponibles para este propósito. Antes de INEX 2004, capacitamos al sistema multitext utilizando las consultas INEX 2003. Como punto de partida, utilizamos los valores B = 0.75 y K1 = 1.2, que funcionan bien en las colecciones TREC ADHOC y se utilizan como valores predeterminados en nuestro sistema. Los resultados fueron sorprendentes. La Figura 3 muestra el resultado de K1 variable con B = 0.75 en los valores del MAP en tres funciones de cuantización. En nuestra experiencia, los valores óptimos para K1 se encuentran típicamente en el rango de 0.0 a 2.0. En este caso, se requieren grandes valores para un buen rendimiento. Entre K1 = 1.0 y K1 = 6.0, el mapa aumenta en más del 15% bajo la cuantificación estricta. Se observan mejoras similares bajo las cuantizaciones generalizadas y SOG. En contraste, nuestro valor predeterminado de B = 0.75 funciona bien en todas las funciones de cuantización (Figura 4). Después de sintonizar en un amplio rango de valores bajo varias funciones de cuantización, seleccionamos valores de k = 10.0 y b = 0.80 para nuestros experimentos INEX 2004, y estos valores se usan para los experimentos informados en la Sección 7. 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.130.14 0.15 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión mediana (INEX-2002) B estricto SOG generalizado Figura 4: Impacto de B en la precisión promedio media INEX-2002 con K1 = 10 (temas de CO INEX 2003).5. Control de superposición Comenzando con una clasificación de elementos generada por el método de línea de base descrito en la sección anterior, los elementos se vuelven a clasificar para controlar la superposición ajustando iterativamente las puntuaciones de los elementos contenidos o contenidos en elementos de clasificación más altos. En un nivel conceptual, el reanimiento del rango procede de la siguiente manera: 1. Informe el elemento de clasificación más alto.2. Ajuste los puntajes de los elementos no reportados.3. Repita los pasos 1 y 2 hasta que se informen los elementos M. Un enfoque para ajustar las puntuaciones de elementos no reportados en el Paso 2 podría basarse en las puntuaciones OKAPI BM25 de los elementos involucrados. Por ejemplo, suponga que un párrafo con puntaje P se informa en el paso 1. En el paso 2, la sección que contiene el párrafo podría tener su puntaje en una cantidad α · P para reflejar la contribución reducida que el párrafo debe hacer a la puntuación de las secciones. En un contexto relacionado, Robertson et al.[20] argumentan fuertemente contra la combinación lineal de las puntuaciones de Okapi de esta manera. Ese trabajo considera el problema de asignar diferentes pesos a diferentes campos de documentos, como el título y el cuerpo asociados con las páginas web. Un enfoque común para este problema puntúa el título y el cuerpo por separado y genera una puntuación final como una combinación lineal de los dos. Robertson et al.Discuta los defectos teóricos en este enfoque y demuestre experimentalmente que en realidad puede dañar la efectividad de la recuperación. En cambio, aplican los pesos al nivel de frecuencia del término, con una aparición de un término de consulta T en el título, lo que hace una mayor contribución a la puntuación que una ocurrencia en el cuerpo. En la ecuación 1, XT se convierte en α0 · yt + α1 · zt, donde yt es el número de veces que ocurre en el título y ZT es el número de veces que ocurre en el cuerpo. Traduciendo este enfoque a nuestro contexto, la contribución de los términos que aparecen en los elementos se reduce dinámicamente como se informa. La siguiente sección presenta y análisis un algoritmo de reanimiento simple que sigue esta estrategia. El algoritmo se evalúa experimentalmente en la Sección 7. Una limitación del algoritmo es que la contribución de los términos que aparecen en los elementos informados se reduce por el mismo factor independientemente del número de elementos informados en los que aparece. En la Sección 8, el algoritmo se extiende para aplicar pesos crecientes, reduciendo la puntuación, cuando un término aparece en más de un elemento informado.6. Algoritmo de rango El algoritmo de reanimiento funciona sobre árboles XML, como el que aparece en la Figura 2. La entrada al algoritmo es una lista de n elementos clasificados de acuerdo con sus puntajes iniciales de BM25. Durante la clasificación inicial, el árbol XML se reconstruye dinámicamente para incluir solo aquellos nodos con puntajes BM25 distintos de cero, por lo que N puede ser considerablemente menor que | n |. La salida del algoritmo es una lista de los principales elementos M, clasificado de acuerdo con sus puntajes ajustados. Un elemento está representado por el nodo x ∈ N en su raíz. Asociados con este nodo están los campos que almacenan la longitud del elemento, las frecuencias de término y otra información requerida por el algoritmo de re -rango, de la siguiente manera: X.F - Vector de frecuencia de término X.G - Ajustes de frecuencia de término X.L - Longitud de elementos X. -H -S -Según Okapi BM25puntaje X. Reportado - BOOLEAN BLAG, inicialmente falso X.Children - Conjunto de nodos infantiles X.Parent - Nodo principal, si existe uno, estos campos están poblados durante el proceso de clasificación inicial y se actualizan a medida que avanza el algoritmo. El Vector X.F contiene información de frecuencia de término correspondiente a cada término en la consulta. El Vector X.G es inicialmente cero y es actualizado por el algoritmo a medida que se informan elementos. El campo de puntuación contiene la puntuación BM25 actual para el elemento, que cambiará a medida que los valores en X.G cambian. La puntuación se calcula utilizando la Ecuación 1, con el valor XT para cada término determinado por una combinación de los valores en X.F y X.G. Dado un término t ∈ Q, deje que FT sea el componente de X.F correspondiente a t, y sea GT el componente de x.g correspondiente a t, entonces: xt = ft-α · gt (2) para procesarse por el algoritmo de re-rangoLos nodos se almacenan en colas prioritarias, ordenadas al disminuir la puntuación. Cada cola prioritaria PQ admite tres operaciones: PQ.Front () - Devuelve el nodo con la mejor puntuación PQ.Add (X) - Agrega el nodo X a la cola PQ.Remove (X) - Elimina el nodo X de la cola cuando se implementa usando estándarEstructuras de datos, la operación frontal requiere o (1) tiempo, y las otras operaciones requieren tiempo O (log n), donde n es el tamaño de la cola. El núcleo del algoritmo de rango se presenta en la Figura 5. El algoritmo toma como entrada la cola de prioridad s que contiene la clasificación inicial, y produce los nodos reorganizados de TOP-M en la cola prioritaria F. Después de inicializar F para estar vacía en la línea 1, el algoritmo es m veces sobre las líneas 215, transfiriendo al menosun nodo de S a F durante cada iteración. Al comienzo de cada iteración, el nodo no declarado en la parte delantera de S tiene la mayor puntuación ajustada, y se elimina y se agrega a F. El algoritmo luego atraviesa el 1 F ← ∅ 2 para i ← 1 a m Do 3 x ←S.front () 4 s.remove (x) 5 x. reportado ← verdadero 6 f.add (x) 7 8 foreach y ∈ X.Children do 9 hacia abajo (y) 10 End haz 11 12 si x no es una raíznodo luego 13 arriba (x, x.parent) 14 final Si 15 fin de la Figura 5: algoritmo de reanimiento: como entrada, el algoritmo toma una cola de prioridad S, que contiene nodos XML clasificados por sus puntajes iniciales, y devuelve sus resultados encola prioritaria F, clasificada por puntajes ajustados.1 up (x, y) ≡ 2 s.remove (y) 3 y.g ← y.g + x.f - x.g 4 recomputar y.score 5 s.add (y) 6 si y no es un nodo raíz, entonces 7 up (x, y.Parent) 8 Fin si 9 10 hacia abajo (x) ≡ 11 si no x. Reportado entonces 12 S.Remove (x) 14 X.g ← X.F 15 Recomputar x.score 16 if x.score> 0 entonces 17 f.add (x) 18 Fin si 19 X. Informado ← Verdadero 20 foreach y ∈ X. Los niños hacen 21 hacia abajo (y) 22 Fin Do 23 End si Figura 6: Rutinas transversales del árbol llamadas por el algoritmo de rehabilitación.0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.6 0.7 0.8 0.9 1.0 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 Media) MAP (SOG) XCG (SOG2) Figura 7: Impacto de α en XCG e INEX-2002 MAP (temas de CO INEX 2004; conjunto de evaluación I).Andos antepasados (líneas 8-10) y descendientes (líneas 12-14) que ajustan las puntuaciones de estos nodos. Las rutinas transversales del árbol, arriba y abajo se dan en la Figura 6. La rutina UP elimina cada nodo del antepasado de S, ajusta sus valores de frecuencia de término, recomputa su puntaje y lo agrega nuevamente a S. El ajuste de los valores de frecuencia del término (línea 3) se suma a Y.G solo las ocurrencias de término previamente no reportadas en x.La recomputación de la puntuación en la línea 4 usa las ecuaciones 1 y 2. La rutina hacia abajo realiza una operación similar en cada descendiente. Sin embargo, dado que el contenido de cada descendiente está completamente contenido en un elemento informado, su puntaje final puede calcularse, y se elimina de S y se agrega a F. Para determinar la complejidad del tiempo del algoritmo, primero nota que un nodo puedeSea un argumento a lo máximo una vez. A partir de entonces, la bandera reportada de su padre es verdadera. Durante cada llamada a abajo, un nodo puede moverse de S a F, lo que requiere el tiempo O (log n). Por lo tanto, el tiempo total para todas las llamadas a Down es o (n log n), y podemos ignorar temporalmente las líneas 8-10 de la Figura 5 al considerar la complejidad del tiempo del bucle sobre las líneas 2-15. Durante cada iteración de este bucle, un nodo y cada uno de sus antepasados se eliminan de una cola de prioridad y luego se agregan nuevamente a una cola de prioridad. Dado que un nodo puede tener en la mayoría de los antepasados H, donde H es la altura máxima de cualquier árbol en la colección, cada una de las intensiones requiere tiempo O (H log n). La combinación de estas observaciones produce una complejidad de tiempo general de log N ((n + mh) log n). En la práctica, volver a clasificar un conjunto de resultados de INEX requiere menos de 200 ms en una PC de escritorio de tres años.7. Evaluación Ninguna de las métricas descritas en la Sección 3.3 es un ajuste cercano con la vista de la superposición defendida por este documento. No obstante, cuando se unen, proporcionan información sobre el comportamiento del algoritmo de reanimiento. Los paquetes de evaluación INEX (INEX_EVAL e INEX_EVAL_NG) se usaron para calcular valores para las métricas INEX-2002 e INEX-2003. Los valores para las métricas XCG se calcularon utilizando software suministrado por sus inventores [11]. La Figura 7 traza las tres variantes de la métrica del mapa INEX-2002 junto con la métrica XCG. Valores para estas métricas 0.0 0.0 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.0 0.1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Precisión mediaConsiderado Figura 8: Impacto de α en el mapa INEX-2003 (temas de CO INEX 2004; conjunto de evaluación I).se trazan para valores de α entre 0.0 y 1.0. Recordando que la métrica XCG está diseñada para penalizar la superposición, mientras que la métrica INEX-2002 ignora la superposición, el conflicto entre las métricas es obvio. Los valores de MAP en un valor extremo (α = 0.0) y el valor XCG en el otro extremo (α = 1.0) representan un rendimiento de recuperación comparable a los mejores sistemas en INEX 2004 [8,12]. Figura 8 Los valores de los gráficos de la métrica del mapa INEX-2003 para dos cuantizaciones, con y sin consideración de superposición. Una vez más, el conflicto es evidente, con la influencia de α sustancialmente disminuida cuando se considera la superposición.8. Algoritmo extendido Una limitación del algoritmo de reanimiento es que se usa un solo peso α para ajustar las puntuaciones de los antepasados y descendientes de los elementos informados. Una extensión obvia es usar diferentes pesos en estos dos casos. Además, el mismo peso se usa independientemente del número de veces que un elemento se contiene en un elemento informado. Por ejemplo, un párrafo puede formar parte de una sección informada y luego formar parte de un artículo informado. Dado que el usuario ahora puede haber visto este párrafo dos veces, su puntaje debe reducirse aún más al aumentar el valor del peso. Motivado por estas observaciones, el algoritmo de reango puede extenderse con una serie de pesos 1 = β0 ≥ β1 ≥ β2 ≥ ... ≥ βm ≥ 0. donde βj es el peso aplicado a un nodo que ha sido descendiente de unNodo J Times informado. Tenga en cuenta que un límite superior en M es H, la altura máxima de cualquier árbol XML en la colección. Sin embargo, en la práctica M es probable que M sea relativamente pequeño (quizás 3 o 4). La Figura 9 presenta reemplazos para las rutinas ascendentes de la Figura 6, incorporando esta serie de pesos. Se requiere un campo adicional en cada nodo, de la siguiente manera: X.J - Cuenta hacia abajo El valor de X.J se establece inicialmente en cero en todos los nodos y se incrementa cada vez que se llama con X como argumento. Al calcular la puntuación del nodo, el valor de x.j selecciona 1 up (x, y) ≡ 2 si no Y. reportado, entonces 3 s.remove (y) 4 y.g ← y.g + x.f - x.g 5 recomputar y. -anotación 6 S.Agregue (y) 8 Si y no es un nodo raíz, entonces 9 hacia arriba (x, y.parent) 10 final si 11 termina si 12 13 hacia abajo (x) ≡ 14 si x.j <m entonces 15 x.j ← x.j + 1 16 si noX. Reportado luego 17 S.Remove (x) 18 Recompute X.Score 19 S.Add (x) 20 Fin Si 21 foreach y ∈ X. Los niños hacen 22 hacia abajo (y) 23 Fin Hacer 24 End si Figura 9: Árbol extendidoRutinas de transversal.El peso que se aplicará al nodo ajustando el valor de XT en la ecuación 1, de la siguiente manera: XT = βx.j · (ft - α · gt) (3) donde Ft y Gt son los componentes de X.F y X.G correspondientes atérmino t.Se requieren algunos cambios adicionales para extenderse hacia arriba y hacia abajo. La rutina UP retornos inmediatamente (línea 2) si su argumento ya se ha informado, ya que las frecuencias de términos ya se han ajustado en sus antepasados. La rutina de abajo no informa su argumento, sino que recomputa su puntaje y la agrega nuevamente a S. Un nodo no puede ser un argumento a la baja más de M +1 veces, lo que a su vez implica una complejidad de tiempo general de O ((NM +mh) log n). Como M ≤ H y M ≤ N, la complejidad del tiempo también es O (NH log n).9. Discusión final Al generar resultados de recuperación en una colección XML, se debe tolerar algunas superposiciones en los resultados y puede ser beneficioso. Por ejemplo, cuando un elemento altamente exhaustivo y bastante específico (3,2) contiene un elemento mucho más pequeño (2,3), ambos deben informarse al usuario, y los algoritmos de recuperación y las métricas de evaluación deberían respetar esta relación. El algoritmo presentado en este documento Controles se superpone ponderando los términos que ocurren en los elementos informados para reflejar su importancia reducida. Otros enfoques también pueden ayudar a controlar la superposición. Por ejemplo, cuando los resultados de recuperación de XML se presentan a los usuarios, puede ser deseable agrupar elementos estructuralmente relacionados juntos, ilustrando visualmente las relaciones entre ellos. Si bien este estilo de interfaz de usuario puede ayudar a un usuario a hacer frente a la superposición, la estrategia presentada en este documento continúa siendo aplicable, determinando los mejores elementos para incluir en cada clúster. En Waterloo, seguimos desarrollando y probando nuestras ideas para INEX 2005. En particular, estamos investigando métodos para aprender los pesos α y βJ. También estamos reevaluando nuestro enfoque para documentar las estadísticas y examinar los ajustes apropiados al parámetro K1 a medida que cambian los pesos de término [20].10. Agradecimientos gracias a Gabriella Kazai y Arjen de Vries por proporcionar una versión temprana de su software para calcular la métrica XCG, y gracias a Phil Tilker y Stefan B¨uttcher por su ayuda con la evaluación experimental. En parte, IBM Canada proporcionó fondos para este proyecto a través del Instituto Nacional de Investigación de Software.11. Referencias [1] N. Bruno, N. Koudas y D. Srivastava. Holistic Twig se une: coincidencia óptima del patrón XML. En Actas de la Conferencia Internacional ACM Sigmod 2002 sobre la gestión de los datos, páginas 310-321, Madison, Wisconsin, junio de 2002. [2] D. Carmel, Y. S. Maarek, M. Mandelbrod, Y. Misa, y A. Soffer. Buscando documentos XML a través de fragmentos XML. En Actas de la 26ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 151-158, Toronto, Canadá, 2003. [3] C. L. A. Clarke y P. L. Tilker. Experimentos de múltiplesext para INEX 2004. En Inex 2004 Workshop Proceedings, 2004. Publicado en LNCS 3493 [8].[4] A. P. de Vries, G. Kazai y M. Lalmas. Tolerancia a la irrelevancia: una evaluación orientada al esfuerzo del usuario de los sistemas de recuperación sin unidad de recuperación predefinida. En RIAO 2004 Actas de la Conferencia, páginas 463-473, Avignon, Francia, abril de 2004. [5] D. Dehaan, D. Toman, M. P. Consens y M. T. ¨ozsu. Una XQuery completa a la traducción de SQL utilizando la codificación de intervalo dinámico. En Actas de la Conferencia Internacional Sigmod de ACM de 2003 sobre la gestión de los datos, San Diego, junio de 2003. [6] N. Fuhr y K. Großjohann. XIRQL: un idioma de consulta para la recuperación de información en documentos XML. En Actas de la 24ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 172-180, Nueva Orleans, septiembre de 2001. [7] N. Fuhr, M. Lalmas y S. Malik, editores. Iniciativa para la evaluación de la recuperación XML. Actas del segundo taller (INEX 2003), Dagstuhl, Alemania, diciembre de 2003. [8] N. Fuhr, M. Lalmas, S. Malik y Zolt´an Szl´avik, editores. Iniciativa para la evaluación de la recuperación XML. Actas del tercer taller (INEX 2004), Dagstuhl, Alemania, diciembre de 2004. Publicado como avances en la recuperación de información XML, Notas de conferencias en informática, Volumen 3493, Springer, 2005. [9] K. J¨avelin y J. Kek¨al¨ainen. Evaluación basada en ganancias acumuladas de técnicas IR. Transacciones ACM en Sistemas de Información, 20 (4): 422-446, 2002. [10] J. Kamps, M. de Rijke y B. Sigurbj¨ornsson. Normalización de longitud en la recuperación XML. En Actas de la 27ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 80-87, Sheffield, Reino Unido, julio de 2004. [11] G. Kazai, M. Lalmas y A. P. De Vries. El problema de superposición en la evaluación de recuperación XML orientada al contenido. En Actas de la 27ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 72-79, Sheffield, Reino Unido, julio de 2004. [12] G. Kazai, M. Lalmas y A. P. de Vries. Pruebas de confiabilidad para las métricas XCG e INEX-2002. En Inex 2004 Workshop Proceedings, 2004. Publicado en LNCS 3493 [8].[13] J. Kek¨al¨ainen, M. Junkkari, P. arvola y T. Aalto. Trix 2004 - Luchando con la superposición. En Inex 2004 Workshop Proceedings, 2004. Publicado en LNCS 3493 [8].[14] S. Liu, Q. Zou y W. W. Chu. Indexación y clasificación configurables para la recuperación de información XML. En Actas de la 27ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 88-95, Sheffield, Reino Unido, julio de 2004. [15] Y. Mass y M. Mandelbrod. Recuperando los componentes XML más relevantes. En los procedimientos del taller de INEX 2003, Dagstuhl, Alemania, diciembre de 2003. [16] Y. Mass y M. Mandelbrod. Clasificación de componentes y refinamiento de consulta automática para recuperación de XML. En Inex 2004 Workshop Proceedings, 2004. Publicado en LNCS 3493 [8].[17] P. Ogilvie y J. Callan. Modelos de lenguaje jerárquico para la recuperación de componentes XML. En Inex 2004 Workshop Proceedings, 2004. Publicado en LNCS 3493 [8].[18] J. Pehcevski, J. A. Thom y A. Vecoustre. Recuperación de XML híbrida re-visitada. En Inex 2004 Workshop Proceedings, 2004. Publicado en LNCS 3493 [8].[19] B. Piwowarski y M. Lalmas. Proporcionando evaluaciones de relevancia consistentes y exhaustivas para la evaluación de recuperación de XML. En Actas de la 13ª Conferencia de ACM sobre Gestión de Información y Conocimiento, páginas 361-370, Washington, DC, noviembre de 2004. [20] S. Robertson, H. Zaragoza y M. Taylor. Extensión simple de BM25 a múltiples campos ponderados. En Actas de la 13ª Conferencia ACM sobre Gestión de Información y Conocimiento, páginas 42-50, Washington, DC, noviembre de 2004. [21] S. E. Robertson, S. Walker y M. Beaulieu. OKAPI en TREC-7: AD-HOC automático, filtrado, VLC y pista interactiva. En Actas de la Séptima Conferencia de Recuperación de Textos, Gaithersburg, MD, noviembre de 1998. [22] A. Trotman y B. Sigurbj¨ornsson. Nexi, ahora y siguiente. En Inex 2004 Workshop Proceedings, 2004. Publicado en LNCS 3493 [8].[23] J. Vittaut, B. Piwowarski y P. Gallinari. Un álgebra para consultas estructuradas en redes bayesianas. En Inex 2004 Workshop Proceedings, 2004. Publicado en LNCS 3493 [8].