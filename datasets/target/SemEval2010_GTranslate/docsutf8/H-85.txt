Learning User Interaction Models for Predicting Web Search Result Preferences Eugene Agichtein Microsoft Research eugeneag@microsoft.com Eric Brill Microsoft Research brill@microsoft.com Susan Dumais Microsoft Research sdumais@microsoft.com Robert Ragno Microsoft Research rragno@microsoft.com ABSTRACT Evaluating user preferencesde los resultados de búsqueda web es crucial para el desarrollo, la implementación y el mantenimiento del motor de búsqueda. Presentamos un estudio del mundo real sobre el modelado del comportamiento de los usuarios de búsqueda web para predecir las preferencias de los resultados de la búsqueda web. El modelado y la interpretación precisos del comportamiento del usuario tienen aplicaciones importantes para clasificar, hacer clic en la detección de spam, la personalización de la búsqueda web y otras tareas. Nuestra idea clave para mejorar la robustez de la interpretación de la retroalimentación implícita es modelar las desviaciones dependientes de la consulta del comportamiento del usuario ruidoso esperado. Mostramos que nuestro modelo de interpretación de clics mejora la precisión de la predicción sobre los métodos de clics de última generación. Generalizamos nuestro enfoque para modelar el comportamiento del usuario más allá de Clickthrough, lo que da como resultado una mayor precisión de predicción de preferencias que los modelos basados solo en la información de clics. Reportamos los resultados de una evaluación experimental a gran escala que muestran mejoras sustanciales sobre los métodos de interpretación de retroalimentación implícitos publicados. Categorías y descriptores de sujetos H.3.3 [Búsqueda y recuperación de información]: proceso de búsqueda, comentarios de relevancia. Algoritmos de términos generales, medición, rendimiento, experimentación.1. Introducción La medición de relevancia es crucial para la búsqueda web y para la recuperación de la información en general. Tradicionalmente, la relevancia de búsqueda se mide mediante el uso de asesores humanos para juzgar la relevancia de los pares de documentos de consulta. Sin embargo, las calificaciones humanas explícitas son costosas y difíciles de obtener. Al mismo tiempo, millones de personas interactúan diariamente con los motores de búsqueda web, proporcionando comentarios valiosos implícitos a través de sus interacciones con los resultados de búsqueda. Si pudiéramos convertir estas interacciones en juicios de relevancia, podríamos obtener grandes cantidades de datos para evaluar, mantener y mejorar los sistemas de recuperación de información. Recientemente, la retroalimentación de relevancia automática o implícita se ha convertido en un área activa de investigación en la comunidad de recuperación de información, al menos en parte debido a un aumento en los recursos disponibles y a la creciente popularidad de la búsqueda web. Sin embargo, la mayoría del trabajo de IR tradicional se realizó sobre colecciones de pruebas controladas y conjuntos de consultas y tareas cuidadosamente seleccionadas. Por lo tanto, no está claro si estas técnicas funcionarán para la búsqueda web general del mundo real. Una distinción significativa es que la búsqueda web no está controlada. Los usuarios individuales pueden comportarse irracionalmente o maliciosamente, o ni siquiera ser usuarios reales;Todo esto afecta los datos que se pueden recopilar. Pero la cantidad de los datos de interacción del usuario es órdenes de magnitud más grandes que cualquier cosa disponible en una configuración de búsqueda no WEB. Al utilizar el comportamiento agregado de grandes cantidades de usuarios (y no tratar a cada usuario como un experto individual), podemos corregir el ruido inherente a las interacciones individuales y generar juicios de relevancia que son más precisos que las técnicas no diseñadas específicamente para la configuración de búsqueda web. Además, las observaciones y las ideas obtenidas en entornos de laboratorio no necesariamente se traducen en uso del mundo real. Por lo tanto, es preferible inducir automáticamente estrategias de interpretación de retroalimentación de grandes cantidades de interacciones del usuario. Aprender automáticamente a interpretar el comportamiento del usuario permitiría a los sistemas adaptarse a las condiciones cambiantes, cambiar los patrones de comportamiento del usuario y diferentes configuraciones de búsqueda. Presentamos técnicas para interpretar automáticamente el comportamiento colectivo de los usuarios que interactúan con un motor de búsqueda web para predecir las preferencias de los usuarios para los resultados de búsqueda. Nuestras contribuciones incluyen: • Un modelo distributivo de comportamiento del usuario, robusto para el ruido dentro de las sesiones de usuarios individuales, que pueden recuperar las preferencias de relevancia de las interacciones del usuario (Sección 3).• Extensiones de estrategias de clic existentes para incluir características de navegación e interacción más ricas (Sección 4).• Una evaluación exhaustiva de nuestros modelos de comportamiento del usuario, así como de técnicas de última generación publicadas anteriormente, en un gran conjunto de sesiones de búsqueda web (Secciones 5 y 6). Discutimos nuestros resultados y describimos las direcciones futuras y varias aplicaciones de este trabajo en la Sección 7, lo que concluye el documento.2. Antecedentes y resultados de búsqueda de clasificación de trabajo relacionados es un problema fundamental en la recuperación de la información. Los enfoques más comunes en el contexto de la web utilizan tanto la similitud de la consulta al contenido de la página como la calidad general de una página [3, 20]. Un motor de búsqueda de última generación puede usar cientos de características para describir una página candidata, empleando algoritmos sofisticados para clasificar las páginas en función de estas características. Los motores de búsqueda actuales se ajustan comúnmente a los juicios de relevancia humana. Los anotadores humanos califican un conjunto de páginas para una consulta de acuerdo con la relevancia percibida, creando el estándar de oro contra el cual se pueden evaluar diferentes algoritmos de clasificación. Reducir la dependencia de los juicios humanos explícitos mediante el uso de la retroalimentación de relevancia implícita ha sido un tema activo de investigación. Varios grupos de investigación han evaluado la relación entre las medidas implícitas y el interés del usuario. En estos estudios, se recopilan tanto el tiempo de lectura como las calificaciones explícitas de interés. Morita y Shinoda [14] estudiaron la cantidad de tiempo que los usuarios pasaron los artículos de noticias de Usenet y descubrieron que el tiempo de lectura podría predecir los niveles de interés de los usuarios. Konstan et al.[13] mostraron que el tiempo de lectura era un fuerte predictor de interés de los usuarios en su sistema Grouplens. Oard y Kim [15] estudiaron si la retroalimentación implícita podría sustituir las calificaciones explícitas en los sistemas de recomendación. Más recientemente, Oard y Kim [16] presentaron un marco para caracterizar los comportamientos de los usuarios observables utilizando dos dimensiones, el propósito subyacente del comportamiento observado y el alcance del elemento que se actúa. Goecks y Shavlik [8] se aproximaron a las etiquetas humanas mediante la recolección de un conjunto de medidas de actividad de la página mientras los usuarios navegaron por la red mundial. Los autores plantearon la hipótesis de correlaciones entre un alto grado de actividad de página y un interés de los usuarios. Si bien los resultados fueron prometedores, el tamaño de la muestra fue pequeño y las medidas implícitas no se probaron contra juicios explícitos de interés del usuario. Claypool et al.[6] estudiaron cómo varias medidas implícitas se relacionaron con los intereses del usuario. Desarrollaron un navegador personalizado llamado Curious Browser para recopilar datos, en un laboratorio de computación, sobre indicadores de intereses implícitos y para investigar los juicios explícitos de las páginas web visitadas. Claypool et al.descubrió que el tiempo dedicado a una página, la cantidad de desplazamiento en una página y la combinación de tiempo y desplazamiento tienen una relación positiva fuerte con un interés explícito, mientras que los métodos de desplazamiento individual y los clics del mouse no estaban correlacionados con un interés explícito. Fox et al.[7] exploró la relación entre medidas implícitas y explícitas en la búsqueda web. Construyeron un navegador instrumentado para recopilar datos y luego desarrollaron modelos bayesianos para relacionar medidas implícitas y juicios de relevancia explícita tanto para consultas individuales como para las sesiones de búsqueda. Descubrieron que el clic era la variable individual más importante, pero que la precisión predictiva podría mejorarse mediante el uso de variables adicionales, en particular el tiempo de permanencia en una página. Joachims [9] desarrolló información valiosa sobre la recopilación de medidas implícitas, introduciendo una técnica basada completamente en datos de clic para aprender funciones de clasificación. Más recientemente, Joachims et al.[10] presentó una evaluación empírica de la interpretación de la evidencia de clics. Al realizar estudios de seguimiento ocular y correlacionar las predicciones de sus estrategias con calificaciones explícitas, los autores mostraron que es posible interpretar con precisión los eventos de clic en un entorno de laboratorio controlado. Una descripción más completa de los estudios de medidas implícitas se describe en Kelly y Teevan [12]. Desafortunadamente, la medida en que la investigación existente se aplica a la búsqueda web del mundo real no está claro. En este documento, construimos una investigación previa para desarrollar modelos de interpretación de comportamiento del usuario sólidos para la configuración de búsqueda web real.3. Aprender los modelos de comportamiento del usuario, como señalamos anteriormente, el comportamiento real del usuario de la búsqueda web real puede ser ruidoso en el sentido de que los comportamientos del usuario solo están probabilísticamente relacionados con juicios y preferencias de relevancia explícita. Por lo tanto, en lugar de tratar a cada usuario como un experto confiable, agregamos información de muchos rastros de sesión de búsqueda de usuarios poco confiables. Nuestro enfoque principal es modelar el comportamiento de búsqueda web del usuario como si fuera generado por dos componentes: un componente de relevancia - comportamiento específico de consulta influenciado por la relevancia de los resultados aparente y un componente de fondo - usuarios que hacen clic indiscriminadamente. Nuestra idea general es modelar las desviaciones del comportamiento esperado del usuario. Por lo tanto, además de las características básicas, que describiremos en detalle en la Sección 3.2, calculamos las características derivadas que miden la desviación del valor de características observadas para un resultado de búsqueda dado de los valores esperados para un resultado, sin información dependiente de la consulta. Motivamos nuestras intuiciones con una característica de comportamiento particularmente importante, el clic de resultados, analizado a continuación y luego presentamos nuestro modelo general de comportamiento del usuario que incorpora otras acciones del usuario (Sección 3.2).3.1 Un estudio de caso en distribuciones de clics Como discutimos, agregamos estadísticas en muchas sesiones de usuario. Un clic en un resultado puede significar que algún usuario encontró el resumen del resultado prometedor;También podría ser causado por personas haciendo clic indiscriminadamente. En general, el comportamiento individual del usuario, el clic y de otro modo, es ruidoso y no se puede confiar en juicios de relevancia precisos. El conjunto de datos se describe con más detalle en la Sección 5.2. Por el presente, es suficiente tener en cuenta que nos centramos en una muestra aleatoria de 3.500 consultas que fueron muestreadas aleatoriamente de los registros de consulta. Para estas consultas agregamos datos de clic en más de 120,000 búsquedas realizadas durante un período de tres semanas. También tenemos juicios de relevancia explícita para los 10 mejores resultados para cada consulta. La Figura 3.1 muestra la frecuencia de clic relativo en función de la posición de resultado. La frecuencia de clics agregada en la posición del resultado P se calcula primero calculando la frecuencia de un clic en P para cada consulta (es decir, aproximando la probabilidad de que un clic elegido al azar para esa consulta aterrice en la posición P). Estas frecuencias se promedian a través de consultas y se normalizan para que la frecuencia relativa de un clic en la posición superior sea 1. La distribución resultante está de acuerdo con observaciones anteriores en que los usuarios hacen clic más a menudo en los resultados de alto rango. Esto refleja el hecho de que los motores de búsqueda hacen un trabajo razonable de clasificar los resultados, así como los sesgos para hacer clic en los resultados superiores y al ruido, intentamos separar estos componentes en el análisis que sigue.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 3 5 7 9 11 13 15 17 1911 21 23 25 27 27 29 Posición de resultado Relativa Primero consideramos la distribución de clics para los documentos relevantes para estas consultas. La Figura 3.2 informa la distribución agregada de clics para consultas con una posición variable del documento relevante (PTR). Si bien hay muchos clics por encima del primer documento relevante para cada distribución, hay claramente picos en la frecuencia de clics para el primer resultado relevante. Por ejemplo, para las consultas con el resultado más relevante en la posición 2, la frecuencia de clics relativo en esa posición (segunda barra) es mayor que la frecuencia de clic en otras posiciones para estas consultas. Sin embargo, muchos usuarios todavía hacen clic en los resultados no relevantes en la posición 1 para tales consultas. Esto muestra una propiedad más fuerte del sesgo en la distribución de clics hacia los mejores resultados: los usuarios hacen clic más a menudo en los resultados que se clasifican más alto, incluso cuando no son relevantes.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 2 3 5 10 Posición de resultado RelativeclickFrequency PTR = 1 PTR = 2 PTR = 3 PTR = 5 PTR = 10 Figura 3.2: Frecuencia de clic relativo para consultas con PTR variable (posición de TOP de arribaDocumento relevante).-0.06 -0.04 -0.0.02 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 1 2 3 5 10 Posición de resultado correcciónPTR (posición de la parte superior relevante). Si restamos la distribución de fondo de la Figura 3.1 de la distribución mixta de la Figura 3.2, obtenemos la distribución en la Figura 3.3, donde la distribución de frecuencia de clics restante puede interpretarse como el componente de relevancia de los resultados. Tenga en cuenta que la distribución de clics corregido se correlaciona estrechamente con la relevancia del resultado real según lo explícitamente calificado por los jueces humanos.3.2 Modelo de comportamiento de usuario robusto Los clics en los resultados de búsqueda comprenden solo una pequeña fracción de las actividades posteriores a la búsqueda realizadas por los usuarios. Ahora presentamos nuestras técnicas para ir más allá de las estadísticas de clics y modelar explícitamente el comportamiento del usuario posterior a la búsqueda. Aunque las distribuciones de clics están fuertemente sesgadas hacia los resultados superiores, acabamos de demostrar cómo la distribución de clics basada en relevancia se puede recuperar corriendo para la distribución anterior de fondo. Conjeturamos que otros aspectos del comportamiento del usuario (por ejemplo, el tiempo de permanencia de la página) están distorsionados de manera similar. Nuestro modelo general incluye dos tipos de características para describir el comportamiento del usuario: directo y desviación donde el primero es los valores medidos directamente, y el último es la desviación de los valores esperados estimados a partir de las distribuciones generales (independientes de la consulta) para las características directamente observadas correspondientes. Más formalmente, postulamos que el valor observado O de una característica F para una consulta q y el resultado R puede expresarse como una mezcla de dos componentes :) ,, () () ,, (frqrelfcfrqo += (1) donde) ((FC es la distribución de fondo anterior para los valores de F agregados en todas las consultas, y Rel (Q, R, F) es el componente del comportamiento influenciado por la relevancia del resultado r. Como se ilustra anteriormente con la función de clic, si restamosLa distribución de fondo (es decir, el clic esperado para un resultado en una posición dada) de la frecuencia de clic observada en una posición determinada, podemos aproximar el componente de relevancia del valor de clic1. Para reducir el efecto de las variaciones individuales del usuario en el comportamiento, promediamos los valores de características observados en todos los usuarios y sesiones de búsqueda para cada par de la consulta-URL. Esta agregación brinda robustez adicional de no confiar en las interacciones individuales de los usuarios ruidosos. En resumen, el comportamiento del usuario para un par de consulta-URL está representado por un vector de características que incluye las características observadas directamente y los valores de características derivados y corregidos. Ahora describimos las características reales que usamos para representar el comportamiento del usuario.3.3 Características para representar el comportamiento del usuario Nuestro objetivo es idear un conjunto de características suficientemente rico que nos permitan caracterizar cuando un usuario estará satisfecho con un resultado de búsqueda web. Una vez que el usuario ha enviado una consulta, realizan muchas acciones diferentes (leyendo fragmentos, haciendo clic en resultados, navegar, refinar su consulta) que capturamos y resumimos. Esta información se obtuvo a través de la instrumentación del lado del cliente de los usuarios de un importante motor de búsqueda web. Esta rica representación del comportamiento del usuario es similar en muchos aspectos al trabajo reciente de Fox et al.[7]. Una diferencia importante es que muchas de nuestras características son (por diseño) consultas específicas, mientras que la suya era (por diseño) un modelo de comportamiento del usuario general de consulta. Además, incluimos características de distribución derivadas calculadas como se describió anteriormente. Las características que utilizamos para representar las interacciones de búsqueda de usuarios se resumen en la Tabla 3.1. Para mayor claridad, organizamos las características en el texto de consulta de grupos, el clic y la navegación. Características del texto de consulta: los usuarios deciden qué resultados examinar con más detalle al observar el título de los resultados, la URL y el resumen; en algunos casos, ni siquiera es necesario mirar el documento original. Para modelar este aspecto de la experiencia del usuario, definimos las características para caracterizar la naturaleza de la consulta y su relación con el texto del fragmento. Estas incluyen características tales como superposición entre las palabras en el título y la consulta (titleOverlap), la fracción de palabras compartidas por la consulta y el resumen de resultados (resumenverlap), etc. Características de navegación: los aspectos simples de las interacciones de la página web del usuario se pueden capturar y cuantificar. Estas características se utilizan para caracterizar las interacciones con páginas más allá de la página de resultados. Por ejemplo, calculamos cuánto tiempo los usuarios viven en una página (tiempo de tiempo de tiempo) o dominio (horario de tiempo), y la desviación del tiempo de permanencia del tiempo de permanencia de la página esperado para una consulta. Estas características nos permiten modelar la diversidad intraleria del comportamiento de navegación de páginas (por ejemplo, consultas de navegación, en promedio, es probable que tengan un tiempo de permanencia de página más corto que las consultas transaccionales o informativas). Incluimos tanto las características directas como las características derivadas descritas anteriormente. Haga clic en las características: los clics son un caso especial de interacción del usuario con el motor de búsqueda. Incluimos todas las características necesarias para aprender las estrategias basadas en clics descritas en las Secciones 4.1 y 4.4. Por ejemplo, para un par de consultas-URL proporcionamos el número de clics para el resultado (ClickFrequency), como 1, por supuesto, esto es solo una estimación aproximada, ya que la distribución de fondo observada también incluye el componente de relevancia.así como si hubo un clic en el resultado a continuación o por encima de la URL actual (ISCLICKBELOW, ISCLICKABOVE). Los valores de características derivados, como ClickRelativeFrequency y ClickDeviation, se calculan como se describe en la Ecuación 1. Las características de la consulta-Texto de la fracción del titleOverlap de las palabras compartidas entre la consulta y el título Resumen de la fracción de las palabras compartidas entre la consulta y la fracción de consulta de consulta resumida de las palabras compartidas entre la consulta y la fracción de consulta URL de las palabras compartidas entre la consulta y el dominio Número de la longitudPalabras compartidas con las próximas características de navegación de consultas Tiempo de tiempo Página de permanencia Tiempo de permanencia CumulativeTimeonPage Tiempo acumulativo para todasNormización utilizada, 1 de otra manera ISredirected 1 Si la URL inicial igual a la URL final, 0 de otra manera ispathFromsearch 1 Si solo siguió los enlaces después de la consulta, 0, de lo contrario, el número de lúpulo de la página para llegar a la página desde la consulta promedio, tiempo promedio de tiempo en página para esta consulta desviación de divulgación de la medición de la promedio general promedioTiempo de permanencia en la página Desviación de evaluación acumulada de la página Desde el tiempo acumulativo promedio en la página Desviación de dominio de la página desde el tiempo promedio del tiempo en el dominio ShorturDeviation Desviation Desde el tiempo promedio de la URL de la URL Posición de la posición de la URL en la URL en la clasificación actual Número de clics de clicde un clic para esta consulta y la desviación de la adviación de URL de la frecuencia esperada de clic en la frecuencia de clics isNexted 1 Si hay un clic en la siguiente posición, 0 de lo contrario ispreviousclicked 1 Si hay un clic en la posición anterior, 0 de lo contrario es el clickabove 1 si hay un clic arriba, 0De lo contrario, ISCLICKBELOW 1 Si hay clic a continuación, 0 de lo contrario Tabla 3.1: Características utilizadas para representar interacciones posteriores a la búsqueda para una consulta determinada URL de resultados de búsqueda 3.4 Aprendizaje Un modelo de comportamiento predictivo que ha descrito nuestras características, ahora pasamos al método real de asignaciónLas características de las preferencias del usuario. Intentamos aprender una estrategia general de interpretación de retroalimentación implícita automáticamente en lugar de depender de la heurística o las ideas. Consideramos que este enfoque es preferible a las estrategias heurísticas, porque siempre podemos extraer más datos en lugar de confiar (solo) en nuestra intuición y evidencia de laboratorio limitada. Nuestro enfoque general es capacitar a un clasificador para inducir pesos para las características del comportamiento del usuario y, en consecuencia, obtener un modelo predictivo de preferencias del usuario. La capacitación se realiza comparando una amplia gama de medidas de comportamiento implícitas con juicios de usuarios explícitos para un conjunto de consultas. Para esto, utilizamos una gran muestra aleatoria de consultas en el registro de consultas de búsqueda de un motor de búsqueda web popular, los conjuntos de resultados (identificados por URL) devueltos para cada una de las consultas, y cualquier juicio de relevancia explícita disponibles para cada consulta/resultadopar. Luego podemos analizar el comportamiento del usuario para todas las instancias en las que estas consultas se enviaron al motor de búsqueda. Para aprender el mapeo de las características a las preferencias de relevancia, utilizamos una implementación escalable de redes neuronales, RankNet [4], capaz de aprender a clasificar un conjunto de elementos dados. Más específicamente, para cada consulta juzgada verificamos si se ha juzgado un enlace de resultado. Si es así, la etiqueta se asigna al par Consulta/URL y al vector de características correspondiente para ese resultado de la búsqueda. Estos vectores de los valores de características correspondientes a las URL juzgadas o no relevantes por los anotadores humanos se convierten en nuestro conjunto de capacitación. RankNet ha demostrado un excelente rendimiento al aprender a clasificar objetos en un entorno supervisado, por lo tanto, usamos RankNet para nuestros experimentos.4. Predecir las preferencias del usuario en nuestros experimentos, exploramos varios modelos para predecir las preferencias del usuario. Estos modelos van desde el uso de la retroalimentación implícita del usuario hasta el uso de todos los comentarios de usuarios implícitos disponibles. La clasificación de los resultados de búsqueda para predecir las preferencias del usuario es un problema fundamental en la recuperación de la información. La mayoría de los enfoques tradicionales de búsqueda de IR y web utilizan una combinación de características de página y enlace para rango de resultados de búsqueda, y un sistema de clasificación de estado de estado representativo se utilizará como nuestro ranker de línea de base (Sección 4.1). Al mismo tiempo, las interacciones de usuario con un motor de búsqueda proporcionan una gran cantidad de información. Un tipo de interacción comúnmente considerado es que el usuario hace clic en los resultados de búsqueda. El trabajo anterior [9], como se describió anteriormente, también examinó qué resultados se omitieron (por ejemplo, omitir arriba y omitir a continuación) y otras estrategias relacionadas para inducir juicios de preferencias de los usuarios que saltan sobre los resultados y no hacen clic en los siguientes resultados. También hemos agregado refinamientos de estas estrategias para tener en cuenta la variabilidad observada en escenarios web realistas. Describimos estas estrategias en la Sección 4.2. Como los clics son solo un aspecto de la interacción del usuario, ampliamos la estimación de relevancia al introducir un modelo de aprendizaje automático que incorpora clics y otros aspectos del comportamiento del usuario, como consultas de seguimiento y tiempo de permanencia de la página (Sección 4.3). Concluimos esta sección describiendo brevemente nuestra línea de base, un algoritmo de clasificación de estado de arte utilizado por un motor de búsqueda web operativo.4.1 Modelo de referencia Una pregunta clave es si el comportamiento de navegación puede proporcionar información ausente de los juicios explícitos existentes utilizados para capacitar a un ranker existente. Para nuestro sistema de referencia, utilizamos un sistema de clasificación de página de última generación que actualmente utiliza un importante motor de búsqueda web. Por lo tanto, llamaremos a este sistema actual para la discusión posterior. Si bien los algoritmos específicos utilizados por el motor de búsqueda están más allá del alcance de este documento, el algoritmo clasifica los resultados basados en cientos de características, como la consulta para documentar la similitud, la consulta para anclar la similitud de texto y la calidad de la página intrínseca. Las clasificaciones actuales de los motores de búsqueda web proporcionan un sistema sólido para la comparación y los experimentos de las siguientes dos secciones.4.2 Modelo de clics Si suponemos que cada clic del usuario fue motivado por un proceso racional que seleccionó el resumen de resultados más prometedor, podemos interpretar cada clic como se describe en Joachims et al. [10]. Al estudiar el seguimiento oyario y comparar los clics con juicios explícitos, identificaron algunas estrategias básicas. Discutimos las dos estrategias que funcionan mejor en sus experimentos, saltamos arriba y saltamos a continuación. Estrategia SA (omitir arriba): para un conjunto de resultados para una consulta y un resultado de clic en la posición P, todos los resultados no reclutados clasificados anteriormente P son menos relevantes que el resultado en p.Además de la información sobre los resultados por encima del resultado hecho, también tenemos información sobre el resultado inmediatamente después del clic. Estudio de seguimiento ocular realizado por Joachims et al.[10] mostraron que los usuarios generalmente consideran el resultado inmediatamente después del resultado hecho en la clasificación actual. Su Skip Next Strategy utiliza esta observación para predecir que un resultado después del resultado hecho en P es menos relevante que el resultado hecho, con una precisión comparable a la estrategia SA anterior. Para una mejor cobertura, combinamos la estrategia de SA con esta extensión para derivar el omitir arriba + omitir la estrategia siguiente: estrategia sa + n (omitir arriba + omitir a continuación): esta estrategia predice todos los resultados no haciendo clic inmediatamente después de un resultado de clics como menos relevanteque el resultado hecho hecho, y combina estas predicciones con las de la estrategia SA anterior. Experimentamos con variaciones de estas estrategias, y descubrimos que SA+N superó a SA y la estrategia original de omitir el próximo, por lo que consideraremos las estrategias SA y SA+N en el resto del documento. Estas estrategias están motivadas y probadas empíricamente para usuarios individuales en un entorno de laboratorio. Como mostraremos, estas estrategias no funcionan tan bien en la configuración de búsqueda web real debido a la inconsistencia inherente y la ruidosa del comportamiento de los usuarios individuales. El enfoque general para usar nuestros modelos de clic directamente es filtrar los clics a aquellos que reflejan la frecuencia de clics superior a la oportunidad. Luego usamos las mismas estrategias SA y SA+N, pero solo para clics que tienen una frecuencia más alta de lo esperado según nuestro modelo. Para esto, estimamos el componente de relevancia Rel (Q, R, F) de la característica de clics observada F como la desviación de la distribución esperada (fondo) de clics) (FC. Estrategia CD (desviación D): para una consulta dada, calcule la distribución de frecuencia de clic observada O (R, P) para todos los resultados r en posiciones p.La desviación de clic para un resultado R en la posición P, dev (R, P) se calcula como:) (), (), (PCPropRdev - = donde C (p) es el clic esperado en la posición p. If dev (r, r,p)> D, retenga la entrada de clics a la estrategia SA+N anterior, y aplique la estrategia SA+N sobre el conjunto filtrado de eventos de clic. La elección de D selecciona la compensación entre el retiro y la precisión. Si bien la estrategia anterior se extiende SA y SA+N, aún asume que se prefiere un resultado hecho (filtrado) sobre todos los resultados no reclutados presentados al usuario por encima de una posición haciendo clic. Sin embargo, para consultas informativas, se pueden hacer clic en múltiples resultados, con una frecuencia variable. Por lo tanto, es preferible comparar individualmente los resultados para una consulta considerando la diferencia entre los componentes de relevancia estimados de la distribución de clics de los resultados de consulta correspondientes. Ahora definimos una generalización de la estrategia de interpretación de clics anterior: Estrategia CDIFF (Margen M): Compute Deviation Dev (R, P) para cada resultado R1 ... Rn en la posición p.Para cada par de resultados RI y RJ, predicen la preferencia de RI sobre RJ IFF Dev (Ri, Pi) -dev (RI, PJ)> m. Como en CD, la elección de M selecciona la compensación entre el retiro y la precisión. Los pares pueden preferirse en el orden original o en reversa. Dado el margen, dos resultados pueden ser efectivamente indistinguibles, pero solo uno puede preferirse sobre el otro. Intuitivamente, CDIFF generaliza la idea de omisión anterior para incluir casos en los que el usuario se saltó (es decir, hizo clic menos de lo esperado) en UJ y preferido (es decir, hizo clic más de lo esperado) en la interfaz de usuario. Además, esta estrategia permite la diferenciación dentro del conjunto de resultados en los que se hace clic, lo que lo hace más apropiado para el ruidoso comportamiento del usuario. C Diff y CD son complementarios. C Diff es una generalización del modelo de frecuencia de clic a través de CD, pero ignora la información posicional utilizada en CD. Por lo tanto, la combinación de las dos estrategias para mejorar la cobertura es un enfoque natural: estrategia CD+CDIFF (desviación D, margen M): unión de predicciones de CD y CDIFF. Se consideraron otras variaciones de las estrategias anteriores, pero estos cinco métodos cubren el rango de rendimiento observado.4.3 Modelo general de comportamiento del usuario Las estrategias descritas en la sección anterior generan pedidos basados únicamente en las frecuencias de clic observadas. Como discutimos, el clic es solo un aspecto, aunque importante, de las interacciones del usuario con los resultados de los motores de búsqueda web. Ahora presentamos nuestra estrategia general que se basa en los modelos de comportamiento predictivo de usuario derivado automáticamente (Sección 3). La Estrategia de UserBehavior: para una consulta dada, cada resultado se representa con las características de la Tabla 3.1. Las preferencias relativas del usuario se estiman utilizando el modelo de comportamiento del usuario erudito descrito en la Sección 3.4. Recuerde que para aprender un modelo de comportamiento predictivo utilizamos las características de la Tabla 3.1 junto con juicios de relevancia explícita como entrada para RankNet, que aprende una ponderación óptima de las características para predecir las preferencias. Esta estrategia modela la interacción del usuario con el motor de búsqueda, lo que le permite beneficiarse de la sabiduría de las multitudes que interactúan con los resultados y las páginas más allá. Como lo demuestran nuestros experimentos en las secciones posteriores, el modelado de un conjunto más rico de interacciones de usuario más allá de los clics da como resultado predicciones más precisas de las preferencias del usuario.5. Configuración experimental ahora describimos nuestra configuración experimental. Primero describimos la metodología utilizada, incluidas nuestras métricas de evaluación (Sección 5.1). Luego describimos los conjuntos de datos (Sección 5.2) y los métodos que comparamos en este estudio (Sección 5.3).5.1 Metodología y métricas de evaluación Nuestra evaluación se centra en el acuerdo por pares entre las preferencias para los resultados. Esto nos permite comparar con trabajos anteriores [9,10]. Además, para muchas aplicaciones, como las funciones de clasificación de ajuste, la preferencia por pares se puede usar directamente para el entrenamiento [1,4,9]. La evaluación se basa en comparar las preferencias predichas por varios modelos con las preferencias correctas derivadas de los juicios explícitos de relevancia del usuario. Discutimos otras aplicaciones de nuestros modelos más allá de la clasificación de búsqueda web en la Sección 7. Para crear nuestro conjunto de pares de pruebas, tomamos cada consulta y calculamos el producto cruzado entre todos los resultados de búsqueda, devolviendo las preferencias para pares de acuerdo con el orden de las etiquetas de relevancia asociadas. Para evitar la ambigüedad en la evaluación, descartamos todos los lazos (es decir, pares con igual etiqueta). Para calcular la precisión de nuestras predicciones de preferencia con respecto a las preferencias correctas, adaptamos el recuerdo estándar y las medidas de precisión [20]. Si bien nuestra tarea de calcular el acuerdo por pares es diferente de la tarea de clasificación de relevancia absoluta, las métricas se usan de manera similar. Específicamente, informamos el recuerdo promedio de consultas y la precisión. Para nuestra tarea, la precisión de consulta y el recuerdo de consulta para una consulta Q se definen como: • Precisión de consulta: fracción de preferencias predichas para resultados para Q que están de acuerdo con las preferencias obtenidas de un juicio humano explícito.• Recuerdo de consulta: fracción de preferencias obtenidas de un juicio humano explícito para Q que se predijeron correctamente. El retiro general y la precisión se calculan como el promedio de recuperación de consultas y precisión de consulta, respectivamente. Un inconveniente de esta medida de evaluación es que algunas preferencias pueden ser más valiosas que otras, que el acuerdo por pares no captura. Discutimos este problema aún más cuando consideramos las extensiones del trabajo actual en la Sección 7. 5.2 conjuntos de datos para la evaluación utilizamos 3.500 consultas que fueron muestreadas aleatoriamente de los registros de consultas (para un motor de búsqueda web importante. Para cada consulta, los 10 mejores resultados de búsqueda devueltos fueron calificados manualmente en una escala de 6 puntos por jueces capacitados como parte del esfuerzo de mejora de relevancia continua. Además para estas consultas, también tuvimos datos de interacción de usuario para más de 120,000 instancias de estas consultas. Las interacciones del usuario se cosecharon de trazas anónimas de navegación que siguieron inmediatamente una consulta enviada al motor de búsqueda web. Esta recopilación de datos formó parte de los comentarios voluntarios enviados por los usuarios del 11 al 31 de octubre. Estas tres semanas (21 días) de los datos de interacción del usuario se filtraron para incluir solo a los usuarios en English-U.S.mercado. Para comprender mejor el efecto de la cantidad de datos de interacción del usuario disponibles para una consulta sobre la precisión, creamos subconjuntos de nuestros datos (Q1, Q10 y Q20) que contienen diferentes cantidades de datos de interacción: • Q1: consultas con clasificación humanaCon al menos 1 clic en los resultados registrados (3500 consultas, 28,093 pares de consulta-url) • Q10: consultas en Q1 con al menos 10 clics (1300 consultas, 18,728 pares de consultas-url).• Q20: consultas en Q1 con al menos 20 clics (1000 consultas en total, 12,922 pares de consulta-URL). Estos conjuntos de datos se recopilaron como parte de la experiencia normal del usuario y, por lo tanto, tienen características diferentes a las de datos informados previamente recopilados en entornos de laboratorio. Además, el tamaño de los datos es un orden de magnitud mayor que cualquier estudio reportado en la literatura.5.3 Métodos comparados consideramos una serie de métodos para la comparación. Comparamos nuestro modelo UserBehavior (Sección 4.3) con técnicas de interpretación de retroalimentación implícitas publicadas previamente y algunas variantes de estos enfoques (Sección 4.2), y a la clasificación actual del motor de búsqueda en función de la consulta y las características de la página solo (Sección 4.1). Específicamente, comparamos las siguientes estrategias: • SA: la estrategia de clic por encima de la estrategia de clic (Sección 4.2) • SA+N: una extensión más completa de SA que aprovecha mejor la clasificación actual del motor de búsqueda.• CD: nuestro refinamiento de SA+N que aprovecha nuestro modelo de mezcla de distribución de clics para seleccionar clics confiables para la interpretación (Sección 4.2).• CDIFF: Nuestra generalización de la estrategia de CD que utiliza explícitamente el componente de relevancia de las probabilidades de clic para inducir preferencias entre los resultados de búsqueda (Sección 4.2).• CD+CDIFF: la estrategia que combina CD y CDIFF como la unión de preferencias predichas de ambos (Sección 4.2).• UserBehavior: ordenamos predicciones basadas en la disminución de la puntuación más alta de cualquier página. En nuestros experimentos preliminares, observamos que las puntuaciones de rango más altas indican una mayor confianza en las predicciones. Esta heurística nos permite hacer una elegante compensación de precisión de recuerdo utilizando el puntaje del resultado más alto en el puesto para umbral de las consultas (Sección 4.3) • Actual: Ranking actual del motor de búsqueda (Sección 4.1). Tenga en cuenta que la implementación actual de Ranker se capacitó en un superconjunto de los pares de consulta/URL nominal en nuestros conjuntos de datos, pero utilizando las mismas etiquetas de verdad que nosotros para nuestra evaluación. Entrenamiento/división de pruebas: la única estrategia para la cual se requirió dividir los conjuntos de datos en la capacitación y la prueba fue el método UserBehavior. Para evaluar userbehavior, entrenamos y validamos en el 75% de las consultas etiquetadas, y probamos el 25% restante. El muestreo se realizó por consulta (es decir, todos los resultados para una consulta elegida se incluyeron en el conjunto de datos respectivo, y no hubo superposición en las consultas entre el entrenamiento y los conjuntos de pruebas). Vale la pena señalar que tanto el ad-hoc sa como el sa+n, así como las estrategias basadas en la distribución (CD, CDIFF y CD+CDIFF), no requieren un conjunto de entrenamiento y prueba separados, ya que se basan enHeurística para detectar frecuencias anómalas de clic para obtener resultados. Por lo tanto, todas las estrategias, excepto UserBehavior, se probaron en el conjunto completo de consultas y las preferencias de relevancia asociadas, mientras que UserBehavior se probó en un subconjunto de retención elegido al azar de las consultas como se describió anteriormente. Para asegurarnos de que no estamos favoreciendo a UserBehavior, también probamos todas las demás estrategias en los mismos conjuntos de pruebas de retención, lo que resulta en los mismos resultados de precisión que las pruebas sobre los conjuntos de datos completos.6. Resultados Ahora recurrimos a la evaluación experimental de predecir la preferencia de relevancia de los resultados de búsqueda web. La Figura 6.1 muestra los resultados de la precisión de recuperación sobre el conjunto de consultas Q1 (Sección 5.2). Los resultados indican que las estrategias de interpretación de clics anteriores, SA y SA+N funcionan subóptimamente en este entorno, exhibiendo precisión 0.627 y 0.638 respectivamente. Además, no existe un mecanismo para recordar la compensación de la precisión con SA y SA+N, ya que no proporcionan confianza de predicción. Por el contrario, nuestras técnicas basadas en distribución de clics CD y CD+CDIFF exhiben una precisión algo más alta que SA y SA+N (0.648 y 0.717 en el retiro de 0.08, lo máximo logrado por SA o SA+N). SA+N SA 0.6 0.62 0.64 0.66 0.68 0.7 0.72 0.74 0.76 0.78 0.8 0 0.05 0.1 0.1 0.2 0.2 0.25 0.3 0.35 0.4 0.45 Recuerdos Precisión SA SA+N CD CDIFF CD+CDIFF Corriente de usuarios Figura 6.1: Precisión vs. Recuerdos de SA, SA+N, CD, CDIFF, CD+CDIFF, UserBehavior y los métodos de predicción de relevancia actual en el conjunto de datos Q1. Curiosamente, el CDIFF solo exhibe una precisión igual a SA (0.627) en el mismo recuerdo en 0.08. Por el contrario, al combinar estrategias CD y CDIFF (método CD+CDIFF) logramos el mejor rendimiento de todas las estrategias basadas en el clic, exhibiendo precisión de más de 0.66 para valores de recuperación de hasta 0.14 y más alto en niveles de recuperación más bajos. Claramente, la agregación y la interpretación de inteligencia de los clics resulta en una ganancia significativa para la búsqueda web realista, que las estrategias descritas anteriormente. Sin embargo, incluso la estrategia de interpretación de clics CD+CDIFF se puede mejorar al aprender automáticamente a interpretar la evidencia de clic agregado. Pero primero, consideramos la estrategia de mejor rendimiento, UserBehavior. La incorporación del historial de navegación posterior a la búsqueda además de los clics (características de navegación) da como resultado el mayor retiro y precisión entre todos los métodos comparados. La navegación exhibe precisión de más de 0.7 en el retiro de 0.16, superando significativamente nuestras estrategias de base y solo por clic. Además, Browse puede lograr un alto retiro (tan alto como 0.43) mientras se mantiene la precisión (0.67) significativamente mayor que la clasificación de línea de base. Para analizar más a fondo el valor de diferentes dimensiones de la retroalimentación implícita modelada por la estrategia de usuario de usuario, consideramos cada grupo de características de forma aislada. La Figura 6.2 informa precisión frente a recuperar para cada grupo de características. Curiosamente, el texto de consulta solo tiene baja precisión (solo marginalmente mejor que al azar). Además, las características de navegación por sí solas tienen una precisión más alta (con un mayor retiro de recuerdo) que considerar todas las características en nuestro modelo de Behavior de usuarios. La aplicación de diferentes métodos de aprendizaje automático para combinar predicciones del clasificador puede aumentar el rendimiento del uso de todas las características para todos los valores de recuperación.0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.01 0.05 0.09 0.13 0.17 0.21 0.25 0.29 0.33 0.37 0.41 0.45 Recarga Precisión Todas las características de la consulta de texto de consulta Figura 6.2: Precisión vs. Recuperación para predecir la relevancia con cada grupo de características individualmente.0.65 0.67 0.69 0.71 0.73 0.75 0.77 0.79 0.81 0.83 0.85 0.01 0.05 0.09 0.13 0.17 0.21 0.25 0.29 0.33 0.37 0.41 0.45 0.49 Recall Precision CD+CDiff:Q1 UserBehavior:Q1 CD+CDiff:Q10 UserBehavior:Q10 CD+CDiff:Q20 UserBehavior:Q20Figura 6.3: Recuerdo vs. Precisión de CD+CDIFF y UserBehavior para conjuntos de consultas Q1, Q10 y Q20 (consultas con al menos 1, al menos 10 y al menos 20 clics respectivamente). Curiosamente, el ranker entrenado sobre las características de solo clic a punto de hacer clic logra un retiro y precisión sustancialmente más alto que las estrategias de interpretación de clicking diseñadas por humanos descritas anteriormente. Por ejemplo, el clasificador capacitado en clic logra 0.67 precisión a 0.42 recordatorio frente al recuerdo máximo de 0.14 logrado por la estrategia CD+CDIFF. Nuestras estrategias de interpretación del comportamiento del usuario y de los usuarios se basan en datos extensos de interacción del usuario. Consideramos los efectos de tener suficientes datos de interacción disponibles para una consulta antes de proponer un reanimiento de resultados para esa consulta. La Figura 6.3 informa las curvas de precisión de recuerdo para los métodos CD+CDIFF y UserBehavior para diferentes conjuntos de consultas de prueba con al menos 1 clic (Q1), 10 clics (Q10) y 20 clics (Q20) disponibles por consulta. No es sorprendente que CD+CDIFF mejore con más clics. Esto indica que la precisión mejorará a medida que se disponga de más historias de interacción del usuario, y más consultas del conjunto Q1 tendrán historiales de interacción integrales. Del mismo modo, la estrategia UserBehavior funciona mejor para consultas con 10 y 20 clics, aunque la mejora es menos dramática que para CD+CDIFF. Para consultas con clics suficientes, CD+CDIFF exhibe una precisión comparable con la navegación en un retiro más bajo.0 0.05 0.1 0.15 0.2 7 12 17 21 21 días de datos de interacción del usuario Recomendado Recuerdo CD+CDIFF21 días). Nuestras técnicas a menudo no hacen predicciones de relevancia para los resultados de búsqueda (es decir, si no hay datos de interacción disponibles para los resultados de menor clasificación), manteniendo en consecuencia una mayor precisión a expensas del recuerdo. En contraste, el motor de búsqueda actual siempre hace una predicción para cada resultado para una consulta dada. Como consecuencia, el retiro de la corriente es alto (0.627) a expensas de la menor precisión como otra dimensión de adquirir datos de capacitación, consideramos la curva de aprendizaje con respecto a la cantidad (días) de los datos de capacitación disponibles. La Figura 6.4 informa el retiro de CD+CDIFF y las estrategias de UserBehavior para cantidades variables de datos de capacitación recopilados a lo largo del tiempo. Fijamos la precisión mínima para ambas estrategias a 0.7 como un punto sustancialmente más alto que la línea de base (0.625). Como se esperaba, el recuerdo de ambas estrategias mejora rápidamente con más días de datos de interacción examinados. Ahora resumimos brevemente nuestros resultados experimentales. Mostramos que al agregar inteligentemente los clics de los usuarios en consultas y usuarios, podemos lograr una mayor precisión en la predicción de las preferencias de los usuarios. Debido a la distribución sesgada de los clics del usuario, nuestras estrategias solo por clic tienen una alta precisión, pero un bajo retiro (es decir, no intentan predecir la relevancia de muchos resultados de búsqueda). Sin embargo, nuestra estrategia de clic CD+CDIFF supera a los resultados de última generación recientes por un gran margen (0.72 precisión para CD+CDIFF frente a 0.64 para SA+N) al nivel de recuperación más alto de SA+N. Además, al considerar las características integrales de UserBehavior que modelan las interacciones del usuario después de la búsqueda y más allá del clic inicial, podemos lograr una precisión y recuperación sustancialmente más altas que considerando solo hacer clic. Nuestra estrategia de Behavior de usuarios logra el recuerdo de más de 0.43 con una precisión de más de 0.67 (con una precisión mucho más alta en niveles de recuperación más bajos), supera sustancialmente la clasificación actual de preferencias de los motores de búsqueda y todos los demás métodos de interpretación de retroalimentación implícita.7. CONCLUSIONES Y EL FUTURO OR Our Paper es el primero, que sepamos, a interpretar el comportamiento de los usuarios posteriores a la investigación para estimar las preferencias de los usuarios en una configuración de búsqueda web real. Mostramos que nuestros modelos robustos dan como resultado una mayor precisión de predicción que las técnicas publicadas anteriormente. Introducimos técnicas nuevas, robustas y probabilísticas para interpretar la evidencia de clics al agregar a los usuarios y consultas. Nuestros métodos dan como resultado una interpretación de clics sustancialmente más precisa que los resultados publicados anteriormente no diseñados específicamente para escenarios de búsqueda web. Nuestros métodos predicciones de preferencias de relevancia son sustancialmente más precisas que la clasificación actual de resultados de búsqueda de estado de última generación que no considera las interacciones del usuario. También presentamos un modelo general para interpretar el comportamiento del usuario posterior a la búsqueda que incorpora características de clic, navegación y consulta. Al considerar la experiencia de búsqueda completa después de la consulta inicial y el clic, demostramos una precisión de predicción que excede la interpretación de la información limitada de clics. Además, demostramos que aprender automáticamente a interpretar el comportamiento del usuario da como resultado un rendimiento sustancialmente mejor que las estrategias de interpretación de clics ad-hoc diseñadas por humanos. Otro beneficio de aprender automáticamente a interpretar el comportamiento del usuario es que dichos métodos pueden adaptarse a las condiciones cambiantes y cambiar los perfiles del usuario. Por ejemplo, el modelo de comportamiento del usuario en la búsqueda de intranet puede ser diferente del comportamiento de búsqueda web. Nuestro método general de usuario de usuario podría adaptarse a estos cambios aprendiendo automáticamente a mapear nuevos patrones de comportamiento a calificaciones de relevancia explícitas. Una aplicación natural de nuestros modelos de predicción de preferencias es mejorar la clasificación de búsqueda web [1]. Además, nuestro trabajo tiene muchas aplicaciones potenciales que incluyen detección de spam de clic, detección de abuso de búsqueda, personalización y clasificación específica del dominio. Por ejemplo, nuestros modelos de comportamiento derivados automáticamente podrían capacitarse en ejemplos de abuso de búsqueda o hacer clic en el comportamiento de spam en lugar de etiquetas de relevancia. Alternativamente, nuestros modelos podrían usarse directamente para detectar anomalías en el comportamiento del usuario, ya sea debido al abuso o a los problemas operativos con el motor de búsqueda. Si bien nuestras técnicas funcionan bien en promedio, nuestras suposiciones sobre las distribuciones de clics (y el aprendizaje de los modelos de comportamiento del usuario) pueden no seguir siendo igualmente bien para todas las consultas. Por ejemplo, las consultas con patrones de acceso divergentes (por ejemplo, para consultas ambiguas con múltiples significados) pueden dar como resultado un comportamiento inconsistente con el modelo aprendido para todas las consultas. Por lo tanto, la agrupación de consultas y el aprendizaje de diferentes modelos predictivos para cada tipo de consulta es una dirección de investigación prometedora. Las distribuciones de consultas también cambian con el tiempo, y sería productivo investigar cómo eso afecta la capacidad predictiva de estos modelos. Además, algunas preferencias predichas pueden ser más valiosas que otras, y planeamos investigar diferentes métricas para capturar la utilidad de las preferencias predichas. Como mostramos en este documento, el uso de la sabiduría de las multitudes puede darnos una interpretación precisa de las interacciones del usuario incluso en la configuración inherentemente de búsqueda web. Nuestras técnicas nos permiten predecir automáticamente las preferencias de relevancia para los resultados de búsqueda web con una precisión mayor que los métodos publicados anteriormente. Las preferencias de relevancia previstas se pueden utilizar para la evaluación y ajuste de relevancia automática, para implementar la búsqueda en nuevos entornos y, en última instancia, para mejorar la experiencia general de búsqueda web.8. Referencias [1] E. Agichtein, E. Brill y S. Dumais, Mejora de la clasificación de búsqueda web incorporando el comportamiento del usuario, en Actas de la Conferencia de la ACM sobre investigación y desarrollo sobre recuperación de información (Sigir), 2006 [2] J. Allan. Descripción general de la pista dura en TREC 2003: recuperación de alta precisión de documentos. En Proceedings of Trec 2003, 24-37, 2004. [3] S. Brin y L. Page, la anatomía de un motor de búsqueda web hipertextual a gran escala,. En Actas de WWW7, 107-117, 1998. [4] C.J.C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender, Aprendiendo a clasificarse utilizando la descendencia de gradiente, en Actas de la Conferencia Internacional sobre Aprendizaje Autor (ICML), 2005 [5] D.M. Chickering, The WinMine Toolkit, Microsoft Technical Report MSR-TR-2002-103, 2002 [6] M. Claypool, D. Brown, P. Lee y M. Waseda. Inferir el interés del usuario, en IEEE Internet Computing.2001 [7] S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White. Evaluar las medidas implícitas para mejorar la experiencia de búsqueda. En Transacciones ACM en Sistemas de Información, 2005 [8] J. Goecks y J. Shavlick. Aprender los intereses de los usuarios observando discretamente su comportamiento normal. En Actas del Taller IJCAI sobre aprendizaje automático para el filtrado de información.1999. [9] T. Joachims, Optimización de los motores de búsqueda utilizando datos de clics, en los procedimientos de la conferencia de ACM sobre descubrimiento de conocimientos y datamining (Sigkdd), 2002 [10] T. Joachims, L. granka, B. Pang, H. Hembrookey G. Gay, interpretando con precisión los datos de clics como retroalimentación implícita, en los procedimientos de la Conferencia de ACM sobre investigación y desarrollo sobre recuperación de información (Sigir), 2005 [11] T. Joachims, haciendo práctico el aprendizaje SVM a gran escala. Avances en los métodos del núcleo, en el aprendizaje de vectores de soporte, MIT Press, 1999 [12] D. Kelly y J. Teevan, Comentarios implícitos para inferir la preferencia del usuario: una bibliografía. En Sigir Forum, 2003 [13] J. Konstan, B. Miller, D. Maltz, J. Herlocker, L. Gordon y J. Riedl. Grouplens: aplicando filtrado colaborativo a Usenet News. En Communications of ACM, 1997. [14] M. morita e Y. shinoda, filtrado de información basado en el análisis de comportamiento del usuario y la mejor recuperación de texto de coincidencia. En Actas de la Conferencia de ACM sobre investigación y desarrollo sobre recuperación de información (Sigir), 1994 [15] D. Oard y J. Kim. Comentarios implícitos para los sistemas de recomendación.En Actas del Taller AAAAI sobre Sistemas de Recomendación.1998 [16] D. Oard y J. Kim. Modelado de contenido de información utilizando comportamiento observable. En Actas de la 64ª Reunión Anual de la Sociedad Americana de Ciencias y Tecnología de la Información.2001 [17] P. Pirolli, El uso del aroma de información proximal para buscar contenido distal en la red mundial. Al trabajar con la tecnología en mente: Brunswikian. Recursos para la ciencia e ingeniería cognitiva, Oxford University Press, 2004 [18] F. Radlinski y T. Joachims, Cadenas de consulta: Aprender a clasificarse a partir de comentarios implícitos, en procedimientos de la Conferencia ACM sobre Discovery y Minería de datos (KDD), ACM, ACM, 2005 [19] F. Radlinski y T. Joachims, evaluando la robustez del aprendizaje de los comentarios implícitos, en el taller ICML sobre el aprendizaje en la búsqueda web, 2005 [20] G. Salton y M. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, 1983 [21] E.M. Voorhees, D. Harman, Descripción general de TREC, 2001