Predicción del rendimiento Uso de la autocorrelación espacial Fernando Díaz Centro para la Información Inteligente Departamento de Recuperación de la Informática Universidad de Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu Resumen La evaluación de los sistemas de recuperación de información es una de las tareas centrales en la recuperación de la información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos para un tema, no la capacidad de gestión de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. El trabajo anterior aborda la evaluación de los sistemas, la clasificación de consultas por dificultad y la clasificación de las recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso sin juicios de relevancia. Nuestro enfoque está en la predicción del rendimiento de cero juzgación de recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de puntajes y juicios de documentos no correlacionados. Si los documentos están integrados en un espacio de alta dimensión (como suelen ser), podemos aplicar técnicas del análisis de datos espaciales para detectar correlaciones entre los puntajes de los documentos. Encontramos que la baja correlación entre las decenas de documentos tópicos a menudo implica un bajo rendimiento de recuperación. En comparación con una línea de base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación proporciona un rendimiento de predicción significativamente mejor. Estos nuevos predictores también se pueden incorporar con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción del rendimiento del juicio cero para un número masivo de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y descriptores de sujetos H.3.3 [Búsqueda y recuperación de información]: modelos de recuperación;H.3.4 [Sistemas y software]: Evaluación del rendimiento (eficiencia y efectividad) Términos generales Rendimiento, diseño, confiabilidad, experimentación 1. Introducción en la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos que reciben una puntuación de Real Valued que indica el grado de relevancia prevista. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares para no compartir el mismo tema. Tome dos documentos relacionados con tópicamente del conjunto y llámelos A y B. Si los puntajes de A y B son muy diferentes, podemos preocuparnos por el rendimiento de nuestro sistema. Es decir, si A y B están en el tema de la consulta, nos gustaría que ambos reciban un puntaje alto;Si A y B no están en el tema de la consulta, nos gustaría que ambos reciban un puntaje bajo. Podríamos preocuparnos más a medida que encontramos más diferencias entre decenas de documentos relacionados. Nos sentiríamos más cómodos con una recuperación donde los puntajes son consistentes entre los documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación integran documentos en algún espacio vectorial. Si los documentos están integrados en un espacio, la proximidad se correlaciona con las relaciones tópicas. La consistencia de la puntuación se puede medir mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto es una reminiscencia de la hipótesis del grupo. La hipótesis del grupo establece: los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una funciones de recuperación de la autocorrelación espacial mide el grado en que los documentos estrechamente relacionados reciben puntajes similares. Debido a esto, interpretamos la autocorrelación como medir el grado en que una función de recuperación satisface la hipótesis de agrupación. Si esta conexión es razonable, en la Sección 6, presentamos evidencia de que el fracaso para satisfacer la hipótesis del grupo se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones, 1. Un método general y robusto para predecir el rendimiento de las recuperaciones con cero juicios de relevancia (Sección 3).2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de última generación (Sección 4).3. Los primeros experimentos a gran escala de predicción de rendimiento de ejecución de un solo juicio cero (secciones 5 y 6).2. Definición del problema Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntajes asociados con los documentos. Nos referimos al conjunto de puntajes para una combinación particular del sistema de consultas como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio media). En este documento, presentamos resultados para las recuperaciones de clasificación de sistemas arbitrarios. Nos gustaría que esta clasificación se aproxime a la clasificación de recuperaciones por la medida de evaluación. Esto es diferente de las consultas de clasificación por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Los puntajes a menudo solo se calculan para los principales documentos N de la colección. Colocamos estos puntajes en la longitud n vector, y, donde Yi se refiere a la puntuación del documento ido. Ajustamos los puntajes para tener una media y varianza de la unidad. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15].3. Correlación espacial en la recuperación de la información, a menudo suponemos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de Dimensional con producto interno de coseno o un simple simplex multinomial con una medida de distancia basada en distribución. A menudo se selecciona un espacio de incrustación para respetar la proximidad tópica;Si están cerca de dos documentos, es más probable que compartan un tema. Debido a la prevalencia y el éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de la información, nos preocupa el puntaje en un punto en un espacio, en el análisis de datos espaciales, nos preocupa el valor de una función en un punto o ubicación en un espacio. Utilizamos la función de término aquí para significar una mapeo de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida denominada autocorrelación espacial [5, 10]. La alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación A nos dirá mucho sobre el valor en una ubicación vecina b. Hay una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que conocer la temperatura en una ubicación A nos dirá mucho sobre la temperatura en una ubicación vecina b. La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación A nos dice poco sobre el valor en una ubicación vecina b. Hay baja autocorrelación espacial en una función que mide el resultado de un lanzamiento de monedas en A y B. En esta sección, comenzaremos describiendo lo que queremos decir con proximidad espacial para los documentos y luego definiremos una medida de la autocorrelación espacial. Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta.3.1 Representación espacial de documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso. En cambio, elegimos un producto interno que se sabe que es efectivo para detectar relaciones tópicas de interdocumento. Específicamente, adoptamos vectores de documento TF.IDF, ˜di = di log „(n + 0.5)-ci 0.5 + ci« (1) donde d es un vector de frecuencias de término, c es la longitud- | v |Vector de frecuencia de documentos. Utilizamos este esquema de ponderación debido a su éxito para la detección de enlaces tópicos en el contexto de las evaluaciones de detección y seguimiento de temas (TDT) [6]. Suponiendo que los vectores se escalan por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud. Dados documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos. Recuerde que se nos da los principales documentos de N recuperados en y. Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, WIJ representa la similitud entre los documentos clasificados I y J. En la práctica, solo incluimos las afinidades para los documentos de los vecinos K-Nears. En todos nuestros experimentos, hemos fijado K a 5. Dejamos la exploración de la sensibilidad de los parámetros al trabajo futuro. También remulemos normalizar la matriz para que pn j = 1 wij = 1 para todos i.3.2 Autocorrelación espacial de una recuperación de recuperación de que estamos interesados en medir la similitud entre las puntuaciones de documentos de cierre espacial. Una de esas medidas adecuadas es el coeficiente de Moran de la autocorrelación espacial. Suponiendo la función sobre las ubicaciones de N, esto se define como ˜in = entre p i, j con p i y 2 i = n etwe yt wy yty (2) donde et we = p ij wij. Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones. Desafortunadamente, el Bound for Ecation 2 no es consistente para diferentes W e Y. Por lo tanto, usamos la desigualdad de Cauchy-Schwartz para establecer una unida, ≤ n etwe s ytwtwy yy y definimos la autocorrelación espacial normalizada como im = yt wy p × ytwtwwy notamos que si dejamos ˜y = wy, entonces nosotros, entonces nosotrospuede escribir esta fórmula como, im = yt ˜y y 2 ˜y 2 (3) que puede interpretarse como la correlación entre las puntuaciones de recuperación originales y un conjunto de puntajes de recuperación difundidos en el espacio. Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con otras recuperaciones A veces estamos interesados en el rendimiento de una sola recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM= 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula. El coeficiente de Moran es una medida local de consistencia de la función. Desde la perspectiva de la recuperación de la información, cada uno de estos espacios de cuadrícula representaría un documento y los documentos se organizarían para que estuvieran junto a documentos relacionados con tópicamente. Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula. Observe que, a medida que aumenta el coeficiente de Moran, las células vecinas tienden a tener valores similares.la misma consulta. En esta situación, podemos usar información combinada de estos puntajes para construir un sustituto para una clasificación de alta calidad [17]. Podemos tratar la correlación entre la recuperación que nos interesa y los puntajes combinados como un predictor de rendimiento. Suponga que se nos dan las funciones de puntaje M, yi, para los mismos n documentos. Representaremos la media de estos vectores como Yµ = PM I = 1 Yi. Utilizamos el vector medio como aproximación a la relevancia. Dado que usamos la normalización de la varianza media cero y la varianza de la unidad, el trabajo en MetaSearch sugiere que esta suposición está justificada [15]. Debido a que Yµ representa una muy buena recuperación, planteamos la hipótesis de que una fuerte similitud entre Yµ e Y se correlacionará positivamente con el rendimiento del sistema. Utilizamos la correlación de productos de productos de Pearsons para medir la similitud entre estos vectores, ρ (y, yµ) = yt µ y 2 yµ 2 (4) Comentaremos sobre la similitud entre la ecuación 3 y 4 en la Sección 7. Por supuesto, podemos combinar ρ (y, ˜y) y ρ (y, yµ) si suponemos que capturan diferentes factores en la predicción. Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal. La forma matemática de nuestros predictores sugiere un medio alternativo de combinación. Dado que ˜y codifica las dependencias espaciales en Y y Yµ codifica las propiedades espaciales de las corridas múltiples, podemos calcular una tercera correlación entre estos dos vectores, ρ (˜y, yµ) = ˜yt y µ ˜y 2 Yµ 2 (5)Podemos interpretar la ecuación 5 como medir la correlación entre una clasificación de alta calidad (Yµ) y una versión espacialmente suavizada de la recuperación (˜y).4. Relación con otros predictores Una forma de predecir la efectividad de una recuperación es mirar el vocabulario compartido de los principales documentos recuperados. Si calculamos las palabras de contenido más frecuentes en este conjunto, esperamos que sean coherentes con nuestro tema. De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resulta en una superposición de ruido terminológico. La claridad de una consulta intenta cuantificar exactamente esto [7]. Específicamente, la claridad mide la similitud de las palabras más utilizadas en documentos recuperados a los más utilizados en todo el corpus. La conjetura es que una buena recuperación usará un lenguaje distinto del texto general;El lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general. Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, p (w | θq) = nx i = 1 p (w | θi) P (q | θi) z (6) Donde θi es el modelo de lenguaje del documento ido dir (p (q | θi) es el puntaje de probabilidad de consulta del documento itto dir (il) una constante de normalización. La similitud entre la multinomial P (W | θq) y un modelo de texto general se puede calcular utilizando la divergencia Kullback-Leiber, DV KL (θq θc). Aquí, la distribución P (W | θc) es nuestro modelo de texto general que se puede calcular utilizando frecuencias de términos en el corpus. En la Figura 2A, presentamos la claridad que mide la distancia entre el centro de masa ponderado de la recuperación (etiquetado y) y el centro de masa no ponderado de la colección (etiquetado O). La claridad alcanza un mínimo cuando una recuperación asigna cada documento el mismo puntaje. Vamos a asumir nuevamente que tenemos un conjunto de N documentos recuperados para nuestra consulta. Otra forma de cuantificar la dispersión de un conjunto de documentos es analizar cuán agrupados están. Podemos plantear la hipótesis de que una buena recuperación devolverá un clúster único y apretado. Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionado que cubren muchos temas. Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio A a su vecino más cercano, b. Una recuperación que está bien agrupada, en promedio, tendrá una distancia baja entre A y B;Una recuperación que está menos cerrada, en promedio, tendrá altas distancias entre A y B. Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los principales documentos N recuperados de un sistema [18]. En la Figura 2A, esto es aproximadamente equivalente a medir el área del conjunto n.Observe que estamos tirando información sobre la función de recuperación y. Por lo tanto, la estadística de Cox-Lewis depende en gran medida de seleccionar los documentos de N Top N.1 Recuerde que tenemos n documentos y un conjunto de puntajes. Supongamos que tenemos acceso al sistema que proporcionó los puntajes originales y que también podemos solicitar puntajes para nuevos documentos. Esto sugiere un tercer método para predecir el rendimiento. Tome algún documento, A, del conjunto recuperado y agregue o elimine arbitrariamente palabras al azar para crear un nuevo documento ˜A. Ahora, podemos pedirle a nuestro sistema que obtenga ˜A con respecto a nuestra consulta. Si, en promedio, sobre los N documentos, las puntuaciones de A y ˜A tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta. Por lo tanto, un enfoque alternativo es medir el SIMI1 que los autores han sugerido acoplar la consulta con la medida de distancia [18]. Sin embargo, la información introducida por la consulta es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de los puntajes de recuperación.YOY (a) Divergencia global µ (y) ˜y (b) Perturbación de puntaje µ (y) Y (c) Multirun promedio Figura 2: representación de varios predictores de rendimiento en una cuadrícula. En la Figura 2A, representamos predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación. En la Figura 2b, representamos predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y. Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntaje. Finalmente, en la Figura 2C, representamos la predicción cuando se les damos recuperaciones de varios otros sistemas en la misma consulta. Aquí, podemos considerar la fusión de esta recuperación como un sustituto de relevancia.Larity entre la recuperación y una versión perturbada de esa recuperación [18, 19]. Esto se puede lograr perturbando los documentos o consultas. La similitud entre las dos recuperaciones se puede medir utilizando alguna medida de correlación. Esto se representa en la Figura 2b. La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y. La naturaleza del proceso de perturbación requiere anotaciones o recuperaciones adicionales. Nuestro predictor no requiere acceso a la función de puntuación original o recuperaciones adicionales. Entonces, aunque nuestro método es similar a otros métodos de perturbación en el espíritu, se puede aplicar en situaciones cuando el sistema de recuperación es inaccesible o costoso de acceder. Finalmente, suponga que tenemos, además de la recuperación que queremos evaluar, recuperaciones de M de una variedad de sistemas diferentes. En este caso, podríamos tomar un documento A, comparar su rango en la recuperación con su rango promedio en las recuperaciones M. Si creemos que las recuperaciones M proporcionan una aproximación satisfactoria a la relevancia, entonces una gran diferencia en rango sugeriría que nuestra recuperación está maltrientando a. Si esta diferencia es grande en promedio en todos los documentos N, entonces podríamos predecir que la recuperación es mala. Si, por otro lado, la recuperación es muy consistente con las recuperaciones M, entonces podríamos predecir que la recuperación es buena. La similitud entre la recuperación y la recuperación combinada se puede calcular utilizando alguna medida de correlación. Esto se representa en la Figura 2c. En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1].5. Experimentos Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ (y, ˜y), ρ (y, yµ) y ρ (˜y, yµ). Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario. Nuestra metodología es consistente con investigaciones previas en que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en precisión promedio. Presentamos resultados para dos conjuntos de experimentos. El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos. Nuestro segundo conjunto de experimentos demuestra la generalización de nuestro enfoque para los métodos de recuperación arbitrarios, los tipos de corpus y los idiomas del corpus.5.1 Experimentos detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de idiomas utilizando nuestro predictor de autocorrelación, ρ (y, ˜y);No consideramos ρ (y, yµ) o ρ (˜y, yµ) porque, en estos experimentos detallados, nos centramos en clasificar las recuperaciones de un solo sistema. Utilizamos recuperaciones, valores para predictores de referencia y medidas de evaluación informadas en trabajos anteriores [19].5.1.1 Temas y colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones del modelo de lenguaje realizadas para consultas asociadas con colecciones en los corpus trec. El uso de colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación. En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 AD-HOC, TREC 5 AD-HOC, ROBUST 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Líneas de base proporcionamos dos líneas de base. Nuestra primera línea de base es el clásico predictor de claridad presentado en la Ecuación 6. La claridad está diseñada para usarse con sistemas de modelado de idiomas. Nuestra segunda línea de base es el predictor de robustez de clasificación Zhou y Crofts. Este predictor corrompe los principales documentos K de la recuperación y vuelva a computa los puntajes del modelo de idioma para estos documentos corruptos. El valor del predictor es la correlación de rango de Spearman entre la clasificación original y la clasificación corrupta. En nuestras tablas, etiquetaremos los resultados para mayor claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de generalización Nuestros predictores no requieren un sistema de recuperación de línea de base particular;Los predictores se pueden calcular para una recuperación arbitraria, independientemente de cómo se generan las puntuaciones. Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo. Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación.5.2.1 Temas y colecciones Recopilamos un conjunto diverso de colecciones de todos los Corporos de TREC posibles. Lanzamos una amplia red para localizar colecciones donde nuestros predictores puedan fallar. Nuestra hipótesis es que los documentos con alta similitud tópica deberían tener puntajes correlacionados. Por lo tanto, evitamos las colecciones donde era poco probable que los puntajes se correlacionaran (por ejemplo, la pregunta de respuesta) o probablemente se correlacionaran negativamente (por ejemplo, novedad). Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no ingleses) o no justificadas en absoluto (por ejemplo, búsqueda de expertos). Utilizamos las pistas ad-hoc de TREC3-8, TREC ROBUST 2003-2005, TREC TERABYTE 20042005, TREC4-5 español, TREC5-6 chino y TREC Enterprise Expert Search 2005. En todos los casos, usamos solo las ejecuciones automáticas para pistas ad-hoc enviadas a NIST. Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1. Para los corpus chinos, utilizamos vectores TF.IDF basados en el personaje de Na¨ıve. Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades cooCcurs.5.2.2 Líneas de base En nuestros experimentos detallados, utilizamos la medida de claridad como línea de base. Dado que estamos prediciendo el rendimiento de las recuperaciones que no se basan en el modelado de idiomas, utilizamos una versión de claridad denominada claridad de lista clasificada [7]. La claridad de la lista de clasificación convierte los rangos de documentos en valores P (Q | θi). Esta conversión comienza reemplazando todos los puntajes en Y con los rangos respectivos. Nuestra estimación de P (Q | θi) de los rangos, entonces es, P (Q | θi) = (2 (C+1 - Yi) C (C+1) Si yi ≤ C 0 de lo contrario (7)un parámetro de corte. Según lo sugerido por los autores, fijamos los parámetros del algoritmo C y λ2 para que C = 60 y λ2 = 0.10. Usamos la ecuación 6 para estimar P (W | θq) y DV Kl (θq θc) para calcular el valor del predictor. Nos referiremos a este predictor como DV KL, superscrito por V para indicar que la divergencia de Kullback-Leiber es con respecto al término espacio de incrustación. Cuando la información de múltiples ejecuciones en la misma consulta está disponible, utilizamos la divergencia multinomial Aslam y Pavlus Document-Space como línea de base [1]. Este método basado en rango primero normaliza los puntajes en una recuperación como un multinomial n-dimensional. Al igual que con la claridad de la lista clasificada, comenzamos reemplazando todos los puntajes en Y con sus respectivos rangos. Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nx k = yi 1 k 1 a (8) En nuestros experimentos multirun, solo usamos los 75 documentos principales de cada recuperación (n = =75);Esto está dentro del rango de valores de parámetros sugeridos por los autores. Sin embargo, admitimos no ajustar este parámetro ni para nuestro sistema o para la línea de base. El predictor es la divergencia entre la distribución del candidato, y, y la distribución media, yµ. Con la combinación lineal uniforme de estas recuperaciones M representadas como Yµ, podemos calcular la divergencia como dn kl (ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma está sobre el conjunto de n documentos. Esta línea de base se desarrolló en el contexto de predecir la dificultad de consulta, pero la adoptamos como una línea de base razonable para predecir el rendimiento de la recuperación.5.2.3 Configuración de parámetros Cuando se les dan múltiples recuperaciones, utilizamos documentos en la unión de los principales documentos K = 75 de cada una de las recuperaciones M para esa consulta. Si el tamaño de esta unión es ˜n, entonces Yµ y cada Yi es de longitud. En algunos casos, un sistema no obtuvo un documento en la Unión. Dado que estamos haciendo una suposición gaussiana sobre nuestros puntajes, podemos probar puntajes para estos documentos invisibles de la cola negativa de la distribución. Específicamente, muestras de la parte de la distribución inferior al valor mínimo de la recuperación normalizada. Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario. Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor. Descubrimos que esto mejoró sustancialmente para todos los predictores, incluidas las líneas de base. Consideramos combinaciones lineales de pares de predictores (marcados por los componentes) y todos los predictores (marcados como β).5.3 Evaluación Dada un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del orden de rango de este establecido por el predictor y por la métrica de rendimiento. Para garantizar la compatibilidad con resultados anteriores, presentamos la correlación τ de Kendall entre la clasificación de predictores y la clasificación basada en la precisión promedio de la recuperación. A menos que se indique explícitamente, todas las correlaciones son significativas con p <0.05. Los predictores a veces pueden funcionar mejor cuando se combinan linealmente [9, 11]. Aunque el trabajo previo ha presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede usarse de manera confiable al comparar ligeras mejoras de la combinación de predictores. Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables. El R2 ajustado nos permite evaluar la mejora en la predicción lograda agregando un parámetro pero pierde la interpretación estadística de R2. Usaremos Kendalls τ para evaluar la magnitud de la correlación y el R2 ajustado para evaluar la combinación de variables.6. Resultados Presentamos resultados para nuestros experimentos detallados que comparan la predicción de las puntuaciones del modelo de lenguaje en la Tabla 1. Aunque la medida de claridad está diseñada teóricamente para las puntuaciones del modelo de lenguaje, constantemente tiene un rendimiento constante de nuestro predictor agnóstico del sistema. La clasificación de robustez se presentó como una mejora de la claridad para las colecciones web (representadas en nuestros experimentos por las colecciones Terabyte04 y Terabyte05), cambiando la correlación τ de 0.139 a 0.150 para Terabyte04 y 0.171 a 0.208 para Terabyte05. Sin embargo, estas mejoras son ligeras en comparación con el rendimiento de la autocorrelación en estas colecciones. Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05. Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores basales. Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en todos los casos, los factores de autocorrelación como un componente necesario de un predictor fuerte. También observamos que el R2 ajustado para líneas de base individuales siempre se mejoran significativamente al incorporar la autocorrelación. Presentamos nuestros resultados de generalización en la Tabla 2. Comenzamos examinando la situación en la columna (a) donde se nos presentan una sola recuperación y sin información de recuperaciones adicionales. Para cada colección, excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada. Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones españolas y chinas a pesar de nuestro procesamiento na¨ıve. No tenemos una correlación de claridad de la lista clasificada para ENT05 porque el modelado de entidades es en sí una pregunta de investigación abierta. Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, tal vez porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coincrución que utilizamos. Como se señaló anteriormente, el rendimiento de pobre claridad en los datos web es consistente con nuestros hallazgos en los experimentos detallados. Clarity también notablemente tiene un rendimiento inferior para varios corpus de noticias (TREC5, TREC7 y ROBUST04). Por otro lado, la autocorrelación parece robusta a los cambios entre diferentes corpus. A continuación, pasamos a la introducción de información de múltiples recuperaciones. Comparamos las correlaciones entre aquellos predictores que no usan esta información en la columna (a) y las que lo hacen en la columna (b). Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones. Inspeccionando los predictores en la columna (b), solo sacamos conclusiones débiles. Nuestros nuevos predictores tienden a funcionar mejor en los corpus de noticias. Y entre nuestros nuevos predictores, el predictor híbrido ρ (˜y, yµ) tiende a funcionar mejor. Recuerde que nuestra medida ρ (˜y, yµ) incorpora información de recuperación espacial y múltiple. Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial. En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones. Observe que en los casos en que la autocorrelación, ρ (y, ˜y), solo funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de retrievia múltiple de ρ (y, yµ) enLa regresión lineal, β. En los casos en que ρ (y, yµ) funciona bien, la incorporación de la autocorrelación rara vez da como resultado una mejora significativa en el rendimiento. De hecho, en todos los casos donde nuestro predictor supera la línea de base, incluye información de múltiples ejecuciones.7. Discusión El resultado más importante de nuestros experimentos implica una predicción cuando no hay información disponible en múltiples ejecuciones (Tablas 1 y 2A). Esta situación surge a menudo en el diseño del sistema. Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir realizar un procesamiento más intensivo, como la retroalimentación o la interacción de pseudo-relevancia. Asumir la presencia de múltiples recuperaciones no es realista en este caso. Creemos que la autocorrelación es, como los algoritmos de retrieval múltiple, aproximando una buena clasificación;En este caso, difundiendo puntajes. ¿Por qué es un sustituto razonable? Sabemos que la difusión de puntajes en el gráfico web y los gráficos del modelo de lenguaje mejora el rendimiento [14, 16]. Por lo tanto, si la difusión de la puntuación tiende a, en general, mejorar el rendimiento, entonces los puntajes difundidos, en general, proporcionarán un buen sustituto de relevancia. Nuestros resultados demuestran que esta aproximación no es tan poderosa como la información de múltiples recuperaciones. Sin embargo, en situaciones en las que falta esta información, la autocorrelación proporciona información sustancial. El éxito de la autocorrelación como predictor también puede tener raíces en la hipótesis de agrupación. Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupación. Nuestros experimentos, entonces, demuestran que un fracaso para respetar la hipótesis de agrupación se correlaciona con un bajo rendimiento. ¿Por qué los sistemas pueden no cumplir con la hipótesis del clúster? Los sistemas de recuperación de información basados en la consulta a menudo obtienen documentos de forma independiente. La puntuación del Documento A puede calcularse examinando las coincidencias de la consulta o la frase, la longitud del documento y quizás las estadísticas de recolección globales. Una vez calculado, un sistema rara vez compara la puntuación de A con la puntuación de un documento bópicamente relacionado b. Con algunas excepciones, la correlación de los puntajes de los documentos se ha ignorado en gran medida. Debemos dejar en claro que hemos seleccionado tareas donde la autocorrelación tópica es apropiada. Ciertamente, hay casos en los que no hay razón para creer que los puntajes de recuperación tendrán autocorrelación tópica. Por ejemplo, las listas clasificadas que incorporan la novedad del documento no deben exhibir autocorrelación espacial;Si algo, la autocorrelación debe ser negativa para esta tarea. Del mismo modo, los candidatos de respuesta en una tarea de respuesta de pregunta pueden o no exhibir autocorrelación;En este caso, la semántica de los enlaces también es cuestionable. Es importante antes de aplicar esta medida para confirmar que, dada la semántica de algún vínculo entre dos elementos recuperados, debemos esperar una correlación entre las puntuaciones.8. Trabajo relacionado En esta sección, dibujamos comparaciones más generales con otros trabajos en la predicción del rendimiento y el análisis de datos espaciales. Hay un creciente cuerpo de trabajo que intenta predecir el rendimiento de las recuperaciones individuales [7, 3, 11, 9, 19]. Hemos intentado colocar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4. Sin embargo, una comparación completa está más allá del alcance de este documento. Sin embargo, observamos que nuestros experimentos cubren un conjunto de recuperaciones, colecciones y temas más grandes y más diversos que los examinados anteriormente. Mucho trabajo previo particularmente en el contexto de los trecfocusos para predecir el rendimiento de los sistemas. Aquí, cada sistema genera recuperaciones K. La tarea es, dadas estas recuperaciones, para predecir la clasificación de los sistemas de acuerdo con alguna medida de rendimiento. Varios documentos intentan abordar esta tarea bajo la restricción de pocos juicios [2, 4]. Algunos trabajos incluso intentan usar juicios cero aprovechando múltiples recuperaciones para la misma consulta [17]. Nuestra tarea difiere porque nos centramos en las recuperaciones de clasificación independientes del sistema generador. La tarea aquí no es probar el sistema de hipótesis A es superior al sistema B, pero probar la recuperación de hipótesis A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación. Neville y Jensen definen la autocorrelación relacional para los problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan la autocorrelación [13]. La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9]. Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal. En nuestro trabajo, nos centramos en el comportamiento de la función sobre las relaciones entre documentos.τ ajustado r2 dv kl p ρ (y, ˜y) dv kl p ρ (y, ˜y) dv kl, p dv kl, ρ (y, ˜y) pρ (y, ˜y) β trec4 0.353 0.548 0.513 0.1680.363 0.422 0.466 0.420 0.557 0.553 TREC5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robusto04 0.418 0.398 0.373 0.256 0.304 0.278 0.403333.4402 0.4442 teraby04 teraby04 Teraby04.450 0.450 0.450 0.454204420442044204204420420442 TERAT 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257Tabla 1: Comparación con las medidas de robustez y claridad para las puntuaciones del modelo de lenguaje. La evaluación replica experimentos de [19]. Presentamos correlaciones entre la medida de claridad clásica (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ (y, ˜y)) cada una con precisión promedio media en términos de Kendalls τ. Se presenta el coeficiente de determinación ajustado para medir la efectividad de la combinación de predictores. Las medidas en negrita representan la correlación más fuerte para ese par de pruebas/recolección.ejecución múltiple (a) (b) (c) τ τ ajustada r2 dkl ρ (y, ˜y) dn kl ρ (y, yµ) ρ (˜y, yµ) dn kl ρ (y, ˜y) ρ (y (y (y, yµ) ρ (˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 TREC4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.4482 0.482 0.450 0.016 0.016 0.2016. 280 0.157 0.375 0.323 0.386 TREC6 0.230 0.227 0.352 0.428 0.4180.203 0.089 0.323 0.325 0.325 TREC7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 TREC8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robuste 0.302 0.3020202. 0.269 0.206 0.274 0.392 0.303 robuste04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robuste050.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.333 Terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.4480 0.434 0.403 trec4-español 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-español 0.220 0.4580.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 TREC5-CHINESE 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 TREC6-Chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.310 trec6-chinese 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: gran escalaExperimentos de predicción. Predecimos la clasificación de grandes conjuntos de recuperaciones para diversas colecciones y sistemas de recuperación. Las correlaciones de Kendalls τ se calculan entre la clasificación prevista y una clasificación basada en la precisión promedio de recuperaciones. En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta. En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones. El coeficiente de determinación ajustado se calcula para determinar la efectividad de la combinación de predictores. Las medidas en negrita representan la correlación más fuerte para ese par de pruebas/recolección. Finalmente, los procesos de reanimiento basados en la regularización también están estrechamente relacionados con nuestro trabajo [8]. Estas técnicas buscan maximizar el acuerdo entre puntajes de documentos relacionados resolviendo un problema de optimización restringido. La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran. Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reanimiento basado en la regularización.9. Conclusión Hemos presentado un nuevo método para predecir el rendimiento de una clasificación de recuperación sin ningún juicio de relevancia. Consideramos dos casos. Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores demuestran correlaciones sólidas y fuertes con precisión promedio. Este rendimiento, combinado con una implementación simple, hace que nuestros predictores, en particular, sean muy atractivos. Hemos demostrado esta mejora para muchos entornos diversos. Hasta donde sabemos, este es el primer examen a gran escala de predicción de rendimiento de retrievación única de juicios cero. En segundo lugar, cuando se proporcionó recuperaciones de otros sistemas, nuestros métodos extendidos demuestran un rendimiento competitivo con líneas de base de última generación. Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones. Nuestros resultados sugieren dos conclusiones. Primero, nuestros resultados podrían afectar el diseño del algoritmo de recuperación. Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la hipótesis del clúster y mejorarán el rendimiento. En segundo lugar, nuestros resultados podrían afectar el diseño de algoritmos de recolección de pruebas mínimas. Gran parte del trabajo reciente en los sistemas de clasificación a veces ignora las correlaciones entre las etiquetas de los documentos y los puntajes. Creemos que estas dos direcciones podrían ser gratificantes dada la evidencia teórica y experimental en este documento.10. Agradecimientos Este trabajo fue apoyado en parte por el Centro para la Recuperación de Información Inteligente y en parte por la Agencia de Proyectos de Investigación Avanzada de Defensa (DARPA) bajo el número de contrato HR0011-06-C-0023. Cualquier opinión, hallazgos y conclusiones o recomendaciones expresadas en este material son los autores y no reflejan necesariamente las del patrocinador. Agradecemos a Yun Zhou y Desissava Petkova por proporcionar datos y Andre Gauthier por su asistencia técnica.11. Referencias [1] J. Aslam y V. Pavlu. Estimación de dureza de consulta utilizando la divergencia de Jensen-Shannon entre múltiples funciones de puntuación. En ECIR 2007: Actas de la 29ª Conferencia Europea sobre Recuperación de Información, 2007. [2] J. A. Aslam, V. Pavlu y E. Yilmaz. Un método estadístico para la evaluación del sistema utilizando juicios incompletos. En S. Dumais, E. N. Efthimiadis, D. Hawking y K. Jarvelin, editores, Actas de la 29a Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 541-548. ACM Press, agosto de 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow y D. Pelleg. ¿Qué hace que una consulta sea difícil? En Sigir 06: Actas de la 29a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 390-397, Nueva York, NY, EE. UU., 2006. ACM Press.[4] B. Carterette, J. Allan y R. Sitaraman. Colecciones de pruebas mínimas para la evaluación de recuperación. En Sigir 06: Actas de la 29a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 268-275, Nueva York, NY, EE. UU., 2006. ACM Press.[5] A. D. Cliff y J. K. Ord. Autocorrelación espacial. Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah y J. Allan. UMass en TDT 2004. Informe técnico CIIR Informe técnico IR - 357, Departamento de Informática, Universidad de Massachusetts, 2004. [7] S. Cronen -Townsend, Y. Zhou y W. B. Croft. Predicción de precisión basada en la coherencia de la lista clasificada. Inf. Retr., 9 (6): 723-755, 2006. [8] F. Díaz. Regularización de puntajes de recuperación ad-hoc. En CIKM 05: Actas de la 14ª Conferencia Internacional de ACM sobre Gestión de Información y Conocimiento, páginas 672-679, Nueva York, NY, EE. UU., 2005. ACM Press.[9] F. Díaz y R. Jones. Uso de perfiles temporales de consultas para predicción de precisión. En Sigir 04: Actas de la 27ª Conferencia Internacional de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 18-24, Nueva York, NY, EE. UU., 2004. ACM Press.[10] D. A. Griffith. Autocorrelación espacial y filtrado espacial. Springer Verlag, 2003. [11] B. Él y yo. Ousis. Inferir el rendimiento de la consulta utilizando predictores pre-retrievales. En el undécimo simposio sobre procesamiento de cadenas y recuperación de información (Spire), 2004. [12] N. Jardine y C. J. V. Rijsbergen. El uso de la agrupación jerárquica en la recuperación de información. Almacenamiento y recuperación de información, 7: 217-240, 1971. [13] D. Jensen y J. Neville. El enlace y la autocorrelación causan sesgo de selección de características en el aprendizaje relacional. En ICML 02: Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Autor, páginas 259-266, San Francisco, CA, EE. UU., 2002. Morgan Kaufmann Publishers Inc. [14] O. Kurland y L. Lee. Estructura del corpus, modelos de idiomas y recuperación de información ad-hoc. En Sigir 04: Actas de la 27ª Conferencia Internacional Anual de Investigación y Desarrollo en Recuperación de Información, páginas 194-201, Nueva York, NY, EE. UU., 2004. ACM Press.[15] M. Montague y J. A. Aslam. Normalización de la puntuación de relevancia para MetaSearch. En CIKM 01: Actas de la Décima Conferencia Internacional sobre Gestión de Información y Conocimiento, páginas 427-433, Nueva York, NY, EE. UU., 2001. ACM Press.[16] T. Qin, T.-Y. Liu, X.-D.Zhang, Z. Chen y W.-Y. Mamá. Un estudio de propagación de relevancia para la búsqueda web. En Sigir 05: Actas de la 28ª Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 408-415, Nueva York, NY, EE. UU., 2005. ACM Press.[17] I. Soboroff, C. Nicholas y P. Cahan. Sistemas de recuperación de clasificación sin juicios de relevancia. En Sigir 01: Actas de la 24ª Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 66-73, Nueva York, NY, EE. UU., 2001. ACM Press.[18] V. Vinay, I. J. Cox, N. Milic-Frayling y K. Wood. Al clasificar la efectividad de las búsquedas. En Sigir 06: Actas de la 29a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 398-404, Nueva York, NY, EE. UU., 2006. ACM Press.[19] Y. Zhou y W. B. Croft. Clasificación de robustez: un marco novedoso para predecir el rendimiento de la consulta. En CIKM 06: Actas de la 15ª Conferencia Internacional de ACM sobre Gestión de Información y Conocimiento, páginas 567-574, Nueva York, NY, EE. UU., 2006. ACM Press.