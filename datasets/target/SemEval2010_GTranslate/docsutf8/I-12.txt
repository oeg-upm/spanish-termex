Compartir experiencias para aprender características del usuario en entornos dinámicos con datos dispersos David Sarne, Barbara J. Grosz Escuela de Ingeniería y Ciencias Aplicadas Harvard University, Cambridge MA 02138 USA {Sarned, Grosz}@eecs.harvard.edu Resumen Este documento investiga el problema de el problema de el problema de el problema de laEstimación del valor de los parámetros probabilísticos necesarios para la toma de decisiones en entornos en los que un agente, que opera dentro de un sistema de múltiples agentes, no tiene información a priori sobre la estructura de la distribución de los valores de los parámetros. El agente debe poder producir estimaciones incluso cuando puede haber hecho solo un pequeño número de observaciones directas y, por lo tanto, debe ser capaz de operar con datos escasos. El documento describe un mecanismo que permite al agente mejorar significativamente su estimación al aumentar sus observaciones directas con las obtenidas por otros agentes con los que está coordinando. Para evitar un sesgo indeseable en entornos relativamente heterogéneos al tiempo que utiliza efectivamente datos relevantes para mejorar sus estimaciones, el mecanismo sopesan las contribuciones de las observaciones de otros agentes en función de una estimación en tiempo real del nivel de similitud entre cada uno de estos agentes y sí mismos. El módulo de autonomía de coordinación de un sistema de administrador de coordinación proporcionó un entorno empírico para la evaluación. Las evaluaciones basadas en la simulación demostraron que el mecanismo propuesto supera las estimaciones basadas exclusivamente en las observaciones propias de los agentes, así como las estimaciones basadas en un agregado no ponderado de todas las observaciones de los demás agentes. Categorías y descriptores de asignaturas I.2.6 [Inteligencia artificial]: aprendizaje de aprendizaje de parámetro;I.2.11 [Inteligencia artificial]: agentes distribuidos de inteligencia artificial-inteligencia, sistemas multiagentes;G.3 [Matemáticas de la computación]: Funciones de probabilidad y estadística Distribución de términos generales Algoritmos, Experimentación 1. Introducción Para muchos escenarios del mundo real, los agentes autónomos deben operar en entornos dinámicos e inciertos en los que solo tienen información incompleta sobre los resultados de sus acciones y características de otros agentes o personas con las que necesitan cooperar o colaborar. En tales entornos, los agentes pueden beneficiarse al compartir la información que recopilan, agrupando sus experiencias individuales para mejorar sus estimaciones de parámetros desconocidos necesarios para el razonamiento sobre las acciones bajo incertidumbre. Este documento aborda el problema de aprender la distribución de los valores de un parámetro probabilístico que representa una característica de una persona que interactúa con un agente informático. La característica a aprender es (o está claramente relacionada) con un factor importante en la toma de decisiones de los agentes.1 El entorno básico que consideramos es uno en el que un agente acumula observaciones sobre una característica específica del usuario y las usa para producir una estimación oportuna deAlguna medida que depende de esa distribución de características. Los mecanismos que desarrollamos están diseñados para ser útiles en una variedad de dominios de aplicación, como el rescate de desastres, que se caracterizan por entornos en los que las condiciones pueden cambiar rápidamente, las acciones (ya sea de agentes autónomos o de personas) y las operaciones generales se producen enUn ritmo rápido, y las decisiones deben tomarse dentro de marcos de tiempo muy limitados. Por lo general, los agentes deben tomar decisiones en tiempo real, concurrentes con la ejecución de la tarea y en medio de gran incertidumbre. En el resto de este documento, utilizamos el término acelerado para referirnos a dichos entornos. En entornos de ritmo rápido, la recopilación de información puede ser limitada, y no es posible aprender fuera de línea o esperar hasta que se recopilen grandes cantidades de datos antes de tomar decisiones. Los entornos de ritmo rápido imponen tres restricciones en cualquier mecanismo para aprender una función de distribución (incluida la amplia gama de técnicas de actualización bayesiana [23]): (a) La restricción de no estructura: no hay información a priori sobre la estructura de la distribución de parámetros estimados nicualquier datos iniciales de los cuales se puede inferir dicha estructura está disponible;(b) la restricción de uso limitado: los agentes generalmente necesitan producir solo un pequeño número de estimaciones en total para este parámetro;(c) La restricción de uso temprano: la alta precisión es un requisito crítico incluso en las etapas iniciales del aprendizaje. Por lo tanto, el objetivo de los métodos de estimación presentados en este documento es minimizar el error promedio con el tiempo, en lugar de determinar un valor preciso al final de un largo período de interacción. Es decir, se espera que el agente trabaje con el usuario por un tiempo limitado, e intenta minimizar el error general en sus estimaciones. En tales entornos, los agentes adquiridos individualmente (sus propias observaciones) son demasiado escasos para que obtenga buenas estimaciones en el marco de tiempo requerido. Dada la restricción sin estructura del entorno, los enfoques que dependen de distribuciones estructuradas pueden dar como resultado un sesgo de estimación significativamente alto. Consideramos este problema en el contexto de un sistema distribuido de múltiples agentes en el que los agentes informáticos apoyan a las personas que realizan tareas complejas en un entorno dinámico. El hecho de que los agentes formen parte de un entorno de múltiples agentes, en el que otros agentes pueden 1 aprender la distribución en lugar de solo determinar algún valor en la distribución es importante cada vez que la forma general de la distribución y no solo las características individuales como la media son importantes..También recopilar datos para estimar una característica similar de sus usuarios, ofrece la posibilidad de que un agente aumente sus propias observaciones con las de otros agentes, mejorando así la precisión de su proceso de aprendizaje. Además, en los entornos que consideramos, los agentes generalmente acumulan datos a una velocidad relativamente similar. No obstante, la medida en que las observaciones de otros agentes serán útiles para un agente dado depende de la medida en que las distribuciones de características de sus usuarios se correlacionen con las del usuario de este agente. No hay garantía de que la distribución para dos agentes diferentes esté altamente correlacionada positivamente, y mucho menos que sean las mismas. Por lo tanto, para utilizar un enfoque de intercambio de datos, un mecanismo de aprendizaje debe ser capaz de identificar de manera efectiva el nivel de correlación entre los datos recopilados por diferentes agentes y sopesar datos compartidos dependiendo del nivel de correlación. El diseño de un módulo de autonomía de coordinación (CA) dentro de un sistema de administrador de coordinación (como parte del Proyecto de Coordinadores de DARPA [18]), en el que los agentes admiten una tarea de programación distribuida, proporcionó la motivación inicial y una configuración conceptual para este trabajo. Sin embargo, los mecanismos en sí son generales y pueden aplicarse no solo a otros dominios de ritmo rápido, sino también en otros entornos de múltiples agentes en los que los agentes recopilan datos que se superponen en cierta medida, a tasas aproximadamente similares, y en el que el entornoimpone las restricciones sin estructura, de uso limitado y temprano definidos anteriormente (por ejemplo, exploración de planetas remotos). En particular, nuestras técnicas serían útiles en cualquier entorno en el que un grupo de agentes realice una tarea en un nuevo entorno, con cada agente obteniendo observaciones a una tasa similar de parámetros individuales que necesitan para su toma de decisiones. En este artículo, presentamos un mecanismo que se utilizó para aprender características clave del usuario en entornos de ritmo rápido. El mecanismo proporciona estimaciones relativamente precisas dentro de los cuadros de tiempo cortos al aumentar las observaciones directas de los agentes individuales con observaciones obtenidas por otros agentes con los que está coordinando. En particular, nos centramos en los problemas relacionados de estimar el costo de interrumpir a una persona y estimar la probabilidad de que esa persona tenga la información requerida por el sistema. Nuestro enfoque adaptativo, al que nos referiremos en todo el documento como comercio compartido selectivo, permite que nuestra CA mejore la precisión de sus estimaciones basadas en la distribución en comparación con confiar solo en las interacciones con un usuario específico (posteriormente, autoaprendizaje) oAgrupar todos los datos incondicionalmente (promedio todo), en particular cuando el número de observaciones disponibles es relativamente pequeña. El mecanismo se probó con éxito utilizando un sistema que simula un entorno de coordinadores. La siguiente sección del documento describe el problema de estimar los parámetros relacionados con el usuario en dominios acelerados. La Sección 3 proporciona una descripción general de los métodos que desarrollamos. La implementación, la configuración empírica y los resultados se dan en las Secciones 4 y 5. Se da una comparación con los métodos relacionados en la Sección 6 y las conclusiones en la Sección 7. 2. Estimación de parámetros en dominios con espacio rápido El módulo CA y los algoritmos que describimos en este documento se desarrollaron y probaron en el dominio de los Coordinadores [21]. En este dominio, los agentes autónomos, llamados coordinadores, tienen la intención de ayudar a maximizar un objetivo general del equipo al manejar los cambios en el horario de tareas a medida que cambian las condiciones de operación. Cada agente opera en nombre de su propietario (por ejemplo, el líder del equipo de un equipo de Firstesponse o un comandante de la unidad) cuyo horario administra. Por lo tanto, las tareas reales que se están programando son ejecutadas por propietarios o por unidades que supervisan, y la responsabilidad de los agentes se limita a mantener la programación de estas tareas y coordinar con los agentes de otros miembros del equipo humano (es decir, otros propietarios). En este dominio, se distribuyen información y limitaciones de programación. Cada agente recibe una visión diferente de las tareas y estructuras que constituyen el problema completo de múltiples agentes, típicamente, solo una parcial, local. El horario de las revisiones que afectan a más de un agente deben coordinarse, por lo que los agentes deben compartir ciertos tipos de información.(En un contexto de equipo, pueden estar diseñados para compartir otros tipos también). Sin embargo, la naturaleza acelerada del dominio limita la cantidad de información que pueden compartir, lo que impide una solución centralizada;Los problemas de programación deben resolverse de manera distribuida. La relación del agente y propietario es colaborativa, y el agente necesita interactuar con su propietario para obtener información de tareas y medio ambiente relevante para la programación. El módulo CA es responsable de decidir de manera inteligente cuándo y cómo interactuar con el propietario para mejorar la programación de los agentes. Como resultado, la CA debe estimar el beneficio esperado de dicha interacción y el costo asociado con ella [19]. En general, el beneficio neto de una interacción potencial es PV - C, donde V es el valor de la información que puede tener el usuario, P es la probabilidad de que el usuario tenga esta información y C es el costo asociado con una interacción. Los valores de P, V y C son variables en el tiempo, y la CA estima su valor en el momento previsto de iniciar la interacción con su propietario. Este documento se centra en los problemas gemelos de estimar los parámetros P y C, los cuales están centrados en el usuario en el sentido de estar determinados por las características del propietario y el entorno en el que el propietario está operando);supone un mecanismo para determinar V [18].2.1 Estimación de costos de interrupción El costo de interrumpir a los propietarios deriva de la degradación potencial en el rendimiento de las tareas que están haciendo causadas por la interrupción [1;9, entre otros]. La investigación sobre la gestión de la interacción ha implementado modelos estadísticos basados en sensores de interrupción humana para inferir el grado de distracción que probablemente sea causado por una interrupción. Este trabajo tiene como objetivo reducir los costos de interrupción al retrasar las interrupciones a los tiempos que son convenientes. Por lo general, utiliza modelos bayesianos para aprender un foco de atención actual o probable de los usuarios de un flujo continuo de acciones. Al usar sensores para proporcionar indicaciones entrantes continuas del estado atencional de los usuarios, estos modelos intentan proporcionar un medio para calcular las distribuciones de probabilidad sobre la atención e intenciones de los usuarios [9]. El trabajo que examina los factores de costo de interrupción como la frustración y la distractibilidad del usuario [10] incluye el trabajo sobre el costo de molestar repetidamente al usuario, lo que tiene en cuenta el hecho de que las interrupciones recientes y las preguntas difíciles deberían tener más peso que las interrupciones en el pasado distante o directoPreguntas [5]. Aunque este trabajo previo utiliza estimaciones de interrupción para equilibrar las interacciones estimadas de importancia contra el grado de distracción que probablemente sea causado, difiere del problema de entornos de ritmo rápido que abordamos de tres maneras que cambian fundamentalmente la naturaleza del problema y, por lo tanto, alteran la posible la posiblesoluciones. Primero, considera la configuración en la que el sistema informático tiene información que puede ser relevante para su usuario en lugar de que el usuario (propietario) tenga información que el sistema necesita, que es el complemento de la situación de intercambio de información que consideramos. En segundo lugar, los modelos de estimación de interrupción se basan en tareas. Por último, se basa en el monitoreo continuo de las actividades de los usuarios. En entornos de ritmo rápido, generalmente no hay una estructura de tareas única, y algunas de las actividades en sí mismas pueden tener poca estructura interna. Como resultado, es difícil determinar el estado atencional real de los propietarios de agentes [15]. En tales entornos, los propietarios deben tomar decisiones complejas que generalmente involucran a otros miembros de sus unidades, mientras que permanecen reactivos a los eventos que divergen de las expectativas [24]. Por ejemplo, durante el rescate por desastre, una unidad de primera respuesta puede comenzar a rescatar a los sobrevivientes atrapados en una casa en llamas, cuando una pared se derrumba repentinamente, obligando a la unidad a la sexta intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 203 Retraiga y replique sus acciones. El trabajo previo ha seguido el enfoque de la atención de los usuarios utilizando una variedad de dispositivos, incluidos los capaces de monitorear los gestos [8] y rastrear los ojos para identificar la atención visual [13, 20], lo que permite estimaciones de carga cognitiva e indicadores físicos de degradación del rendimiento. Los mecanismos descritos en este documento también suponen la existencia de tales sensores. Sin embargo, en contraste con el trabajo previo, que se basa en estos dispositivos que operan continuamente, nuestro mecanismo supone que los entornos de ritmo rápido solo permiten la activación de sensores por cortos períodos de tiempo de forma ad-hoc, porque los recursos de los agentes son severamente limitados. Los métodos que dependen de predecir lo que una persona hará a continuación solo en lo que el usuario está haciendo actualmente (por ejemplo, MDP) no son apropiados para modelar el enfoque de atención en los dominios de ritmo rápido, porque un agente no puede confiar en que el estado atencional de una persona sea atencional que seaBien estructurado y el monitoreo solo se puede hacer de forma esporádica y no continua. Por lo tanto, en cualquier momento, el costo de interacción con el usuario es esencialmente probabilístico, como se refleja en un solo evento de monitoreo aleatorio, y se le puede asignar una función de distribución de probabilidad. En consecuencia, en entornos de ritmo rápido, un agente necesita una estrategia de muestreo mediante la cual la CA muestrea el nivel de interrupción de sus propietarios (con algún costo) y decide si iniciar una interacción en este momento específico o retrasar hasta que se observe un costo más bajo en el futuromuestras. El método que describimos en el resto de esta subsección aplica conceptos de la teoría de la búsqueda económica [16] a este problema. La estimación de costos de CAS utiliza un mecanismo que integra la distribución de un nivel de interrupción de los propietarios (según lo estimado por la CA) en una estrategia de búsqueda económica, de manera que se minimice el costo general combinado de los costos del sensor y los costos de interacción. En su forma más básica, el problema de búsqueda económica tiene como objetivo identificar una oportunidad que minimice el costo esperado o maximizará la utilidad esperada. El proceso de búsqueda en sí está asociado con un costo y las oportunidades (en nuestro caso, oportunidades de interrupción) están asociados con una función de distribución estacionaria. Utilizamos una estrategia de búsqueda secuencial [16] en la que se dibuja una observación a la vez, en múltiples etapas de búsqueda. La estrategia dominante en este modelo es una estrategia basada en el valor de reserva que determina un límite inferior y sigue dibujando muestras siempre que no se haya dibujado ninguna oportunidad por encima del límite. En particular, consideramos la situación en la que el propietario de un agente tiene un costo de interrupción descrito por una función de distribución de probabilidad (PDF) F (x) y una función de distribución acumulativa (CDF) F (x). El agente puede activar los dispositivos de detección para obtener una estimación del costo de interrupción, X, en el momento actual, pero hay un costo C de operar los dispositivos de detección para una sola unidad de tiempo. El módulo CA establece un valor de reserva y siempre que la observación basada en el sensor X sea mayor que este valor de reserva, la CA esperará y volverá a mostrar al usuario para una nueva estimación. El costo esperado, V (XRV), utilizando dicha estrategia con valor de reserva XRV se describe mediante la Ecuación 1, V (XRV) = C + R XRV y = 0 yf (y) F (XRV), (1) que se descompone endos partes. La primera parte, C dividida por F (XRV), representa el costo de muestreo esperado. El segundo, la integral dividida por F (XRV), representa el costo esperado de la interrupción, porque el número esperado de ciclos de búsqueda es (aleatorio) geométrico y la probabilidad de éxito es F (XRV). Tomando la derivada del lado izquierdo de la ecuación 1 y igualarlo a cero, produce las características del valor de reserva óptimo, a saber, x ∗ rv debe satisfacer, v (x ∗ rv) = x ∗ rv.(2) Sustituir (2) en la ecuación 1 produce la ecuación 3 (después de la integración por partes) de la cual se puede calcular el valor de reserva óptimo, x ∗ rv y, en consecuencia, (de la ecuación 2) V (x ∗ rv) se puede calcular.c = z x ∗ rv y = 0 f (y) (3) Este método, que depende de extraer la secuencia óptima de muestreo de usuarios basado en sensores, depende en gran medida de la estructura de la función de distribución, F (x). Sin embargo, solo necesitamos una parte de la función de distribución, a saber, del origen al valor de reserva.(Ver la ecuación 1 y la Figura 1.) Por lo tanto, cuando consideramos compartir datos, no es necesario confiar en la similitud completa en la función de distribución de diferentes usuarios. Para algunos parámetros, incluido el nivel de interrupción de los usuarios, es suficiente para confiar en la similitud en la parte relevante de la función de distribución. La implementación descrita en las Secciones 4-5 se basa en este hecho. Figura 1: La estructura de distribución que afecta el cálculo de costos esperados 2.2 Estimando la probabilidad de tener información una forma en que un agente puede estimar la probabilidad de que un usuario tenga información que necesita (por ejemplo, sabrá en un tiempo de interrupción específico, con cierto nivel de confiabilidad,El resultado real de una tarea que se está ejecutando actualmente) es confiar en interacciones previas con este usuario, calculando la relación entre el número de veces que el usuario tuvo la información y el número total de interacciones. Alternativamente, el agente puede intentar inferir esta probabilidad de las características medibles del comportamiento de los usuarios, lo que puede evaluar sin requerir una interrupción. Este enfoque indirecto, que no requiere interrumpir al usuario, es especialmente útil en dominios de ritmo rápido. El módulo de CA que diseñamos utiliza un método indirecto: las interacciones del medio ambiente del propietario se utilizan como un proxy para medir si el propietario tiene cierta información. Por ejemplo, en escenarios similares a los coordinadores, los propietarios pueden obtener una variedad de información a través de reuniones de coordinación ocasionales de todos los propietarios, comunicación directa con otros propietarios individuales que participan en la ejecución de una tarea conjunta (a través de la cual pueden aprender informalmente sobre la existencia o estado de otrosAcciones que están ejecutando), abiertas comunicaciones que escuchan (por ejemplo, si los comandantes dejan sus radios abiertas, pueden escuchar mensajes asociados con otros equipos en su área) y otros canales de comunicación formales o informales [24]. Por lo tanto, los niveles de comunicación de los propietarios con otros, que se pueden obtener sin interrumpirlos, proporcionan alguna indicación de la frecuencia con la que obtienen nueva información. Dadas las actualizaciones ocasionales sobre su nivel de comunicación de propietarios, la CA puede estimar la probabilidad de que una interacción aleatoria con el propietario genere la información que necesita. Denota la función de distribución de probabilidad de la cantidad de comunicación que el usuario generalmente mantiene con su entorno por g (x) y utilizando la función de transformación z (x), mapeando de un nivel de comunicación, x, a la probabilidad de tener la información,La probabilidad esperada de obtener la información que se necesita del propietario al interrumpir en un momento dado se puede calcular a partir de P = Z ∞ 0 Z (x) G (x) Dy.(4) 204 El sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07), cuantas más observaciones se pueda acumular un agente sobre la distribución de la frecuencia de la interacción de los propietarios con el entorno en un momento dado, mejor puede estimar la probabilidad que el propietario tenga la información necesariapor el sistema.3. El mecanismo de intercambio selectivo Esta sección presenta el mecanismo de intercambio selectivo por el cual la CA aprende la función de distribución de un parámetro probabilístico aprovechando los datos recopilados por otros CA en su entorno. Primero explicamos la necesidad de aumentar el número de observaciones utilizadas como base de la estimación y luego presentar un método para determinar cuántos datos adoptar de otros agentes. El método más directo para que la CA aprenda las funciones de distribución asociadas con los diferentes parámetros que caracterizan a un propietario es construir un histograma basado en las observaciones que ha acumulado hasta el punto de estimación. Según este histograma, la CA puede estimar el parámetro teniendo en cuenta el rango completo de valores (por ejemplo, para estimar la media) o una parte de la misma (por ejemplo, para encontrar el costo esperado al usar un valor de reserva basado en el valor de la reservaestrategia). La precisión de la estimación variará ampliamente si se basa solo en un pequeño número de observaciones. Por ejemplo, la Figura 2 ilustra el costo basado en el valor de reserva calculado de acuerdo con las observaciones recibidas de un propietario con una distribución de costos de interrupción uniforme U (0, 100) en función del número de observaciones acumuladas utilizadas para generar el histograma de distribución.(En esta simulación, se consideró que el costo de activación del dispositivo era C = 0.5). Figura 2: La convergencia de una sola CA a su estrategia óptima estas desviaciones del valor real (verdadero) (que es 10 en este caso, según la ecuación 3) se debe a que la muestra utilizada en cada etapa no puede capturar con precisión la estructura real dela función de distribución. Finalmente, este método produce una estimación muy precisa para el costo de interrupción esperado. Sin embargo, en las etapas iniciales del proceso, su estimación se desvía significativamente del valor real. Este error podría degradar seriamente el proceso de toma de decisiones de CAS: la subestimación del costo puede resultar en iniciar interacciones costosas y no beneficiosas, y sobreestimar el costo puede dar lugar a oportunidades faltantes para interacciones valiosas. Cualquier mejora que se pueda lograr al predecir los valores de costos, especialmente en las etapas iniciales del aprendizaje, puede marcar una diferencia significativa en el rendimiento, especialmente porque el agente está severamente limitado en el número de veces que puede interactuar con su propietario en dominios con espacio rápido. Una forma de disminuir la desviación del valor real es aumentar los datos que la CA adquiere observando a su propietario con observaciones hechas por otros agentes de propietarios. Tal enfoque depende de identificar a otros propietarios con funciones de distribución para la característica de interés similar al propietario de CAS. Esta idea de dataugmentation es simple: diferentes propietarios pueden exhibir comportamientos o patrones básicos similares en escenarios de tareas de ritmo rápido similares. Dado que todos están coordinando en una tarea general común y están operando en el mismo entorno, es razonable asumir cierto nivel de similitud en la función de distribución de sus parámetros modelados. Las personas varían en su comportamiento, por lo que, obviamente, puede haber diferentes tipos de propietarios: algunos enfatizarán la comunicación con sus equipos y otros pasarán más tiempo en la planificación basada en mapas;A algunos les disgustará ser perturbados mientras intentan evaluar el progreso de sus equipos, mientras que otros pueden estar más abiertos a las interrupciones. En consecuencia, es probable que un propietario CA pueda encontrar algunos CA que trabajen con propietarios que sean similares a su propietario. Al adoptar datos recopilados por otros agentes, las dos preguntas principales son en qué agentes deben confiar la CA y en qué medida debe confiar en cada uno de ellos. El mecanismo de intercambio selectivo se basa en una medida estadística de similitud que permite a la CA de cualquier usuario específico identificar la similitud entre su propietario y otros propietarios dinámicamente. Según este nivel de similitud, la CA decide si y en qué medida importar otros datos CAS para aumentar sus observaciones directas y, por lo tanto, permitir un mejor modelado de las características de sus propietarios. Es notable que el costo de transferir observaciones entre diferentes módulos de CA de diferentes agentes sea relativamente pequeño. Esta información puede transferirse como parte de la comunicación regular de negociación entre los agentes. El volumen de dicha comunicación es insignificante: implica solo la transmisión de nuevos valores de observaciones. En nuestro mecanismo de aprendizaje, la CA actualiza constantemente su estimación del nivel de similitud entre su propietario y los propietarios representados por otros CA en el entorno. Cada nueva observación obtenida por esa CA o cualquiera de las otras actualizaciones de CAS esta estimación. El nivel de similitud se determina utilizando la prueba de suma de rango Wilcoxon (subsección 3.1). Siempre que sea necesario producir una estimación de parámetros, la CA decide sobre el número de observaciones adicionales en las que tiene la intención de confiar para extraer su estimación. El número de observaciones adicionales que se tomarán del agente de otro es una función del número de observaciones que tiene actualmente de interacciones anteriores con su propietario y el nivel de confianza que la CA tiene en la similitud entre su propietario y otros propietarios. En la mayoría de los casos, el número de observaciones que la CA querrá tomar de otro agente es menor que el número general de observaciones que tiene el otro agente;Por lo tanto, muestra al azar (sin repeticiones) el número requerido de observaciones de esta base de datos de otros agentes. Las observaciones adicionales que la CA toma de otros agentes se usa solo para modelar las características de sus propietarios. La determinación del nivel de similitud futura no se ve afectada por este procedimiento de aumento de información.3.1 La prueba de Wilcoxon usamos un método no paramétrico (es decir, uno que no ofrece suposiciones sobre la forma paramétrica de las distribuciones de las que se extrae cada conjunto), porque las características del usuario en dominios de ritmo rápido no tienen la estructura necesaria para enfoques paramétricos. Dos ventajas adicionales de un enfoque no paramétrico son su utilidad para lidiar con observaciones inesperadas y periféricas (posiblemente problemáticas para un enfoque paramétrico), y el hecho de que los enfoques no paramétricos son computacionalmente muy simples y, por lo tanto.escaso. La prueba de suma de rango Wilcoxon que usamos es una alternativa no paramétrica a la prueba t de dos muestras [22, 14] 2. Mientras que la prueba t se compara significa, la prueba de Wilcoxon se puede usar para probar la hipótesis nula de que dos poblaciones x e y tienen la misma distribución continua. Suponemos que tenemos muestras aleatorias independientes {x1, x2, ..., xm} y {y1, y2, ..., yn}, de tamaños my n respectivamente, de cada población. Luego fusionamos los datos y clasificamos cada medición de más baja a más alta. A todas las secuencias de lazos se les asigna un rango promedio. De la suma de las filas de la prueba de bondad de ajuste de 2 chi-cuadrado más pequeña es para una sola muestra y, por lo tanto, no es adecuada. El sexto intl. Conf.En los agentes autónomos y los sistemas de múltiples agentes (AAMAS 07) 205 muestra, calculamos el estadístico de prueba y extraemos el nivel de confianza para rechazar la hipótesis nula. Este nivel de confianza se convierte en la medida del nivel de similitud entre los dos propietarios. La prueba de Wilcoxon no requiere que los datos se origen de una población normalmente distribuida o que la distribución se caracterice por un conjunto finito de parámetros.3.2 Determinar la información requerida identificando correctamente el número correcto de observaciones adicionales para recopilar es un determinante clave del éxito del mecanismo de intercambio selectivo. Obviamente, si la CA puede identificar a otro propietario que tiene características idénticas al propietario que representa, entonces debería usar todas las observaciones recopiladas por ese agente de propietarios. Sin embargo, es probable que los casos de coincidencias idénticas sean muy poco comunes. Además, incluso para establecer que otro usuario es idéntico al suyo, la CA necesitaría tamaños de muestra sustanciales para tener un nivel de confianza relativamente alto. Por lo tanto, por lo general, la CA necesita decidir cuánto depender de los datos de otros agentes al tiempo que estiman varios niveles de similitud con un nivel cambiante de confianza. Al comienzo de su proceso, el mecanismo de intercambio selectivo casi no tiene datos en los que confiar y, por lo tanto, no se puede utilizar una medida de similitud. En este caso, el módulo CA depende en gran medida de otros agentes, con la expectativa de que todos los propietarios tengan un nivel básico de similitud en su distribución (ver Sección 2). A medida que aumenta el número de sus observaciones directas, el módulo CA refina el número de observaciones adicionales requeridas. Nuevamente, hay dos efectos contradictorios. Por un lado, cuantos más datos tenga la CA, mejor puede determinar su nivel de confianza en las calificaciones de similitud que tiene para otros propietarios. Por otro lado, suponiendo que hay alguna diferencia entre los propietarios (incluso si aún no se nota), a medida que aumenta el número de sus observaciones directas, los propietarios poseen datos deberían aumentar de peso en su análisis. Por lo tanto, cuando CAI decide cuántas observaciones adicionales, se debe adoptar oi J de la base de datos de CAJS, calcula Oi J como sigue: oi j = n ∗ (1 - αi, j) √ n + 2 + ln (n) n (5) Donde N es el número de observaciones que CAI ya tiene (que es similar en magnitud al número de observaciones que CAJ tiene) y αi, J es la confianza de rechazar la hipótesis nula de Wilcoxon. La función en la ecuación 5 asegura que el número de observaciones adicionales que se tomarán de otro módulo CA aumenta a medida que aumenta la confianza en la similitud con la fuente de estas observaciones adicionales. Al mismo tiempo, asegura que el nivel de dependencia de las observaciones externas disminuya a medida que aumenta el número de observaciones directas. Al calcular el parámetro αi, J, siempre realizamos la prueba durante el intervalo relevante para la función de distribución de CAS de origen. Por ejemplo, al estimar el costo de interrumpir al usuario, aplicamos la prueba de Wilcoxon solo para observaciones en el intervalo que comienza desde cero y termina ligeramente a la derecha del RV anteriormente estimado (ver Figura 1).4. Configuración empírica probamos el mecanismo de intercambio selectivo en un sistema que simula un MAS distribuido, similar a los coordinadores. Este entorno de Testbed incluye un número variable de agentes, cada uno correspondiente a un solo módulo de CA. A cada agente se le asigna una fuente externa (simulando un propietario) que muestra periódicamente para obtener un valor de la distribución que se estima. El sistema de simulación nos permitió evitar la sobrecarga innecesaria de la programación y la comunicación entre agentes (que son una parte inherente del entorno de los coordinadores) y, por lo tanto, aislar mejor el rendimiento y la efectividad de los mecanismos de estimación y toma de decisiones. Las funciones de distribución utilizadas en los experimentos (es decir, las funciones de distribución asignadas a cada usuario en el entorno simulado) son de forma multirrectangular. Este tipo de función es ideal para representar funciones de distribución empírica. Se compone de k rectángulos, donde cada rectángulo I se define durante el intervalo (xi - 1, xi), y representa una probabilidad Pi, (Pk i = 1 pi = 1). Para cualquier valor x en el rectángulo I, podemos formular f (x) y f (x) como: f (x) = pi xi - xi - 1 f (x) = i - 1x j = 1 pj + (x - xi−1) Pi xi-xi-1 (6) Por ejemplo, la función multirrectangular en la Figura 3 representa una posible distribución de costos de interrupción para un usuario específico. Cada rectángulo está asociado con una de las actividades típicas de los usuarios, caracterizadas por un conjunto de costos de interrupción típicos.(Asumimos que la distribución del costo dentro de cada actividad es uniforme). El área rectangular representa la probabilidad de que el usuario participe en este tipo de actividad cuando se interrumpe al azar. Cualquier superposición entre los costos de interrupción de dos o más actividades da como resultado un nuevo rectángulo para el intervalo superpuesto. El usuario asociado con la función de distribución anterior pasa la mayor parte de su tiempo en la presentación de informes (observe que este es el rectángulo más grande en términos de área), una actividad asociada con un costo relativamente alto de interrupción. El usuario también pasa una gran parte de su tiempo en planificación (asociado con un costo muy alto de interrupción), monitoreando a su equipo (con un costo de interrupción relativamente pequeño) y recibir informes (costo de interrupción de nivel medio). El usuario pasa una porción relativamente pequeña de su tiempo en explorar al enemigo (asociado con un costo de interrupción relativamente alto) y descansando. Figura 3: Representar la distribución de los costos de interrupción utilizando una función multirrectangular Las funciones multirangulares son modulares y permiten la representación de cualquier forma de distribución controlando el número y las dimensiones de los rectángulos utilizados. Además, estas funciones tienen ventajas computacionales, principalmente debido a la capacidad de reutilizar muchos de sus componentes al calcular el valor de reserva óptimo en los modelos de búsqueda económicos. También se ajustan bien a los parámetros que la CA está tratando de estimar en dominios de ritmo rápido, porque estos parámetros están en su mayoría influenciados por actividades en las que el usuario está involucrado. El sistema Testbed nos permitió definir funciones de distribución multidrectangulares hechas a mano o generadas automáticamente. En cada paso de una simulación, cada una de las muestras de CAS su propietario (es decir, todos los CA en el sistema recopilan datos a una velocidad similar) y luego estima el parámetro (ya sea el costo esperado cuando se usa la técnica de interrupción secuencial descrita en la Sección 2 oLa probabilidad de que el propietario tenga la información requerida) utilizando uno de los siguientes métodos: (a) confiar únicamente en los datos de observación directa (autoaprendizaje);(b) confiar en los datos combinados de todos los demás agentes (promedio de todos);y, (c) confiar en sus propios datos y porciones selectivas de los datos de otros agentes basados en el mecanismo de intercambio selectivo descrito en la Sección 3. 5. Resultados Presentamos los resultados en dos partes: (1) utilizando un entorno de muestra específico para ilustrar el comportamiento básico del mecanismo selectivo;y (2) usar entornos generales que se generaron automáticamente.206 El sexto intl. Conf.En agentes autónomos y sistemas de agentes múltiples (AAMAS 07) 5.1 Entorno de muestra para ilustrar la ganancia obtenida utilizando el mecanismo de intercambio selectivo, utilizamos un entorno de 10 agentes, asociado con 5 diferentes tipos de funciones de distribución de costos de interrupción. La tabla de la Figura 4 detalla la división de los 10 agentes en tipos, las dimensiones de los rectángulos que forman las funciones de distribución, y la media teórica y el valor de reserva (RV) (después de la ecuación 3) con un costo C = 2 para detectar elCosto de interrupción. Aunque los medios de los cinco tipos son relativamente similares, el uso de una estrategia de interrupción basada en el valor de reserva produce costos de interrupción esperados relativamente diferentes (RV, después de la ecuación 2). El histograma en esta figura muestra el número de observaciones obtenidas para cada contenedor de tamaño 1 de una muestra de 100000 observaciones tomadas de la función de distribución de cada tipo. Tipo de agentes rect. Rango de prueba media RV I 1,2 1 0-20 0.40 50 14.1 2 20-80 0.20 3 80-100 0.40 II 3,4,5,6 1 0-40 0.25 50 25.3 2 40-60 0.50 3 60-100 0.25III 7 1 0-80 0.10 85 56.6 2 80-100 0.90 IV 8,9 1 0-60 0.60 48 20.0 2 60-90 0.40 V 10 1 0-100 1.00 50 20.0 0 500 1000 1500 2000 2500 1 8 15 22 29 2936 43 50 57 64 71 78 85 92 99 Tipo I Tipo II Tipo III Tipo IV Tipo V #Fobservations Rango Figura 4: Funciones de distribución de costos de interrupción de usuarios (5 tipos) La Figura 5 proporciona un rendimiento de CA al estimar el costo esperado de la interrupción cuando se usa el uso delTécnica de iniciación de interrupción basada en el valor de reserva. Cada gráfico presenta la precisión de predicción promedio (en términos de la desviación absoluta del valor teórico, por lo que cuanto menor sea la curva, mejor será el rendimiento) de un tipo diferente, basado en las ejecuciones de simulación de 10000. Las tres curvas en cada gráfico representan los métodos que se están comparando (autodeclaración, promedio todos y compartir selectivo). Los datos se dan en función del número acumulado de observaciones recopiladas. El sexto gráfico de la figura es el promedio de todos los tipos, ponderado según el número de agentes de cada tipo. Del mismo modo, la siguiente tabla resume el rendimiento promedio general en términos de la desviación absoluta del valor teórico de cada uno de los diferentes métodos: iteraciones de autoaprendizaje promedio-todo Selectivo compartido % Mejora3 5 20.08 8.70 9.51 53 % 15 12.62 7.84 8.14 36 36 36 36 36% 40 8.16 7.42 6.35 22% Tabla 1: Error absoluto promedio A lo largo del tiempo Se pueden hacer varias observaciones de la Figura 5. Primero, aunque el método promedio de todo puede producir resultados relativamente buenos, rápidamente alcanza el estancamiento, mientras que los otros dos métodos exhiben una mejora continua en función de la cantidad de datos acumulados. Para el entorno de la Figura 4, el promedio de todo es una buena estrategia para los agentes de tipo II, IV y V, porque el valor de reserva teórico de cada uno de estos tipos está cerca de la obtenida en función de la función de distribución agregada (es decir, 21.27).4 Sin embargo, para los tipos I y III para los cuales el RV óptimo difiere de ese valor, el método promedio de todo funciona significativamente peor. En general, el sexto gráfico y la tabla anterior muestran que, si bien en este entorno específico, el método promedio de todo funciona bien en las primeras interacciones, 3 la mejora se mide en porcentajes en relación con el método de autoaprendizaje.4 El valor se obtiene construyendo la función distribuida agregada ponderada de acuerdo con los diferentes tipos de agentes y extrayendo la RV óptima usando la ecuación 3. 0 4 8 12 16 20 1 6 11 16 16 26 26 36 Tipo I 0 4 8 12 16 20 1 16 11 16 21 26 31 36 36 Selective compartir el promedio de auto-aprendizaje Todo 0 4 8 12 16 20 1 6 11 16 21 26 31 36 36 Tipo II 0 8 16 24 32 40 1 6 11 16 21 26 31 36 36 Tipo III 0 4 8 1216 20 1 6 11 16 21 26 26 31 36 Tipo IV 0 4 8 12 16 20 1 6 11 16 21 26 31 36 Tipo V 0 4 8 12 16 20 1 6 11 16 16 26 31 36 Promedio ponderado Figura 5: Desviación absoluta promedioDesde el RV teórico en cada método (10000 ejecuciones) se supera rápidamente por el mecanismo de intercambio selectivo. Además, cuantas más observaciones de los usuarios acumulan (es decir, a medida que extendemos el eje horizontal), mejor sean los otros dos métodos en comparación con el promedio de todos. A largo plazo (y como se muestra en la siguiente subsección para el caso general), el método promedio de todo exhibe el peor rendimiento. En segundo lugar, el mecanismo de intercambio selectivo comienza con una mejora significativa en comparación con depender de las propias observaciones de los agentes, y luego esta mejora disminuye gradualmente hasta que finalmente su curva de rendimiento coincide con la curva de métodos de autoaprendizaje. El mecanismo de intercambio selectivo funciona mejor o peor, dependiendo del tipo, porque la prueba de Wilcoxon no puede garantizar una identificación exacta de similitud;Las diferentes combinaciones de la función de distribución pueden dar lugar a una incapacidad para identificar exactamente a los usuarios similares para algunos de los tipos específicos. Por ejemplo, para los agentes tipo I, el mecanismo de intercambio selectivo en realidad funciona peor que el autoaprendizaje a corto plazo (a largo plazo, los dos métodos convergen el rendimiento). Sin embargo, para los otros tipos en nuestro ejemplo, el mecanismo de intercambio selectivo es el más eficiente y supera a los otros dos métodos en general. En tercer lugar, es notable que para los agentes que tienen un tipo único (por ejemplo, Agente III), el mecanismo de intercambio selectivo converge rápidamente para confiar en los datos autocollectados. Este comportamiento garantiza que incluso en escenarios en los que los usuarios son completamente diferentes, el método exhibe una degradación inicial elegante pero administra, en unos pocos pasos, adoptar el comportamiento adecuado de contar exclusivamente en datos autogenerados. Por último, a pesar de la diferencia en su función de distribución general, los agentes de Tipo IV y V exhiben un rendimiento similar porque la parte relevante de sus funciones de distribución (es decir, las partes efectivas que afectan el cálculo de RV como se explica en la Figura 1) es idéntica. Por lo tanto, el mecanismo de intercambio selectivo permite que el agente del tipo V, a pesar de su función de distribución única, adopte información relevante recopilada por agentes de los tipos IV, lo que mejora su estimación del costo de interrupción esperado.5.2 Evaluación general Para evaluar el intercambio selectivo, ejecutamos una serie de simulaciones en las que el entorno se generó aleatoriamente. Estos experimentos se centraron en las estimaciones CAS de la probabilidad de que el usuario tenga la información requerida si se interrumpe. Utilizaron una función de distribución de probabilidad multirrectangular para representar el sexto INTL. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 207 La cantidad de comunicación en la que se dedica el usuario a su entorno. Modelamos el crecimiento de la probabilidad que el usuario tenga la información requerida en función de la cantidad de comunicación utilizando la función logística, 5 g (x) = 1 + e −x 12 1 + 60E −x 12.(7) El valor esperado (media) del parámetro que representa la probabilidad que el usuario tenga la información requerida es, por lo tanto, μ = z ∞ y = 0 g (y) f (y) dy = kx i = 1 hx + 708ln (60 +E x 12) Pi 60 (xi - xi - 1) ixi xi - 1 (8) donde k es el número de rectángulos utilizados. Ejecutamos 10000 corridas de simulación. Para cada simulación, el sistema generó automáticamente un nuevo entorno de 20 agentes, y los agentes se dividieron aleatoriamente en un número aleatorio de diferentes tipos.6 Para cada tipo, se generó una función de distribución de 3 rectángulos aleatorias. Cada simulación corrió 40 pasos de tiempo. En cada paso de tiempo, cada uno de los agentes acumuló una observación adicional. Cada CA calculó una estimación de la probabilidad de que su usuario tuviera la información necesaria de acuerdo con los tres métodos, y se registró el error absoluto (diferencia del valor teórico calculado según la Ecuación 8). La siguiente tabla resume el rendimiento promedio de los tres mecanismos a lo largo de diferentes horizontes temporales (medidos en 5, 15 y 40 pasos de tiempo): iteraciones Autoaprendizaje promedio: todo el sharing sharing % mejora 5 0.176 0.099 0.103 41.4 % 15 0.115 0.088 0.087 23.9.9.9% 40 0.075 0.082 0.065 13.6% Tabla 2: Error absoluto promedio A lo largo de los pasos de tiempo como se puede ver en la tabla anterior, el método de intercambio selectivo propuesto supera los otros dos métodos sobre cualquier ejecución en el que se recopilen más de 15 observaciones de cada uno delos agentes. Como en el entorno de muestra, el método promedio de todo funciona bien en los pasos de tiempo iniciales, pero no exhibe una mejora adicional. Por lo tanto, cuanto más datos recopilados, mayor es la diferencia entre este último método y los otros dos métodos. La diferencia promedio entre el intercambio selectivo y el autoaprendizaje disminuye a medida que se recopilan más datos. Finalmente, medimos el efecto del número de tipos en el medio ambiente. Para este propósito, utilizamos el mismo método de autogeneración, pero controlamos el número de tipos generados para cada ejecución. El número de tipos es una buena indicación del nivel de heterogeneidad en el medio ambiente. Para cada número de tipos, ejecutamos 10000 simulaciones. La Figura 6 muestra el rendimiento de los diferentes métodos (para un período de recolección de 40 observación para cada agente). Dado que todas las ejecuciones de simulación utilizadas para generar la Figura 6 se basan en la misma semilla, el rendimiento del mecanismo de autoaprendizaje es constante independientemente del número de tipos en el entorno. Como se esperaba, el mecanismo promedio de todo funciona mejor cuando todos los agentes son del mismo tipo;Sin embargo, su rendimiento se deteriora a medida que aumenta el número de tipos. Del mismo modo, el mecanismo de intercambio selectivo exhibe buenos resultados cuando todos los agentes son del mismo tipo, y a medida que aumenta el número de tipos, su rendimiento se deteriora. Sin embargo, la disminución del rendimiento es significativamente más modesta en comparación con la experimentada en el mecanismo promedio de todo.5 Los coeficientes específicos utilizados garantizan una curva de crecimiento similar a S, a lo largo del intervalo (0, 100), donde la etapa inicial de crecimiento es aproximadamente exponencial, seguida de un crecimiento asintóticamente desacelerado.6 En este esquema de generación de entorno sugerido no hay garantía de que cada agente tenga un agente similar potencial para compartir información. En aquellos escenarios no raros en los que la CA es la única de su tipo, rápidamente necesitará dejar de confiar en los demás.0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 1 2 3 4 5 Auto aprendizaje promedio All Selective Compartir Número de tipos AverageBeBsoluteError Figura 6: Desviación absoluta promedio del valor real en 20 escenarios de agentes en función del nivel de heterogeneidad de los agentes en general, el intercambio selectivo en general, el intercambio selectivoEl mecanismo supera a los otros métodos para cualquier número de tipos mayores que uno.6. Trabajo relacionado Además de la literatura de gestión de interrupciones revisadas en la Sección 2, varias otras áreas de trabajo previo son relevantes para el mecanismo de intercambio selectivo descrito en este documento. El filtrado colaborativo, que hace predicciones (filtrado) sobre los intereses de un usuario [7], funciona de manera similar al intercambio selectivo. Sin embargo, los sistemas de filtrado colaborativo exhiben un bajo rendimiento cuando no hay suficiente información sobre los usuarios y cuando no hay información suficiente sobre un nuevo usuario cuyo gusto el sistema intenta predecir [7]. El intercambio selectivo se basa en la capacidad de encontrar similitud entre partes específicas de la función de distribución de probabilidad asociada con una característica de diferentes usuarios. Esta capacidad está estrechamente relacionada con la agrupación y la clasificación, un área ampliamente estudiada en el aprendizaje automático. Dadas las consideraciones de espacio, nuestra revisión de esta área está restringida a algunos enfoques representativos para la agrupación. A pesar de la riqueza de los algoritmos de agrupación disponibles (como el famoso algoritmo de agrupamiento de K-means [11], los métodos jerárquicos, los clasificadores bayesianos [6] y la máxima entropía), varias características de dominios de ritmo rápido no se alinean bien con los bien con losCaracterísticas de los mecanismos de agrupación basados en atributos, lo que sugiere que estos mecanismos no funcionarían bien en tales dominios. De particular importancia es que la CA necesita encontrar similitud entre las funciones, definidas en un intervalo continuo, sin atributos predefinidos distintos. Una dificultad adicional es definir la medida de distancia. Se han utilizado muchas técnicas de agrupación en la minería de datos [2], con un enfoque particular en actualizaciones incrementales de la agrupación, debido al gran tamaño de las bases de datos [3]. Sin embargo, la aplicabilidad de estos a dominios de ritmo rápido es bastante limitada porque dependen de un gran conjunto de datos existentes. Del mismo modo, los algoritmos de agrupación diseñados para la tarea de identificación de clase en bases de datos espaciales (por ejemplo, depender de una noción basada en densidad [4]) no son útiles para nuestro caso, porque nuestros datos no tienen atributos espaciales. El método más relevante para nuestros propósitos es el índice de entropía relativa Kullback-Leibbler que se utiliza en la teoría de la probabilidad y la teoría de la información [12]. Esta medida, que también se puede aplicar en variables aleatorias continuas, se basa en una medida de distancia natural desde una distribución de probabilidad verdadera (ya sea basada en la observación o calculada) a una distribución de probabilidad arbitraria. Sin embargo, el método funcionará mal en escenarios en los que las funciones se alternan entre diferentes niveles mientras mantienen la estructura general y los momentos. Por ejemplo, considere las dos funciones f (x) = (x mod2)/100 y g (x) = (x mod2)/100 definidas durante el intervalo (0, 200). Si bien estas dos funciones están asociadas con valores de reserva casi idénticos (para cualquier costo de muestreo) y media, el método Kullback-Leiber asignará una correlación deficiente entre 208 el Sexto INTL. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) ellos, mientras que nuestro enfoque basado en Wilcoxon les dará el rango más alto en términos de similitud. Si bien la prueba de Wilcoxon es un procedimiento estadístico ampliamente utilizado [22, 14], generalmente se usa para comparar dos conjuntos de datos de un solo variado. Hasta donde sabemos, aún no se ha intentado extender sus propiedades como una infraestructura para determinar con quién y en qué medida la información debe compartirse, como se presenta en este documento. El uso típico de esta herramienta no paramétrica incluye la detección de eventos raros en las series de tiempo (por ejemplo, una predicción de falla del disco duro [17]) y aplicaciones bioinformáticas (por ejemplo, encontrar genes informativos a partir de datos de microarrays). En estas aplicaciones, se utiliza principalmente como una herramienta de identificación y criterio de clasificación.7. Discusión y conclusiones El mecanismo de intercambio selectivo presentado en este documento no hace ninguna suposición sobre el formato de los datos utilizados o sobre la estructura de la función de distribución del parámetro a estimar. Es computacionalmente liviano y muy simple de ejecutar. El intercambio selectivo permite que un agente se beneficie de las observaciones de otros agentes en escenarios en los que están disponibles fuentes de datos del mismo tipo. También garantiza, como un respaldo, un rendimiento equivalente al de un autoaprendedor cuando la fuente de información es única. Además, el intercambio selectivo no requiere ningún conocimiento previo sobre los tipos de fuentes de información disponibles en el entorno o sobre el número de agentes asociados con cada tipo. Los resultados de nuestras simulaciones demuestran la efectividad de los mecanismos de intercambio selectivos para mejorar la estimación producida para los parámetros probabilísticos basados en un conjunto limitado de observaciones. Además, la mayor parte de la mejora se logra en las interacciones iniciales, lo cual es de gran importancia para los agentes que operan en entornos de ritmo rápido. Aunque probamos el mecanismo de intercambio selectivo en el contexto del proyecto Coordinators, es aplicable en cualquier entorno MAS que tenga las características de un entorno de ritmo rápido (por ejemplo, entornos de rescate). La evidencia de su efectividad general se proporciona en la sección de evaluación general, donde los entornos se generaron continuamente al azar. La estadística de Wilcoxon utilizada como se describe en este documento para proporcionar un clasificador para la similitud entre los usuarios proporciona una alta flexibilidad con bajos costos computacionales y es aplicable para cualquier característica que se aprenda. Su uso proporciona una buena medida de similitud que un agente puede usar para decidir cuánta información externa adoptar para sus evaluaciones.8. Reconocimiento La investigación reportada en este documento fue apoyada en parte por el contrato número 55-000720, un subcontrato al contrato de SRI Internationals DARPA No. FA8750-05-C-0033. Cualquier opinión, hallazgos y conclusiones, o recomendaciones expresadas en este material son las de los autores y no reflejan necesariamente las opiniones de DARPA o el gobierno de los Estados Unidos. Agradecemos a un revisor anónimo de AAMAS por una revisión excepcionalmente completa de este documento.9. Referencias [1] P. Adamczyk, S. Iqbal y B. Bailey. Un método, sistema y herramientas para la gestión de interrupción inteligente. En Tamodia 05, páginas 123-126, Nueva York, NY, EE. UU., 2005. ACM Press.[2] P. Berkhin. Encuesta de técnicas de minería de datos de agrupación. Informe técnico, Software de Accrue, San José, CA, 2002. [3] M. Ester, H. Kriegel, J. Sander, M. Wimmer y X. Xu. La agrupación incremental para la minería en un entorno de almacenamiento de datos. En Proc.24º int. Conf. Bases de datos muy grandes, VLDB, páginas 323-333, 24-27 de 1998. [4] M. Ester, H. Kriegel, J. Sander y X. Xu. Un algoritmo basado en densidad para descubrir grupos en grandes bases espaciales con ruido. En KDD-96, páginas 226-231, 1996. [5] M. Fleming y R. Cohen. Un procedimiento de decisión para que los agentes autónomos razonen sobre la interacción con los humanos. En AAAI SIMP de primavera.sobre la interacción entre humanos y sistemas autónomos sobre operación extendida, 2004. [6] N. Friedman, D. Geiger y M. Goldszmidt. Clasificadores de red bayesianos. Machine Learning, 29: 131-163, 1997. [7] N. Good, J. Ben Schafer, J. Konstan, A. Borchers, B. Sarwar, J. Herlocker y J. Riedl. Combinando el filtrado colaborativo con agentes personales para mejores recomendaciones. En AAAI/IAAI, Páginas 439-446, 1999. [8] K. Hinckley, J. Pierce, M. Sinclair y E. Horvitz. Técnicas de detección para la interacción móvil. En Uist 00, páginas 91-100, Nueva York, NY, EE. UU., 2000. ACM Press.[9] E. Horvitz, C. Kadie, T. Paek y D. Hovel. Modelos de atención en informática y comunicación: desde principios hasta aplicaciones. Comun. ACM, 46 (3): 52-59, 2003. [10] B. Hui y C. Boutilier. ¿Quién pide ayuda?: Un enfoque bayesiano para la asistencia inteligente. En IUI 06, 2006. [11] J. Jang, C. Sun y E. Mizutani. Neuro-Fuzzy y Soft Computing Un enfoque computacional para el aprendizaje e inteligencia artificial. Prentice Hall, 1997. [12] S. Kullback y R. Leibler. Sobre información y suficiencia. Ana. Matemáticas. Statist., 22: 79-86, 1951. [13] P. Maglio, T. Matlock, C. Campbell, S. Zhai y B. Smith. Mirada y habla en atentos interfaces de usuarios. En ICMI, páginas 1-7, 2000. [14] H. Mann y D. Whitney. En una prueba de si una de las 2 variables aleatorias es estocásticamente más grande que la otra. Annals of Mathematical Statistics, 18: 50-60, 1947. [15] W. McClure. Tecnología y comando: implicaciones para las operaciones militares en el siglo XXI. Base de la Fuerza Aérea Maxwell, Centro de Estrategia y Tecnología, 2000. [16] J. McMillan y M. Rothschild. Buscar. En Robert J. Aumann y Amsterdam Sergiu Hart, editores, Manual de teoría de juegos con aplicaciones económicas, páginas 905-927.1994. [17] J. Murray, G. Hughes y K. Kreutz-Delgado. Métodos de aprendizaje automático para predecir fallas en discos duros: una aplicación de instancia múltiple. J. Mach. Aprender. Res., 6: 783-816, 2005. [18] D. Sarne y B. J. Grosz. Estimación del valor de la información en sistemas colaborativos de planificación de agentes múltiples. En AAMAS07, página (para aparecer), 2007. [19] D. Sarne y B. J. Grosz. Interrupciones de tiempo para una mejor planificación coordinada de la computadora humana. En AAAI SIMP de primavera.Sobre la gestión de planes y programas distribuidos, 2006. [20] R. Vertegaal. El sistema Gaze Groupware: mediación de la atención conjunta en comunicación multipartidista y colaboración. En Chi, páginas 294-301, 1999. [21] T. Wagner, J. Phelps, V. Guralnik y R. Vanriper. Una vista de aplicación de los coordinadores: gerentes de coordinación para los socorristas. En AAAI, páginas 908-915, 2004. [22] F Wilcoxon. Comparaciones individuales por métodos de clasificación. Biometrics, 1: 80-83, 1945. [23] D. Zeng y K. Sycara. Aprendizaje bayesiano en negociación. En AAAAI Simposio sobre adaptación, coevolución y aprendizaje en sistemas multiagentes, páginas 99-104, 1996. [24] Y. Zhang, K. Biggers, L. He, S. Reddy, D. Sepulvado, J. Yen y T. Ioerger. Una arquitectura de agente inteligente distribuido para simular el comportamiento e interacciones de nivel agregado en el campo de batalla. En Sci-2001, páginas 58-63, 2001. El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 209