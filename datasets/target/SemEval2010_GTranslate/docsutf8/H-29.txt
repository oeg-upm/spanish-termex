Estimación y uso de la incertidumbre en la pseudo-relevancia Comentarios Kevyn Collins-Thompson y Jamie Callan Language Technologies Institute School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213-8213 U.S.A. {KCT |callan }@cs.cmu.edu Abstract Los métodos de retroalimentación de pseudo-relevancia existentes típicamente tienen un promedio de los documentos de recuperación de alto rendimiento, pero ignoran una dimensión estadística importante: el riesgo o la varianza asociada con los modelos de documentos individuales o su combinación. Al tratar el método de retroalimentación de referencia como un cuadro negro, y el modelo de retroalimentación de salida como una variable aleatoria, estimamos una distribución posterior para el modelo de retroalimentación al volver a muestrear un dado documentos de retrato de consultas, utilizando la media o modo posterior de retroalimentación mejorada como el modelo de retroalimentación mejorada. Luego realizamos una combinación de modelos en varios modelos mejorados, cada uno basado en una consulta ligeramente modificada muestreada a partir de la consulta original. Encontramos que los documentos de remuestreo ayudan a aumentar la precisión del modelo de retroalimentación individual al eliminar los términos de ruido, mientras que el muestreo de la consulta mejora la robustez (peor rendimiento) al enfatizar los términos relacionados con múltiples aspectos de la consulta. El resultado es un algoritmo de meta-retroalimentación que es más robusto y más preciso que el método de referencia original original. Categorías y descriptores de sujetos: H.3.3 [Recuperación de información]: Modelos de recuperación Términos generales: Algoritmos, Experimentación 1. Introducción La incertidumbre es una característica inherente de la recuperación de información. No solo no sabemos las consultas que se presentarán a nuestro algoritmo de recuperación con anticipación, sino que la necesidad de la información de los usuarios puede ser vaga o especificada de manera incompleta por estas consultas. Incluso si la consulta se especificó perfectamente, el lenguaje en los documentos de la recolección es inherentemente complejo y ambiguo y coincidir ese lenguaje de manera efectiva es un problema formidable por sí mismo. Con esto en mente, deseamos tratar muchas cantidades importantes calculadas por el sistema de recuperación, ya sea un puntaje de relevancia para un documento o un peso para un término de expansión de consulta, como variables aleatorias cuyo verdadero valor es incierto, pero donde la incertidumbre sobre la verdaderaEl valor puede cuantificarse reemplazando el valor fijo con una distribución de probabilidad sobre valores posibles. De esta manera, los algoritmos de recuperación pueden intentar cuantificar el riesgo o la incertidumbre asociada con sus clasificaciones de producción, o mejorar la estabilidad o precisión de sus cálculos internos. Los algoritmos actuales para la retroalimentación de pseudo-relevancia (PRF) tienden a seguir el mismo método básico, ya sea que utilizamos algoritmos vectoriales basados en el espacio, como la fórmula Rocchios [16], o los enfoques de modelado de idiomas más recientes como los modelos de relevancia [10]. Primero, se obtiene un conjunto de documentos de alto retrato de una consulta inicial y se supone que se aproxima a un conjunto de documentos relevantes. A continuación, se calcula un solo vector de modelo de retroalimentación de acuerdo con algún tipo de promedio, centroide o expectativa sobre el conjunto de modelos de documentos posiblemente relevantes. Por ejemplo, los vectores de documentos pueden combinarse con la misma ponderación, como en Rocchio, o por probabilidad de consulta, como se puede hacer utilizando el modelo de relevancia1. El uso de una expectativa es razonable por razones prácticas y teóricas, pero por sí solo ignora información potencialmente valiosa sobre el riesgo del modelo de retroalimentación. Nuestra hipótesis principal en este documento es que estimar la incertidumbre en la retroalimentación es útil y conduce a mejores modelos de retroalimentación individuales y modelos combinados más robustos. Por lo tanto, proponemos un método para estimar la incertidumbre asociada con un modelo de retroalimentación individual en términos de una distribución posterior sobre los modelos de lenguaje. Para hacer esto, variamos sistemáticamente las entradas al método de retroalimentación de línea de base y se ajustan a una distribución de Dirichlet a la salida. Utilizamos la media o el modo posterior como la estimación del modelo de retroalimentación mejorada. Este proceso se muestra en la Figura 1. Como mostramos más adelante, la media y el modo pueden variar significativamente del modelo de retroalimentación única propuesta por el método de referencia. También realizamos una combinación de modelos utilizando varios modelos de lenguaje de retroalimentación mejorados obtenidos por un pequeño número de nuevas consultas muestreadas de la consulta original. Un peso de los modelos combina dos factores complementarios: la probabilidad de los modelos de generar la consulta y la varianza del modelo, con modelos de alta varianza obteniendo un menor peso.1 Por ejemplo, un vector de parámetros esperado condicionado en la observación de la consulta se forma a partir de documentos de alto retrato, que se tratan como cadenas de entrenamiento (ver [10], p. 62). Figura 1: Estimación de la incertidumbre del modelo de retroalimentación para una sola consulta.2. Comentarios basados en muestreo en las Secciones 2.1-2.5 Describimos un método general para estimar una distribución de probabilidad sobre el conjunto de posibles modelos de lenguaje. En las Secciones 2.6 y 2.7 resumimos cómo se utilizan diferentes muestras de consultas para generar múltiples modelos de retroalimentación, que luego se combinan.2.1 Modelado de la incertidumbre de retroalimentación Dada una consulta Q y una colección C, asumimos un sistema de recuperación probabilística que asigna una puntuación de documento de valor real F (d, Q) a cada documento D en C, de modo que el puntaje es proporcional a la probabilidad estimadade relevancia. No hacemos otras suposiciones sobre F (D, Q). La naturaleza de F (d, q) puede ser compleja: por ejemplo, si el sistema de recuperación admite lenguajes de consulta estructurados [12], entonces F (d, q) puede representar la salida de una red de inferencia arbitrariamente compleja definida por la consulta estructuradaoperadores. En teoría, la función de puntuación puede variar de consulta a consulta, aunque en este estudio por simplicidad mantenemos la función de puntuación igual para todas las consultas. Nuestro método de consulta específico se da en la Sección 3. Tratamos el algoritmo de retroalimentación como un cuadro negro y asumimos que las entradas al algoritmo de retroalimentación son la consulta original y los documentos de retrato de alto nivel correspondientes, con una puntuación dada a cada documento. Suponemos que la salida del algoritmo de retroalimentación es un vector de pesos a término para agregar o volver a poner en peso de los términos en la representación de la consulta original, con el vector normalizado para formar una distribución de probabilidad. Vemos las entradas al cuadro negro de retroalimentación como variables aleatorias, y analizamos el modelo de retroalimentación como una variable aleatoria que cambia en respuesta a los cambios en las entradas. Al igual que la función de puntuación de documentos F (d, Q), el algoritmo de retroalimentación puede implementar una fórmula de puntuación compleja y no lineal, y así que sus entradas varían, los modelos de retroalimentación resultantes pueden tener una distribución compleja sobre el espacio de los modelos de retroalimentación (elespacio muestral). Debido a esta complejidad potencial, no intentamos derivar una distribución posterior en forma cerrada, sino que usamos simulación. Llamamos a esta distribución sobre posibles modelos de retroalimentación la distribución del modelo de retroalimentación. Nuestro objetivo en esta sección es estimar una aproximación útil a la distribución del modelo de retroalimentación. Para un marco específico para experimentos, utilizamos el enfoque de modelado de idiomas (LM) para la recuperación de información [15]. La puntuación de un documento D con respecto a una consulta Q y la colección C viene dada por P (Q | D) con respecto a los modelos de lenguaje ˆθq y ˆθd estimados para la consulta y el documento respectivamente. Denotamos el conjunto de K documentos de retrato de K de la colección C en respuesta a Q por DQ (K, C). Por simplicidad, suponemos que las consultas y los documentos son generados por distribuciones multinomiales cuyos parámetros están representados por modelos de lenguaje Unigram. Para incorporar retroalimentación en el enfoque LM, asumimos un esquema basado en modelo en el que nuestro objetivo es tomar la consulta y los documentos clasificados resultantes DQ (k, c) como entrada, y emitir un modelo de lenguaje de expansión ˆθe, que luego se interpola con elModelo de consulta original ˆθq: ˆθnew = (1 - α) · ˆθq + α · ˆθe (1) Esto incluye la posibilidad de α = 1 donde el modo de consulta original está completamente reemplazado por el modelo de retroalimentación. Nuestro espacio de muestras es el conjunto de todos los modelos de lenguaje posibles que se pueden obtener como modelos de retroalimentación. Nuestro enfoque es tomar muestras de este espacio y luego ajustar una distribución a las muestras utilizando la máxima probabilidad. Para simplificar, comenzamos asumiendo que la distribución de comentarios latentes tiene la forma de una distribución de Dirichlet. Aunque el Dirichlet es una distribución unimodal, y en general bastante limitada en su expresividad en el espacio muestral, es una coincidencia natural para el modelo de lenguaje multinomial, puede estimarse rápidamente y puede capturar las características más destacadas de los modelos de retroalimentación seguros e inciertos, como la propagación general de la distribución.2.2 Modelos de documento de remuestreo Nos gustaría una aproximación a la distribución posterior del modelo de retroalimentación LF. Para lograr esto, aplicamos una técnica de simulación ampliamente utilizada llamada muestreo de bootstrap ([7], p. 474) en los parámetros de entrada, a saber, el conjunto de documentos de retrato superior. El muestreo de bootstrap nos permite simular el efecto aproximado de perturbar los parámetros dentro del algoritmo de retroalimentación de la caja negra al perturbar las entradas a ese algoritmo de manera sistemática, al tiempo que no hace suposiciones sobre la naturaleza del algoritmo de retroalimentación. Específicamente, muestreamos documentos K con reemplazo de DQ (k, c) y calculamos un modelo de lenguaje de expansión θb utilizando el método de retroalimentación de cuadros negros. Repetimos este proceso B veces para obtener un conjunto de modelos de lenguaje de retroalimentación B, a los que luego ajustamos una distribución de Dirichlet. Por lo general, B se encuentra en el rango de 20 a 50 muestras, y el rendimiento es relativamente estable en este rango. Tenga en cuenta que en lugar de tratar cada documento superior como igualmente probable, muestreamos de acuerdo con las probabilidades estimadas de relevancia de cada documento en DQ (k, c). Por lo tanto, es más probable que un documento sea elegido cuanto más alto sea en la clasificación.2.3 Justificación para un enfoque de muestreo La justificación para nuestro enfoque de muestreo tiene dos partes. Primero, queremos mejorar la calidad de los modelos de retroalimentación individual al suavizar la variación cuando el modelo de retroalimentación de referencia es inestable. A este respecto, nuestro enfoque se asemeja a los ataques [4], un enfoque de conjunto que genera múltiples versiones de un predictor haciendo copias de arranque del conjunto de entrenamiento y luego promedia los predictores (numéricos). En nuestra aplicación, los documentos de alto retrato pueden verse como una especie de ruidoso entrenamiento establecido para la relevancia. En segundo lugar, el muestreo es una forma efectiva de estimar las propiedades básicas de la distribución posterior de retroalimentación, que luego se puede utilizar para mejorar la combinación de modelos. Por ejemplo, un modelo puede verse ponderado por su confianza de predicción, estimado en función de la variabilidad del posterior alrededor del modelo.foo2-401.map-dim: 5434, tamaño: 12*12Units, gaussianneighborhood (a) tema 401 minorías extranjeras, alemania foo2-402.map-dim: 5698, tamaño: 12*12units, gaussianneighborhood (b) tema 402 genética conductualfoo2-459.map-dim: 8969, tamaño: 12*12Units, gaussianneighborhood (c) Tema 459 ¿Cuándo puede un prestamista ejecutar en la propiedad Figura 2: Visualización de la varianza del modelo de lenguaje de expansión utilizando mapas de autoorganización, que muestra la distribución de modelos de lenguaje?Eso resulta del remuestreo de las entradas al método de expansión de referencia. El modelo de idioma que habría sido elegido por la expansión de línea de base está en el centro de cada mapa. La función de similitud es la divergencia de Jensenshannon.2.4 Visualización de distribuciones de retroalimentación Antes de describir cómo encajamos y usamos la distribución de Dirichlet sobre los modelos de retroalimentación, es instructivo ver algunos ejemplos de distribuciones de modelos de retroalimentación reales que resultan de la muestra de bootstrap los documentos superiores de diferentes temas de TREC. Cada punto en nuestro espacio muestral es un modelo de idioma, que generalmente tiene varios miles de dimensiones. Para ayudar a analizar el comportamiento de nuestro método, utilizamos un mapa de autoorganización (a través del paquete Som-Pak [9]), para aplanar y visualizar la función de densidad de alta dimensión22. Los mapas de densidad para tres temas de TREC se muestran en la Figura 2 arriba. Las áreas oscuras representan regiones de alta similitud entre los modelos de idiomas. Las áreas de luz representan regiones de baja similitud: los valles entre grupos. Cada diagrama se centra en el modelo de idioma que habría sido elegido por la expansión de referencia. Un solo pico (modo) es evidente en algunos ejemplos, pero aparece una estructura más compleja en otros. Además, si bien la distribución generalmente está cerca del modelo de retroalimentación de línea de base, para algunos temas están separados (según lo medido por la divergencia de Jensenshannon), como en la subfigura 2C. En tales casos, el modo o la media de la distribución de retroalimentación a menudo funciona significativamente mejor que la línea de base (y en una proporción menor de casos, significativamente peor).2.5 Conjunto de una distribución de retroalimentación posterior Después de obtener muestras del modelo de retroalimentación al volver a muestrear las entradas del modelo de retroalimentación, estimamos la distribución de retroalimentación. Suponemos que los modelos de retroalimentación multinomial {ˆθ1 ,..., ˆΘb} se generaron mediante una distribución latente de Dirichlet con parámetros {α1 ,..., αn}. Para estimar el {α1 ,..., αn}, ajustamos los parámetros de Dirichlet a las muestras del modelo de lenguaje B de acuerdo con la máxima probabilidad utilizando un procedimiento generalizado de Newton, cuyos detalles se dan en Minka [13]. Asumimos un dirichlet simple antes sobre el {α1 ,..., αn}, estableciendo cada uno a αi = μ · P (wi | c), donde μ es un parámetro y p (· | c) es el modelo de lenguaje de recolección estimado a partir de un conjunto de documentos de la colección C. el ajuste de parámetros converge muyRápidamente: por lo general, solo 2 o 2 porque nuestros puntos son modelos de lenguaje en el simplex multinomial, extendimos Som-Pak para apoyar la divergencia de Jensenshannon, una medida de similitud ampliamente utilizada entre las distribuciones de probabilidad.3 iteraciones son suficientes, para que sea práctico aplicar en el tiempo de consulta cuando la sobrecarga computacional debe ser pequeña. En la práctica, podemos restringir el cálculo del vocabulario de los documentos mejorados, en lugar de toda la colección. Tenga en cuenta que para este paso estamos reutilizando los documentos recuperados existentes y no realizando consultas adicionales. Dados los parámetros de una DIR de distribución de Dirichlet N-dimensional (α), los vectores medios μ y MODE X son fáciles de calcular y se dan respectivamente por μi = αIP αi (2) y Xi = αi-1p αI-N.(3) Luego podemos elegir el modelo de idioma en la media o el modo de la parte posterior como el modelo de retroalimentación mejorada final.(Encontramos el modo para dar un rendimiento ligeramente mejor). Para la recuperación de la información, es probable que el número de muestras que tendremos disponibles sea bastante pequeña por razones de rendimiento, generalmente menos de diez. Además, aunque el muestreo aleatorio es útil en ciertos casos, es perfectamente aceptable permitir distribuciones de muestreo deterministas, pero deben diseñarse cuidadosamente para aproximar una varianza de salida precisa. Dejamos esto para futuros estudios.2.6 Variantes de consulta Utilizamos los siguientes métodos para generar variantes de la consulta original. Cada variante corresponde a una suposición diferente sobre qué aspectos de la consulta original pueden ser importantes. Esta es una forma de muestreo determinista. Seleccionamos tres métodos simples que cubren suposiciones complementarias sobre la consulta. Sin expansión Use solo la consulta original. La suposición es que los términos dados son una descripción completa de la necesidad de la información. Dejar un solo término queda fuera de la consulta original. La suposición es que uno de los términos de la consulta es un término de ruido. Un solo término se elige un solo término de la consulta original. Esto supone que solo un aspecto de la consulta, a saber, el representado por el término, es más importante. Después de generar una variante de la consulta original, la combinamos con la consulta original usando una αsub de peso para que no nos desviemos demasiado. En este estudio, establecemos αSub = 0.5. Por ejemplo, utilizando el lenguaje de consulta Indri [12], una variante de licencia de la consulta inicial que omite el término Irlanda para TREC Tema 404 es: #Weight (0.5 #Combine (Irlanda Peace Talks) 0.5 #Combine (Peace Talks)) 2.7 Combinación de modelos de retroalimentación mejorados de múltiples variantes de consulta Al usar múltiples variantes de consulta, los modelos de retroalimentación mejorados resultantes se combinan utilizando la combinación de modelos bayesianos. Para hacer esto, tratamos cada palabra como un elemento para ser clasificado como perteneciente a una clase relevante o no relevante, y derivamos una probabilidad de clase para cada palabra combinando los puntajes de cada variante de consulta. Cada puntaje está dado por esos términos probabilidad en la distribución de Dirichlet. Los puntajes del término están ponderados por el inverso de la varianza del término en los modelos de retroalimentación mejorados Dirichlet Distribution. La probabilidad previa de una membresía de palabras en la clase relevante viene dada por la probabilidad de la consulta original en todo el modelo de expansión mejorada.3. Evaluación En esta sección, presentamos resultados que confirman la utilidad de estimar una distribución de modelo de retroalimentación a partir de remuestreo ponderado de documentos de primer nivel, y de combinar los modelos de retroalimentación obtenidos de diferentes cambios pequeños en la consulta original.3.1 Método general Evaluamos el rendimiento en un total de 350 consultas derivadas de cuatro conjuntos de temas de TREC: 51-200 (TREC-1 y 2), 351-400 (TREC-7), 401-450 (TREC-8) y 451-550 (WT10G, TREC-9 y 10). Elegimos por sus variadas propiedades de contenido y documento. Por ejemplo, los documentos WT10G son páginas web con una amplia variedad de temas y estilos, mientras que los documentos TREC-1 y 2 son artículos de noticias más homogéneos. La indexación y recuperación se realizó utilizando el sistema Indri en el kit de herramientas Lemur [12] [1]. Nuestras consultas se derivaron de las palabras en el campo del título de los temas de TREC. No se usaron frases. Para generar las consultas de referencia pasadas a Indri, envolvimos los términos de consulta con el operador de #combine de Indris. Por ejemplo, la consulta inicial para el Tema 404 es: #Combine (Irlanda Peace Talks) Realizamos Krovetz Stemming para todos los experimentos. Debido a que encontramos que el método de expansión de línea de base (INDRI) funcionó mejor utilizando una lista de palabras de parada con el modelo de retroalimentación, todos los experimentos utilizaron una lista de parada de 419 palabras en inglés comunes. Sin embargo, un efecto secundario interesante de nuestro enfoque de remuestreo es que tiende a eliminar muchas palabras de parada del modelo de retroalimentación, haciendo que una lista de parada sea menos crítica. Esto se discute más a fondo en la Sección 3.6.3.2 Método de retroalimentación de línea de base Para nuestro método de expansión de línea de base, utilizamos un algoritmo incluido en Indri 1.0 como el método de expansión predeterminado. Este método primero selecciona términos utilizando un cálculo de log-ODDS descrito por Ponte [14], pero asigna pesos de término final utilizando el modelo de relevancia Lavrenkos [10]. Elegimos el método Indri porque ofrece una línea de base consistentemente fuerte, se basa en un enfoque de modelado de idiomas y es fácil de experimentar. En una evaluación de TREC utilizando el Corpus Gov2 [6], el método fue una de las ejecuciones de aumento, logrando una ganancia del 19.8% en MAP en comparación con el uso de consultas no expandidas. En este estudio, logra una ganancia promedio en el mapa del 17.25% sobre las cuatro colecciones. El método de expansión de Indris calcula primero una relación log-ODDS O (v) para cada término de expansión potencial V dada por o (v) = x d log p (v | d) p (v | c) (4) En todos los documentos d que contienen v v v, en la colección C. Entonces, los candidatos a término de expansión se clasifican descendiendo O (V), y se eligen las M Finalmente, el término pesos r (v) utilizados en la consulta expandida se calcula en función del modelo de relevancia R (v) = x D P (Q | D) P (V | D) P (V) P (D) (5)La cantidad P (Q | D) es el puntaje de probabilidad asignado al documento en la recuperación inicial. Utilizamos el suavizado de Dirichlet de P (V | D) con μ = 1000. Este modelo de relevancia se combina con la consulta original utilizando interpolación lineal, ponderada por un parámetro α. Por defecto, utilizamos los 50 documentos principales para la retroalimentación y los 20 principales términos de expansión, con el parámetro de interpolación de retroalimentación α = 0.5 a menos que se indique lo contrario. Por ejemplo, la consulta ampliada de línea de base para el Tema 404 es: #Weight (0.5 #Combine (Irlanda Peace Talks) 0.5 #Weight (0.10 Irlanda 0.08 Peace 0.08 Northern ...) 3.3 rendimiento de expansión Medimos nuestros algoritmos de retroalimentación por dos criterios principales: Precisión y robustez. La robustez, y la compensación entre precisión y robustez, se analiza en la Sección 3.4. En esta sección, examinamos la precisión y la precisión promedio en los 10 documentos principales (P10). También incluimos retiro en 1,000 documentos. Para cada consulta, obtuvimos un conjunto de modelos de retroalimentación B utilizando la línea de base de Indri. Cada modelo de retroalimentación se obtuvo de una muestra aleatoria de los principales documentos K tomados con reemplazo. Para estos experimentos, b = 30 y k = 50. Cada modelo de retroalimentación contenía 20 términos. En el lado de la consulta, utilizamos muestreo de licencia uno-out (loo) para crear las variantes de consulta. El muestreo de consultas de un solo término tuvo un rendimiento consistentemente peor en todas las colecciones y, por lo tanto, nuestros resultados aquí se centran en el muestreo LOO. Utilizamos los métodos descritos en la Sección 2 para estimar un modelo de retroalimentación mejorado de la distribución posterior de Dirichlet para cada variante de consulta, y para combinar los modelos de retroalimentación de todas las variantes de consulta. Llamamos a nuestro método de remuestreo de expansión y la denotamos como RS-FB aquí. Denotamos el método de retroalimentación de línea de base Indri como base-FB. Los resultados de la aplicación del método de expansión de línea de base (base-FB) y la expansión de remuestreo (RS-FB) se muestran en la Tabla 1. Observamos varias tendencias en esta tabla. Primero, la precisión promedio de RS-FB fue comparable a Base-FB, logrando una ganancia promedio de 17.6% en comparación con el uso de no expansión en las cuatro colecciones. La ganancia de expansión basal de Indri fue del 17.25%. Además, el método RS-FB logró mejoras consistentes en P10 sobre Base-FB para cada conjunto de temas, con una mejora promedio de 6.89% sobre Base-FB para los 350 temas. La ganancia P10 más baja sobre la base-FB fue de +3.82% para TREC-7 y la más alta fue +11.95% para WT10G. Finalmente, tanto Base-FB como RS-FB también mejoraron constantemente el retiro sobre el uso de no expansión, con Base-FB logrando un mejor retiro que RS-FB para todos los conjuntos de temas.3.4 Robustez de recuperación Utilizamos el término robustez para significar el rendimiento de precisión promedio de peor, de un algoritmo de retroalimentación. Idealmente, un método de retroalimentación robusto nunca funcionaría peor que usar la consulta original, mientras que a menudo se desempeña mejor utilizando la expansión. Para evaluar la robustez en este estudio, utilizamos una medida muy simple llamada Índice de robustez (RI) 3. Para un conjunto de consultas q, la medida RI se define como: ri (q) = n+ - n− | q |(6) donde N+ es el número de consultas ayudadas por el método de retroalimentación y N- es el número de consultas perjudicadas. Aquí, por ayudado nos referimos a obtener una precisión promedio más alta como resultado de la retroalimentación. El valor de RI varía de un mínimo 3. Esto a veces también se llama la confiabilidad del índice de mejora y se usó en Sakai et al.[17]. Colección NoEXP Base-FB RS-FB TREC 1 y 2 AVGP 0.1818 0.2419 (+33.04%) 0.2406 (+32.24%) P10 0.4443 0.4913 (+10.57%) 0.5363 (+17.83%) Recall 15084/37393 19172/373393 15396/37333333333333333393 C.AVGP 0.1890 0.2175 (+15.07%) 0.2169 (+14.75%) P10 0.4200 0.4320 (+2.85%) 0.4480 (+6.67%) Recuperación 2179/4674 2608/4674 2487/4674 TREC 8 AVGP 0.2031 0.2361 (+16.25%)+11.70%) P10 0.3960 0.4160 (+5.05%) 0.4340 (+9.59%) Recuerdos 2144/4728 2642/4728 2485/4728 WT10g AVGP 0.1741 0.1829 (+5.06%) 0.1946 (+11.78%) P10 0.2760) 0.2960 (+7.24%) Recuerde 3361/5980 3725/5980 3664/5980 Tabla 1: Comparación de la retroalimentación de línea de base (base-FB) y la retroalimentación utilizando el reamualización (RS-FB). La mejora que se muestra para BASFB y RS-FB es relativa a no usar expansión.(a) TREC 1 y 2 (curva superior);Trec 8 (curva inferior) (b) trec 7 (curva superior);WT10G (curva inferior) Figura 3: La compensación entre robustez y precisión promedio para corpus diferentes. El eje x da el cambio en el mapa sobre el uso de la expansión de referencia con α = 0.5. El Yaxis da el índice de robustez (RI). Cada curva a través de puntos no encerrados muestra la compensación de RI/MAP utilizando la estrategia simple de Small-α (ver texto) a medida que α disminuye de 0.5 a cero en la dirección de la flecha. Los puntos en circulación representan las compensaciones obtenidas al volver a muestrear la retroalimentación para α = 0.5. Colección n base-fb rs-fb n− ri n− ri trec 1 y 2 103 26 +0.495 15 +0.709 trec 7 46 14 +0.391 10 +0.565 TREC 8 44 12 +0.455 12 +0.455 WT10G 91 48 -0.055 39 +0.143 Combinado284 100 +0.296 76 +0.465 Tabla 2: Comparación del índice de robustez (RI) para la retroalimentación de línea de base (base-FB) frente a la retroalimentación de remuestreo (RS-FB). También se muestran el número real de consultas perjudicadas por la retroalimentación (N−) para cada método y colección. Las consultas para la cual la precisión promedio inicial fue insignificante (≤ 0.01) se ignoraron, dando el recuento de consultas restante en la columna N. de -1.0, cuando todas las consultas se ven afectadas por el método de retroalimentación, a +1.0 cuando todas las consultas se ayudan. La medida RI no tiene en cuenta la magnitud o distribución de la cantidad de cambio en el conjunto Q. Sin embargo, es fácil de entender como una indicación general de robustez. Una forma obvia de mejorar el rendimiento del peor de los casos de la retroalimentación es simplemente usar un parámetro de interpolación α fijo más pequeño, como α = 0.3, colocando menos peso en el modelo de retroalimentación (posiblemente riesgoso) y más en la consulta original. Llamamos a esto la estrategia pequeña-α. Sin embargo, dado que también estamos reduciendo las ganancias potenciales cuando el modelo de retroalimentación es correcto, esperaríamos una compensación entre la precisión promedio y la robustez. Por lo tanto, comparamos la compensación de precisión/robustez entre nuestro algoritmo de retroalimentación de remuestreo y el método simple de Small-α. Los resultados se resumen en la Figura 3. En la figura, la curva para cada conjunto de temas se interpola entre los puntos de compensación, comenzando en x = 0, donde α = 0.5, y continuando en la dirección de la flecha a medida que disminuye α y la consulta original recibe cada vez más peso. Como se esperaba, la robustez aumenta continuamente a medida que avanzamos a lo largo de la curva, pero la precisión promedio media generalmente cae a medida que se eliminan las ganancias de la retroalimentación. A modo de comparación, el rendimiento de la retroalimentación de remuestreo en α = 0.5 se muestra para cada colección como el punto en círculo. Más alto y a la derecha es mejor. Esta figura muestra que la retroalimentación de remuestreo proporciona una compensación algo mejor que el enfoque pequeño-α para 3 de las 4 colecciones. Figura 4: Histograma que muestra la robustez mejorada de la retroalimentación de remuestreo (RS-FB) sobre la retroalimentación de referencia (base-FB) para todos los conjuntos de datos combinados. Las consultas se agrupan por % de cambio en AP en comparación con la consulta no expandida. Collection DS + QV DS + No QV TREC 1&2 AvgP 0.2406 0.2547 (+5.86%) P10 0.5263 0.5362 (+1.88%) RI 0.7087 0.6515 (-0.0572) TREC 7 AvgP 0.2169 0.2200 (+1.43%) P10 0.4480 0.4300 (-4.02%) RI 0.5652 0.2609 (-0.3043) TREC 8 AVGP 0.2268 0.2257 (-0.49%) P10 0.4340 0.4200 (-3.23%) RI 0.4545 0.4091 (-0.0454) WT10g AVGP 0.1946 0.1865 (-4.16%) %)RI 0.1429 0.0220 (-0.1209) Tabla 3: Comparación de la retroalimentación de remuestreo utilizando el muestreo de documentos (DS) con (QV) y sin (sin QV) combinando modelos de retroalimentación de variantes de consulta múltiples. La Tabla 2 ofrece los puntajes del índice de robustez para Base-FB y RS-FB. El método de retroalimentación RS-FB obtuvo mayor robustez que Base-FB en tres de los cuatro conjuntos de temas, con un rendimiento solo un poco peor en TREC-8. La Figura 4 dio una vista más detallada que muestra la distribución sobre los cambios relativos en AP en la Figura 4. En comparación con Base-FB, el método RS-FB logra una reducción notable en el número de consultas perjudicadas significativamente por la expansión (es decir, donde AP se ve afectado en un 25% o más), al tiempo que preserva ganancias positivas en AP.3.5 Efecto de los métodos de muestreo de consultas y documentos Dados nuestros algoritmos mejorados de robustez vistos en la Sección 3.4, una pregunta importante es qué componente de nuestro sistema es responsable. ¿Es el uso del reamemplamiento de documentos, el uso de múltiples variantes de consulta o algún otro factor? Los resultados en la Tabla 3 sugieren que la combinación del modelo basada en las variantes de consulta puede explicarse en gran medida para la robustez mejorada. Cuando las variantes de consulta se apagan y la consulta original se usa solo con el muestreo de documentos, hay poco cambio neto en la precisión promedio, una pequeña disminución en P10 para 3 de los 4 conjuntos de temas, pero una caída significativa en la robustez para todo el temaconjuntos. En dos casos, la medida RI cae en más del 50%. También examinamos el efecto del método de muestreo de documentos sobre la efectividad de la recuperación, utilizando dos estrategias diferentes. La estrategia de ponderación uniforme ignoró los puntajes de relevancia de la recuperación inicial y le dio a cada documento en la parte superior K la misma probabilidad de selección. En contraste, la estrategia de ponderación de puntaje de relevancia eligió documentos con probabilidad proporcional a sus puntajes de relevancia. De esta manera, los documentos que tenían más calificación tenían más probabilidades de ser seleccionados. Los resultados se muestran en la Tabla 4. La estrategia de ponderación de puntaje de relevancia funciona mejor en general, con puntajes RI y P10 significativamente más altos en 3 de los 4 conjuntos de temas. Sin embargo, la diferencia en la precisión promedio entre los métodos es menos marcada. Esto sugiere que los actos de ponderación uniforme para aumentar la varianza en los resultados de la recuperación: cuando la precisión promedio inicial es alta, hay muchos documentos relevantes en la K y un muestreo uniforme puede dar un modelo de relevancia más representativo que centrarse en los elementos altamente clasificados. Por otro lado, cuando la precisión inicial es baja, hay pocos documentos relevantes en los rangos inferiores y mezclas de muestreo uniforme en más documentos no relevantes. Por razones de espacio solo resumimos nuestros hallazgos en el tamaño de la muestra aquí. El número de muestras tiene algún efecto en la precisión cuando es de menos de 10, pero el rendimiento se estabiliza en alrededor de 15 a 20 muestras. Usamos 30 muestras para nuestros experimentos. Mucho más allá de este nivel, los beneficios adicionales de más muestras disminuyen a medida que la distribución de puntaje inicial está más en forma y el tiempo de procesamiento aumenta.3.6 El efecto del remuestreo en la calidad del término de expansión Idealmente, un modelo de recuperación no debe requerir una lista de palabras de parada al estimar un modelo de relevancia: un modelo estadístico robusto debe bajar las palabras de parada automáticamente dependiendo del contexto. Las palabras de parada pueden dañar la retroalimentación si se seleccionan como términos de retroalimentación, ya que suelen ser discriminadores pobres y desperdician valiosos espacios de términos. En la práctica, sin embargo, debido a que la mayoría de los métodos de selección de términos se asemejan a un tipo de ponderación de TF · IDF, los términos con IDF bajas pero TF muy alto a veces se pueden seleccionar como candidatos a término de expansión. Esto sucede, por ejemplo, incluso con el enfoque del modelo de relevancia que es parte de nuestros comentarios de referencia. Para garantizar una línea de base lo más fuerte posible, utilizamos una lista de parada para todos los experimentos informados aquí. Sin embargo, si apagamos la lista de palabras de parada, obtenemos resultados como los que se muestran en la Tabla 5, donde cuatro de los diez principales términos de retroalimentación de línea de base para TREC Tema 60 (dicho, pero, no) son las palabras de parada utilizando el método BOOFB.(Los 100 principales términos de expansión se seleccionaron para generar este ejemplo). El método de Indris intenta abordar el problema de la palabra de parada aplicando un paso inicial basado en Ponte [14] para seleccionar términos menos comunes que tengan altos log-Odds de estar en los documentos mejor clasificados en comparación con toda la colección. Sin embargo, esto no supera el problema de la palabra de parada por completo, especialmente a medida que crece el número de términos de retroalimentación. Sin embargo, el uso de la retroalimentación de remuestreo parece mitigar la recolección QV + uniforme QV + ponderación de la puntuación de relevancia TREC 1 y 2 AVGP 0.2545 0.2406 (-5.46%) P10 0.5369 0.5263 (-1.97%) RI 0.6212 0.7087 ( + 14.09%) TREC 7 AVGP 0.2174)0.2169 (-0.23%) P10 0.4320 0.4480 (+3.70%) RI 0.4783 0.5652 (+18.17%) TREC 8 AVGP 0.2267 0.2268 (+0.04%) P10 0.4120 0.4340 (+5.34%) RI 0.44545 0.4545 (+0.00%) P10 0.4340 (+5.34%) RI 0.44545 0.44545 (+0.00%) Wt10gp.0.1808 0.1946 (+7.63%) P10 0.2680 0.2960 (+10.45%) RI 0.0220 0.1099 (+399.5%) Tabla 4: Comparación de muestreo de documentos ponderado uniforme y ponderado por relevancia. El cambio porcentual en comparación con el muestreo uniforme se muestra entre paréntesis. QV indica que las variantes de consulta se usaron en ambas corridas. Bas basal FB P (WI | R) RESUMENTO FB P (WI | R) dijo 0.055 Tribunal 0.026 Tribunal 0.055 Pague 0.018 PAGO 0.034 Federal 0.012 pero 0.026 Educación 0.011 Empleados 0.024 maestros 0.010 sus 0.024 empleados 0.010 no 0.023 CASO 0.010 Federal 0.021 sus 0.009 trabajadores 0.02010Apelaciones 0.008 Educación 0.020 Union 0.007 Tabla 5: Calidad de término de retroalimentación Cuando no se usa una lista de parada. Términos de retroalimentación para TREC Tema 60: Merit Pay vs AtroTity.El efecto de las palabras de parada automáticamente. En el ejemplo de la Tabla 5, la retroalimentación de remuestreo deja solo una palabra de parada (su) en los diez primeros. Observamos un comportamiento de término de retroalimentación similar en muchos otros temas. La razón de este efecto parece ser la interacción de la puntuación de selección del término con el límite de término Top-M. Si bien la presencia e incluso la proporción de palabras de parada particulares es bastante estable en diferentes muestras de documentos, su posición relativa en la lista Top-M no es, como se examinan los conjuntos de documentos con un número variable de mejores candidatos a término de menor frecuencia para cada muestra. Como resultado, si bien pueden aparecer una cantidad de palabras de parada en cada conjunto de documentos muestreados, cualquier palabra de parada dada tiende a caer por debajo del corte para múltiples muestras, lo que lleva a su clasificación como una característica de alta varianza y bajo peso.4. Trabajo relacionado Nuestro enfoque está relacionado con el trabajo anterior de varias áreas de recuperación de información y aprendizaje automático. Nuestro uso de la variación de consultas se inspiró en el trabajo de Yomtov et al.[20], Carpineto et al.[5], y Amati et al.[2], entre otros. Estos estudios utilizan la idea de crear múltiples subconsules y luego examinar la naturaleza de la superposición en los documentos y/o los términos de expansión que resultan de cada subconsulta. La combinación de modelos se realiza utilizando heurística. En particular, los estudios de Amati et al.y Carpineto et al.investigó la combinación de términos de métodos de distribución individuales utilizando una combinación de combinación de término heurística. En un conjunto de temas de TREC, encontraron una amplia variación promedio en la distancia de rango de los términos de diferentes métodos de expansión. Su método de combinación dio mejoras positivas modestas en la precisión promedio. La idea de examinar la superposición entre listas de términos sugeridos también se ha utilizado en los enfoques de expansión de consultas tempranas. El método Xu y Crofts de análisis de contexto local (LCA) [19] incluye un factor en la fórmula de ponderación derivada empíricamente que hace que se prefieran los términos de expansión que tienen conexiones con múltiples términos de consulta. En el lado del documento, el trabajo reciente de Zhou & Croft [21] exploró la idea de agregar ruido a los documentos, volver a anotarlos y usar la estabilidad de las clasificaciones resultantes como una estimación de la dificultad de consulta. Esto está relacionado con nuestro uso del muestreo de documentos para estimar el riesgo del modelo de retroalimentación creado a partir de los diferentes conjuntos de documentos de recuperación de alto nivel. Sakai et al.[17] propuso un enfoque para mejorar la robustez de la retroalimentación de pseudo-relevancia utilizando un método que llaman muestreo selectivo. La esencia de su método es que permiten omitir algunos documentos de primer nivel, basados en un criterio de agrupación, para seleccionar un conjunto de documentos más variado y novedoso más adelante en la clasificación para usar por un método tradicional de pseudo-retroalimentación. Su estudio no encontró mejoras significativas en la robustez (RI) ni en el mapa de sus corpus. Greiff, Morgan y Ponte [8] exploraron el papel de la varianza en la ponderación del término. En una serie de simulaciones que simplificaron el problema a los documentos de 2 características, descubrieron que la precisión promedio se degrada a medida que la varianza de frecuencia a término aumenta el ruido. Los términos de downweighting con alta varianza dieron como resultado una precisión promedio mejorada. Esto parece de acuerdo con nuestros propios hallazgos para los modelos de comentarios individuales. Recientemente se han utilizado estimaciones de la varianza de salida para una mejor clasificación de texto. Lee et al.[11] utilizaron estimaciones de varianza específica de consulta de las salidas del clasificador para realizar una combinación de modelo mejorada. En lugar de usar el muestreo, pudieron obtener expresiones de forma cerrada para la varianza del clasificador asumiendo clasificadores base utilizando tipos simples de redes de inferencia. Ando y Zhang propusieron un método que llaman retroalimentación estructural [3] y mostraron cómo aplicarlo a la expansión de la consulta para la pista de genómica TREC. Utilizaron variaciones de consultas R para obtener R diferentes conjuntos SR de documentos de clasificación superior que se han cruzado con los documentos de clasificación superior obtenidas de la consulta original Qorig. Para cada SI, se calcula el vector centroide normalizado ˆWI de los documentos. El análisis de componentes principales (PCA) se aplica al ˆWI para obtener la matriz φ de H vectores singulares izquierdos φh que se utilizan para obtener la nueva consulta expandida QEXP = Qorig + φt φQorig.(7) En el caso H = 1, tenemos un solo vector singular izquierdo φ: QEXP = Qorig + (φt Qorig) φ de modo que el producto DOT φt Qorig es un tipo de peso dinámico en la consulta expandida que se basa en elSimilitud de la consulta original a la consulta ampliada. El uso de la varianza como medida de calidad del modelo de retroalimentación ocurre indirectamente a través de la aplicación de PCA. Sería interesante estudiar las conexiones entre este enfoque y nuestro propio método de modelfitización. Finalmente, en los enfoques de modelado de lenguaje para la retroalimentación, Tao y Zhai [18] describen un método para una retroalimentación más sólida que permite que cada documento tenga una retroalimentación diferente α. Los pesos de retroalimentación se derivan automáticamente utilizando EM regularizado. Un equilibrio aproximadamente igual de consulta y modelo de expansión está implícito en su condición de detención EM. Proponen adaptar el parámetro de detención η basado en una función de alguna medida de calidad de los documentos de retroalimentación.5. Conclusiones Hemos presentado un nuevo enfoque para la retroalimentación de pseudo-relevancia basadas en el documento y el muestreo de consultas. El uso del muestreo es un dispositivo muy flexible y potente y está motivado por nuestro deseo general de extender los modelos actuales de recuperación al estimar el riesgo o la varianza asociada con los parámetros o la salida de los procesos de recuperación. Dichas estimaciones de varianza, por ejemplo, pueden usarse naturalmente en un marco bayesiano para mejorar la estimación y combinación del modelo. Las aplicaciones como la expansión selectiva se pueden implementar de manera principalmente. Si bien nuestro estudio utiliza el enfoque de modelado de idiomas como un marco para los experimentos, hacemos pocos supuestos sobre el funcionamiento real del algoritmo de retroalimentación. Creemos que es probable que cualquier algoritmo de retroalimentación basal razonablemente efectivo se beneficie de nuestro enfoque. Nuestros resultados en las colecciones estándar de TREC muestran que nuestro marco mejora la robustez de un fuerte método de retroalimentación de referencia en una variedad de colecciones, sin sacrificar la precisión promedio. También ofrece ganancias pequeñas pero consistentes en la precisión top10. En el trabajo futuro, imaginamos una investigación sobre cómo variables el conjunto de métodos de muestreo utilizados y el número de muestras controla la compensación entre robustez, precisión y eficiencia. Agradecimientos Agradecemos a Paul Bennett por sus valiosas discusiones relacionadas con este trabajo, que fue apoyado por las subvenciones de NSF #IIS-0534345 y #CNS-0454018, y el Departamento de Educación de EE. UU. Subvención #R305G03123. Cualquier opinión, hallazgos y conclusiones o recomendaciones expresadas en este material son los autores.y no reflejan necesariamente los de los patrocinadores.6. Referencias [1] El conjunto de herramientas Lemur para el modelado y la recuperación de idiomas.http://www.lemurproject.org.[2] G. Amati, C. Carpineto y G. Romano. Dificultad de consulta, robustez y aplicación selectiva de la expansión de consultas. En Proc.del 25º conf. Europeo.sobre recuperación de información (ECIR 2004), páginas 127-137.[3] R. K. Ando y T. Zhang. Un método de aprendizaje semi-supervisado de alto rendimiento para fragmentos de texto. En Proc.de la 43ª Reunión Anual de la ACL, páginas 1-9, junio de 2005. [4] L. Breiman. Predictores de embolsado. Aprendizaje automático, 24 (2): 123-140, 1996. [5] C. Carpineto, G. Romano y V. Giannini. Mejora de la retroalimentación de recuperación con una combinación de funciones de rango a término múltiple. ACM Trans. Información. Sistemas, 20 (3): 259 - 290. [6] K. Collins -Thompson, P. Ogilvie y J. Callan. Resultados iniciales con consultas estructuradas y modelos de lenguaje en medio terabyte de texto. En Proc.de 2005 Conferencia de recuperación de texto. Publicación especial de NIST.[7] R. O. Duda, P. E. Hart y D. G. Stork. Clasificación de patrones. Wiley and Sons, 2ª edición, 2001. [8] W. R. Greiff, W. T. Morgan y J. M. Ponte. El papel de la varianza en la ponderación del término para la recuperación de información probabilística. En Proc.del 11 ° Intl. Conf.en información.y conocimiento mgmt.(CIKM 2002), páginas 252-259.[9] T. Kohonen, J. Hynninen, J. Kangas y J. Laaksonen. Sompak: el paquete del programa de mapa autoorganizado. Informe técnico A31, Universidad Tecnológica de Helsinki, 1996. http://www.cis.hut.fi/research/papers/som tr96.ps.z.[10] V. Lavrenko. Una teoría generativa de relevancia. Tesis doctoral, Universidad de Massachusetts, Amherst, 2004. [11] C.-H.Lee, R. Greiner y S. Wang. Uso de estimaciones de varianza específica de consulta para combinar clasificadores bayesianos. En Proc.del 23º Intl. Conf.En el aprendizaje automático (ICML 2006), páginas 529-536.[12] D. Metzler y W. B. Croft. Combinando el modelo de idioma y los enfoques de red de inferencia para la recuperación. Información. Processing y Mgmt., 40 (5): 735-750, 2004. [13] T. Minka. Estimación de una distribución de Dirichlet. Informe técnico, 2000. http://research.microsoft.com/ Minka/Papers/Dirichlet.[14] J. Ponte. Avances en la recuperación de la información, modelos de lenguaje de capítulos para comentarios de relevancia, páginas 73-96.2000. W.B. Croft, ed.[15] J. M. Ponte y W. B. Croft. Un enfoque de modelado de idiomas para la recuperación de información. En Proc.de la Conferencia ACM Sigir sobre investigación y desarrollo de 1998 en recuperación de información, páginas 275-281.[16] J. Rocchio. El sistema de recuperación inteligente, retroalimentación de relevancia del capítulo en la recuperación de información, páginas 313-323. Prentice-Hall, 1971. G. Salton, ed.[17] T. Sakai, T. Manabe y M. Koyama. Comentarios de pseudo-relevancia flexibles a través de muestreo selectivo. Transacciones ACM en procesamiento de información del idioma asiático (Talip), 4 (2): 111-135, 2005. [18] T. Tao y C. Zhai. Estimación regularizada de modelos de mezcla para retroalimentación de pseudo-relevancia robusta. En Proc.de la Conferencia ACM Sigir de 2006 sobre investigación y desarrollo en recuperación de información, páginas 162-169.[19] J. Xu y W. B. Croft. Mejora de la efectividad de la recuperación de información con el análisis de contexto local. ACM Trans. Inf. Syst., 18 (1): 79-112, 2000. [20] E. Yomtov, S. Fine, D. Carmel y A. Darlow. Aprender a estimar la dificultad de consulta. En Proc.del 2005 ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 512-519.[21] Y. Zhou y W. B. Croft. Clasificación de robustez: un marco novedoso para predecir el rendimiento de la consulta. En Proc.del 15 ° ACM INTL. Conf.Sobre información y conocimiento Mgmt.(CIKM 2006), páginas 567-574.