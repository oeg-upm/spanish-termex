Hacia las evaluaciones de gestión de información personal basadas en tareas de David Elsweiler Departamento de Comportación e Ciencias de la Información de la Universidad de Strathclyde dce@cis.strath.ac.uk Ian Ruthven Departamento de Computación e Información Ciencias de la Información, Universidad de Strathclyde ir@cis.strath.ac.uk Abstract Personal Personal de Resumen de Resumen PersonalLa gestión de la información (PIM) es un área de investigación de rápido crecimiento preocupada por la forma en que las personas almacenan, administran y vuelven a encontrar información. Una característica de PIM Research es que muchos sistemas han sido diseñados para ayudar a los usuarios a administrar y volver a encontrar información, pero se han evaluado muy pocos. Esto ha sido observado por varios académicos y explicado por las dificultades involucradas en la realización de evaluaciones PIM. Las dificultades incluyen que las personas vuelvan a encontrar información de colecciones personales únicas;Los investigadores saben poco sobre las tareas que hacen que las personas vuelvan a encontrar información;y numerosos problemas de privacidad relacionados con información personal. En este documento, nuestro objetivo es facilitar las evaluaciones PIM abordando cada una de estas dificultades. En la primera parte, presentamos un estudio diario de tareas de reinicio de información. El estudio examina el tipo de tareas que requieren que los usuarios vuelvan a encontrar información y produzcan una taxonomía de reiniciar tareas para mensajes de correo electrónico y páginas web. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando dos métodos diferentes de creación de tareas. Categorías y descriptores de sujetos H3.3 [Búsqueda y recuperación de información]: Términos generales Medición, gestión, experimentación, factores humanos 1. Introducción La gestión de información personal (PIM) es un área de investigación de rápido crecimiento en cuestión de cómo las personas almacenan, administran y vuelven a encontrar información. Los sistemas PIM, los métodos y procedimientos por los cuales las personas manejan, clasifican y recuperan la información del día a día [18], se están volviendo cada vez más populares. Sin embargo, la evaluación de estos sistemas PIM es problemática. Una de las principales dificultades es causada por la naturaleza personal de PIM. Las personas recopilan información como consecuencia natural de completar otras tareas. Esto significa que las colecciones que generan las personas son exclusivas de ellas y la información dentro de una colección está intrínsecamente vinculada con las experiencias personales de los propietarios. Como las colecciones personales son únicas, no podemos crear tareas de evaluación aplicables a todos los participantes en una evaluación. En segundo lugar, las colecciones personales pueden contener información de que los participantes se sienten incómodos compartiendo dentro de una evaluación. La naturaleza precisa de esta información, qué información preferirían mantener privadas, varía entre las personas que dificultan basar las tareas de búsqueda en el contenido de las colecciones individuales. Por lo tanto, los experimentadores enfrentan una serie de desafíos para realizar evaluaciones PIM realistas pero controladas. Una característica particular de PIM Research es que muchos sistemas han sido diseñados para ayudar a los usuarios a administrar y volver a encontrar su información, pero muy pocos han sido evaluados;Una situación observada por varios estudiosos [1, 6, 7]. Recientemente, sin embargo, los investigadores han comenzado a centrarse en las formas de abordar el problema de la evaluación PIM. Por ejemplo, Kelly [16] propone que se deben tomar numerosas metodologías para examinar y comprender los muchos problemas involucrados en PIM, aunque hace referencia explícita a la necesidad de estudios PIM basados en el laboratorio y un conjunto común de tareas compartidas para hacer esto posible.. CAPRA [6] también identifica la necesidad de evaluaciones de laboratorio PIM controladas para complementar otras técnicas de evaluación, lo que pone énfasis específico en la necesidad de comprender el comportamiento PIM a nivel de tarea. En este documento, intentamos abordar las dificultades involucradas para facilitar las evaluaciones de PIM de laboratorio controladas. En la primera parte de este artículo presentamos un estudio diario de tareas de reinicio de información. El estudio examina el tipo de tareas que requieren que los usuarios vuelvan a encontrar información y produzcan una taxonomía de reiniciar tareas para mensajes de correo electrónico y páginas web. También observamos las características de las tareas que dificultan la reinfección. En la segunda parte, proponemos una metodología de evaluación basada en tareas basada en nuestros hallazgos y examinamos la viabilidad del enfoque utilizando diferentes métodos de creación de tareas. Por lo tanto, este documento ofrece dos contribuciones al campo: una mayor comprensión del comportamiento PIM en el nivel de tarea y un método de evaluación que facilitará más investigaciones.2. Trabajo relacionado Una variedad de enfoques están disponibles para estudiar PIM. Los enfoques naturalistas estudian participantes que se desempeñan naturalmente, completando sus propias tareas a medida que ocurren, dentro de entornos familiares. Estos enfoques permiten a los investigadores superar muchas de las dificultades causadas por la naturaleza personal del PIM. Como las tareas realizadas son reales y no simuladas, los participantes pueden utilizar sus propias experiencias, conocimiento previo y colecciones de información para completar las tareas. Un beneficio del enfoque es que los datos se pueden capturar continuamente durante períodos de tiempo prolongados y las mediciones se pueden tomar en puntos fijos en el tiempo dentro de estos [15]. Los enfoques naturalistas se pueden aplicar realizando el trabajo de campo [17, 8], métodos etnográficos según lo sugerido por [15] o mediante análisis de archivos de registro [9, 7]. Los métodos etnográficos y de trabajo de campo requieren la presencia de un experimentador para evaluar cómo se realiza PIM, lo que plantea una serie de problemas. En primer lugar, la evaluación de esta manera es costosa;Tomando largos períodos para estudiar un pequeño número de participantes y estas pequeñas muestras pueden no ser representativas del comportamiento de las poblaciones más grandes. En segundo lugar, debido a que los participantes no pueden observarse continuamente, los experimentadores deben elegir cuándo observar y esto puede afectar los hallazgos. Una estrategia alternativa para realizar evaluaciones naturalistas es utilizar el análisis de archivos de registro. Este enfoque utiliza el software de registro que captura una amplia muestra de las actividades del usuario en el contexto del uso natural de un sistema. En [9] se implementó una nueva herramienta de búsqueda PIM en 234 usuarios y los datos de registro proporcionaron información detallada sobre la naturaleza de las consultas de los usuarios, las interacciones con la interfaz de consulta y sobre las propiedades de los elementos recuperados. El análisis de archivos de registro es una metodología poderosa, ya que permite la captura de una gran cantidad de información detallada sobre cómo los usuarios se comportan con el sistema sin el gasto y la influencia de distracción de un observador. Sin embargo, hay limitaciones en esta estrategia. En primer lugar, para obtener resultados útiles, el prototipo implementado debe ser algo que las personas usarían, es decir, debe ser una pieza de software completamente funcional que ofrece una mejora en los sistemas que normalmente estén disponibles para los participantes. Desarrollar un prototipo de investigación a este estándar está más allá de los recursos de muchos investigadores. Además, se debe tener precaución al analizar registros, ya que los datos capturados no muestran nada sobre los objetivos e intenciones que el usuario tenía en ese momento. Por lo tanto, es difícil hacer declaraciones concretas sobre las razones del comportamiento representado en los registros. Esto revela la necesidad de complementar los estudios naturalistas con experimentos controlados donde el experimentador puede relacionar el comportamiento de los participantes del estudio con los objetivos asociados con las tareas de búsqueda conocidas. Los estudios basados en el laboratorio simulan a los usuarios el medio ambiente del mundo real en el entorno controlado del laboratorio, ofreciendo la capacidad de estudiar problemas estrictamente definidos y de alcance estrecho. Una dificultad para realizar este tipo de evaluación es obtener colecciones para evaluar. Kelly [16] propone la introducción de una colección de pruebas compartidas que proporcionaría conjuntos de datos, tareas y métricas compartibles y reutilizables para aquellos interesados en realizar investigaciones PIM. Esto puede ser útil para probar algoritmos de una manera similar a TREC en la corriente principal [13]. Sin embargo, una colección compartida no sería adecuada para los estudios de usuarios porque no sería posible incorporar los aspectos personales del PIM mientras usa una colección común y desconocida. Un enfoque alternativo es pedir a los usuarios que proporcionen sus propias colecciones de información para simular entornos familiares dentro del laboratorio. Este enfoque se ha aplicado para estudiar la reinicia de las fotografías personales [11], los mensajes de correo electrónico [20] y las marcas web [21]. La utilidad de este enfoque depende de lo fácil que sea transferir la colección o obtener acceso remoto. Otra solución es usar toda la web como una colección al estudiar la reinicia de la página web [4]. Esto puede ser apropiado para estudiar la reinicia de la página web porque los estudios anteriores han demostrado que las personas a menudo usan motores de búsqueda web para este propósito [5]. Una segunda dificultad para realizar estudios de laboratorio PIM es crear tareas para que los participantes se realicen que se pueden resolver buscando una colección compartida o personal. Las tareas se relacionan con la actividad que resulta en una necesidad de información [14] y se reconoce que son importantes para determinar el comportamiento del usuario [26]. Se ha llevado a cabo un gran trabajo para comprender la naturaleza de las tareas y cómo el tipo de tarea influye en el comportamiento de búsqueda de información del usuario. Por ejemplo, las tareas se han clasificado en términos de creciente complejidad [3] y se ha sugerido que la complejidad de la tarea afecte cómo los buscadores perciben sus necesidades de información [25] y cómo intentan encontrar información [3]. Otros trabajos anteriores han proporcionado metodologías que permiten la simulación de tareas al estudiar la información que busca el comportamiento [2]. Sin embargo, se sabe poco sobre los tipos de tareas que hacen que las personas busquen en sus tiendas personales o vuelvan a encontrar información que han visto antes. En consecuencia, es difícil idear situaciones de tareas de trabajo simuladas para PIM. La excepción es el estudio de la gestión de fotografías personales, donde Roddens trabaja en clasificar las tareas de búsqueda de fotografías personales ha facilitado la creación de situaciones de tareas de trabajo simuladas [22]. Ha habido otras sugerencias sobre cómo clasificar las tareas PIM. Por ejemplo, [5] pidió a los participantes que clasificaran las tareas en función de la frecuencia con la que realizan el tipo de tarea en su vida diaria y cuán familiarizados estaban con la ubicación de la información solicitada y varios académicos han clasificado los objetos de información por la frecuencia de su uso.p.ej.[24]. Si bien estas son propiedades interesantes que pueden afectar la forma en que se realizará una tarea, no les dan a los experimentadores suficiente alcance para diseñar tareas. Las colecciones personales son una razón por la cual la creación de tareas es tan difícil. La taxonomía de tareas de fotos de Roddens proporciona una solución aquí porque permite clasificar las tareas, adaptadas a colecciones privadas. Los sistemas se pueden comparar en todos los tipos de tareas para diferentes usuarios [11]. Desafortunadamente, no existe taxonomía equivalente para otros tipos de objeto de información. Además, otros tipos de objetos son más sensibles a la privacidad que las fotografías;Es poco probable que los participantes estén tan contentos de permitir a los investigadores navegar por sus colecciones de correo electrónico para crear tareas como lo fueron con fotografías en [11]. Esto presenta un problema grave: ¿cómo pueden los investigadores idear tareas que correspondan a colecciones privadas sin comprender los tipos de tareas que las personas realizan o poniendo en peligro la privacidad de los participantes del estudio? Se han propuesto algunos métodos. Por ejemplo, [20] estudió la búsqueda por correo electrónico pidiendo a los participantes que vuelvan a encontrar correos electrónicos que habían sido enviados a todos los miembros de un departamento;permitiendo que se usen las mismas tareas para todos los participantes del estudio. Este enfoque aseguró que se evitaran problemas de privacidad y que los participantes pudieran usar cosas que recuerdan para completar las tareas. Sin embargo, los sistemas solo se probaron utilizando un tipo de tarea: se les pidió a los participantes que encontraran correos electrónicos individuales, cada uno de los cuales compartía propiedades comunes. En la Sección 4 mostramos que las personas realizan una gama más amplia de tareas de reinicio por correo electrónico que esta. En [4], las tareas de búsqueda genéricas se crearon artificialmente ejecutando evaluaciones en dos sesiones. En la primera sesión, se pidió a los participantes que completaran tareas de trabajo que implicaron encontrar información desconocida. En la segunda sesión, los participantes completaron las mismas tareas nuevamente, lo que naturalmente implicó algún comportamiento de reinicio. Las limitaciones de esta técnica son que no permite a los participantes explotar ninguna conexión personal con la información porque la información que buscan puede no corresponder a ningún otro aspecto de sus vidas. Además, si el tiempo se utiliza por un sistema o interfaz que se está probando, el enfoque no es adecuado porque todos los objetos encontrados en la primera sesión se habrá accedido dentro del mismo período de tiempo. Nuestra revisión de los enfoques de evaluación motiva un requisito de experimentos controlados de laboratorio que permitan probar aspectos estrictamente definidos de los sistemas o interfaces. Desafortunadamente, también se ha demostrado que existen dificultades involucradas en el desempeño de este tipo de evaluación: es difícil obtener colecciones y idear tareas que correspondan a colecciones privadas, al mismo tiempo que protegen la privacidad de los participantes del estudio. En la siguiente sección presentamos un estudio diario de tareas de refinamiento para correo electrónico y páginas web. El resultado es una clasificación de tareas similares a la ideada por Rodden para fotografías personales [22]. En la Sección 5, construimos sobre este trabajo examinando métodos para crear tareas que no comprometen la privacidad de los participantes y discuten cómo nuestro trabajo puede facilitar las evaluaciones de los usuarios PIM basadas en tareas. Mostramos que al recopilar tareas utilizando diarios electrónicos, no solo podemos aprender sobre las tareas que hacen que las personas vuelvan a encontrar información personal, sino que podemos aprender sobre el contenido de las colecciones privadas sin comprometer la privacidad de los participantes. Este conocimiento se puede utilizar para construir tareas para su uso en evaluaciones PIM.3. Los estudios de diario del método son una técnica naturalista, que ofrece la capacidad de capturar datos objetivos, en un entorno natural, sin la influencia que distrae un observador. Las limitaciones de la técnica incluyen dificultades para mantener los niveles de dedicación de los participantes y convencer a los participantes de que la información aparentemente mundana es útil y debe informarse [19].[12] sugieren que los efectos de los negativos pueden ser limitados, sin embargo, con un diseño cuidadoso y una buena implementación. En nuestro estudio del diario, seguimos las sugerencias en [12] para lograr los mejores datos posibles. Con este fin, restringimos las tareas grabadas a la redacción web y por correo electrónico. Al pedir a los usuarios que registren menos tareas, se anticipó que la apatía de los participantes se reduciría y se mantendría los niveles de dedicación. Los participantes recibieron un formulario web personalizado en el que podían registrar detalles sobre sus necesidades de información y los contextos en los que se desarrollaron estas necesidades. Los formularios web se implementaron en lugar de diarios basados en papel porque para volver a encontrar información web y por correo electrónico, el usuario estaría en una computadora con una conexión a Internet y no habría necesidad de buscar un diario y un bolígrafo basados en papel. El formulario del diario solicitó la siguiente información: si la información necesita relacionada con la reinicio de una página web o un mensaje de correo electrónico y una descripción de la tarea que están realizando. Esta descripción era contener tanto la información que el participante deseaba encontrar como la razón por la que necesitaba la información. Para ayudar con esto, el formulario dio tres descripciones de tareas de ejemplo, que también se explicaron verbalmente a cada participante durante una sesión introductoria. El experimentador aseguró que los participantes entendieron que las tareas a registrar no se limitaron a los tipos que se muestran en los ejemplos. Los ejemplos se suministraron exclusivamente para que los participantes pensaran en los tipos de cosas que podían registrar y para mostrar el nivel y el tipo de detalles esperados. El formulario también pidió a los participantes que calificaran cada tarea en términos de dificultad (en una escala de 1-5, donde 1 fue muy fácil y 5 fue muy difícil). Finalmente, se les preguntó cuándo fue la última vez que miraron la información buscada. Una vez más, pudieron elegir entre 5 opciones (hace menos de un día, hace menos de una semana, hace menos de un mes, hace menos de un año, hace más de un año). La información de tiempo se utilizó para examinar la frecuencia con la que los participantes vuelven a descubrir información antigua y nueva, y cuando se combinan con las calificaciones de dificultad crearon una imagen de si el período de tiempo entre el acceso y la reaccionamiento impactó en cuán difíciles se perciben las tareas de los participantes.ser.Se pidió a 36 participantes, reclutados por anuncios masivos a través de canales de comunicación departamentales, reuniones de grupos de investigación y conferencias de pregrado, que registraran digitalmente los detalles de sus tareas de reinicio de información durante un período de aproximadamente 3 semanas. La población final constaba de 4 miembros del personal académico, 8 miembros del personal de investigación, 6 estudiantes de investigación y 18 estudiantes de pregrado. Las edades de los participantes oscilaron entre 19 y 59. A medida que se registraron las tareas personales y de trabajo, los resultados recopilados cubren una amplia gama de tareas de reinicio.4. Resultados Se realizaron varios análisis en los datos capturados. Las siguientes secciones presentan los hallazgos. En primer lugar, examinamos los tipos de tareas de reinicio que se realizaron tanto al buscar en el correo electrónico como en la web. A continuación, consideramos la distribución de tareas, qué tipos de tareas fueron realizadas con mayor frecuencia por los participantes. Por último, exploramos los tipos de tareas de reinicio que los participantes percibieron como difíciles.4.1 Naturaleza de las tareas de reinicio de la web y el correo electrónico durante el estudio 412 tareas se registraron.150 (36.41%) de estas tareas se basaron en correo electrónico, 262 (63.59%) fueron a base de web. Como con la mayoría de los estudios diarios, el número de tareas registradas varió ampliamente entre los participantes. La mediana del número de tareas por participante fue 8 (rango intercuartil (IQR) = 9.5). Se registraron más tareas web (mediana = 5, IQR = 7.5) que las tareas de correo electrónico (mediana = 3, IQR = 3). Esto significa que, en promedio, cada participante registró aproximadamente una tarea cada dos días. De las descripciones suministradas por los participantes, encontramos características similares en las tareas grabadas tanto para el correo electrónico como para la reinfección web. Según esta observación, se diseñó un esquema de clasificación conjunta, que abarca tareas de correo electrónico y web. Las tareas se clasificaron como uno de los tres tipos: tareas de búsqueda, tareas de elementos y tareas de múltiples elementos. Las tareas de búsqueda implican la búsqueda de información específica de un recurso, por ejemplo, un correo electrónico o una página web, donde el recurso puede o no ser conocido. Algunos ejemplos grabados de tareas de búsqueda fueron: • LU1: Buscando el código de curso para una clase: se usa en un script que se ejecuta para configurar una práctica. ID obtuvo previamente esto hace aproximadamente 3 semanas de nuestro sitio web.• LU2: Estoy tratando de determinar la fecha en que renuncio como examinador externo. Esto está en un correo electrónico en algún lugar • LU3: Buscando una descripción del formato de registro del sistema R desarrollado para el proyecto estudiantil. Creo que me envió en TI, un elemento de correo electrónico implica buscar un correo electrónico o página web en particular, tal vez para transmitir a otra persona o cuando se necesita todo el contenido para completar la tarea. Algunos ejemplos registrados de tareas de elementos fueron: • I1: Buscando el documento Sigir 2002 para dar a otro estudiante • I2: Encuentre la recepción de una compra de una aerolínea en línea requerida para reclamar los gastos • i3: Necesito los formularios de evaluación de pares para la clase MIA ELos envió por correo electrónico para aclarar, las tareas de búsqueda difieren de las tareas de los elementos de dos maneras, en la cantidad de información requerida y en lo que el usuario sabe sobre lo que está buscando. Las tareas de búsqueda implican la necesidad de una pequeña información, p.un número de teléfono o un ingrediente, y el usuario puede o no saber exactamente el recurso que contiene esta información. En las tareas de elementos, el usuario sabe exactamente el recurso que está buscando y necesita todo el contenido de ese recurso. Las tareas de múltiples elementos fueron tareas que requerían información contenida en numerosas páginas web o mensajes de correo electrónico. A menudo, estas tareas requerían que el usuario procesara o recopile la información para resolver la tarea. Algunos ejemplos grabados fueron: • MI1: Buscando obituarios y otro material sobre el novelista John Fowles, quien murió el fin de semana. Accedió al Guradian en línea e IMES • MI2: tratando de encontrar detalles sobre el marco de gráficos Piccolo. Recuérdame qué es y qué hace. Buscando construir una GUI dentro de Eclipse • MI3: Estoy tratando de presentar mis correos electrónicos con respecto a IPM y estoy buscando correos electrónicos de esta revista o sobre este diario, hubo una serie de tareas que fueron difíciles de clasificar. Por ejemplo, considere la siguiente tarea registrada: • LU4: Vuelva a encontrar el documento de culo sobre evaluaciones de relevancia calificadas porque quiero ver cómo presentó sus resultados para un documento. Estoy escribiendo esta tarea en realidad consta de dos subasquetas: 1 tarea de elemento(Refinte el documento) y 1 tarea de búsqueda (busque información específica dentro del documento). Se decidió tratar esto como una tarea de búsqueda porque el objetivo final de los usuarios era acceder y usar la información dentro del recurso. Hubo una serie de ejemplos de tareas combinadas, principalmente del elemento de formulario que la búsqueda, pero también hubo ejemplos de elementos que luego múltiples. Por ejemplo: • MI4: Vuelva a encontrar el sitio web de Kelkoo para que pueda volver a verificar los precios de los escaladores de cabello para mi novia, una segunda fuente de ambigüedad provino de tareas, como encontrar un correo electrónico que contenga una URL como un medio para volver a accederuna página web. También se decidió clasificarlas como tareas de búsqueda porque en todos los casos fueron registrados por los participantes como búsquedas por correo electrónico y, dentro de este contexto, lo que estaban buscando era información dentro de un correo electrónico. Otro problema era que algunos de los registros carecían del detalle requerido para realizar una categorización, p.• U1: Buscando cómo recuperar la selección de usuarios de un cuadro de mensaje. Decidió usar otros medios que tales tareas se etiquetaron como U para no clasificable. Para verificar la consistencia de la taxonomía, las tareas fueron recativoradas por el mismo investigador después de un retraso de dos semanas. El acuerdo entre los resultados de los dos análisis fue en gran medida consistente (96.8%). Además, le pedimos a un investigador sin conocimiento del proyecto o el campo que clasifique una muestra de 50 tareas. El segundo investigador logró un acuerdo del 90%. Creemos que este alto acuerdo sobre una gran cantidad de tareas de más de un investigador proporciona evidencia de la confiabilidad del esquema de clasificación. La distribución de los tipos de tareas se muestra en la Tabla 1. En general, las tareas de búsqueda y ítems fueron las más comunes, con tareas de múltiples múltiples que solo representan el 8.98% de las registradas. La distribución de los tipos de tareas fue diferente para la reinfección web y por correo electrónico. La mayoría de las tareas de correo electrónico (60%) involucraban la búsqueda de información dentro de un correo electrónico (búsqueda), en contraste con las tareas web donde la mayoría de las tareas (52.67%) implicaban buscar una sola página web (elemento). Otra distinción fue el número de tareas de múltiples elementos grabadas para la web y el correo electrónico. Las tareas de múltiples elementos eran muy raras para la reinfección de correo electrónico (solo el 2.67% de las tareas de correo electrónico implicaban la búsqueda de recursos múltiples), pero relativamente comunes para la reinfección web (12.6%). Elemento de búsqueda de múltiples ítems desenchillados. Correo electrónico 90 (60%) 52 (34.67%) 4 (2.67%) 4 (2.67%) Web 87 (33.21%) 138 (52.67%) 33 (12.60%) 4 (1.53%) Todos 177 (42.96%) 190 (46.12%) 37 (8.98%) 8 (1.94%) Tabla 1: La distribución de los tipos de tareas además de la clasificación de tres vías descrita anteriormente, las tareas registradas se clasificaron con respecto a la metáfora de temperatura propuesta por [24], queClasifica la información como una de las tres temperaturas: caliente, cálida y fría. Clasificamos las tareas utilizando los datos del formulario. La información que se había visto menos de un día o menos de una semana antes de que la tarea se definiera como caliente, la información que se había visto menos de un mes antes de la tarea como cálida e información que se había visto menos de un año o más queun año antes de la tarea como frío. Desafortunadamente, una dificultad técnica con el formulario solo permitió clasificar 335 (81.3%) de las tareas. El resto se definió como U para no clasificable. En la Tabla 2 se muestra una tabulación cruzada de los tipos de tareas y las temperaturas. Caliente y caliente frío. Correo electrónico 50 (33.33%) 36 (24.00%) 37 (24.67%) 27 (18%) Web 112 (42.75%) 60 (22.90%) 40 (15.27%) 50 (19.08%) Todos 162 (39.32%) 96 (23.30%) 77 (18.69%) 77 (18.69%) Tabla 2: La distribución de temperaturas La mayoría de las tareas que hicieron que las personas volvieran a encontrar páginas web (42.75%) y mensajes de correo electrónico (33.33%) implican buscar información que tuvo información que tienese ha accedido en la última semana. Sin embargo, también hubo una serie de tareas de reinicio que implicaron la búsqueda de información anterior: el 23.30% de las tareas registradas (24.00% para el correo electrónico y el 22.90% para la web) implicó la búsqueda de información accedida en el último mes y el 18.69% de las tareasregistrado (24.67% para correo electrónico y 15.27% para la web) buscaban información aún más antigua. Esto es importante con respecto a la evaluación porque existe evidencia psicológica que sugiere que las personas recuerdan menos con el tiempo, p.[23]. Esto significa que los usuarios pueden encontrar más difícil buscar información anterior o tal vez alterar su estrategia de búsqueda al buscar información caliente, cálida o fría.4.2 ¿Qué tareas son difíciles? Buscamos patrones en los datos registrados para determinar si ciertas tareas se percibían como más difíciles que otras. Por ejemplo, examinamos si el tipo de medios afectó lo difícil que los participantes percibieron la tarea. No hubo evidencia de que los participantes encontraran correo electrónico (mediana = 2 IQR = 2) o Web (mediana = 2 IQR = 2) tareas más difíciles. También investigamos si el tipo de tarea o el período de tiempo entre el acceso y el reembolso hicieron que una tarea fuera más difícil. La Figura 1 muestra esta información gráficamente. Figura 1: Calificaciones de dificultad para los tipos de tareas de la Figura 1, no parece que ningún tipo de tarea en particular se percibiera como difícil con respecto a los demás, aunque existe una sugerencia de que las tareas de búsqueda se perciban más difíciles cuando se buscaba información fría que caliente quey las tareas de los elementos se percibieron más difíciles para información cálida que caliente. Para evaluar la relación entre la temperatura de la información y la dificultad percibida, utilizamos las pruebas medias de los estados de ánimo para determinar si el rango de puntajes de dificultad estaba de acuerdo para las temperaturas de la información que se comparaban (p <0.05). Para los datos de tareas de búsqueda, hubo evidencia de que las tareas calientes se percibían más fácilmente que el frío (p = 0.0001) y que las tareas cálidas se percibían más fácilmente que las tareas frías (p = 0.0041), pero no había evidencia para distinguir entre la dificultadCalificaciones de tareas calientes y cálidas (P = 0.593). Para los datos de la tarea del ítem, hubo evidencia de que las tareas calientes y frías se calificaron de manera diferente (p = 0.024), pero no hay evidencia para distinguir entre tareas calientes y cálidas (p = 0.05) o tareas cálidas y frías (P = 0.272). Estas pruebas confirman que el período de tiempo entre acceder y volver a acceder a la información solicitada influyó en cómo los participantes difíciles percibieron la tarea. Sin embargo, la gran cantidad de tareas de todo tipo y temperaturas calificadas por los participantes como fáciles, es decir, <3, sugiere que hay otros factores que influyen en cuán difícil se percibe que es una tarea. Aprender sobre estos factores requeriría el tipo de evaluaciones de usuarios propuestas por [16, 6], el tipo de evaluaciones facilitadas por nuestro trabajo.4.3 Resumen En la primera parte de este documento, describimos un estudio diario de tareas de reinicio web y por correo electrónico. Examinamos los tipos de tareas que hicieron que los participantes registraran sus tiendas personales y encontramos tres categorías principales de tareas: tareas en las que el usuario requiere información específica de un solo recurso, tareas donde se requiere un solo recurso y tareas que requieren informaciónser recuperado de múltiples recursos. Se descubrió que las tareas de búsqueda y elemento se registraron con mayor frecuencia que las tareas de múltiples elementos. Aunque no se encontraron evidencia de que las tareas web o de correo electrónico fueran más difíciles, hubo alguna evidencia que mostrara que el tiempo entre el acceso y el reacio afectó lo difícil que las participantes percibieron las tareas. Estos hallazgos tienen implicaciones para evaluar el comportamiento PIM en el nivel de tarea. El resto de este documento se concentra en esto, discutiendo lo que significan los hallazgos con respecto a realizar evaluaciones de usuarios PIM basadas en tareas.5. Evaluaciones PIM basadas en tareas Los hallazgos descritos en la Sección 4 son útiles con respecto a la evaluación porque proporcionan a los experimentadores suficiente conocimiento para realizar evaluaciones controladas de usuarios en condiciones de laboratorio. Se pueden construir diseños experimentales de greco-latin cuadrado donde a los participantes se les asigna n tareas de los tres tipos descritos anteriormente para realizar en sus propias colecciones utilizando sistemas X. Esto permitiría que el rendimiento de los sistemas o el comportamiento de los participantes que usen diferentes sistemas se analizaran con respecto al tipo de tarea que se realiza (búsqueda, elemento o múltiple ítems). En las siguientes secciones evaluamos la viabilidad de este enfoque al emplear diferentes métodos de creación de tareas.5.1 Uso de tareas reales Un método para crear tareas de reinicio realistas sin comprometer la privacidad de los participantes es usar tareas reales. Los estudios diarios, similares a los descritos anteriormente, permitirían a los experimentadores capturar un grupo de tareas para que los participantes completen buscando en sus propias colecciones. Esto es extremadamente ventajoso porque permitiría a los experimentadores evaluar el comportamiento de los usuarios reales, completando tareas de búsqueda reales en colecciones reales mientras están en un entorno controlado. También existe el beneficio adicional de que las descripciones de tareas no harían suposiciones sobre lo que el usuario recordaría en una situación de la vida real porque solo incluiría la información que se había registrado, es decir, la información disponible cuando el usuario realizó originalmente la tarea. Sin embargo, para obtener estos beneficios debemos, en primer lugar, confirmar que las descripciones de tareas registradas son de calidad suficiente para permitir que la tarea se vuelva a actuar en una fecha posterior. En segundo lugar, debemos asegurarnos de que un estudio diario proporcione a los experimentadores suficientes tareas para construir un diseño experimental equilibrado que satisfaga sus necesidades de datos. Para examinar la calidad de las tareas registradas, 6 semanas después de que el estudio del diario se haya completado, preguntamos a 6 de nuestros participantes, seleccionados al azar del grupo de aquellos que registraron suficientes tareas, que volvieran a realizar 5 de sus propias tareas. Las tareas se seleccionaron al azar desde el grupo de los disponibles. Las tareas emitidas constaban de 10 correo electrónico y 20 tareas web, 9 de las cuales eran tareas de búsqueda, 12 eran tareas de elementos y 8 eran tareas de múltiples elementos. Las tareas emitidas representaban un muestreo amplio del conjunto completo de tareas grabadas. También incluyeron tareas con descripciones vagas, p.• LU5: encuentre una clave de software para una aplicación que necesite para reinstalar.• LU6: Tratando de encontrar una cita para usar en un documento. No puedo recordar que la persona o la cita exacta la utilidad de tales tareas dependería de los recuerdos de los participantes, es decir, la grabadora de la tarea LU5 recordaría a qué aplicación se refirió y el registrador de LU6 recordaría lo suficiente sobre el contexto en el que tuvo lugar la tareapara volver a realizar la tarea? Presentado con las tareas exactamente como las registraron, se les pidió a los participantes que volvieran a realizar cada tarea con cualquier sistema de su elección. De las 30 tareas emitidas, 26 (86.67%) se completaron sin problemas, 2 (6.67%) de las tareas no se completaron porque la descripción registrada era insuficiente para recrear la tarea y 2 tareas (6.67%) no se completaron porque laLa tarea era demasiado difícil o la página web requerida ya no existía. Es probable que los experimentadores estén interesados en el grupo final de tareas porque es importante descubrir qué dificulta la tarea y cómo el comportamiento del usuario cambia en estas circunstancias. Por lo tanto, a partir de las 30 tareas probadas, solo 2 tareas no eran de calidad suficiente para ser utilizadas en una situación de evaluación. Además, no parecía haber ningún problema del tipo, las calificaciones de temperatura o dificultad que afectan la calidad de las descripciones de las tareas. Estos hallazgos sugieren que los participantes que registraron la mayoría de las tareas en el estudio del diario también registraron tareas con suficiente calidad. Sin embargo, ¿el estudio del diario generó suficientes tareas para satisfacer las necesidades de los experimentadores? Tareas de participante Elemento de búsqueda de múltiples ítems.10 26 16 8 2 0 43 9 4 5 0 0 0 26 9 5 4 0 0 8 9 8 1 0 0 40 8 5 3 0 0 18 7 3 4 0 0 0 4 6 5 1 0 0 7 6 5 0 1 0 12 5 54 0 0 1 22 5 4 1 0 0 36 5 0 5 0 0 46 5 2 2 0 1 3 5 3 2 0 0 Tabla 3: Las cantidades de tareas de correo electrónico registradas Tareas de los participantes de los participantes Elemento de la búsqueda de múltiples artículos.26 32 7 20 5 0 32 31 11 11 18 2 0 10 19 0 10 7 2 33 18 5 13 0 0 5 15 0 7 2 4 8 11 0 6 5 0 22 10 0 3 5 2 28 10 1 7 2 0 37 101 9 0 0 35 9 7 2 0 0 6 9 0 1 8 0 40 7 1 5 1 0 9 7 0 0 5 2 12 7 1 0 3 2 42 6 0 4 2 0 29 6 0 3 3 0 15 5 0 21 2 4 5 0 4 1 0 43 5 2 3 0 0 18 5 0 0 0 3 2 Tabla 4: Las cantidades de tareas web registradas naturalmente el número exacto de tareas necesarias para realizar una evaluación del usuario dependerá de los objetivos de la evaluación,El número de usuarios y el número de sistemas a probar, etc. Sin embargo, con fines ilustrativos elegimos 5 tareas como punto de corte para nuestros datos. Desde las Tablas 3 y 4, que muestran las cantidades de correo electrónico y tareas web registradas para cada participante, podemos ver que los de 36 participantes, solo 13 (36.1%) registraron 5 o más tareas de correo electrónico y 20 (55.6%) registrados 5 oMás tareas web. Esto significa que muchos de los participantes reclutados no podrían participar en la evaluación final. Esta es una limitación importante del uso de tareas registradas en las evaluaciones porque el reclutamiento de los participantes para las pruebas de usuario es un desafío y puede que no sea posible reclutar suficientes participantes si los experimentadores pierden entre la mitad y dos tercios de sus poblaciones. Además, hubo cierto desequilibrio en el número de tareas registradas de diferentes tipos. Algunos participantes registraron varias tareas de búsqueda, pero muy pocas tareas de elementos y otras grabaron varias tareas de elementos, pero pocas tareas de búsqueda. También hubo una falta específica de tareas de correo electrónico de múltiples elementos. Esta situación hace que sea muy difícil para los experimentadores preparar diseños experimentales equilibrados. Por lo tanto, a pesar de que nuestra primera prueba sugiere que la calidad de las tareas registradas fue suficiente para que los participantes vuelvan a realizar las tareas en una etapa posterior, el número de tareas registradas fue probablemente demasiado baja para hacer de esta una opción viable para la creación de tareas experimentales. Sin embargo, puede ser posible aumentar el número de tareas registradas con frecuentemente recordando a los participantes o realizando visitas personales, etc. 5.2 utilizando tareas simuladas basadas en tareas reales Otro beneficio de los estudios del diario es que proporcionan información sobre los contenidos y usos de los usos privadoscolecciones sin invadir la privacidad de los participantes. Esta sección explora la posibilidad de utilizar una combinación del conocimiento obtenido de los estudios diarios y otros atributos conocidos sobre los participantes para crear artificialmente tareas de reinicio correspondientes a la taxonomía definida en la Sección 4.1. Explicamos las técnicas utilizadas y demostramos la viabilidad de crear tareas simuladas dentro del contexto de una evaluación de usuarios que investiga el comportamiento de reinicio del correo electrónico. Las limitaciones de espacio nos impiden informar nuestros hallazgos;En cambio, nos concentramos en los métodos de creación de tareas. Como preparación para la evaluación, realizamos un segundo estudio diario, donde 34 nuevos participantes, que constan de 16 estudiantes de posgrado y 18 estudiantes de subgrado, registraron 150 tareas de correo electrónico durante un período de aproximadamente 3 semanas. Los datos recopilados revelaron varios patrones que ayudaron con la creación de tareas artificiales. Por ejemplo, los estudiantes de ambos grupos registraron tareas relacionadas con clases que estaban tomando en ese momento y, a menudo, diferentes participantes registraron tareas que implicaban buscar la misma información. Esto fue útil porque nos proporcionó una pista de que, aunque algunos de los participantes no registraron una tarea en particular, era posible que la tarea aún fuera aplicable a sus colecciones. Otros patrones revelados incluyeron que los estudiantes dentro del mismo grupo a menudo buscaban correos electrónicos que contenían anuncios de la misma fuente. Por ejemplo, varios estudiantes de pregrado registraron tareas que incluían la reinicio de la información relacionada con las vacantes de empleo. También hubo tareas que fueron registradas por los participantes en ambos grupos. Por ejemplo, la búsqueda de un correo electrónico que vuelva a confirmar el código PIN requerido para acceder a los laboratorios de computación. Para complementar nuestro conocimiento de las colecciones de correo electrónico de los participantes, pedimos a 2 participantes de cada grupo que proporcionen recorridos por correo electrónico. Estos consistieron en breves sesiones de 5-10 minutos, donde se les pidió a los participantes que explicaran por qué usan el correo electrónico, quién les envía correo electrónico y sus estrategias organizativas. Este enfoque se ha utilizado con éxito en el pasado como un medio no intrusivo para aprender sobre cómo las personas almacenan y mantienen su información personal [17]. Originalmente, habíamos planeado pedir a más participantes que proporcionaran giras, pero encontramos que 2 tours por grupo eran suficientes para nuestras necesidades. Nuevamente, surgieron patrones que ayudaron con la creación de tareas. Encontramos el contenido superpuesto dentro y entre grupos que confirmaron muchas de nuestras observaciones de los datos del estudio del diario. Por ejemplo, los estudiantes que dieron giras revelaron que recibieron correos electrónicos de profesores para tareas de clase particulares, recibos para tareas completadas y varios anuncios de soporte de sistemas y vacantes de empleo. Es importante destacar que los participantes también pudieron confirmar qué otros estudiantes habían recibido la misma información. Esto confirmó que muchas de las tareas registradas durante el estudio del diario eran aplicables, no solo para la grabadora, sino para cada participante en 1 o ambos grupos. Según este trabajo de investigación inicial, se creó un conjunto de 15 tareas (5 de cada tipo en nuestra taxonomía) para cada grupo de participantes. También creamos un conjunto de tareas para un tercer grupo de participantes que consistían en miembros de la investigación y el personal académico, basado en nuestro conocimiento de los correos electrónicos que reciben nuestros colegas. Cuando sea posible, utilizamos la información registrada en las descripciones del estudio del diario para proporcionar un contexto para la tarea, es decir, una tarea de trabajo o motivación que requeriría que se realice la tarea. Cuando los datos del estudio del diario no proporcionaron información de contexto suficiente para proporcionar a los participantes una descripción robusta de la necesidad de la información, creamos situaciones de tareas de trabajo simuladas de acuerdo con las directrices de [2]. Una ventaja adicional del uso de tareas simuladas de esta manera, en lugar de tareas reales, es que algunos de los usuarios no habrán realizado la tarea en el pasado reciente y esto permite el examen de tareas que buscan información de diferentes temperaturas. Si solo se hubieran utilizado tareas reales, todos los participantes habrían realizado las tareas durante el período del estudio del diario. Las tareas creadas se utilizaron en una evaluación final, donde examinamos el comportamiento de reinicio del correo electrónico de los usuarios con tres sistemas de correo electrónico diferentes.21 usuarios (7 en cada grupo) realizaron 9 tareas cada una (1 tarea de cada tipo en cada sistema) utilizando sus propias colecciones personales en un diseño experimental de greco-latina cuadrada. Realizar una evaluación PIM de esta manera permitió el examen del comportamiento de reinicio de una manera que no era posible antes: pudimos observar las estrategias de reinfección de correo electrónico empleadas por usuarios reales, realizando tareas realistas, en sus propias colecciones en un entorno controlado.. El estudio reveló que los participantes recordaron diferentes atributos de correos electrónicos, demostraron diferentes comportamientos de búsqueda y exhibieron diferentes niveles de rendimiento cuando se les pidió que completaran tareas de los diferentes tipos en la taxonomía. La clave tanto para la creación de tareas como para el análisis de los resultados fue nuestra taxonomía, que proporcionó la plantilla para crear tareas y también un medio para comparar el comportamiento y el rendimiento de diferentes usuarios (y sistemas) que realizan diferentes tareas del mismo tipo. Algunos de los hallazgos de la evaluación se publicarán en [10]. Resumiendo el enfoque, para realizar un experimento de usuario utilizando nuestra metodología, los investigadores deberían realizar los siguientes pasos: 1) realizar un estudio de diario como anteriormente 1.2) Analice las tareas registradas que buscan superposición entre los participantes.3) Complementar el conocimiento adquirido sobre el contenido de las colecciones de los participantes pidiendo a una selección de los participantes que proporcionen un recorrido por su colección.4) Use el conocimiento obtenido para idear tareas de los tres tipos diferentes definidos dentro de la taxonomía. Se puede encontrar más información DE1 sobre esto y los formularios de diario requeridos en http://www.cis.strath.ac.uk/˜dce/pimevaluations información sobre cómo usar la investigación descrita en este documento para realizar PIM basados en tareasLas evaluaciones se pueden encontrar en nuestro sitio web (ver nota 1).6. Conclusiones Este documento se ha centrado en superar las dificultades involucradas en la realización de evaluaciones PIM. La naturaleza personal de PIM significa que es difícil construir experimentos equilibrados porque los participantes tienen sus propias colecciones únicas que se autogeneran al completar otras tareas. Sugerimos que para incorporar los aspectos personales de PIM en las evaluaciones, el rendimiento de los sistemas o usuarios debe examinarse cuando los usuarios completen tareas en sus propias colecciones. Este enfoque en sí mismo tiene problemas porque la creación de tareas para colecciones personales es difícil: los investigadores no saben mucho sobre los tipos de tareas de reinicio que las personas realizan y no saben qué información hay dentro de las colecciones personales individuales. En este artículo describimos formas de superar estos desafíos para facilitar las evaluaciones de los usuarios PIM basadas en tareas. En la primera parte del documento realizamos un estudio de diario que examinó las tareas que hicieron que las personas volvieran a encontrar mensajes de correo electrónico y páginas web. Los datos recopilados incluyeron una amplia gama de tareas relacionadas con el trabajo y no laboral, y en base a los datos creamos una taxonomía de las tareas de reinicio de Web y Correo electrónico. Descubrimos que las personas realizan tres tipos principales de tareas de reinicio: tareas que requieren información específica de un solo recurso, tareas que requieren un solo recurso completo y tareas que requieren que la información se recupere de múltiples recursos. En la segunda parte del documento, discutimos la importancia de la taxonomía con respecto a la evaluación PIM. Demostramos que los experimentos equilibrados podrían realizarse comparando el sistema o el rendimiento del usuario en las categorías de tareas dentro de la taxonomía. También sugerimos dos métodos para crear tareas que se pueden completar en colecciones personales. Estos métodos no comprometen la privacidad de los participantes del estudio. Examinamos las técnicas sugeridas, en primer lugar, simulando una situación experimental: se les pidió a los participantes que volvieran a realizar sus propias tareas mientras las registraban y, en segundo lugar, en el contexto de una evaluación completa. Realizar evaluaciones de esta manera permitirá que los sistemas que se han propuesto mejorar la capacidad de los usuarios para administrar y volver a encontrar su información para que se pruebe, para que podamos aprender sobre las necesidades y deseos de los usuarios. Por lo tanto, este documento ha ofrecido dos contribuciones al campo: una mayor comprensión del comportamiento PIM en el nivel de tarea y un método de evaluación que facilitará más investigaciones.7. Agradecimientos Nos gustaría agradecer al Dr. Mark Baillie por sus perspicaces comentarios y ayudar a analizar los datos.8. Referencias [1] R. Boardman, Mejora del soporte de herramientas para la gestión de información personal, Ph.D.Tesis, Imperial College London, 2004. [2] P. Borlund, El modelo de evaluación IIR: un marco para la evaluación de sistemas de recuperación de información interactiva, Information Research 8 (2003), no.3, papel no.152. [3] K. Bystr¨om y K. J¨arvelin, La complejidad de la tarea afecta la búsqueda y uso de la información, Procesamiento y gestión de la información 31 (1995), no.2, 191-213.[4] R. G. Capra y M. A. Pérez-Quinones, Reiniciando cosas encontradas: un estudio exploratorio de cómo los usuarios vuelven a encontrar información, tecnología.Informe, Virginia Tech, 2003. [5] R. G. Capra y M. A. Pérez-Quinones, utilizando motores de búsqueda web para encontrar y refindir información, Computer 38 (2005), no.10, 36-42.[6] R. G. Capra y M. A. Pérez-Quinones, Factores y evaluación de los comportamientos de refindación., Taller Sigir 2006 sobre gestión de la información personal, 10-11 de agosto de 2006, Seattle, Washington, 2006. [7] E. Cutrell, D.Robbins, S.Dumais y R.Sarin, Filtrado rápido y flexible con Phlat, Proc. Sigchi 06 (Nueva York, NY, EE. UU.), ACM Press, 2006, pp. 261-270.[8] M. Czerwinski, E. Horvitz y S. Wilhite, Un estudio diario del cambio de tareas e interrupciones, Proc. Sigchi 04, 2004, pp. 175-182.[9] S. Dumais, E. Currell, J. Cadiz, G. Jancke, R. Sarin y D.C. Robbins, Stuffe Se ha visto: un sistema para recuperación y reutilización de información personal, Proc. Sigir 03:, 2003, pp. 72-79.[10] D. Elsweiler e I. Ruthven, Memoria y reinicio de correo electrónico, en preparación para los números especiales ACM TOIS CFP sobre el mantenimiento, la reinicia y el intercambio de información personal (2007).[11] D. Elsweiler, I. Ruthven y C. Jones, que se ocupan del recuerdo fragmentado del contexto en la gestión de la información, el taller de recuperación de información basada en el contexto (CIR-05) en el contexto-05, 2005. [12] D. ElsweilerI. Ruthven y C. Jones, hacia la memoria que respalda las herramientas de gestión de la información personal, (para aparecer en) Journal of the American Society for Information Science and Technology (2007).[13] D. Harman, Lo que hemos aprendido, y no aprendimos, de Trec, Proc. Ecir 2000, 2000. [14] P. Ingwersen, Interacción de recuperación de información, Taylor Graham, 1992. [15] D. Kelly, B. Bederson, M. Czerwinski, J. Gemmell, W. Pratt y M. Skeels (eds (eds.), Informe del taller PIM: Medición y diseño, 2005. [16] D. Kelly y J. Teevan, (para aparecer en) Gestión de la información personal, cap. Comprensión de lo que funciona: Evaluación de herramientas de gestión de la información personal, Seattle: University of Washington Press., 2007. [17] B. H. Kwasnik, cómo los documentos personales previstos el uso o el propósito afecta su clasificación en una oficina, Sigir89 23 (1989), no. Si, 207-210.[18] M.W. Lansdale, The Psychology of Personal Information Management., Appl Ergon 19 (1988), no.1, 55-66.[19] L. Palen y M. Salzman, Estudios de diario de correo de voz para la captura de datos naturalistas en condiciones móviles, CSCW 02: Actas de la Conferencia ACM de 2002 sobre el trabajo cooperativo compatible con la computadora, 2002. [20] M. Ringel, E.CUTRELL, S. Dumais y E. Horvitz, Hitos en el tiempo: el valor de los puntos de referencia en la recuperación de la información de las tiendas personales., Proc. Interact 2003, 2003. [21] G. Robertson, M. Czerwinski, K. Larson, D. C. Robbins, D. Thiel y M. van Dantzich, Data Mountain: Uso de la memoria espacial para la gestión de documentos, Proc. UIST 98:, 1998. [22] K. Rodden, ¿Cómo organizan las personas sus fotografías, BCS IRSG 21º Coloquio anual sobre investigación de recuperación de información, Glasgow, Escocia, 1999. [23] D.C. Rubin y A.E. Wenzel, Cien años de olvido: una descripción cuantitativa de la retención, Boletín Psicológico 103 (1996), 734-760.[24] A. J. Sellen y R. H. R. Harper, The Myth of the Paperless Office, MIT Press, Cambridge, MA, EE. UU., 2003. [25] P. Vakkari, Complejidad de tareas, estructura de problemas y acciones de información: Integración de estudios en la búsqueda de información y la búsqueda de información yRecuperación., Procesamiento de información y gestión 35 (1999), 819-837.[26] P. Vakkari, Una teoría de la recuperación de información basada en tareas, Journal of Documentation 57 (2001), no.1, 44-60.