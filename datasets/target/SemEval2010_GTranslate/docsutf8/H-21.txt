Clasificación robusta de consultas raras utilizando el conocimiento web Andrei Broder, Marcus Fontoura, Evgeniy Gabrilovich, Amruta Joshi, Vanja Josifovski, Tong Zhang Yahoo! Research, 2821 Mission College Blvd, Santa Clara, CA 95054 {Broder |Marcusf |GABR |Amrutaj |VANJAJ |tzhang}@yahoo-inc.com Resumen Proponemos una metodología para construir un sistema de clasificación de consultas sólido práctico que pueda identificar miles de clases de consultas con precisión razonable, al tiempo que tratamos en tiempo real con el volumen de consultas de un motor de búsqueda web comercial. Utilizamos una técnica de retroalimentación ciega: dada una consulta, determinamos su tema clasificando los resultados de búsqueda web recuperados por la consulta. Motivado por las necesidades de la publicidad de búsqueda, nos centramos principalmente en consultas raras, que son los más difíciles desde el punto de vista del aprendizaje automático, pero en la agregación representan una fracción considerable del tráfico de motores de búsqueda. La evaluación empírica confirma que nuestra metodología produce una precisión de clasificación considerablemente mayor que la informada anteriormente. Creemos que la metodología propuesta conducirá a una mejor coincidencia de anuncios en línea con consultas raras y, en general, a una mejor experiencia de usuario. Categorías y descriptores de sujetos H.3.3 [Algorización y recuperación de información de información]: Búsqueda de información y recuperación de retroalimentación de relevancia, proceso de búsqueda de términos generales Algoritmos, medición, rendimiento, experimentación 1. Introducción En su vida útil de 12 años, Web Search había crecido enormemente: se ha convertido simultáneamente en un factor en la vida diaria de quizás mil millones de personas y al mismo tiempo una industria de ocho mil millones de dólares alimentada por la publicidad web. Una cosa, sin embargo, se ha mantenido constante: las personas usan consultas muy cortas. Varios estudios estiman la longitud promedio de una consulta de búsqueda entre 2.4 y 2.7 palabras, que, según todas las cuentas, pueden transportar solo una pequeña cantidad de información. Los motores de búsqueda comercial hacen un trabajo notablemente bueno al interpretar estas cuerdas cortas, pero no son (¡todavía!) Omniscient. Por lo tanto, el uso de un conocimiento externo adicional para aumentar las consultas puede contribuir en gran medida a mejorar los resultados de búsqueda y la experiencia del usuario. Al mismo tiempo, una mejor comprensión del significado de la consulta tiene el potencial de impulsar la base económica de la búsqueda web, a saber, la publicidad en línea, a través del mecanismo de búsqueda patrocinado que coloca anuncios relevantes junto con los resultados de búsqueda. Por ejemplo, saber que la consulta SD450 se trata de cámaras, mientras que NC4200 trata sobre las computadoras portátiles, obviamente, puede conducir a anuncios más enfocados, incluso si ningún anunciante ha presentado específicamente estas consultas particulares. En este estudio presentamos una metodología para la clasificación de consultas, donde nuestro objetivo es clasificar las consultas en una taxonomía comercial de consultas web con aproximadamente 6000 nodos. Dadas tales clasificaciones, uno puede usarlas directamente para proporcionar mejores resultados de búsqueda, así como anuncios más enfocados. El problema de la clasificación de consultas es extremadamente difícil debido a la brevedad de las consultas. Observe, sin embargo, que en muchos casos un humano que mira una consulta de búsqueda y los resultados de la consulta de búsqueda funcionan notablemente bien para darle sentido. Por supuesto, el gran volumen de consultas de búsqueda no se presta a la supervisión humana y, por lo tanto, necesitamos fuentes alternativas de conocimiento sobre el mundo. Por ejemplo, en el ejemplo anterior, SD450 trae páginas sobre las cámaras canónicas, mientras que NC4200 trae páginas sobre las computadoras portátiles de Compaq, por lo tanto, a un humano, la intención es bastante clara. Los motores de búsqueda indexan cantidades colosales de información, y como tales pueden verse como repositorios de conocimiento muy completos. Después de la heurística descrita anteriormente, proponemos utilizar los resultados de búsqueda en sí mismos para obtener ideas adicionales para la interpretación de la consulta. Con este fin, empleamos el paradigma de retroalimentación de pseudo relevancia y asumimos que los principales resultados de búsqueda son relevantes para la consulta. Ciertamente, no todos los resultados son igualmente relevantes y, por lo tanto, utilizamos esquemas de votación elaborados para obtener un conocimiento confiable sobre la consulta. Para el propósito de este estudio, primero enviamos la consulta dada a un motor de búsqueda web general y recopilamos una serie de las URL de mayor puntuación. Rastizamos las páginas web señaladas por estas URL y clasificamos estas páginas. Finalmente, utilizamos estas clasificaciones de la página de resultados para clasificar la consulta original. Nuestra evaluación empírica confirma que el uso de los resultados de búsqueda web de esta manera produce mejoras sustanciales en la precisión de la clasificación de consultas. Tenga en cuenta que en una implementación práctica de nuestra metodología dentro de un motor de búsqueda comercial, todas las páginas indexadas se pueden clasificar previamente utilizando la tubería normal de procesamiento e indexación de texto. Por lo tanto, en el tiempo de ejecución solo necesitamos ejecutar el procedimiento de votación, sin hacer ningún rastreo o clasificación. Esta sobrecarga adicional es mínima y, por lo tanto, el uso de resultados de búsqueda para mejorar la clasificación de consultas es completamente factible en tiempo de ejecución. Otro aspecto importante de nuestro trabajo radica en la elección de consultas. El volumen de consultas en los motores de búsqueda de hoy sigue la ley de poder familiar, donde algunas consultas aparecen muy a menudo, mientras que la mayoría de las consultas aparecen solo unas pocas veces. Si bien las consultas individuales en esta larga cola son raras, juntas representan una masa considerable de todas las búsquedas. Además, el volumen agregado de tales consultas proporciona una oportunidad sustancial para los ingresos a través de la publicidad en línea.1 Las plataformas de búsqueda y publicidad pueden estar capacitadas para obtener buenos resultados para consultas frecuentes, incluidos datos auxiliares como mapas, atajos a información estructurada relacionada, exitosaanuncios, y así sucesivamente. Sin embargo, las consultas de la cola simplemente no tienen suficientes ocurrencias para permitir el aprendizaje estadístico de manera por cuarta. Por lo tanto, necesitamos agregar tales consultas de alguna manera y razonar a nivel de grupos de consultas agregados. Una elección natural para dicha agregación es clasificar las consultas en una taxonomía tópica. Saber qué nodos de taxonomía son más relevantes para la consulta dada nos ayudará a proporcionar el mismo tipo de soporte para consultas raras que para consultas frecuentes. En consecuencia, en este trabajo nos centramos en la clasificación de consultas raras, cuya clasificación correcta es probable que sea particularmente beneficiosa. Los primeros estudios en la interpretación de la consulta se centraron en el aumento de consultas a través de diccionarios externos [22]. Estudios más recientes [18, 21] también intentaron reunir algunos conocimientos adicionales de la Web. Sin embargo, estos estudios tuvieron una serie de deficiencias, que superamos en este documento. Específicamente, los trabajos anteriores en el campo utilizaron taxonomías de clasificación de consultas muy pequeñas de solo unas pocas docenas de nodos, que no permiten una amplia especificidad para la publicidad en línea [11]. También utilizaron una taxonomía auxiliar separada para documentos web, de modo que se tuviera que emplear un nivel adicional de indirección para establecer la correspondencia entre las taxonomías auxiliares y principales [18]. Las principales contribuciones de este documento son las siguientes. Primero, construimos el clasificador de consulta directamente para la taxonomía objetivo, en lugar de usar una estructura auxiliar secundaria;Esto simplifica enormemente el mantenimiento y el desarrollo de la taxonomía. La taxonomía utilizada en este trabajo es dos órdenes de magnitud más grandes que la utilizada en estudios anteriores. La evaluación empírica demuestra que nuestra metodología para usar el conocimiento externo logra mayores mejoras que las reportadas anteriormente. Dado que nuestra taxonomía es considerablemente mayor, el problema de clasificación que enfrentamos es mucho más difícil, lo que hace que las mejoras que logramos sean particularmente notables. También informamos los resultados de un estudio empírico exhaustivo de diferentes esquemas de votación y diferentes profundidades de conocimiento (por ejemplo, utilizando resúmenes de búsqueda frente a páginas gastadas completas). Descubrimos que rastrear los resultados de búsqueda produce un conocimiento más profundo y conduce a mayores mejoras que los meros resúmenes. Este resultado contrasta con los hallazgos anteriores en la clasificación de consultas [20], pero está respaldado por la investigación en la clasificación de texto convencional [5].2. Metodología Nuestra metodología tiene dos fases principales. En la primera fase, 1 en los ejemplos anteriores, SD450 y NC4200 representan modelos de dispositivos bastante antiguos, y por lo tanto, hay anunciantes que colocan anuncios en estas consultas. Sin embargo, en este documento tratamos principalmente con consultas raras que son extremadamente difíciles de igualar con los anuncios relevantes.Construimos un clasificador de documentos para clasificar los resultados de búsqueda en la misma taxonomía en la que se clasificarán consultas. En la segunda fase, desarrollamos un clasificador de consulta que invoca el clasificador de documentos en los resultados de búsqueda, y utiliza este último para realizar la clasificación de consultas.2.1 Construcción del clasificador de documentos En este trabajo utilizamos una taxonomía de clasificación comercial de aproximadamente 6000 nodos utilizados en un importante motor de búsqueda de EE. UU. (Ver Sección 3.1). Los editores humanos poblaron los nodos de taxonomía con ejemplos etiquetados que utilizamos como instancias de capacitación para aprender un clasificador de documentos en la fase 1. Dada una taxonomía de este tamaño, la eficiencia computacional de la clasificación es un problema importante. Pocos algoritmos de aprendizaje automático pueden manejar de manera eficiente tantas clases diferentes, cada una con cientos de ejemplos de capacitación. Los candidatos adecuados incluyen el vecino más cercano y el clasificador Naive Bayes [3], así como los métodos de formación de prototipos como los clasificadores Rocchio [15] o basados en centroides [7]. Un estudio reciente [5] mostró que los clasificadores basados en centroides son efectivos y eficientes para las taxonomías a gran escala y, en consecuencia, utilizamos un clasificador centralide en este trabajo.2.2 Clasificación de consultas mediante la búsqueda Al haber desarrollado un clasificador de documentos para la taxonomía de la consulta, ahora recurrimos al problema de obtener una clasificación para una consulta dada basada en los resultados de búsqueda iniciales que produce. Supongamos que hay un conjunto de documentos d = d1...DM indexado por un motor de búsqueda. El motor de búsqueda se puede representar por una función f = similitud (q, d) que cuantifica la afinidad entre una consulta q y un documento d.Ejemplos de tales puntajes de afinidad utilizados en este documento son el rango: el rango del documento en la lista ordenada de resultados de búsqueda;puntaje estático: el puntaje de la bondad de la página, independientemente de la consulta (por ejemplo, PageRank);y puntaje dinámico: la cercanía de la consulta y el documento. La clasificación de consultas se determina mediante la evaluación primero de las probabilidades condicionales de todas las clases posibles P (CJ | Q), y luego seleccionando la alternativa con la mayor probabilidad Cmax = Arg Maxcj ∈C P (CJ | Q). Nuestro objetivo es estimar la probabilidad condicional de cada clase posible utilizando los resultados de búsqueda inicialmente devueltos por la consulta. Utilizamos la siguiente fórmula que incorpora clasificaciones de resultados de búsqueda individuales: P (CJ | Q) = D∈D P (CJ | Q, D) · P (D | Q) = D∈D P (Q | CJ, D) P (Q | D) · P (CJ | D) · P (D | Q). Suponemos que P (Q | CJ, D) ≈ P (Q | D), es decir, una probabilidad de una consulta dada un documento se puede determinar sin conocer la clase de la consulta. Este es el caso de la mayoría de las consultas que son inequívocas. Los ejemplos de mostrador son consultas como Jaguar (marca de animales y automóviles) o manzana (fabricante de frutas e informáticos), pero tales consultas ambiguas no pueden clasificarse por definición, y generalmente consiste en palabras comunes. En este trabajo nos concentramos en consultas raras, que tienden a contener palabras raras, ser más largas y coincidir con menos documentos;En consecuencia, en nuestro entorno, esta suposición se mantiene principalmente. Usando esta suposición, podemos escribir P (CJ | Q) = D∈D P (CJ | D) · P (D | Q). La probabilidad condicional de una clasificación para un documento P (CJ | D) se estima utilizando la salida del clasificador de documento (Sección 2.1). Si bien P (D | Q) es más difícil de calcular, consideramos el modelo de relevancia subyacente para clasificar documentos dados una consulta. Este problema se explora más a fondo en la siguiente sección.2.3 Modelo de relevancia basado en la clasificación Para describir una relación formal de clasificación y colocación de anuncios (o búsqueda), consideramos un modelo para usar la clasificación para determinar la relevancia de anuncios (o búsqueda). Que A sea un anuncio y Q sea una consulta, denotamos por r (a, q) la relevancia de a a q. Este número indica cuán relevante es el anuncio A para consultar q, y se puede usar para clasificar los anuncios A para una consulta dada q. En este artículo, consideramos la siguiente aproximación de la función de relevancia: R (A, Q) ≈ RC (A, Q) = CJ ∈C W (CJ) S (CJ, A) S (CJ, Q).(1) El lado derecho expresa cómo usamos el esquema de clasificación C para clasificar los anuncios, donde S (C, a) es una función de puntuación que especifica qué probable A está en la Clase C, y S (C, Q) es Afunción de puntuación que especifica qué probable es Q en la clase C.El valor W (c) es un término de ponderación para la categoría C, lo que indica la importancia de la categoría C en la fórmula de relevancia. Esta función de relevancia es una adaptación de las reglas de recuperación tradicionales basadas en palabras. Por ejemplo, podemos dejar que las categorías sean las palabras en el vocabulario. Tomamos S (CJ, a) como la palabra cuenta de CJ en A, S (CJ, Q) como la palabra cuenta de CJ en Q, y W (CJ) como el término IDF ponderación para la palabra CJ. Con tales opciones, el método dado por (1) se convierte en la regla de recuperación estándar de TFIDF. Si tomamos S (CJ, A) = P (CJ | A), S (CJ, Q) = P (CJ | Q) y W (CJ) = 1/P (CJ), y suponga que Q y Ase generan independientemente dado un concepto oculto C, entonces tenemos rc (a, q) = cj ∈C p (cj | a) p (cj | q)/p (cj) = cj ∈C p (cj | a) p (q| Cj)/p (q) = p (q | a)/p (q). Es decir, los anuncios se clasifican según P (Q | A). Este modelo de relevancia se ha empleado en varias técnicas de modelado de lenguaje estadístico para la recuperación de la información. La intuición se puede describir de la siguiente manera. Suponemos que una persona busca un anuncio A construyendo una consulta Q: La persona primero elige un concepto CJ de acuerdo con los pesos P (CJ | A), y luego construye una consulta Q con probabilidad P (Q | CJ) basada en elconcepto cj. Para este proceso de generación de consultas, los anuncios se pueden clasificar en función de la probabilidad de que se genere la consulta observada a partir de cada anuncio. Debe mencionarse que en nuestro caso, cada consulta y anuncio pueden tener múltiples categorías. Para simplificar, denotamos por CJ una variable aleatoria que indica si Q pertenece a la categoría CJ. Usamos P (CJ | Q) para denotar la probabilidad de Q perteneciente a la categoría CJ. Aquí la suma cj ∈C p (cj | q) puede no igual a uno. Luego consideramos la siguiente fórmula de clasificación: rc (a, q) = cj ∈C p (cj | a) p (cj | q).(2) Asumimos que la estimación de P (CJ | A) se basa en un sistema de categorización de texto existente (que se conoce). Por lo tanto, solo necesitamos obtener estimaciones de P (CJ | Q) para cada consulta q. La ecuación (2) es el modelo de relevancia AD que consideramos en este documento, con parámetros desconocidos P (CJ | Q) para cada consulta q. Para obtener sus estimaciones, utilizamos los resultados de búsqueda de los principales motores de búsqueda de EE. UU., Donde suponemos que la fórmula de clasificación en (2) ofrece una buena clasificación para la búsqueda. Es decir, los resultados principales clasificados por los motores de búsqueda también deben clasificarse altos por esta fórmula. Por lo tanto, dada una consulta Q, y las páginas de resultados K Top K D1 (Q) ,..., DK (Q) De un motor de búsqueda importante, ajustamos los parámetros P (CJ | Q) para que RC (DI (Q), Q) tenga puntajes altos para i = 1 ,..., K. Vale la pena mencionar que utilizando este método solo podemos calcular la fuerza relativa de P (CJ | Q), pero no la escala, porque la escala no afecta la clasificación. Además, es posible que los parámetros estimados puedan ser de la forma G (P (CJ | Q)) para alguna función monótona G (·) de la probabilidad realmente condicional G (P (CJ | Q)). Aunque esto puede cambiar el significado de los parámetros desconocidos que estimamos, no afecta la calidad del uso de la fórmula para clasificar los anuncios. Tampoco afecta la clasificación de consultas con umbrales elegidos adecuadamente. En lo que sigue, consideramos dos métodos para calcular la información de clasificación P (CJ | Q).2.4 El método de votación nos gustaría calcular P (CJ | Q) para que RC (DI (Q), Q) sean altos para i = 1 ,..., K y RC (D, Q) son bajos para un documento aleatorio d.Suponga que el vector [P (CJ | D)] CJ ∈C es aleatorio para un documento promedio, entonces la condición de que CJ ∈C P (CJ | Q) 2 es pequeño implica que RC (D, Q) también es pequeño promediadod.Por lo tanto, un método natural es maximizar k i = 1 wirc (di (q), q) sujeto a cj ∈C p (cj | q) 2 es pequeño, donde wi son pesos asociados con cada rango I: max [p (·| q)]   1 k k i = 1 wi cj ∈C p (cj | di (q)) p (cj | q) - λ cj ∈C p (cj | q) 2 , donde asumimos k i = 1Wi = 1, y λ> 0 es un parámetro de regularización de ajuste. La solución óptima es p (cj | q) = 1 2λ k i = 1 wip (cj | di (q)). Dado que tanto p (cj | di (q)) como p (cj | q) pertenecen a [0, 1], podemos tomar λ = 0.5 para alinear la escala. En el experimento, simplemente tomaremos pesos uniformes WI. Una estrategia más compleja es dejar que W también dependa de D: P (CJ | Q) = D W (D, Q) G (P (CJ | D)), donde G (x) es una cierta transformación de x. En esta formulación general, W (D, Q) puede depender de factores distintos del rango de D en los resultados del motor de búsqueda para q. Por ejemplo, puede ser una función de R (D, Q) donde R (D, Q) es el puntaje de relevancia devuelto por el motor de búsqueda subyacente. Además, si se nos da un conjunto de pares de categoría/consulta de entrenamiento marcado a mano (C, Q), tanto los pesos W (D, Q) como la transformación G (·) se pueden aprender utilizando técnicas de clasificación estándar.2.5 Clasificación discriminativa Podemos tratar el problema de estimar P (CJ | Q) como un problema de clasificación, donde para cada Q, etiquetamos Di (Q) para i = 1 ,..., K como datos positivos, y los documentos restantes como datos negativos. Es decir, asignamos la etiqueta yi (q) = 1 para di (q) cuando i ≤ k, y etiqueta yi (q) = −1 para di (q) cuando i> k. en esta configuración, la regla de puntuación de clasificación paraUn documento di (q) es lineal. Sea xi (q) = [p (cj | di (q))], y w = [p (cj | q)], luego cj ∈C p (cj | q) p (cj | di (q)) = w· Xi (Q). Los valores P (CJ | D) son las características para el clasificador lineal, y [P (CJ | D)] es el vector de peso, que se puede calcular utilizando cualquier método de clasificación lineal. En este artículo, consideramos estimar W usando regresión logística [17] de la siguiente manera: P (· | Q) = arg minw i ln (1 + e - w · xi (q) yi (q))).0 200 400 600 800 1000 1200 1400 1600 1800 2000 0 1 2 3 4 5 6 7 8 9 10 NumberOfcategories Taxonomy Nivel Figura 1: Número de categorías por nivel 3. Evaluación En esta sección, evaluamos nuestra metodología que utiliza resultados de búsqueda web para mejorar la clasificación de consultas.3.1 Taxonomía Nuestra elección de taxonomía fue guiada por una aplicación de publicidad web. Dado que queremos que las clases sean útiles para hacer coincidir anuncios con consultas, la taxonomía debe ser lo suficientemente elaborada como para facilitar una amplia especificidad de clasificación. Por ejemplo, clasificar todas las consultas médicas en un nodo probablemente dará como resultado una mala coincidencia de anuncios, ya que tanto las consultas doloridas como las de gripe terminarán en el mismo nodo. Sin embargo, los anuncios apropiados para estas dos consultas son muy diferentes. Para evitar tales situaciones, la taxonomía debe proporcionar una discriminación suficiente entre los temas comerciales comunes. Por lo tanto, en este documento empleamos una taxonomía elaborada de aproximadamente 6000 nodos, dispuestos en una jerarquía con profundidad media 5 y profundidad máxima 9. La Figura 1 muestra la distribución de categorías por niveles de taxonomía. Los editores humanos poblaron la taxonomía con consultas etiquetadas (aproximadamente 150 consultas por nodo), que se utilizaron como un conjunto de capacitación;Se ha asignado una pequeña fracción de consultas a más de una categoría.3.2 Digresión: los conceptos básicos de la búsqueda patrocinada para discutir nuestro conjunto de consultas de evaluación, necesitamos una breve introducción a algunos conceptos básicos de publicidad web. La publicidad patrocinada de búsqueda (o búsqueda pagada) está colocando anuncios textuales en las páginas de resultados de los motores de búsqueda web, con anuncios impulsados por la consulta de origen. Todos los principales motores de búsqueda (Google, Yahoo!, Y MSN) admiten tales anuncios y actúan simultáneamente como un motor de búsqueda y una agencia de publicidad. Estos anuncios textuales se caracterizan por una o más frases de oferta que representan esas consultas donde los anunciantes desean que se muestre su anuncio.(La frase de oferta de nombre proviene del hecho de que los anunciantes ofrecen varias cantidades para asegurar su posición en la torre de anuncios asociados a una consulta. Una discusión sobre los mecanismos de licitación y colocación está más allá del alcance de este documento [13]. Sin embargo, muchas búsquedas no utilizan explícitamente frases en las que alguien ofrece. En consecuencia, los anunciantes también compran coincidencias amplias, es decir, pagan para colocar sus anuncios en consultas que constituyen alguna modificación de la frase de oferta deseada. En Broad Match, se pueden aplicar varias modificaciones sintácticas a la consulta para que coincida con la frase de oferta, por ejemplo, que cae o agregue palabras, sustitución de sinónimos, etc. Estas transformaciones se basan en reglas y diccionarios. A medida que los anunciantes tienden a cubrir consultas de alto volumen y de alto ingreso, las consultas de amplio partido caen en la cola de la distribución con respecto tanto al volumen como a los ingresos.3.3 Conjuntos de datos utilizamos dos conjuntos representativos de 1000 consultas. Ambos conjuntos contienen consultas que no se pueden igualar directamente con los anuncios, es decir, ninguna de las consultas contiene una frase de oferta (esto significa que eliminamos prácticamente todas las consultas populares). El primer conjunto de consultas se puede coincidir con al menos un anuncio usando una coincidencia amplia como se describió anteriormente. Las consultas en el segundo set no pueden coincidir incluso con una coincidencia amplia y, por lo tanto, el motor de búsqueda utilizado en nuestro estudio actualmente no muestra ninguna publicidad para ellos. En cierto sentido, estas son consultas aún más raras y más lejos de consultas comunes. Como medida de rareza de consulta, estimamos su frecuencia en un mes de registros de consultas para un importante motor de búsqueda de EE. UU.;La frecuencia media fue 1 para consultas en el conjunto 1 y 0 para consultas en el conjunto 2. Las consultas en los dos conjuntos difieren en su dificultad de clasificación. De hecho, las consultas en el Set 2 son difíciles de interpretar incluso para los evaluadores humanos. Las consultas en el conjunto 1 tienen en promedio 3.50 palabras, con la más larga que tiene 11 palabras;Las consultas en el conjunto 2 tienen en promedio 4.39 palabras, con la consulta más larga de 81 palabras. Estudios recientes estiman que la duración promedio de las consultas web es de poco menos de 3 palabras2, que es más baja que en nuestros conjuntos de pruebas. Como otra medida de dificultad de consulta, medimos la fracción de consultas que contienen comillas, ya que esta última ayuda a la interpretación de la consulta al agrupar significativamente las palabras. Solo el 8% consultas en el conjunto 1 y 14% en el conjunto 2 contenían comillas.3.4 Metodología y métricas de evaluación Los dos conjuntos de consultas se clasificaron en la taxonomía objetivo utilizando las técnicas presentadas en la Sección 2. Según los valores de confianza asignados, las 3 clases principales para cada consulta se presentaron a los evaluadores humanos. Estos evaluadores fueron personal editorial capacitado que poseía conocimiento sobre la taxonomía. Los editores consideraron todos los pares de consulta y los calificaron en la escala 1 a 4, con 1, lo que significa que la clasificación es muy relevante y 4 significa que es irrelevante para la consulta. Alrededor de 2.4% consultas en el conjunto 1 y 5.4% consultas en el conjunto 2 se consideraron que no era clasificable (por ejemplo, cadenas aleatorias de caracteres), y en consecuencia se excluyeron de la evaluación. Para calcular las métricas de evaluación, tratamos las clasificaciones con las calificaciones 1 y 2 para ser correctas, y aquellos con calificaciones 3 y 4 para ser incorrectas. Utilizamos métricas de evaluación estándar: precisión, recuperación y F1. En lo que sigue, trazamos gráficos de precisión de precisión para todos los experimentos. Para comparación con otros estudios publicados, también informamos valores de precisión y F1 correspondientes al recuerdo completo (r = 1). Debido a la falta de espacio, solo mostramos gráficos para el conjunto de consultas 1;Sin embargo, mostramos los resultados numéricos para ambos conjuntos en las tablas.3.5 Resultados Comparamos nuestro método con un clasificador de consulta de referencia que no utiliza ningún conocimiento externo. Nuestro clasificador de línea de base amplió consultas utilizando técnicas de expansión de consultas estándar, agrupó sus términos utilizando un reconocimiento de frases, aumentó ciertas frases en la consulta en función de sus propiedades estadísticas y realizó clasificación utilizando los 2 http://www.rankstat.com/html/en/Seo-News1-Mother-Peopleuse-2-Word-Phrases-In-Search-Engines.html 0.4 0.5 0.6 0.7 0.7 0.8 0.9 1 1.00.90.80.70.60.50.40.30.20.1 Motor de base de recuperación de precisión Un motor de página completa A A un motor de página completa A A A un motor A de página completa.Resumen Motor B Motor de página completa B Resumen Figura 2: El efecto del conocimiento externo más cercano-vecino. Este clasificador de línea de base es en realidad una versión de producción del clasificador de consultas que se ejecuta en un importante motor de búsqueda de EE. UU. En nuestros experimentos, variamos valores de parámetros pertinentes que caracterizan la forma exacta de usar los resultados de búsqueda. En lo que sigue, comenzamos con la evaluación general del efecto del uso de resultados de búsqueda web. Luego procedemos a explorar técnicas más refinadas, como usar solo resúmenes de búsqueda en lugar de rastrear las URL devueltas. También experimentamos con el uso de diferentes números de resultados de búsqueda por consulta, así como con variando el número de clasificaciones consideradas para cada resultado de la búsqueda. Por falta de espacio, solo mostramos gráficos para consultas del conjunto 1 y omitimos los gráficos para consultas del conjunto 2, que exhiben fenómenos similares.3.5.1 El efecto de las consultas de conocimiento externo por sí mismas es muy corto y difícil de clasificar. Utilizamos los mejores resultados de los motores de búsqueda para recopilar conocimiento de fondo para consultas. Empleamos dos principales motores de búsqueda de EE. UU., Y utilizamos sus resultados de dos maneras, ya sea solo resúmenes o el texto completo de las páginas de resultados rastreados. La Figura 2 y la Tabla 1 muestran que dicho conocimiento adicional mejora considerablemente la precisión de la clasificación. Curiosamente, descubrimos que el motor de búsqueda A funciona constantemente mejor con el texto de la página completa, mientras que el motor de búsqueda B funciona mejor cuando se utilizan resúmenes. Contexto del motor prec. F1 prec. F1 establecido 1 conjunto 1 conjunto 2 conjunto 2 una página completa 0.72 0.84 0.509 0.721 b Página completa 0.706 0.827 0.497 0.665 un resumen 0.586 0.744 0.396 0.572 b Resumen 0.645 0.788 0.467 0.638 base 0.534 0.696 0.365 0.536 Tabla 1: el efecto de la tasa 1: el efecto de usar el efecto externo de la línea de base de usar 0.534 0.365 0.536.Conocimiento 3.5.2 Técnicas de agregación Hay dos formas principales de utilizar los resultados de búsqueda como conocimiento adicional. Primero, los resultados individuales se pueden clasificar por separado, con la votación posterior entre clasificaciones individuales. Alternativamente, los resultados de búsqueda individuales se pueden agrupar como un metadocumento y clasificarse como tal utilizando el clasificador de documento. La Figura 3 presenta los resultados de estos dos enfoques cuando se utilizan páginas de texto completo, la técnica que utiliza clasificaciones individuales de resultados de búsqueda, evidentemente, supera el enfoque de agrupación por un amplio margen. Sin embargo, en el caso de los resúmenes, se encuentra que agruparse es consistentemente mejor que la clasificación individual. Esto se debe a que los resúmenes por sí mismos son demasiado cortos para clasificarse correctamente individualmente, pero cuando se agrupan, son mucho más estables.0.4 0.5 0.6 0.7 0.8 0.9 1 1.00.90.80.70.60.50.40.30.20.1 Recuerdos de precisión Línea de base Bundled Votación de página completa Página completa Resumen de votación Bundled Votación Resumen 3: Votación versus Bundling 3.5.3 Texto de página completa Vs. Resumen a Summary toResumir las dos secciones anteriores, el conocimiento de los antecedentes para cada consulta se obtiene utilizando el texto de la página completa o solo los resúmenes de los resultados de búsqueda principales. Se encontró que el texto de la página completa era más en conjunto con la clasificación votada, mientras que los resúmenes eran útiles cuando se agruparon juntos. Los mejores resultados en general se obtuvieron con resultados de página completa clasificadas individualmente, con la votación posterior utilizada para determinar la clasificación final de consulta. Esta observación difiere de los hallazgos de Shen et al.[20], quien encontró que los resúmenes son más útiles. Atribuimos esta distinción al hecho de que las consultas que utilizamos en este estudio son las colas, que son raras y difíciles de clasificar.3.5.4 Variando el número de clases por resultado de búsqueda también variamos el número de clasificaciones por resultado de la búsqueda, es decir, cada resultado se permitió tener clases 1, 3 o 5. La Figura 4 muestra los gráficos de recuperación de precisión correspondientes tanto para la página completa como para la configuración de solo suma. Como se puede ver fácilmente, las tres variantes producen resultados muy similares. Sin embargo, la curva de recuperación de precisión para el experimento de 1 clase tiene fluctuaciones más altas. El uso de 3 clases por resultado de búsqueda produce una curva más estable, mientras que con 5 clases por resultado, la curva de recolección de precisión es muy suave. Por lo tanto, a medida que aumentamos el número de clases por resultado, observamos una mayor estabilidad en la clasificación de consultas.3.5.5 Variando el número de resultados de búsqueda obtenidos también experimentamos con diferentes números de resultados de búsqueda por consulta. La Figura 5 y la Tabla 2 presentan los resultados de este experimento. En línea con nuestra intuición, observamos que la precisión de clasificación aumenta constantemente a medida que aumentamos el número de resultados de búsqueda utilizados de 10 a 40, con una ligera caída a medida que continuamos utilizando aún más resultados (50). Esto se debe a que el uso de muy pocos resultados de búsqueda proporciona muy poco conocimiento externo, mientras que el uso de demasiados resultados introduce ruido adicional. Usando la prueba t emparejada, evaluamos la significación estadística 0.4 0.5 0.6 0.7 0.8 0.9 1 1.00.90.80.70.60.50.40.30.20.1 Recuerda de precisión Línea base 1 Clase de clase completa 3 Clases Full Page 5 Clases Full-Page 1 Class Summary de clase 1 Class Summary3 Clases Resumen 5 Clases Resumen Figura 4: Variando el número de clases por página 0.4 0.5 0.6 0.7 0.8 0.9 1 1.00.90.80.70.60.50.40.30.20.1 RECUERDO DE PRECISIÓN 10 20 30 40 50 Base Figura 5: Varicando el número de resultados de resultados.por consulta de las mejoras debido a nuestra metodología versus la línea de base. Encontramos que los resultados son muy significativos (p <0.0005), confirmando así el valor del conocimiento externo para la clasificación de consultas.3.6 Votación versus métodos alternativos Como se explica en la Sección 2.2, uno puede usar varios métodos para clasificar las consultas de los resultados del motor de búsqueda en función de nuestro modelo de relevancia. Como hemos visto, el método de votación funciona bastante bien. En esta sección, comparamos el rendimiento de los resultados de búsqueda de los diez mejores con los siguientes dos métodos: • A: Aprendizaje discriminativo de la clasificación de consulta basada en la regresión logística, descrita en la Sección 2.5.• B: Pesos de aprendizaje basados en la puntuación de calidad devuelta por un motor de búsqueda. Discretizamos el puntaje de calidad S (D, Q) de un par de consultas/documentos en {alto, mediano, bajo}, y aprendemos los tres pesos W en un conjunto de consultas de entrenamiento y probamos las consultas de rendimiento en retención. La fórmula de clasificación, como se explica al final de la Sección 2.4, es P (CJ | Q) = D W (S (D, Q)) P (CJ | D). El método B requiere una división de entrenamiento/prueba. Ni la votación ni el método A requieren tal división;Sin embargo, para consistencia, dibujamos aleatoriamente las divisiones de entrenamiento/prueba de 50-50 durante diez veces e informamos el rendimiento medio ± desviación estándar en la división de prueba para los tres métodos. Para este experimento, en lugar de precisión y retiro, utilizamos DCG-K (k = 1, 5), popular en la evaluación del motor de búsqueda. La métrica DCG (ganancia acumulada con descuento), descrita en [8], es una medida de clasificación donde se le pide al sistema que clasifique un conjunto de candidatos (en número de resultados de precisión F1 0.534 0.696 10 0.706 0.827 20 0.751 0.857 30 0.796 0.886 400.807 0.893 50 0.798 0.887 Tabla 2: variando el número de resultados de búsqueda en nuestro caso, categorías juzgadas para cada consulta) y calcula para cada consulta Q: DCGK (Q) = K i = 1 g (CI (Q))/ Log2 (I+ 1), donde CI (Q) es la categoría I-Th para la consulta Q clasificada por el sistema, y G (CI) es el grado de CI: asignamos el grado de 10, 5, 1, 0 al 4 puntosEscala de juicio descrita anteriormente para calcular DCG. La elección en descomposición de LOG2 (i + 1) es convencional, que no tiene particular importancia. El DCG general de un sistema es el DCG promedio sobre consultas. Utilizamos esta métrica en lugar de precisión/retiro en este experimento porque puede manejar directamente la salida de múltiples accesorios. Por lo tanto, como una sola métrica, es conveniente para comparar los métodos. Tenga en cuenta que las curvas de precisión/retiro utilizadas en las secciones anteriores producen algunas ideas adicionales que no son aparentes inmediatamente de los números de DCG. Conjunto 1 Método DCG-1 DCG-5 Oracle 7.58 ± 0.19 14.52 ± 0.40 Votación 5.28 ± 0.15 11.80 ± 0.31 Método A 5.48 ± 0.16 12.22 ± 0.34 Método B 5.36 ± 0.18 12.15 ± 0.35 Conjunto 2 Método DCG-1 DCG-5 ORACREG.± 0.18 9.94 ± 0.32 Votación 3.50 ± 0.17 7.80 ± 0.28 Método A 3.63 ± 0.23 8.11 ± 0.33 Método B 3.55 ± 0.18 7.99 ± 0.31 Tabla 3: Votación y métodos alternativos Los resultados de nuestros experimentos se dan en la Tabla 3. El método Oracle es la mejor clasificación de categorías para cada consulta después de ver juicios humanos. No se puede lograr mediante ningún algoritmo realista, pero se incluye aquí como un límite superior absoluto en el rendimiento de DCG. El método de votación simple funciona muy bien en nuestros experimentos. Los métodos más complicados pueden conducir a una ganancia de rendimiento moderada (especialmente el método A, que utiliza capacitación discriminativa en la Sección 2.5). Sin embargo, ambos métodos son computacionalmente más costosos, y la ganancia potencial es lo suficientemente menor como para ser descuidado. Esto significa que, como método simple, la votación es bastante efectiva. Podemos observar que el método B, que utiliza la puntuación de calidad devuelta por un motor de búsqueda para ajustar los pesos de importancia de las páginas devueltas para una consulta, no produce una mejora apreciable. Esto implica que poner en el mismo peso (votación) funciona de manera similar, ya que poner pesos más altos a documentos de mayor calidad y pesos más bajos a documentos de calidad más bajos (Método B), al menos para los resultados de búsqueda principales. Puede ser posible mejorar este método al incluir otras características de página que pueden diferenciar los resultados de búsqueda de mejor clasificación. Sin embargo, la efectividad requerirá una mayor investigación que no probamos. También podemos observar que el rendimiento en el conjunto 2 es más bajo que el del conjunto 1, lo que significa que las consultas en el conjunto 2 son más difíciles que las del conjunto 1. 3.7 Análisis de falla, examinamos los casos cuando el conocimiento externo no mejoró la clasificación de consultas e identificamosTres causas principales de tal falta de mejora.(1) Consultas que contienen cadenas aleatorias, como los números de teléfono: estas consultas no producen resultados de búsqueda coherentes, por lo que estas últimas no pueden ayudar a la clasificación (alrededor del 5% de las consultas fueron de este tipo).(2) consultas que no producen resultados de búsqueda en absoluto;Hubo un 8% de tales consultas en el conjunto 1 y 15% en el conjunto 2. (3) consultas correspondientes a eventos recientes, para las cuales el motor de búsqueda aún no tenía una amplia cobertura (alrededor del 5% de las consultas). Un ejemplo notable de tales consultas son los nombres completos de artículos de noticias, si el artículo exacto aún no ha sido indexado por el motor de búsqueda, es probable que los resultados de búsqueda sean de poca utilidad.4. Trabajo relacionado a pesar de que la duración promedio de las consultas de búsqueda aumenta constantemente con el tiempo, una consulta típica sigue siendo más corta que 3 palabras. En consecuencia, muchos investigadores estudiaron posibles formas de mejorar las consultas con información adicional. Una dirección importante para mejorar las consultas es a través de la expansión de la consulta. Esto se puede hacer utilizando diccionarios electrónicos y tesauros [22], o mediante técnicas de retroalimentación de relevancia que utilizan algunos resultados de búsqueda de alta puntuación. El trabajo temprano en la recuperación de la información se concentró en revisar manualmente los resultados devueltos [16, 15]. Sin embargo, el gran volumen de consultas hoy en día no se presta a la supervisión manual y, por lo tanto, los trabajos posteriores se centran en la retroalimentación de relevancia ciega, que básicamente asume que los resultados devueltos son relevantes [23, 12, 4, 14]. Más recientemente, los estudios en el aumento de consultas se centraron en la clasificación de consultas, suponiendo que tales clasificaciones sean beneficiosas para una interpretación de consultas más enfocada. De hecho, Kowalczyk et al.[10] encontraron que el uso de clases de consulta mejoró el rendimiento de la recuperación de documentos. Los estudios en el campo persiguen diferentes enfoques para obtener información adicional sobre las consultas. Beitzel et al.[1] utilizó el aprendizaje semi-supervisado, así como datos no etiquetados [2]. Gravano et al.[6] Consultas clasificadas con respecto a la localidad geográfica para determinar si su intención es local o global. La Copa KDD 2005 en la clasificación de consultas web inspiró otra línea de investigación, que se centró en enriquecer consultas utilizando motores y directorios de búsqueda web [11, 18, 20, 9, 21]. La especificación de la tarea KDD proporcionó una pequeña taxonomía (67 nodos) junto con un conjunto de consultas etiquetadas, y planteó un desafío para usar estos datos de capacitación para construir un clasificador de consulta. Varios equipos utilizaron la web para enriquecer las consultas y proporcionar más contexto para la clasificación. Las principales preguntas de investigación de este enfoque son (1) cómo construir un clasificador de documentos, (2) cómo traducir sus clasificaciones en la taxonomía objetivo y (3) cómo determinar la clase de consulta basada en clasificaciones de documentos. La solución ganadora de la Copa KDD [18] propuso usar un conjunto de clasificadores junto con la búsqueda de múltiples motores de búsqueda. Para abordar el problema (1) anterior, su solución utilizó el Proyecto Open Directory (ODP) para producir un clasificador de documentos basado en ODP. La jerarquía ODP se asignó a la taxonomía objetivo utilizando coincidencias de palabras en nodos individuales. Se creó un clasificador de documentos para la taxonomía objetivo utilizando las páginas en la taxonomía de ODP que aparecen en los nodos asignados al nodo objetivo particular. Por lo tanto, los documentos web se clasificaron primero con respecto a la jerarquía de ODP, y sus clasificaciones se asignaron posteriormente a la taxonomía objetivo para la clasificación de consultas. En comparación con este enfoque, resolvimos el problema de la clasificación de documentos directamente en la taxonomía objetivo mediante el uso de las consultas para producir el clasificador de documentos como se describe en la Sección 2. Esto simplifica el proceso y elimina la necesidad de mapeo entre taxonomías. Esto también optimiza el mantenimiento y el desarrollo de la taxonomía. Usando este enfoque, pudimos lograr un buen rendimiento en una taxonomía a gran escala. También evaluamos algunas alternativas sobre cómo combinar clasificaciones de documentos individuales al clasificar la consulta. En un artículo de seguimiento [19], Shen et al.propuso un marco para la clasificación de consultas basado en puentes entre dos taxonomías. En este enfoque, el problema de no tener un clasificador de documentos para resultados web se resuelve mediante el uso de un conjunto de capacitación disponible para documentos con una taxonomía diferente. Para esto, se utiliza una taxonomía intermedia con un conjunto de capacitación (ODP). Luego se juzgan varios esquemas que establecen una correspondencia entre las taxonomías o permiten el mapeo del conjunto de capacitación desde la taxonomía intermedia hasta la taxonomía objetivo. A diferencia de esto, creamos un clasificador de documentos para la taxonomía objetivo directamente, sin usar documentos de una taxonomía intermedia. Si bien no pudimos comparar directamente los resultados debido al uso de diferentes taxonomías (utilizamos una taxonomía mucho mayor), nuestros resultados de precisión y recuerdo son consistentemente más altos incluso sobre el conjunto de consultas más difícil.5. Conclusiones La clasificación de consultas es una tarea importante de recuperación de información. Es probable que la clasificación precisa de las consultas de búsqueda beneficie una serie de tareas de nivel superior, como la búsqueda en la web y la coincidencia de anuncios. Dado que las consultas de búsqueda suelen ser cortas, por sí mismas generalmente llevan información insuficiente para una precisión de clasificación adecuada. Para abordar este problema, propusimos una metodología para usar los resultados de búsqueda como fuente de conocimiento externo. Con este fin, enviamos la consulta a un motor de búsqueda y asumimos que una pluralidad de los resultados de búsqueda de alquileres son relevantes para la consulta. La clasificación de estos resultados nos permite clasificar la consulta original con una precisión sustancialmente mayor. Los resultados de nuestra evaluación empírica confirmaron definitivamente que el uso de la Web como un repositorio del conocimiento mundial contribuye con información valiosa sobre la consulta y ayuda en su clasificación correcta. En particular, nuestro método exhibe una precisión significativamente mayor que los métodos descritos en estudios anteriores3 en comparación con estudios anteriores, nuestro enfoque no requiere ninguna taxonomía auxiliar, y producimos un clasificador de consulta directamente para la taxonomía objetivo. Además, la taxonomía utilizada en este estudio es aproximadamente 2 órdenes de magnitud más grandes que la utilizada en trabajos anteriores. También experimentamos con diferentes valores de parámetros que caracterizan nuestro método. Al usar los resultados de búsqueda, uno puede usar solo resúmenes de los resultados proporcionados por 3 ya que el campo de la clasificación de consultas aún no ha establecido y acordado con puntos de referencia, la comparación directa de los resultados es ciertamente complicado.El motor de búsqueda, o realmente rastreó las páginas de resultados para obtener un conocimiento aún más profundo. En general, el rendimiento de la clasificación de consultas fue el mejor cuando se usa las páginas gastadas completas (Tabla 1). Estos resultados son consistentes con estudios previos [5], que encontraron que el uso de páginas gastadas completas es superior para la clasificación de documentos que el uso solo de resúmenes breves. Nuestros hallazgos, sin embargo, son diferentes de los reportados por Shen et al.[19], quien encontró resúmenes para producir mejores resultados. Atribuimos nuestras observaciones al uso de un esquema de votación más elaborado entre las clasificaciones de los resultados de búsqueda individuales, así como al uso de un conjunto más difícil de consultas raras. En este estudio utilizamos dos principales motores de búsqueda, A y B. Curiosamente, encontramos distinciones notables en la calidad de su producción. En particular, para el motor A, los resultados generales fueron mejores cuando se usan las páginas gastadas completas de los resultados de búsqueda, mientras que para el motor B parece ser más beneficioso utilizar los resúmenes de los resultados. Esto implica que si bien la calidad de los resultados de búsqueda devueltos por el motor A es aparentemente mejor, el motor B hace un mejor trabajo para resumir las páginas. También descubrimos que los mejores resultados se obtuvieron mediante el uso de páginas gastadas completas y realizando votación entre sus clasificaciones individuales. Para un clasificador externo al motor de búsqueda, recuperar páginas completas puede ser prohibitivamente costoso, en cuyo caso uno podría preferir usar resúmenes para obtener eficiencia computacional. Por otro lado, para los propietarios de un motor de búsqueda, la clasificación completa de la página es mucho más eficiente, ya que es fácil preprocesar todas las páginas indexadas clasificándolas una vez en la taxonomía (fija). Luego, las clasificaciones de la página se obtienen como parte de los metadatos asociados con cada resultado de la búsqueda, y la clasificación de consultas puede ser casi instantánea. Al usar resúmenes, parece que se obtienen mejores resultados concatenando primero los resúmenes individuales en un meta-documento, y luego utilizando su clasificación en su conjunto. Creemos que la razón de esta observación es que los resúmenes son cortos e inherentemente más ruidosos, y por lo tanto, su agregación ayuda a identificar correctamente el tema principal. De acuerdo con nuestra intuición, el uso de muy pocos resultados de búsqueda produce un conocimiento útil pero insuficiente, y el uso de demasiados resultados de búsqueda conduce a la inclusión de páginas web marginalmente relevantes. Los mejores resultados se obtuvieron al usar 40 golpes de búsqueda superiores. En este trabajo, primero clasificamos los resultados de búsqueda y luego usamos sus clasificaciones directamente para clasificar la consulta original. Alternativamente, uno puede usar las clasificaciones de los resultados de búsqueda como características para aprender un clasificador de segundo nivel. En la Sección 3.6, hicimos algunos experimentos preliminares en esta dirección, y descubrimos que aprender tal clasificador secundario no produjo ventajas considerablemente. Planeamos investigar más a fondo esta dirección en nuestro trabajo futuro. También es esencial tener en cuenta que la implementación de nuestra metodología incurre en poca sobrecarga. Si el motor de búsqueda clasifica las páginas rastreadas durante la indexación, entonces en la hora de consulta solo necesitamos obtener estas clasificaciones y hacer la votación. Para concluir, creemos que nuestra metodología para el uso de resultados de búsqueda web tiene una promesa considerable para mejorar sustancialmente la precisión de las consultas de búsqueda web. Esto es particularmente importante para las consultas raras, para la cual se puede hacer poco aprendizaje de perQrey, y en este estudio demostramos que tal escasez de información podría abordarse aprovechando el conocimiento encontrado en la Web. Creemos que nuestros hallazgos tendrán aplicaciones inmediatas para mejorar el manejo de consultas raras, tanto para mejorar los resultados de búsqueda como para producir anuncios mejor coincidentes. En nuestra investigación adicional, también planeamos utilizar la información de la sesión para aprovechar el conocimiento sobre consultas anteriores para clasificar mejor las posteriores.6. Referencias [1] S. Beitzel, E. Jensen, O. Frieder, D. Grossman, D. Lewis, A. Chowdhury y A. Kolcz. Clasificación automática de consultas web utilizando datos de capacitación etiquetados y no etiquetados. En Actas de Sigir05, 2005. [2] S. Beitzel, E. Jensen, O. Frieder, D. Lewis, A. Chowdhury y A. Kolcz. Mejora de la clasificación automática de consultas a través del aprendizaje semi-supervisado. En Actas de ICDM05, 2005. [3] R. Duda y P. Hart. Clasificación de patrones y análisis de la escena. John Wiley and Sons, 1973. [4] E. Efthimiadis y P. Biron. UCLA-OKAPI en TREC-2: Experimentos de expansión de consultas. En TREC-2, 1994. [5] E. Gabrilovich y S. Markovitch. Generación de características para la categorización de texto utilizando el conocimiento mundial. En IJCAI05, páginas 1048-1053, 2005. [6] L. Gravano, V. Hatzivassiloglou y R. Lichtenstein. Categorizar consultas web de acuerdo con la localidad geográfica. En CIKM03, 2003. [7] E. Han y G. Karypis. Clasificación de documentos basada en centroides: análisis y resultados experimentales. En PKDD00, septiembre de 2000. [8] K. Jarvelin y J. Kekalainen. IR Métodos de evaluación para recuperar documentos altamente relevantes. En Sigir00, 2000. [9] Z. Kardkovacs, D. Tikk y Z. Bansaghi. El algoritmo de ferretía para el problema de la Copa KDD 2005. En Sigkdd Explorations, Volumen 7. ACM, 2005. [10] P. Kowalczyk, I. Zukerman y M. Niemann. Analizar el efecto de la clase de consulta en el rendimiento de la recuperación de documentos. En Proc. Conf. Australiano.en AI, páginas 550-561, 2004. [11] Y. Li, Z. Zheng y H. Dai. Informe KDD CUP-2005: enfrentar un gran desafío. En Sigkdd Explorations, Volumen 7, páginas 91-99. ACM, diciembre de 2005. [12] M. Mitra, A. Singhal y C. Buckley. Mejora de la expansión automática de consultas. En Sigir98, páginas 206-214, 1998. [13] M. Moran y B. Caza. Search Engine Marketing, Inc.: Conducir el tráfico de búsqueda al sitio web de su empresa. Prentice Hall, Upper Saddle River, NJ, 2005. [14] S. Robertson, S. Walker, S. Jones, M. Hancock-Beaulieu y M. Gatford. Okapi en TREC-3. En Trec-3, 1995. [15] J. Rocchio. Comentarios de relevancia en la recuperación de información. En el sistema de recuperación inteligente: experimentos en el procesamiento automático de documentos, páginas 313-323. Prentice Hall, 1971. [16] G. Salton y C. Buckley. Mejora del rendimiento de la recuperación por retroalimentación relevante. Jasis, 41 (4): 288-297, 1990. [17] T. Santner y D. Duffy. El análisis estadístico de datos discretos. Springer-Verlag, 1989. [18] D. Shen, R. Pan, J. Sun, J. Pan, K. Wu, J. Yin y Q. Yang. Q2C@UST: Nuestra clasificación de solución ganadora para consultar en KDDCUP 2005. En Sigkdd Explorations, Volumen 7, páginas 100-110. ACM, 2005. [19] D. Shen, R. Pan, J. Sun, J. Pan, K. Wu, J. Yin y Q. Yang. Enriquecimiento de consulta para la clasificación de cuidias web. ACM TOIS, 24: 320-352, julio de 2006. [20] D. Shen, J. Sun, Q. Yang y Z. Chen. Construyendo puentes para la clasificación de consultas web. En Sigir06, páginas 131-138, 2006. [21] D. Vogel, S. Bickel, P. Haider, R. Schimpfky, P. Siemen, S. Bridges y T. Scheffer. Clasificación de consultas del motor de búsqueda utilizando la web como conocimiento de fondo. En Sigkdd Explorations, Volumen 7. ACM, 2005. [22] E. Voorhees. Expansión de consulta utilizando relaciones léxicas semánticas. En Sigir94, 1994. [23] J. Xu y W. Bruce Croft. Mejora de la efectividad de la recuperación de información con el análisis de contexto local. ACM TOIS, 18 (1): 79-112, 2000.