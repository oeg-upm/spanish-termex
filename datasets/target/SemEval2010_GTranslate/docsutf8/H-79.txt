Beyond PageRank: Aprendizaje automático para el ranking estático Matthew Richardson Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 722-3325 mattri@microsoft.com Amit Prakash MSN One Microsoft Way Redmond, WA 98052 +1 (425) 705-6015amitp@microsoft.com Eric Brill Microsoft Research One Microsoft Way Redmond, WA 98052 +1 (425) 705-4992 Brill@microsoft.com Resumen desde la publicación de Brin and Pages Paper en Pagerank, muchos en la comunidad web han dependido de PagerankPara el pedido estático (independiente de la consulta) de las páginas web. Mostramos que podemos superar significativamente a PageRank utilizando características que son independientes de la estructura de enlace de la web. Obtuvimos un aumento adicional en la precisión mediante el uso de datos sobre la frecuencia en que los usuarios visitan páginas web. Utilizamos RankNet, un algoritmo de aprendizaje automático de clasificación, para combinar estas y otras características estáticas basadas en el texto de anclaje y las características de dominio. El modelo resultante logra una precisión de clasificación estática por pares de 67.3% (frente a 56.7% para PageRank o 50% para aleatorio). Categorías y descriptores de sujetos I.2.6 [Inteligencia artificial]: aprendizaje. H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información. Algoritmos de términos generales, medición, rendimiento, experimentación.1. Introducción En la última década, la web ha crecido exponencialmente en tamaño. Desafortunadamente, este crecimiento no se ha aislado a páginas de buena calidad. El número de sitios incorrectos, spam y maliciosos (por ejemplo, phishing) también ha crecido rápidamente. El gran número de páginas buenas y malas en la web ha llevado a una creciente dependencia de los motores de búsqueda para el descubrimiento de información útil. Los usuarios confían en los motores de búsqueda no solo para devolver páginas relacionadas con su consulta de búsqueda, sino también para separar el bien de lo malo y los resultados de orden para que las mejores páginas se sugieran primero. Hasta la fecha, la mayoría de los trabajos en la clasificación de la página web se ha centrado en mejorar el orden de los resultados que se devuelven al usuario (clasificación de consultas o clasificación dinámica). Sin embargo, tener una buena clasificación independiente de la consulta (clasificación estática) también es de manera crucial para un motor de búsqueda. Un buen algoritmo de clasificación estática proporciona numerosos beneficios: • Relevancia: el rango estático de una página proporciona un indicador general de la calidad general de la página. Esta es una entrada útil para el algoritmo de clasificación dinámica.• Eficiencia: típicamente, el índice de motores de búsqueda está ordenado por rango estático. Al atravesar el índice de alta calidad a páginas de baja calidad, el ranker dinámico puede abortar la búsqueda cuando determina que ninguna página posterior tendrá un rango dinámico tan alto como los ya encontrados. Cuanto más preciso sea el rango estático, mejor esta habilidad de parto temprano y, por lo tanto, más rápido puede responder el motor de búsqueda a las consultas.• Prioridad de rastreo: la web crece y cambia tan rápido como los motores de búsqueda pueden rastrearla. Los motores de búsqueda necesitan una forma de priorizar su rastreo para determinar qué páginas reclazar, con qué frecuencia y con qué frecuencia buscar nuevas páginas. Entre otros factores, el rango estático de una página se utiliza para determinar esta priorización. Un mejor rango estático proporciona al motor un índice de mayor calidad y más actualizado. Google a menudo se considera el primer motor de búsqueda comercialmente exitoso. Su clasificación se basó originalmente en el algoritmo de PageRank [5] [27]. Debido a esto (y posiblemente debido a la promoción de Googles de PageRank al público), PageRank es ampliamente considerado como el mejor método para la clasificación estática de las páginas web. Aunque históricamente se ha pensado que PageRank se desempeña bastante bien, aún ha habido poca evidencia académica para respaldar esta afirmación. Peor aún, recientemente ha habido trabajo que muestra que PageRank puede no funcionar mejor que otras medidas simples en ciertas tareas. Upstill et al.han descubierto que para la tarea de encontrar páginas de inicio, el número de páginas que vinculan a una página y el tipo de URL fueron como o más efectivos que PageRank [32]. Encontraron resultados similares para la tarea de encontrar compañías de alta calidad [31]. PageRank también se ha utilizado en sistemas para TRECS muy grandes concursos de colección y pista web, pero con mucho menos éxito de lo esperado [17]. Finalmente, Amento et al.[1] encontraron que las características simples, como el número de páginas en un sitio, se realizan así como PageRank. A pesar de estos, la creencia general sigue siendo entre muchos, tanto académicos como en el público, que PageRank es un factor esencial para un buen rango estático. No se supone que no se supone que usar la estructura del enlace es crucial, en forma del número de insultos o la cantidad de texto de anclaje. En este artículo, mostramos que hay una serie de características simples a base de URL o página que superan significativamente a PageRank (a los efectos de las páginas web de clasificación estáticamente) a pesar de ignorar la estructura de la web. Combinamos estas y otras características estáticas utilizando el aprendizaje automático para lograr un sistema de clasificación que sea significativamente mejor que PageRank (en un acuerdo por pares con etiquetas humanas). Un enfoque de aprendizaje automático para la clasificación estática tiene otras ventajas además de la calidad de la clasificación. Debido a que la medida consta de muchas características, es más difícil para los usuarios maliciosos manipularla (es decir, elevar sus páginas de rango estático a un nivel inmerecido a través de técnicas cuestionables, también conocidas como spam web). Esto es particularmente cierto si no se conoce el conjunto de características. Por el contrario, una sola medida como PageRank puede ser más fácil de manipular porque los spammers solo necesitan concentrarse en un objetivo: cómo hacer que más páginas apunten a su página. Con un algoritmo que aprende, una característica que se vuelve inutilizable debido a la manipulación de spammer simplemente se reducirá o eliminará del cálculo final del rango. Esta flexibilidad permite que un sistema de clasificación reaccione rápidamente a las nuevas técnicas de spam. Un enfoque de aprendizaje automático para la clasificación estática también puede aprovechar cualquier avance en el campo de aprendizaje automático. Por ejemplo, el trabajo reciente sobre la clasificación adversa [12] sugiere que puede ser posible modelar explícitamente las acciones de spammers de la página web (el adversario), ajustando el modelo de clasificación antes de los intentos de los spammers para eludirlo. Otro ejemplo es la eliminación de los valores atípicos en la construcción del modelo, lo que ayuda a reducir el efecto que los sitios únicos pueden tener en la calidad general del rango estático. Al mover la clasificación estática a un marco de aprendizaje automático, no solo ganamos con precisión, sino también ganamos la capacidad de reaccionar ante las acciones de Spammers, para agregar rápidamente nuevas características al algoritmo de clasificación y aprovechar los avances en el campo de rápido crecimiento de la máquina.aprendiendo. Finalmente, creemos que habrá ventajas significativas en el uso de esta técnica para otros dominios, como buscar un disco duro local o una intranet de las corporaciones. Estos son dominios en los que la estructura del enlace es particularmente débil (o inexistente), pero hay otras características específicas del dominio que podrían ser igual de potentes. Por ejemplo, el autor de una página de Intranet y su posición en la organización (por ejemplo, CEO, gerente o desarrollador) podría proporcionar pistas significativas sobre la importancia de esa página. Por lo tanto, un enfoque de aprendizaje automático permite el rápido desarrollo de un buen algoritmo estático en los nuevos dominios. Esta contribución de documentos es un estudio sistemático de las características estáticas, incluida PageRank, a los efectos de las páginas web de clasificación (estáticamente). Estudios anteriores sobre PageRank típicamente usan subconjuntos de la web que son significativamente más pequeños (por ejemplo, el Corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas). Además, el rendimiento de PageRank y otras características estáticas se ha evaluado típicamente en el contexto de un sistema completo para la clasificación dinámica, o para otras tareas, como la respuesta a las preguntas. Por el contrario, exploramos el uso de PageRank y otras características para la tarea directa de las páginas web de clasificación estáticamente. Primero describimos brevemente el algoritmo de PageRank. En la Sección 3 presentamos RankNet, la técnica de aprendizaje automático utilizada para combinar características estáticas en una clasificación final. La Sección 4 describe las características estáticas. El corazón del documento se encuentra en la Sección 5, que presenta nuestros experimentos y resultados. Concluimos con una discusión sobre el trabajo relacionado y futuro.2. Pagerank La idea básica detrás de PageRank es simple: un enlace de una página web a otra puede verse como un respaldo de esa página. En general, los enlaces son hechos por personas. Como tal, son indicativos de la calidad de las páginas a las que señalan: al crear una página, un autor presumiblemente elige vincular a las páginas que se consideran de buena calidad. Podemos aprovechar esta información de vinculación para ordenar páginas web de acuerdo con su calidad percibida. Imagine a un surfista web que salta de página web a página web, eligiendo con una probabilidad uniforme que enlace a seguir en cada paso. Para reducir el efecto de los ciclos sin salida o interminables, el surfista ocasionalmente saltará a una página aleatoria con una pequeña probabilidad α, o cuando está en una página sin enlaces externos. Si se promedia en un número suficiente de pasos, la probabilidad de que el surfista esté en la página J en algún momento viene dada por la fórmula: ∑∈ + - = Ji I ip n jp b f) () 1 () (α α (1) Donde Fi es el conjunto de páginas a las que la página I enlaza, y BJ es el conjunto de páginas que enlazan a la página j. La puntuación de PageRank para el nodo J se define como esta probabilidad: PR (J) = P (J). Debido a que la ecuación (1) es recursiva, debe evaluarse iterativamente hasta que p (j) converge (típicamente, la distribución inicial para p (j) es uniforme). La intuición es, porque un surfista aleatorio terminaría en la página con más frecuencia, es probable que sea una mejor página. Una vista alternativa para la ecuación (1) es que a cada página se le asigna una calidad, p (j). Una página ofrece una parte igual de su calidad a cada página a la que señala. PageRank es computacionalmente costoso. Nuestra colección de 5 mil millones de páginas contiene aproximadamente 370 mil millones de enlaces. Computing PageRank requiere iterarse sobre estos miles de millones de enlaces varias veces (hasta la convergencia). Requiere grandes cantidades de memoria (o esquemas de almacenamiento de almacenamiento muy inteligente que disminuyen aún más el cálculo), y si se extienden en múltiples máquinas, requiere una comunicación significativa entre ellas. Aunque se ha trabajado mucho para optimizar el cálculo de PageRank (ver, por ejemplo, [25] y [6]), sigue siendo una propiedad relativamente lenta y computacionalmente costosa para calcular.3. RankNet se ha realizado mucho trabajo en el aprendizaje automático sobre los problemas de clasificación y regresión. Sea x = {xi} una colección de vectores de características (por lo general, una característica es cualquier número valorado real), y y = {yi} es una colección de clases asociadas, donde yi es la clase del objeto descrito por características vector xi. El problema de clasificación es aprender una función f que mapea yi = f (xi), para todos i. Cuando Yi también tiene un valor real, esto se llama regresión. La clasificación estática puede verse como un problema de regresión. Si dejamos que Xi represente las características de la página I, y Yi sea un valor (por ejemplo, el rango) para cada página, podríamos aprender una función de regresión que mapeó cada página de las características a su rango. Sin embargo, esto limita demasiado el problema que deseamos resolver. Todo lo que realmente nos importa es el orden de las páginas, no el valor real que se les asigna. Trabajo reciente sobre este problema de clasificación [7] [13] [18] intenta optimizar directamente el orden de los objetos, en lugar del valor asignado a ellos. Para estos, deje que Z = {<i, j>} sea una colección de pares de elementos, donde el elemento me asignaran un valor más alto que el elemento j. El objetivo del problema de clasificación, entonces, es aprender una función f tal que, () () (,, ji ffji xxz> ∈∀ 708 Tenga en cuenta que, como con el aprendizaje de una función de regresión, el resultado de este proceso es una función (f) que mapas presentan vectores a valores reales. Esta función aún se puede aplicar en cualquier lugar para que se pueda aplicar una función de regresión. La única diferencia es la técnica utilizada para aprender la función. Al optimizar directamente el orden de los objetos, estos métodos pueden aprender una función que hace un mejor trabajo de clasificación que hacer técnicas de regresión. Utilizamos RankNet [7], una de las técnicas antes mencionadas para las funciones de clasificación de aprendizaje, para aprender nuestra función de rango estático. RankNET es una modificación directa al algoritmo estándar de la red neuronal posterior. Al igual que con Back-Prop, RankNet intenta minimizar el valor de una función de costo ajustando cada peso en la red de acuerdo con el gradiente de la función de costo con respecto a ese peso. La diferencia es que, si bien una función de costo de red neuronal típica se basa en la diferencia entre la salida de la red y la salida deseada, la función de costo RankNet se basa en la diferencia entre un par de salidas de red. Es decir, para cada par de vectores de características <i, j> En el conjunto de entrenamiento, RankNet calcula las salidas de red OI y OJ. Dado que se supone que el vector I se clasifica más alto que el vector j, cuanto más grande es oj-oi, mayor será el costo. RankNet también permite que los pares en Z se pondera con una confianza (planteada como la probabilidad de que el par satisfaga el orden inducido por la función de clasificación). En este artículo, utilizamos una probabilidad de uno para todos los pares. En la siguiente sección, discutiremos las características utilizadas en nuestros vectores de características, XI.4. Características Para aplicar RankNet (u otras técnicas de aprendizaje automático) al problema de clasificación, necesitábamos extraer un conjunto de características de cada página. Dividimos nuestra característica establecida en cuatro categorías mutuamente exclusivas, a nivel de página (página), nivel de dominio (dominio), texto de anclaje e inclinos (ancla) y popularidad (popularidad). También utilizamos opcionalmente el PageRank de una página como característica. A continuación, describimos cada una de estas categorías de características con más detalle. PageRank calculamos PageRank en un gráfico web de 5 mil millones de páginas rastreadas (y 20 mil millones de URL conocidas vinculadas por estas páginas). Esto representa una parte significativa de la web, y es aproximadamente el mismo número de páginas que utilizan Google, Yahoo y MSN para sus motores de búsqueda. Debido a que PageRank es un algoritmo basado en gráficos, es importante que se ejecute en un subconjunto lo más grande posible de la web. La mayoría de los estudios anteriores en PageRank utilizaron subconjuntos de la web que son significativamente más pequeños (por ejemplo, el corpus TREC VLC2, utilizado por muchos, contiene solo 19 millones de páginas) Calculamos PageRank usando el valor estándar de 0.85 para α. Popularidad Otra característica que utilizamos es la popularidad real de una página web, medida como la cantidad de veces que los usuarios lo han visitado durante algún período de tiempo. Tenemos acceso a dichos datos de usuarios que han instalado la barra de herramientas de MSN y han optado por proporcionarlos a MSN. Los datos se agregan en un recuento, para cada página web, del número de usuarios que vieron esa página. Aunque los datos de popularidad generalmente no están disponibles, hay otras dos fuentes para ello. El primero es de los registros proxy. Por ejemplo, una universidad que requiere que sus estudiantes usen un poder tienen un registro de todas las páginas que han visitado mientras están en el campus. Desafortunadamente, los datos proxy son bastante sesgados y relativamente pequeños. Otra fuente, internos para los motores de búsqueda, son los registros de los cuales los resultados de sus usuarios hicieron clic. Dichos datos fueron utilizados por el golpe directo del motor de búsqueda, y recientemente se ha explorado para fines de clasificación dinámica [20]. Una ventaja de los datos de la barra de herramientas sobre esto es que contiene información sobre visitas de URL que no son solo el resultado de una búsqueda. La popularidad en bruto se procesa en una serie de características, como la cantidad de veces que se vio una página y se vio el número de veces cualquier página en el dominio. Se proporcionan más detalles en la Sección 5.5. Texto de anclaje e insultos Estas características se basan en la información asociada con los enlaces a la página en cuestión. Incluye características como la cantidad total de texto en enlaces que apuntan a la página (texto de anclaje), el número de palabras únicas en ese texto, etc. Página Esta categoría consta de características que pueden determinarse mirando solo la página (y su URL). Utilizamos solo ocho características simples, como el número de palabras en el cuerpo, la frecuencia del término más común, etc. Dominio Esta categoría contiene características que se calculan como promedios en todas las páginas del dominio. Por ejemplo, el número promedio de ataques en cualquier página y el PageRank promedio. Muchas de estas características han sido utilizadas por otras para clasificar páginas web, particularmente las características de anclaje y página. Como se mencionó, la evaluación es típicamente para la clasificación dinámica, y deseamos evaluar el uso de ellos para la clasificación estática. Además, hasta donde sabemos, este es el primer estudio sobre el uso de la popularidad de las visitas de página real para la clasificación estática. El trabajo similar más cercano está en usar el comportamiento de clics (es decir, los resultados del motor de búsqueda en los que hacen los usuarios) para afectar la clasificación dinámica (ver, por ejemplo, [20]). Debido a que utilizamos una amplia variedad de características para encontrar una clasificación estática, nos referimos a esto como Frank (para la clasificación basada en características).Frank usa RankNet y el conjunto de características descritas en esta sección para aprender una función de clasificación para páginas web. A menos que se especifique lo contrario, Frank fue entrenado con todas las características.5. Experimentos En esta sección, demostraremos que podemos realizar PageRank aplicando el aprendizaje automático a un conjunto directo de características. Antes de los resultados, primero discutimos los datos, la métrica de rendimiento y el método de entrenamiento.5.1 Datos Para evaluar la calidad de una clasificación estática, necesitábamos un estándar de oro que define el orden correcto para un conjunto de páginas. Para esto, empleamos un conjunto de datos que contiene juicios humanos para 28000 consultas. Para cada consulta, a varios resultados se les asigna manualmente una calificación, de 0 a 4, por jueces humanos. La calificación está destinada a ser una medida de cuán relevante es el resultado para la consulta, donde 0 significa pobre y 4 significa excelente. Hay aproximadamente 500k juicios en total, o un promedio de 18 calificaciones por consulta. Las consultas se seleccionan eligiendo al azar consultas de entre las emitidas al motor de búsqueda MSN. La probabilidad de que se seleccione una consulta es proporcional a su frecuencia entre los 709 de las consultas. Como resultado, es más probable que consultas comunes sean juzgadas que consultas poco comunes. Como ejemplo de cuán diversas son las consultas, las primeras cuatro consultas en el set de entrenamiento son las escuelas de chefs, Chicagoland Speedway, Eagles Fan Club y la cultura turca. Los documentos seleccionados para juzgar son aquellos que esperábamos, en promedio, serían razonablemente relevantes (por ejemplo, los diez principales documentos devueltos por MSNS Search Engine). Esto proporciona significativamente más información que seleccionar aleatoriamente documentos en la web, la gran mayoría de los cuales sería irrelevante para una consulta dada. Debido a este proceso, las páginas juzgadas tienden a ser de mayor calidad que la página promedio en la web, y tienden a ser páginas que se devolverán para consultas de búsqueda comunes. Este sesgo es bueno al evaluar la calidad de la clasificación estática a los efectos del orden de índice y devolver documentos relevantes. Esto se debe a que la parte más importante del índice a estar bien ordenada y relevante es la parte que se devuelve con frecuencia para consultas de búsqueda. Debido a este sesgo, sin embargo, los resultados en este documento no son aplicables a la priorización de rastreo. Para obtener resultados experimentales sobre la priorización de rastreo, necesitaríamos calificaciones en una muestra aleatoria de páginas web. Para convertir los datos de la consulta dependiente de consulta independiente, simplemente eliminamos la consulta, tomando el máximo sobre los juicios para una URL que aparece en más de una consulta. El razonamiento detrás de esto es que una página que es relevante para alguna consulta e irrelevante para otra es probablemente una página decente y debería tener un alto rango estático. Debido a que evaluamos las páginas en consultas que ocurren con frecuencia, nuestros datos indican el orden de índice correcto y asigna un alto valor a las páginas que probablemente sean relevantes para una consulta común. Asignamos consultas al azar a un conjunto de capacitación, validación o prueba, de modo que contenían 84%, 8%y 8%de las consultas, respectivamente. Cada conjunto contiene todas las clasificaciones para una consulta dada, y no aparece ninguna consulta en más de un conjunto. El set de entrenamiento se utilizó para entrenar a Frank. El conjunto de validación se utilizó para seleccionar el modelo que tuviera el rendimiento más alto. El conjunto de pruebas se usó para los resultados finales. Estos datos nos proporcionan un pedido de páginas independiente de la consulta. El objetivo para un algoritmo de clasificación estática será reproducir este orden lo más cerca posible. En la siguiente sección, describimos la medida que utilizamos para evaluar esto.5.2 Medida Elegimos usar la precisión por pares para evaluar la calidad de una clasificación estática. La precisión por pares es la fracción del tiempo que el algoritmo de clasificación y los jueces humanos acuerdan el orden de un par de páginas web. Si S (x) es la clasificación estática asignada a la página X, y H (x) es el juicio humano de relevancia para x, entonces considere los siguientes conjuntos:)} () (:, {yhxhyx> = ph y)} () (:, {ysxsyx> = ps La precisión por pares es la porción de HP que también está contenida en SP: P PP H SH ∩ = AccuracyPairwise Esta medida se eligió por dos razones. Primero, los juicios humanos discretos proporcionan solo un pedido parcial en las páginas web, lo que dificulta aplicar una medida como el coeficiente de correlación de orden de rango de Spearman (en la medida de precisión por pares, un par de documentos con el mismo juicio humano no afecta elpuntaje). En segundo lugar, la precisión por pares tiene un significado intuitivo: es la fracción de pares de documentos que, cuando los humanos afirman que uno es mejor que el otro, el algoritmo de rango estático los ordena correctamente.5.3 Método Entrenamos a Frank (una red neuronal basada en RankNet) utilizando los siguientes parámetros. Utilizamos una red de 2 capas totalmente conectada. La capa oculta tenía 10 nodos ocultos. Los pesos de entrada a esta capa se inicializaron para ser cero. La capa de salida (solo un nodo solo) se inicializaron utilizando una distribución aleatoria uniforme en el rango [-0.1, 0.1]. Utilizamos Tanh como la función de transferencia de las entradas a la capa oculta, y una función lineal desde la capa oculta a la salida. La función de costo es la función de costo de entropía cruzada por pares como se discutió en la Sección 3. Las características en el conjunto de entrenamiento se normalizaron para tener media media y desviación estándar de la unidad. Luego se aplicó la misma transformación lineal a las características en los conjuntos de validación y prueba. Para el entrenamiento, presentamos a la red 5 millones de emparejamientos de páginas, donde una página tenía una calificación más alta que la otra. Los emparejamientos se eligieron uniformemente al azar (con reemplazo) de todos los emparejamientos posibles. Al formar los pares, ignoramos la magnitud de la diferencia entre las clasificaciones (la propagación de calificación) para las dos URL. Por lo tanto, el peso para cada par era constante (uno), y la probabilidad de que se seleccionara un par era independiente de su propagación de calificación. Entrenamos la red para 30 épocas. En cada época, los pares de entrenamiento se barajaban al azar. La tasa de entrenamiento inicial fue de 0.001. En cada época, verificamos el error en el conjunto de entrenamiento. Si el error había aumentado, entonces disminuimos la tasa de entrenamiento, bajo la hipótesis de que la red probablemente había superado. La tasa de entrenamiento en cada época se estableció para: tasa de entrenamiento = 1+ε κ donde κ es la tasa inicial (0.001), y ε es el número de veces que el error del conjunto de entrenamiento ha aumentado. Después de cada época, medimos el rendimiento de la red neuronal en el conjunto de validación, utilizando 1 millón de pares (elegidos al azar con reemplazo). Se seleccionó la red con la mayor precisión por pares en el conjunto de validación y luego se probó en el conjunto de pruebas. Reportamos la precisión por pares en el conjunto de pruebas, calculada utilizando todos los pares posibles. Estos parámetros se determinaron y fijaron antes de los experimentos de rango estático en este documento. En particular, la elección de la tasa de entrenamiento inicial, el número de épocas y la función de desintegración de la tasa de entrenamiento se tomaron directamente de Burges et al [7]. Aunque teníamos la opción de preprocesar cualquiera de las características antes de que fueran ingresadas a la red neuronal, nos abstuvimos de hacerlo en la mayoría de ellas. La única excepción fueron las características de popularidad. Como con la mayoría del fenómeno web, encontramos que la distribución de la popularidad del sitio es Zipfian. Para reducir el rango dinámico y, con suerte, hacer que la característica sea más útil, presentamos la red tanto sin practicos como el logaritmo de las características de popularidad (como con las demás, los valores de características logarítmicas también se normalizaron para tener cero mediay desviación estándar de la unidad).710 Aplicar Frank a un documento es computacionalmente eficiente, tomando un tiempo que solo es lineal en el número de características de entrada;Por lo tanto, se encuentra dentro de un factor constante de otros métodos simples de aprendizaje automático, como Bayes ingenuos. En nuestros experimentos, calcular el Frank para las cinco mil millones de páginas web fue aproximadamente 100 veces más rápido que calcular el PageRank para el mismo conjunto.5.4 Resultados Como muestra la Tabla 1, Frank supera significativamente a PageRank a los efectos de la clasificación estática. Con una precisión por pares de 67.4%, Frank duplica más que la precisión de PageRank (en relación con la línea de base del 50%, que es la precisión que se lograría mediante un orden aleatorio de páginas web). Tenga en cuenta que una de las características de entrada de Franks es el PageRank de la página, por lo que esperaríamos que no funcione peor que PageRank. El aumento significativo en la precisión implica que las otras características (ancla, popularidad, etc.) de hecho contienen información útil sobre la calidad general de una página. Tabla 1: Precisión de la técnica de resultados básicos (%) Ninguno (línea de base) 50.00 PageRank 56.70 Frank 67.43 Hay una serie de decisiones que van al cálculo de PageRank, como cómo lidiar con páginas que no tienen extractores, la elección de α, la elección de α,Precisión numérica, umbral de convergencia, etc. Pudimos obtener un cálculo de PageRank de una implementación completamente independiente (proporcionada por Marc Najork) que varió un poco en estos parámetros. Logró una precisión por pares de 56.52%, casi idéntica a la obtenida por nuestra implementación. Por lo tanto, concluimos que la calidad del PageRank no es sensible a estas variaciones menores en el algoritmo, ni PageRanks tenía baja precisión debido a problemas con nuestra implementación de la misma. También queríamos encontrar qué tan bien realizado cada conjunto de características. Para responder esto, para cada conjunto de características, entrenamos y probamos a Frank usando solo ese conjunto de características. Los resultados se muestran en la Tabla 2. Como se puede ver, cada característica establece un PageRank superado individualmente en esta prueba. Quizás el resultado más interesante es que las características de nivel de página tuvieron el rendimiento más alto de todos los conjuntos de características. Esto es sorprendente porque estas son características que no dependen de la estructura gráfica general de la web, ni siquiera de lo que las páginas apuntan a una página determinada. Esto es contrario a la creencia común de que la estructura del gráfico web es la clave para encontrar una buena clasificación estática de páginas web. Tabla 2: Resultados para conjuntos de características individuales. Precisión del conjunto de características (%) PageRank 56.70 Popularidad 60.82 Anchor 59.09 Página 63.93 Dominio 59.03 Todas las características 67.43 porque estamos utilizando una red neuronal de dos capas, las características en la red aprendida pueden interactuar entre sí de manera interesante y no lineal. Esto significa que una característica particular que parece tener poco valor de forma aislada podría ser muy importante cuando se usa en combinación con otras características. Para medir la contribución final de un conjunto de características, en el contexto de todas las otras características, realizamos un estudio de ablación. Es decir, para cada conjunto de características, entrenamos una red para contener todas las características, excepto ese conjunto. Luego comparamos el rendimiento de la red resultante con el rendimiento de la red con todas las características. La Tabla 3 muestra los resultados de este experimento, donde la disminución de la precisión es la diferencia en la precisión por pares entre la red entrenada con todas las características, y la red falta el conjunto de características dado. Tabla 3: Estudio de ablación. Se muestra la disminución de la precisión cuando entrenamos una red que tiene todas las características, excepto el conjunto dado. La última línea muestra el efecto de eliminar las características de ancla, PageRank y dominio, de ahí que un modelo no contiene información basada en red o enlace. La disminución del conjunto de características en la precisión PageRank 0.18 Popularidad 0.78 Anchor 0.47 Page 5.42 Ancla de dominio, PageRank y Domain 0.10 0.60 Los resultados del estudio de ablación son consistentes con el estudio de conjunto de características individuales. Ambos muestran que el conjunto de características más importante es el conjunto de características a nivel de página, y el segundo más importante es el conjunto de funciones de popularidad. Finalmente, deseamos ver cómo mejoró el rendimiento de Frank mientras agregamos características;Queríamos encontrar en qué punto agregar más conjuntos de características se volvió relativamente inútil. Comenzando sin características, agregamos con avidez el conjunto de características que más mejoró el rendimiento. Los resultados se muestran en la Tabla 4. Por ejemplo, la cuarta línea de la tabla muestra que Frank usa la página, la popularidad y las características de anclaje superaron a cualquier red que usara la página, la popularidad y algunos otros conjuntos de características, y que el rendimiento de esta red fue del 67.25%. Tabla 4: Se agregan el rendimiento de Frank como conjuntos de características. En cada fila, el conjunto de características que dio el mayor aumento en la precisión se agregó a la lista de características (es decir, realizamos una búsqueda codiciosa sobre conjuntos de características). Precisión del conjunto de características (%) Ninguno 50.00 +Página 63.93 +Popularidad 66.83 +Anchor 67.25 +PageRank 67.31 +Dominio 67.43 711 Finalmente, presentamos una comparación cualitativa de PageRank vs. Frank. En la Tabla 5 están las diez URL principales que regresaron para PageRank y para Frank. Los resultados de PageRanks están muy ponderados hacia los sitios de tecnología. Contiene dos URL rápidas (software de reproducción de video de manzanas), así como las URL de Internet Explorer y Firefox (las cuales son navegadores web).Frank, por otro lado, contiene sitios más orientados al consumidor como American Express, Target, Dell, etc. El sesgo de PageRanks hacia la tecnología puede explicarse a través de dos procesos. Primero, hay muchas páginas con botones en la parte inferior que sugieren que el sitio está optimizado para Internet Explorer, o que el visitante necesita QuickTime. Estos generalmente se vinculan con, en estos ejemplos, los sitios de descarga de Internet Explorer y QuickTime. En consecuencia, PageRank clasifica esas páginas altamente. Aunque estas páginas son importantes, no son tan importantes como pueden parecer al observar la estructura del enlace sola. Una solución para esto es agregar información sobre el enlace al cálculo de PageRank, como el tamaño del texto, ya sea en la parte inferior de la página, etc. El otro sesgo proviene del hecho de que la población de autores del sitio web es diferente a la población de usuarios web. Los autores web tienden a estar orientados tecnológicamente y, por lo tanto, su comportamiento de vinculación refleja esos intereses.Frank, al conocer la popularidad de las visitas real de un sitio (el conjunto de características de popularidad), puede eliminar parte de ese sesgo. Tiene la capacidad de depender más de dónde visiten los usuarios web reales en lugar de dónde se han vinculado los autores del sitio web. Los resultados confirman que Frank supera a PageRank con precisión por pares. Los dos conjuntos de características más importantes son la página y las características de popularidad. Esto es sorprendente, ya que las características de la página consistieron solo en algunas (8) características simples. Otros experimentos encontraron que, de las características de la página, las basadas en el texto de la página (a diferencia de la URL) tuvieron el mejor rendimiento. En la siguiente sección, exploramos la función de popularidad con más detalle.5.5 Datos de popularidad Como se menciona en la Sección 4, nuestros datos de popularidad provienen de los usuarios de la barra de herramientas de MSN. Por razones de privacidad, solo tuvimos acceso a un recuento agregado de, para cada URL, cuántas veces fue visitado por cualquier usuario de la barra de herramientas. Esto limitó las posibles características que podríamos derivar de estos datos. Para posibles extensiones, consulte la Sección 6.3, trabajo futuro. Para cada URL en nuestro tren y conjuntos de pruebas, le proporcionamos una característica a Frank, que era cuántas veces había sido visitado por un usuario de la barra de herramientas. Sin embargo, esta característica era bastante ruidosa y escasa, particularmente para las URL con parámetros de consulta (por ejemplo, http://search.msn.com/results.aspx?q=machine+learning&form=qbhp). Una solución fue proporcionar una característica adicional que era el número de veces que un usuario de la barra de herramientas visitó cualquier URL en el dominio dado. Agregar esta característica mejoró drásticamente el rendimiento de Frank. Llevamos este paso más y utilizamos la estructura jerárquica incorporada de las URL para construir muchos niveles de retroceso entre la URL completa y el dominio. Hicimos esto utilizando el conjunto de características que se muestran en la Tabla 6. Tabla 6: Funciones de URL utilizadas para calcular el conjunto de características de popularidad. Ejemplo de función exacto URL cnn.com/2005/tech/wikipedia.html?v=mobile Sin parámetros cnn.com/2005/tech/wikipedia.html Página wikipedia.html url-1 cnn.com/2005/tech URL-2 CNN.com/2005 ... Dominio CNN.com Dominio+1 CNN.com/2005 ... A cada URL se le asignó una característica para cada función que se muestra en la tabla. El valor de la característica fue el recuento de la cantidad de veces que un usuario de la barra de herramientas visitó una URL, donde la función aplicada a esa URL coincide con la función aplicada a la URL en cuestión. Por ejemplo, una visita a los usuarios a CNN.com/2005/sports.html incrementaría el dominio y el dominio+1 características para la URL cnn.com/2005/tech/wikipedia.html. Como se ve en la Tabla 7, agregar los recuentos de dominios mejoró significativamente la calidad de la función de popularidad, y agregar las numerosas funciones de retroceso enumeradas en la Tabla 6 mejoró aún más la precisión. Tabla 7: Efecto de agregar retroceso al conjunto de características de popularidad Precisión de precisión (%) URL Count 58.15 URL y recuento de dominio 59.31 Todas las funciones de retroceso (Tabla 6) 60.82 Tabla 5: Diez URL principales para PageRank vs. Frank Pagerank Frank Google.com Google.com Apple.com/quicktime/download yahoo.com amazon.com americanExpress.com Yahoo.com hp.com Microsoft.com/windows/ie Target.com Apple.com/quicktime bestbuy.com mapquest.com Dell.com ebay.COM AutoTrader.com mozilla.org/products/firefox dogpile.com ftc.gov bankofamerica.com 712 El respaldo a los subconjuntos de la URL es una técnica para tratar la escasez de datos. También es informativo ver cómo el rendimiento de Frank depende de la cantidad de datos de popularidad que hemos recopilado. En la Figura 1 mostramos el rendimiento de Frank entrenado con solo el conjunto de características de popularidad frente a la cantidad de datos que tenemos para el conjunto de características de popularidad. Cada día, recibimos datos de popularidad adicionales, y como se puede ver en la trama, esto aumenta el rendimiento de Frank. La relación es logarítmica: duplicar la cantidad de datos de popularidad proporciona una mejora constante en la precisión por pares. En resumen, hemos descubierto que las características de popularidad proporcionan un impulso útil para la precisión general de Frank. Recopilar más datos de popularidad, así como emplear estrategias simples de retroceso, mejorar este impulso aún más.5.6 Resumen de resultados Los experimentos proporcionan una serie de conclusiones. Primero, Frank funciona significativamente mejor que PageRank, incluso sin ninguna información sobre el gráfico web. En segundo lugar, el nivel de página y las características de popularidad fueron los contribuyentes más importantes para la precisión por pares. Tercero, al recopilar más datos de popularidad, podemos continuar mejorando el rendimiento de los francos. Los datos de popularidad proporcionan dos beneficios a Frank. Primero, vemos que cualitativamente, Franks Ordening of Web Pages tiene un sesgo más favorable que PageRanks.El pedido de Franks parece corresponder a lo que prefieren los usuarios de la web, en lugar de los autores de la página web. En segundo lugar, los datos de popularidad son más oportunos que la información del enlace de PageRanks. La barra de herramientas proporciona información sobre las páginas web que las personas encuentran interesantes en este momento, mientras que los enlaces se agregan a las páginas más lentamente, ya que los autores encuentran el tiempo y el interés.6. Trabajo relacionado y futuro 6.1 mejoras para PageRank Desde el artículo original de PageRank, ha habido trabajo para mejorarlo. Gran parte de ese trabajo se centra en acelerar y paralelarse el cálculo [15] [25]. Un problema reconocido con PageRank es el de la deriva del tema: una página sobre perros tendrá un alto PageRank si está vinculada por muchas páginas que tienen alto rango, independientemente de su tema. Por el contrario, un usuario de un motor de búsqueda que busca buenas páginas sobre perros probablemente preferiría encontrar páginas que sean apuntadas por muchas páginas que sean sobre perros. Por lo tanto, un enlace que está en el tema debería tener un mayor peso que un enlace que no lo es. Richardson y Domingoss Consulta PageRank [29] y el PageRank sensible al tema de Haveliwalas [16] son dos enfoques que abordan este problema. Otras variaciones para PageRank incluyen enlaces de ponderación de manera diferente para enlaces intervs. intra dominio, agregar un paso hacia atrás al surfista aleatorio para simular el botón de retroceso en la mayoría de los navegadores [24] y modificar la probabilidad de salto (α) [3]. Vea Langville y Meyer [23] para una buena encuesta de estos y otras modificaciones a PageRank.6.2 Otro trabajo relacionado PageRank no es el único algoritmo de análisis de enlaces utilizado para clasificar las páginas web. El otro más conocido son los éxitos [22], que utilizan el motor de búsqueda de Teoma [30]. Hits produce una lista de centros y autoridades, donde los centros son páginas que apuntan a muchas páginas de autoridad, y las autoridades son páginas que muchos centros apuntan. El trabajo anterior ha mostrado éxitos para realizar comparablemente a PageRank [1]. Un campo de interés es el de la poda del índice estático (ver, por ejemplo, Carmel et al. [8]). Los métodos de poda del índice estático reducen el tamaño del índice de motores de búsqueda mediante la eliminación de documentos que es poco probable que se devuelvan por una consulta de búsqueda. La poda generalmente se realiza en función de la frecuencia de los términos de consulta. Del mismo modo, Pandey y Olston [28] sugieren páginas rastreando con frecuencia si es probable que aparezcan incorrectamente (o no aparezcan) como resultado de una búsqueda. Se podrían incorporar métodos similares al rango estático (por ejemplo, cuántas consultas frecuentes contienen palabras que se encuentran en esta página). Otros han investigado el efecto que PageRank tiene en la web en general [9]. Argumentan que las páginas con PageRank alta tienen más probabilidades de encontrar los usuarios de la web, por lo que es más probable que se vinculen y, por lo tanto, es más probable que mantengan un PageRank más alto que otras páginas. Lo mismo puede ocurrir para los datos de popularidad. Si aumentamos la clasificación de páginas populares, es más probable que se hagan clic, aumentando aún más su popularidad. Cho et al.[10] argumentan que una medida más apropiada de la calidad de la página web dependería no solo de la estructura de enlace actual de la web, sino también del cambio en esa estructura de enlace. La misma técnica puede ser aplicable a los datos de popularidad: el cambio en la popularidad de una página puede ser más informativo que la popularidad absoluta. Un trabajo relacionado interesante es el de Ivory y Hearst [19]. Su objetivo era construir un modelo de sitios web que se consideren de alta calidad desde la perspectiva del contenido, la estructura y la navegación, el diseño visual, la funcionalidad, la interactividad y la experiencia general. Utilizaron más de 100 características de nivel de página, así como características que abarcan el rendimiento y la estructura del sitio. Esto les permite describir cualitativamente las cualidades de una página que lo hacen parecer atractivo (por ejemplo, el uso raro de la cursiva, al menos 9 puntos, ...) y (en el trabajo posterior) para construir un sistema que ayuda a los autores novedosos de la página web a crearPáginas de calidad evaluándolo de acuerdo con estas características. Las principales diferencias entre este trabajo y la nuestra son el objetivo (descubrir lo que constituye una buena página web versus páginas web de pedido a los efectos de la búsqueda web), el tamaño del estudio (utilizaron un conjunto de datos de menos de 6000 páginas versus nuestrasConjunto de 468,000), y nuestra comparación con PageRank.y = 0.577ln (x) + 58.283 r 2 = 0.9822 58 58.5 59 59.5 60 60.5 61 1 10 100 Días de la barra de herramientas Datos de pareja de parejas Figura 1: Relación entre la cantidad de datos de popularidad y el rendimiento del conjunto de características de popularidad. Nota El eje X es una escala logarítmica.713 Sin embargo, su trabajo proporciona información a características estáticas útiles adicionales que podríamos incorporar a Frank en el futuro. El trabajo reciente para incorporar características novedosas en la clasificación dinámica incluye que por Joachims et al.[21], quienes investigan el uso de comentarios implícitos de los usuarios, en la forma en que se hacen clic en los resultados del motor de búsqueda. Craswell et al.[11] Presente un método para determinar la mejor transformación para aplicar a las características independientes de consulta (como las utilizadas en este documento) con el propósito de mejorar la clasificación dinámica. Otro trabajo, como Boyan et al.[4] y Bartell et al.[2] Aplique el aprendizaje automático para mejorar la relevancia general de un motor de búsqueda (es decir, la clasificación dinámica). No aplican sus técnicas al problema de la clasificación estática.6.3 Trabajo futuro Hay muchas formas en que nos gustaría extender este trabajo. Primero, Frank usa solo una pequeña cantidad de características. Creemos que podríamos lograr resultados aún más significativos con más características. En particular, la existencia, o falta de ella, de ciertas palabras podría resultar muy significativa (por ejemplo, en construcción probablemente significa una página de baja calidad). Otras características podrían incluir el número de imágenes en una página, tamaño de esas imágenes, número de elementos de diseño (tablas, divs y tramos), uso de hojas de estilo, conformes a los estándares W3C (como XHTML 1.0 Strict), color de fondo de unpágina, etc. Muchas páginas se generan dinámicamente, cuyo contenido puede depender de los parámetros en la URL, la hora del día, el usuario que visita el sitio u otras variables. Para tales páginas, puede ser útil aplicar las técnicas que se encuentran en [26] para formar una aproximación estática a los fines de extraer características. La gramática resultante que describe la página podría ser una fuente de características adicionales que describen la complejidad de la página, como cuántos nodos no terminales tienen, la profundidad del árbol de la gramática, etc. Frank permite especificar una confianza en cada uno.emparejamiento de documentos. En el futuro, experimentaremos con probabilidades que dependen de la diferencia en los juicios humanos entre los dos elementos de la pareja. Por ejemplo, un par de documentos en los que uno se clasificó 4 y el otro 0 debería tener una mayor confianza que un par de documentos con calificación 3 y 2. Los experimentos en este documento están sesgados hacia páginas que tienen una calidad más alta que el promedio. Además, Frank con todas las características solo se puede aplicar a las páginas que ya se han rastreado. Por lo tanto, Frank es principalmente útil para ordenar índices y mejorar la relevancia, no para dirigir el rastreo. También nos gustaría investigar un enfoque de aprendizaje automático para la priorización de rastreo. Puede ser que una combinación de métodos sea mejor: por ejemplo, usar PageRank para seleccionar los mejores 5 mil millones de 20 mil millones de páginas en la web, luego usar Frank para ordenar el índice y afectar la relevancia de búsqueda. Otra dirección interesante para la exploración es incorporar características franco y de nivel de página directamente en el cálculo de PageRank. Trabajar en el sesgo del vector de salto de PageRank [16] y la matriz de transición [29], han demostrado la viabilidad y las ventajas de dicho enfoque. Hay razones para creer que una aplicación directa de [29], utilizando el franco de una página para su relevancia, podría conducir a un rango estático general mejorado. Finalmente, los datos de popularidad se pueden usar de otras maneras interesantes. Los hábitos generales de navegación y búsqueda de usuarios web varían según la hora del día. La actividad en la mañana, el día y la tarde a menudo son bastante diferentes (por ejemplo, leer las noticias, resolver problemas y acceder al entretenimiento, respectivamente). Podemos obtener información sobre estas diferencias utilizando los datos de popularidad, divididos en segmentos del día. Cuando se emite una consulta, usaríamos los datos de popularidad que coinciden con el tiempo de consulta para hacer la clasificación de páginas web. También planeamos explorar características de popularidad que usan más que solo los recuentos de la frecuencia con la que se visitó una página. Por ejemplo, cuánto tiempo los usuarios tendieron a detenerse en una página, dejaron la página haciendo clic en un enlace o presionando el botón Atrás, etc. Fox et al.hizo un estudio que mostró que características como esta pueden ser valiosas para el propósito de la clasificación dinámica [14]. Finalmente, los datos de popularidad podrían usarse como etiqueta en lugar de una característica. El uso de Frank de esta manera para predecir la popularidad de una página puede ser útil para las tareas de relevancia, eficiencia y prioridad de rastreo. También hay datos significativamente más populares que los datos etiquetados por humanos, lo que potencialmente permite métodos de aprendizaje automático más complejos y significativamente más características.7. Conclusiones Una buena clasificación estática es un componente importante para los motores de búsqueda de hoy y los sistemas de recuperación de información. Hemos demostrado que PageRank no proporciona una muy buena clasificación estática;Hay muchas características simples que individualmente realizan PageRank. Al combinar muchas características estáticas, Frank logra una clasificación que tiene una precisión por pares significativamente más alta que PageRank solo. Una evaluación cualitativa de los principales documentos muestra que Frank es menos sesgada de tecnología que PageRank;Al usar datos de popularidad, está sesgado hacia páginas que los usuarios web, en lugar de los autores web, visitan. El componente de aprendizaje automático de Frank le brinda el beneficio adicional de ser más robusto contra los spammers, y le permite aprovechar más desarrollos en la comunidad de aprendizaje automático en áreas como la clasificación adversaria. Solo hemos comenzado a explorar las opciones y creemos que se pueden hacer avances significativos en el área de clasificación estática mediante experimentación adicional con características adicionales, otras técnicas de aprendizaje automático y fuentes adicionales de datos.8. Agradecimientos Gracias a Marc Najork por proporcionarnos cálculos adicionales de PageRank y a Timo Burkard por su ayuda con los datos de popularidad. Muchas gracias a Chris Burges por proporcionar código y soporte significativo en el uso de redes de rango de capacitación. Además, agradecemos a Susan Dumais y Nick Craswell por sus ediciones y sugerencias.9. Referencias [1] B. Amento, L. Terveen y W. Hill. ¿La autoridad significa calidad? Predicción de calificaciones de calidad de expertos de documentos web. En Actas de la 23a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, 2000. [2] B. Bartell, G. Cottrell y R. Belew. Combinación automática de sistemas de recuperación de rango múltiple. En Actas de la 17ª Conferencia Anual Internacional de ACM Sigir sobre Investigación y Desarrollo en Recuperación de Información, 1994. [3] P. Boldi, M. Santini y S. Vigna. PageRank en función del factor de amortiguación. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. 714 [4] J. Boyan, D. Freitag y T. Joachims. Una arquitectura de aprendizaje automático para optimizar los motores de búsqueda web. En el taller de AAAI sobre sistemas de información basados en Internet, agosto de 1996. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. En Actas de la Séptima Conferencia Internacional de la Buidad de la Amplia, Brisbane, Australia, 1998. Elsevier.[6] A. Broder, R. Lempel, F. Maghoul y J. Pederson. Aproximación eficiente de PageRank a través de la agregación de gráficos. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [7] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, G. Hullender. Aprendiendo a clasificarse usando descenso de gradiente. En Actas de la 22a Conferencia Internacional sobre Aprendizaje Machine, Bonn, Alemania, 2005. [8] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer. Poda de índice estático para sistemas de recuperación de información. En Actas de la 24ª Conferencia Anual de ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 43-50, Nueva Orleans, Louisiana, EE. UU., Septiembre de 2001. [9] J. Cho y S. Roy. Impacto de los motores de búsqueda en la popularidad de la página. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2004. [10] J.Cho, S. Roy, R. Adams. Calidad de la página: en busca de una clasificación web imparcial. En Actas de la Conferencia ACM Sigmod 2005. Baltimore, Maryland. Junio de 2005. [11] n.Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para la evidencia independiente de la consulta. En Actas de la 28ª Conferencia Anual sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), agosto de 2005. [12] n.Dalvi, P. Domingos, Mausam, S. Sanghai, D. Verma. Clasificación adversa. En Actas de la Décima Conferencia Internacional sobre Discovery y Minería de Datos (pp. 99-108), Seattle, WA, 2004. [13] o.Dekel, C. Manning e Y. Cantante. Modelos log-lineales para el rango de etiquetas. En avances en sistemas de procesamiento de información neural 16. Cambridge, MA: MIT Press, 2003. [14] s.Fox, K S. Fox, K. Karnawat, M. Mydland, S. T. Dumais y T. White (2005). Evaluar las medidas implícitas para mejorar las experiencias de búsqueda. En las transacciones ACM en Sistemas de Información, 23 (2), pp. 147-168. Abril de 2005. [15] t.Haveliwala. Cálculo eficiente de PageRank. Informe técnico de la Universidad de Stanford, 1999. [16] t.Haveliwala. PageRank sensible al tema. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2002. [17] d.Hawking y N. Craswell. Recuperación a gran escala y búsqueda web. En D. Harman y E. Voorhees (eds), The Trec Book. MIT Press.[18] r.Herbrich, T. Graepel y K. Obermayer. Apoye el aprendizaje del vector para la regresión ordinal. En Actas de la Novena Conferencia Internacional sobre Redes Neurales Artificiales, pp. 97-102.1999. [19] m.Ivory y M. Hearst. Perfiles estadísticos de sitios web altamente calificados. En Actas de la Conferencia ACM Sigchi sobre Factores Humanos en Sistemas de Computación, 2002. [20] T.Joachims. Optimización de los motores de búsqueda utilizando datos de clics. En Actas de la Conferencia ACM sobre Discovery de Conocimiento y Minería de datos (KDD), 2002. [21] T.Joachims, L. Granka, B. Pang, H. Hembrooke y G. Gay. Interpretar con precisión los datos de clics como retroalimentación implícita. En Actas de la Conferencia sobre Investigación y Desarrollo en Recuperación de Información (SIGIR), 2005. [22] J.Kleinberg. Fuentes autorizadas en un entorno hipervínculos. Journal of the ACM 46: 5, pp. 604-32.1999. [23] a.Langville y C. Meyer. Más profundo dentro de PageRank. Internet Mathematics 1 (3): 335-380, 2004. [24] f.Matthieu y M. Bouklit. El efecto del botón Atrás en una caminata aleatoria: aplicación para PageRank. En documentos de pista alternativos y carteles de la Decimotercera Conferencia Internacional World Wide Webs, 2004. [25] f.McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [26] y.Minamida. Aproximación estática de páginas web generadas dinámicamente. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [27] l.Page, S. Brin, R. Motwani y T. Winograd. Ranking de citas de PageRank: traer orden a la web. Informe técnico, Universidad de Stanford, Stanford, CA, 1998. [28] s.Pandey y C. Olston. Gastamiento web centrado en el usuario. En Actas de la Conferencia Internacional de la World Wide Web, mayo de 2005. [29] m.Richardson y P. Domingos. El surfista inteligente: combinación probabilística de información de enlace e contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural 14, pp. 1441-1448. Cambridge, MA: MIT Press, 2002. [30] c.Sherman. Teoma vs. Google, Ronda 2. Disponible en World Wide Web (http://dc.internet.com/news/article.php/ 1002061), 2002. [31] t.Upstill, N. Craswell y D. Hawking. Predicción de fama y fortuna: ¿PageRank o Indegree?. En el octavo Simposio de Computación de Documentos de Australia.2003. [32] t.Upstill, N. Craswell y D. Hawking. Evidencia independiente de la consulta en el hallazgo de la página de inicio. En transacciones ACM en sistemas de información.2003. 715