Uso de contextos de consulta en la recuperación de información Jing Bai 1, Jian-Yun Nie 1, Hugues Bouchard 2, Guihong Cao 1 1 Departamento IRO, Universidad de Montreal CP. 6128, Sucursale Centre-ville, Montreal, Quebec, H3C 3J7, Canadá {Baijing, Nie, Caogui}@iro.umontreal.ca 2 Yahoo! Inc. Montreal, Quebec, Canadá bouchard@yahoo-inc.com La consulta de usuario abstracto es un elemento que especifica una necesidad de información, pero no es la única. Los estudios en literatura han encontrado muchos factores contextuales que influyen fuertemente en la interpretación de una consulta. Estudios recientes han tratado de considerar los intereses de los usuarios creando un perfil de usuario. Sin embargo, un solo perfil para un usuario puede no ser suficiente para una variedad de consultas del usuario. En este estudio, proponemos utilizar contextos específicos de consultas en lugar de los centrados en el usuario, incluido el contexto en torno a la consulta y el contexto dentro de la consulta. El primero especifica el entorno de una consulta como el dominio de interés, mientras que el segundo se refiere a palabras de contexto dentro de la consulta, que es particularmente útil para la selección de relaciones de término relevantes. En este artículo, ambos tipos de contexto están integrados en un modelo IR basado en el modelado de idiomas. Nuestros experimentos en varias colecciones de TREC muestran que cada uno de los factores de contexto trae mejoras significativas en la efectividad de la recuperación. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información - Modelos de recuperación Algoritmos de términos generales, rendimiento, experimentación, teoría.1. Las consultas de introducción, especialmente consultas cortas, no proporcionan una especificación completa de la necesidad de la información. Muchos términos relevantes pueden estar ausentes de las consultas y los términos incluidos pueden ser ambiguos. Estos problemas se han abordado en una gran cantidad de estudios anteriores. Las soluciones típicas incluyen expandir el documento o la representación de la consulta [19] [35] explotando diferentes recursos [24] [31], utilizando la desambiguación del sentido de las palabras [25], etc. Sin embargo, en estos estudios, generalmente se ha asumido que la consulta es el único elemento disponible sobre la necesidad de la información del usuario. En realidad, la consulta siempre se formula en un contexto de búsqueda. Como se ha encontrado en muchos estudios previos [2] [14] [20] [21] [26], los factores contextuales tienen una fuerte influencia en los juicios de relevancia. Estos factores incluyen, entre muchos otros, el dominio de los usuarios de interés, conocimiento, preferencias, etc. Todos estos elementos especifican los contextos alrededor de la consulta. Entonces los llamamos contexto en torno a la consulta en este documento. Se ha demostrado que la consulta de los usuarios debe colocarse en su contexto para una interpretación correcta. Estudios recientes han investigado la integración de algunos contextos alrededor de la consulta [9] [30] [23]. Por lo general, se construye un perfil de usuario para reflejar los dominios de los usuarios de interés y antecedentes. Se utiliza un perfil de usuario para favorecer los documentos que están más estrechamente relacionados con el perfil. Sin embargo, un solo perfil para un usuario puede agrupar una variedad de dominios diferentes, que no siempre son relevantes para una consulta en particular. Por ejemplo, si un usuario que trabaja en informática emite un Hotel Java de consulta, los documentos sobre el idioma Java serán favorecidos incorrectamente. Una posible solución a este problema es usar perfiles o modelos relacionados con la consulta en lugar de los centrados en el usuario. En este documento, proponemos modelar dominios de temas, entre los cuales se seleccionará el (s) (s) (s) relacionado (s) para una consulta dada. Este método nos permite seleccionar un contexto específico de consulta más apropiado alrededor de la consulta. Otro factor contextual fuerte identificado en la literatura es el conocimiento del dominio o las relaciones de términos específicas del dominio, como el programa → computadora en la informática. Usando esta relación, uno podría expandir el programa de consulta con el término computadora. Sin embargo, el conocimiento del dominio está disponible solo para unos pocos dominios (p. Ej. Medicamento). La escasez de conocimientos de dominio ha llevado a la utilización del conocimiento general para la expansión de la consulta [31], que está más disponible a partir de recursos como los tesauros, o se puede extraer automáticamente de los documentos [24] [27]. Sin embargo, el uso del conocimiento general da lugar a un enorme problema de ambigüedad del conocimiento [31]: a menudo no podemos determinar si una relación se aplica a una consulta. Por ejemplo, generalmente hay poca información disponible para determinar si el programa → la computadora es aplicable al programa Java de consultas y el programa de televisión. Por lo tanto, la relación se ha aplicado a todas las consultas que contienen el programa en estudios anteriores, lo que lleva a una expansión incorrecta para el programa de televisión. Sin embargo, observando los dos ejemplos de consultas, las personas pueden determinar fácilmente si la relación es aplicable, considerando las palabras de contexto Java y la televisión. Entonces, la pregunta importante es cómo podemos servir estas palabras de contexto en consultas para seleccionar las relaciones apropiadas para aplicar. Estas palabras de contexto forman un contexto dentro de la consulta. En algunos estudios anteriores [24] [31], las palabras de contexto en una consulta se han utilizado para seleccionar los términos de expansión sugeridos por las relaciones de términos, que, sin embargo, son independientes del contexto (como el programa → computadora). Aunque se observan mejoras en algunos casos, son limitadas. Argumentamos que el problema proviene de la falta de información de contexto necesaria en las relaciones en sí, y una solución más radical radica en la adición de contextos en las relaciones. El método que proponemos es agregar palabras de contexto a la condición de una relación, como {java, programa} → computadora, para limitar su aplicabilidad al contexto apropiado. Este documento tiene como objetivo hacer contribuciones en los siguientes aspectos: • Modelo de dominio específico de consulta: construimos modelos de dominio más específicos en lugar de un solo modelo de usuario que agrupa todos los dominios. El dominio relacionado con una consulta específica se selecciona (ya sea manual o automáticamente) para cada consulta.• Contexto dentro de la consulta: integramos palabras de contexto en las relaciones de términos para que solo se puedan aplicar relaciones apropiadas a la consulta.• Factores contextuales múltiples: finalmente, proponemos un marco basado en el enfoque de modelado de lenguaje para integrar múltiples factores contextuales. Nuestro enfoque ha sido probado en varias colecciones de TREC. Los experimentos muestran claramente que ambos tipos de contexto pueden dar como resultado mejoras significativas en la efectividad de la recuperación, y sus efectos son complementarios. También mostraremos que es posible determinar automáticamente el dominio de la consulta, y esto da como resultado una efectividad comparable a una especificación manual del dominio. Este artículo está organizado de la siguiente forma: En la Sección 2, revisamos algún trabajo relacionado e presentamos el principio de nuestro enfoque. La Sección 3 presenta nuestro modelo general. Luego, las secciones 4 y 5 describen respectivamente el modelo de dominio y el modelo de conocimiento. La Sección 6 explica el método para el entrenamiento de parámetros. Los experimentos se presentan en la Sección 7 y las conclusiones en la Sección 8. 2. Contextos y utilización En IR existen muchos factores contextuales en IR: el dominio de los usuarios de interés, conocimiento sobre el tema, preferencia, la retencia de documentos, etc. [2] [14]. Entre ellos, el dominio de los usuarios de interés y conocimiento se considera entre los más importantes [20] [21]. En esta sección, revisamos algunos de los estudios en IR sobre estos aspectos. Dominio de interés y contexto en torno a la consulta Un dominio de interés especifica un fondo particular para la interpretación de una consulta. Se puede usar de diferentes maneras. La mayoría de las veces, se crea un perfil de usuario para abarcar todos los dominios de interés de un usuario [23]. En [5], un perfil de usuario contiene un conjunto de categorías de temas de ODP (Proyecto Open Directory, http://dmoz.org) identificados por el usuario. Los documentos (páginas web) clasificadas en estas categorías se utilizan para crear un vector de término, que representa todos los dominios de interés del usuario. Por otro lado, [9] [15] [26] [30], así como la búsqueda personalizada de Google [12] usa los documentos leídos por el usuario, almacenados en la computadora de los usuarios o extraídos del historial de búsqueda de usuarios. En todos estos estudios, observamos que un solo perfil de usuario (generalmente un modelo estadístico o vector) se crea para un usuario sin distinguir los diferentes dominios del tema. La aplicación sistemática del perfil de usuario puede sesgar incorrectamente los resultados para consultas no relacionadas con el perfil. Esta situación a menudo puede ocurrir en la práctica, ya que un usuario puede buscar una variedad de temas fuera de los dominios en los que ha buscado o identificado previamente. Una posible solución a este problema es la creación de múltiples perfiles, uno para un dominio de interés separado. Los dominios relacionados con una consulta se identifican de acuerdo con la consulta. Esto nos permitirá usar un perfil de consulta más apropiado, en lugar de uno centrado en el usuario. Este enfoque se utiliza en [18] en el que se utilizan los directorios ODP. Sin embargo, solo se ha llevado a cabo un experimento a pequeña escala. Se utiliza un enfoque similar en [8], donde los modelos de dominio se crean utilizando categorías ODP y las consultas de usuarios se asignan manualmente a ellos. Sin embargo, los experimentos mostraron resultados variables. No está claro si los modelos de dominio se pueden usar de manera efectiva en IR. En este estudio, también modelamos dominios de temas. Realizaremos experimentos en identificación automática y manual de dominios de consulta. Los modelos de dominio también se integrarán con otros factores. En la siguiente discusión, llamaremos al dominio del tema de una consulta un contexto sobre la consulta para contrastar con otro contexto dentro de la consulta que presentaremos. El conocimiento y el contexto dentro de la consulta debido a la falta de disponibilidad del conocimiento específico del dominio, los recursos de conocimiento general, como WordNet y las relaciones a término extraídas automáticamente, se han utilizado automáticamente para la expansión de la consulta [27] [31]. En ambos casos, las relaciones se definen entre dos términos individuales, como T1 → T2. Si una consulta contiene el término T1, entonces T2 siempre se considera un candidato para la expansión. Como mencionamos anteriormente, nos enfrentamos al problema de la ambigüedad de la relación: algunas relaciones se aplican a una consulta y otras no deberían hacerlo. Por ejemplo, el programa → la computadora no debe aplicarse al programa de TV incluso si este último contiene el programa. Sin embargo, hay poca información disponible en la relación para ayudarnos a determinar si un contexto de aplicación es apropiado. Para remediar este problema, se han propuesto enfoques para hacer una selección de términos de expansión después de la aplicación de relaciones [24] [31]. Por lo general, uno define algún tipo de relación global entre el término de expansión y toda la consulta, que generalmente es una suma de sus relaciones con cada palabra de consulta. Aunque se pueden eliminar algunos términos de expansión inapropiados porque solo están débilmente conectados a algunos términos de consulta, muchos otros permanecen. Por ejemplo, si el programa de relación → la computadora es lo suficientemente fuerte, la computadora tendrá una relación global fuerte con todo el programa de TV de consulta y sigue siendo un término de expansión. Es posible integrar un control más fuerte sobre la utilización del conocimiento. Por ejemplo, [17] definió fuertes relaciones lógicas para codificar el conocimiento de diferentes dominios. Si la aplicación de una relación conduce a un conflicto con la consulta (o con otras pruebas), entonces no se aplica. Sin embargo, este enfoque requiere codificar todas las consecuencias lógicas, incluidas las contradicciones en el conocimiento, que es difícil de implementar en la práctica. En nuestro estudio anterior [1], se propone un enfoque más simple y más general para resolver el problema en su fuente, es decir, la falta de información de contexto en las relaciones de términos: al introducir condiciones más estrictas en una relación, por ejemplo {Java, programa} →computadora y {algoritmo, programa} → computadora, la aplicabilidad de las relaciones se limitará naturalmente a contextos correctos. Como resultado, la computadora se utilizará para expandir las consultas del programa Java o el algoritmo del programa, pero no el programa de televisión. Este principio es similar al de [33] para la desambiguación del sentido de las palabras. Sin embargo, no asignamos explícitamente un significado a una palabra;Más bien tratamos de hacer diferencias entre los usos de palabras en diferentes contextos. Desde este punto de vista, nuestro enfoque es más similar a la discriminación de sentido de las palabras [27]. En este artículo, utilizamos el mismo enfoque y lo integraremos en un modelo más global con otros factores de contexto. Como las palabras de contexto agregadas en las relaciones nos permiten explotar el contexto de la palabra dentro de la consulta, llamamos a tales factores contexto dentro de la consulta. Dentro de la consulta, el contexto existe en muchas consultas. De hecho, los usuarios a menudo no usan una sola palabra ambigua como Java como consulta (si son conscientes de su ambigüedad). Algunas palabras de contexto a menudo se usan junto con él. En estos casos, los contextos dentro de la consulta se crean y se pueden explotar. Perfil de consulta y otros factores Se han hecho muchos intentos en IR para crear perfiles específicos de consulta. Podemos considerar la retroalimentación implícita o la retroalimentación ciega [7] [16] [29] [32] [35] en esta familia. Se crea un modelo de retroalimentación a corto plazo para la consulta dada de los documentos de retroalimentación, que se ha demostrado que es efectivo para capturar algunos aspectos de la intención de los usuarios detrás de la consulta. Para crear un buen modelo de consulta, se debe integrar dicho modelo de retroalimentación específica de la consulta. Hay muchos otros factores contextuales ([26]) con los que no tratamos en este documento. Sin embargo, parece claro que muchos factores son complementarios. Como se encuentra en [32], un modelo de retroalimentación crea un contexto local relacionado con la consulta, mientras que el conocimiento general o todo el corpus define un contexto global. Ambos tipos de contextos han demostrado ser útiles [32]. El modelo de dominio especifica otro tipo de información útil: refleja un conjunto de términos de fondo específicos para un dominio, por ejemplo, contaminación, lluvia, invernadero, etc. para el dominio del medio ambiente. Estos términos a menudo se presume cuando un usuario emite una consulta, como la limpieza de residuos en el dominio. Es útil agregarlos a la consulta. Vemos una clara complementariedad entre estos factores. Entonces es útil combinarlos en un solo modelo IR. En este estudio, integraremos todos los factores anteriores dentro de un marco unificado basado en el modelado de idiomas. Cada factor contextual del componente determinará un puntaje de clasificación diferente, y la clasificación final del documento los combina todos. Esto se describe en la siguiente sección.3. Modelo general IR En el marco de modelado de idiomas, una función de puntuación típica se define en la divergencia kl de la siguiente manera: () () () () dq vt dq kltptpdqscore θθθθ dqθd es un modelo de lenguaje (unigram) creado para un documento d, θq un modelo de lenguaje para la consulta q y v el vocabulario. Se reconoce que el suave en el modelo de documento es crucial [35], y uno de los métodos de suavizado comunes es el suavizado de interpolación Jelinek-Mercer: () () () () CDD TPTPP θλθλθ || 1 |+ - = (2) donde λ es un parámetro de interpolación y θc el modelo de recolección. En los enfoques básicos de modelado de idiomas, el modelo de consulta se estima mediante una estimación de máxima probabilidad (MLE) sin suavizado. En tal entorno, la operación de recuperación básica todavía se limita a la coincidencia de palabras clave, según algunas palabras en la consulta. Para mejorar la efectividad de la recuperación, es importante crear un modelo de consulta más completo que represente mejor la necesidad de la información. En particular, todas las palabras relacionadas y presuntas deben incluirse en el modelo de consulta. Se ha propuesto un modelo de consulta más completo por varios métodos utilizando documentos de retroalimentación [16] [35] o utilizando relaciones de término [1] [10] [34]. En estos casos, construimos dos modelos para la consulta: el modelo de consulta inicial que contiene solo los términos originales y un nuevo modelo que contiene los términos agregados. Luego se combinan a través de la interpolación. En este artículo, generalizamos este enfoque e integramos más modelos para la consulta. Usemos 0 Qθ para denotar el modelo de consulta original, F qθ para el modelo de retroalimentación creado a partir de documentos de retroalimentación, DOM Qθ para un modelo de dominio y k qθ para un modelo de conocimiento creado mediante la aplicación de relaciones de términos.0 Qθ puede ser creado por MLE. F qθ se ha utilizado en varios estudios anteriores [16] [35]. En este documento, F qθ se extrae utilizando los 20 documentos de retroalimentación ciega. Describiremos los detalles para construir DOM Qθ y K qθ en la Sección 4 y 5. Dados estos modelos, creamos el siguiente modelo de consulta final por interpolación: ∑∈ = Xi i qiq tptp) | () | (θαθ (3) donde x = {0, dom, k, f} es el conjunto de todos los modelos de componentese Iα (con 1 = ∑∈Xi Iα) son sus pesos de mezcla. Entonces la puntuación del documento en la ecuación (1) se extiende de la siguiente manera: () ∑∑∑años ∈ance ∈ == Xi II VT XI D I QI DQSCORETPTPDQSCORE), () | (log) | (, αθθα (4) donde) |(log) | (), (D VT I Qi TPTPDQScore θθ∑∈ = es la puntuación de acuerdo con cada modelo de componente. Aquí podemos ver que nuestra estrategia de mejorar el modelo de consulta por factores contextuales es equivalente a documentar el reanimiento, que se usa en [5] [15] [30]. El problema restante es construir modelos de dominio y modelo de conocimiento y combinar todos los modelos (configuración de parámetros). Describimos esto en las siguientes secciones.4. Construyendo y utilizando modelos de dominio como en estudios anteriores, explotamos un conjunto de documentos ya clasificados en cada dominio. Estos documentos se pueden identificar de dos maneras diferentes: 1) Uno puede tomar ventajas de una jerarquía de dominio existente y los documentos clasificados manualmente en ellos, como ODP. En ese caso, una nueva consulta debe clasificarse en los mismos dominios, ya sea manual o automáticamente.2) Un usuario puede definir sus propios dominios. Al asignar un dominio a sus consultas, el sistema puede reunir un conjunto de respuestas a las consultas automáticamente, que luego se consideran documentos en el dominio. Las respuestas podrían ser las que el usuario ha leído, examinado o juzgado relevante para una consulta en el dominio, o pueden ser simplemente los resultados de recuperación mejor clasificados. Un estudio anterior [4] ha comparado las dos estrategias anteriores utilizando las consultas TREC 51-150, para lo cual se ha asignado manualmente un dominio. Estos dominios se han asignado a categorías ODP. Se encuentra que ambos enfoques mencionados anteriormente son igualmente efectivos y dan como resultado un rendimiento comparable. Por lo tanto, en este estudio, solo usamos el segundo enfoque. Esta elección también está motivada por la posibilidad de comparar entre la asignación manual y automática de dominio con una nueva consulta. Esto se explicará en detalle en nuestros experimentos. Cualquiera sea la estrategia, obtendremos un conjunto de documentos para cada dominio, de los cuales se puede extraer un modelo de idioma. Si la estimación de máxima verosimilitud se usa directamente en estos documentos, el modelo de dominio resultante contendrá tanto términos específicos de dominio como términos generales, y el primero no emerge. Por lo tanto, empleamos un proceso EM para extraer la parte específica del dominio de la siguiente manera: suponemos que los documentos en un dominio son generados por un modelo específico de dominio (que se extraerá) y el modelo de lenguaje general (modelo de recolección). Entonces la probabilidad de un documento en el dominio se puede formular de la siguiente manera: () () () () () [] () ∏∈ + - = dt dtc cdomdom tptpdp;|| 1 |θηθηθ (5) donde c (t; d) es el recuento de t en el documento d y η es un parámetro de suavizado (que se fijará en 0.5 como en [35]). El algoritmo EM se usa para extraer el modelo de dominio DOMθ que maximiza P (DOM | θdom) (donde DOM es el conjunto de documentos en el dominio), es decir,: () () () () [] () ∏ ∏∈∈ + - = = domd dt dtc cdom domdom tptp domp dom dom;|| 1maxarg | maxarg θηθη θθ θ θ (6) Este es el mismo proceso que el que se usa para extraer el modelo de retroalimentación en [35]. Es capaz de extraer las palabras más específicas del dominio de los documentos mientras se filtra las palabras comunes del lenguaje. Esto se puede observar en la siguiente tabla, que muestra algunas palabras en el modelo de dominio del entorno antes y después de las emiteraciones (50 iteraciones). Tabla 1. Probabilidades a término antes/después de EM Término Inicial Cambio final Término Inicial Cambio final Aire 0.00358 0.00558 + 56% Año 0.00357 0.00052 - 86% Entorno 0.00213 0.00340 + 60% Sistema 0.00212 7.13*E -6 - 99% Rain 0.00197 0.00336 + 71% Programa 0.00189 Programa 0.001890.00040 - 79% contaminación 0.00177 0.00301 + 70% millón 0.00131 5.80*E -6 - 99% tormenta 0.00176 0.00302 + 72% Haga 0.00108 5.79*E -5 - 95% inundación 0.00164 0.00281 + 71% Compañía 0.00099 8.52*E -8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 8 - 899% Tornado 0.00072 0.00125 + 74% Presidente 0.00077 2.71*E -6 - 99% Greenhouse 0.00034 0.00058 + 72% Mes 0.00073 3.88*E -5 - 95% dado un conjunto de modelos de dominio, los relacionados deben asignarse a A a Anueva consulta. El usuario puede hacer esto manualmente o automáticamente por el sistema utilizando la clasificación de consultas. Compararemos ambos enfoques. La clasificación de consultas se ha investigado en varios estudios [18] [28]. En este estudio, utilizamos un método de clasificación simple: el dominio seleccionado es el que la puntuación de la divergencia KL consulta es la más baja, es decir, :) | (log) | (Minarg 0 DOM Qt Q DOM Q TPTP DOM θθ θ ∑∈ = (7) Este método de clasificación es una extensión a los bayes ingenuos como se muestra en [22]. La puntuación que depende del modelo de dominio es el siguiente: ∑∈ = Vt D DOM Qdom tptpdqscore) | (log) | (), (θθ (8) Aunque la ecuación anterior requiere usar todos los términos en el vocabulario, en la práctica, en práctica,Solo los términos más fuertes en el modelo de dominio son útiles y los términos con bajas probabilidades son a menudo ruido. Por lo tanto, solo conservamos los 100 términos más fuertes principales. La misma estrategia se utiliza para el modelo de conocimiento. Aunque los modelos de dominio son más refinados que un solo perfil de usuario, los temas en un solo dominio pueden ser muy diferentes, lo que hace que el modelo de dominio sea demasiado grande. Esto es particularmente cierto para dominios grandes, como la ciencia y la tecnología definidas en las consultas de TREC. El uso de un modelo de dominio tan grande, ya que el fondo puede introducir muchos términos de ruido. Por lo tanto, construimos aún más un modelo de subdominio más relacionado con la consulta dada, mediante el uso de un subconjunto de documentos internos que están relacionados con la consulta. Estos documentos son los documentos mejor clasificados recuperados con la consulta original dentro del dominio. Este enfoque es de hecho una combinación de modelos de dominio y retroalimentación. En nuestros experimentos, veremos que esta especificación adicional del subdominio es necesaria en algunos casos, pero no en total, especialmente cuando también se usa el modelo de retroalimentación.5. Extrayendo relaciones de término dependientes del contexto de los documentos en este documento, extraemos las relaciones de término de la recopilación de documentos automáticamente. En general, una relación de término puede representarse como A → B. Tanto A como B se han restringido a términos individuales en estudios anteriores. Un solo término en un medio que la relación es aplicable a todas las consultas que contienen ese término. Como explicamos anteriormente, esta es la fuente de muchas aplicaciones incorrectas. La solución que proponemos es agregar más términos de contexto a A, para que sea aplicable solo cuando todos los términos en un aparecen en una consulta. Por ejemplo, en lugar de crear una relación de contexto independiente de Java → Programa, crearemos {Java, Computer} → Programa, lo que significa que el programa se selecciona cuando Java y Computer aparecen en una consulta. El término agregado en la condición especifica un contexto más estricto para aplicar la relación. Llamamos a este tipo de relación relación dependiente del contexto. En principio, la adición no está restringida a un término. Sin embargo, haremos esta restricción debido a las siguientes razones: • Las consultas de los usuarios suelen ser muy cortas. Agregar más términos a la condición creará muchas relaciones raramente aplicables;• En la mayoría de los casos, una palabra ambigua como Java puede ser desambiguada efectivamente por una palabra de contexto útil, como computadora o hotel;• La adición de más términos también conducirá a un espacio más alto y complejidad del tiempo para extraer y almacenar relaciones a términos. La extracción de relaciones de tipo {TJ, TK} → Ti se puede realizar utilizando algoritmos de minería para las reglas de asociación [13]. Aquí, utilizamos un análisis simple de concurrencia. Las ventanas de tamaño fijo (10 palabras en nuestro caso) se utilizan para obtener recuentos de concurrencia de tres términos, y la probabilidad) | (kJi tttp se determina de la siguiente manera: ∑ = lt kjlkjikji tttcttttttp) ,, () ,, ()| ((9) donde) ,, (KJi TTTC es el conteo de concurrencias. Para reducir el requisito de espacio, aplicamos además los siguientes criterios de filtrado: • Los dos términos en la condición deben aparecer al menos cierto tiempo juntos en la colección (10 en nuestro caso) y deben estar relacionados. Utilizamos la siguiente información mutua puntual como una medida de relación (mi> 0) [6]:) () (), (log), (kj kJ kj tptp ttp ttmi = • La probabilidad de una relación debe ser mayor que unumbral (0.0001 en nuestro caso); con un conjunto de relaciones, el modelo de conocimiento correspondiente se define de la siguiente manera :) | () | () | () | () | () | (00) (0) (qkqjkj qtt iQkjkj qtt i k q tpttttp ttptttptp kj kj θθ θθ ∑ ∑ ∈ ∈ = = (10) donde (tj tk) ∈Q significa cualquier combinación de dos términos en la consulta. Esta es una extensión directa del modelo de traducción propuesto en [3] a nuestras relaciones dependientes del contexto. La puntuación de acuerdo con el modelo de conocimiento se define de la siguiente manera: ∑ ∑∈ ∈ = vt diqkqjkj qtt ik i kj tptpttttpdqscore) | (log) | () | () | (), (00) (θθ (11) nuevamente, nuevamente,, nuevamente, nuevamente,Solo se utilizan los 100 principales términos de expansión. 6. Parámetros del modelo Hay varios parámetros en nuestro modelo: λ en la ecuación (2) y αi (i∈ {0, Dom, K, F}) en la ecuación (3). Como el parámetro λ solo afecta el modelo de documento, lo estableceremos en el mismo valor en todos nuestros experimentos. El valor λ = 0.5 se determina para maximizar la efectividad de los modelos de referencia (ver Sección 7.2) en los datos de capacitación: TREC consultas 1-50 y documentos en el disco 2. Los pesos de la mezcla αi de los modelos de componentes están entrenados en los mismos datos de entrenamiento utilizando el siguiente método de búsqueda de línea [11] para maximizar la precisión promedio media (MAP): cada parámetro se considera como una dirección de búsqueda. Comenzamos buscando en una dirección, probando todos los valores en esa dirección, mientras mantiene los valores en otras direcciones sin cambios. Cada dirección se busca a su vez, hasta que no se observa una mejora en el mapa. Para evitar estar atrapados en un máximo local, comenzamos desde 10 puntos aleatorios y se selecciona la mejor configuración.7. Los experimentos 7.1 Configuración de los datos de la prueba principal son de las pistas AD-hoc y filtrantes TREC 1-3, incluidas las consultas 1-150, y documentos en los discos 1-3. La elección de esta colección de pruebas se debe a la disponibilidad de dominio especificado manualmente para cada consulta. Esto nos permite comparar con un enfoque utilizando la identificación de dominio automático. A continuación se muestra un ejemplo de tema: <num> Número: 103 <dom> Dominio: Ley y Gobierno <Título> Tema: Reforma de bienestar Solo usamos títulos de temas en todas nuestras pruebas. Las consultas 1-50 se utilizan para el entrenamiento y 51-150 para las pruebas.13 dominios se definen en estas consultas y sus distribuciones entre los dos conjuntos de consultas se muestran en la figura 1. Podemos ver que la distribución varía fuertemente entre dominios y entre los dos conjuntos de consultas. También hemos probado en datos TREC 7 y 8. Para esta serie de pruebas, cada colección se usa a su vez como datos de entrenamiento, mientras que la otra se usa para las pruebas. Algunas estadísticas de los datos se describen en Tab.2. Todos los documentos están preprocesados usando Porter Stemmer en Lemur y se usa la lista de parada estándar. Algunas consultas (4, 5 y 3 en los tres conjuntos de consultas) solo contienen una palabra. Para estas consultas, el modelo de conocimiento no es aplicable. En los modelos de dominio, examinamos varias preguntas: • Cuando el dominio de la consulta se especifica manualmente, ¿es útil incorporar el modelo de dominio?• Si no se especifica el dominio de la consulta, ¿se puede determinar automáticamente? ¿Qué tan efectivo es este método?• Describimos dos formas de recopilar documentos para un dominio: utilizando documentos juzgados relevantes para consultas en el dominio o usando documentos recuperados para estas consultas. ¿Cómo se comparan? En el modelo de conocimiento, además de probar su efectividad, también queremos comparar las relaciones dependientes del contexto con las independientes del contexto. Finalmente, veremos el impacto de cada modelo de componente cuando se combinen todos los factores.7.2 Métodos de referencia Se utilizan dos modelos de referencia: el modelo clásico unigram sin expansión y el modelo con retroalimentación. En todos los experimentos, los modelos de documentos se crean utilizando el suavizado Jelinek-Mercer. Esta elección se realiza según la observación en [36] de que el método funciona muy bien para consultas largas. En nuestro caso, a medida que se amplían las consultas, funcionan de manera similar a las consultas largas. En nuestras pruebas preliminares, también encontramos que este método funcionó mejor que los otros métodos (p. Dirichlet), especialmente para el método de referencia principal con el modelo de retroalimentación. La Tabla 3 muestra la efectividad de la recuperación en todas las colecciones.7.3 Modelos de conocimiento Este modelo se combina con ambos modelos de referencia (con o sin retroalimentación). También comparamos el modelo de conocimiento dependiente del contexto con las relaciones de término tradicionales independientes del contexto (definidas entre dos términos individuales), que se utilizan para expandir las consultas. Este último selecciona los términos de expansión con una relación global más fuerte con la consulta. Esta relación se mide por la suma de las relaciones con cada uno de los términos de consulta. Este método es equivalente a [24]. También es similar al modelo de traducción [3]. Lo llamamos 0 5 10 15 20 25 30 35 ENTERNIMENTOS FINANCIAS IN. M edical & bio.m ilitarypolitics Sci. & Tech. U S Econom ics U S Politics Consuly 1-50 Consulta 51-150 Figura 1. Distribución de dominios Tabla 2. TREC COLECCIÓN ESTADÍSTICAS Tamaño del documento de colección (GB) VOC.# de doc. Disco de capacitación de consultas 2 0.86 350,085 231,219 1-50 Discos 1-3 Discos 1-3 3.10 785,932 1,078,166 51-150 Discos TREC7 4-5 1.85 630,383 528,155 351-400 TREC8 DISCURAS 4-5 1.85 630,383 528,155en la Tabla 4. La prueba t también se realiza para la significación estadística. Como podemos ver, las relaciones simples de concurrencia pueden producir mejoras relativamente fuertes;Pero las relaciones dependientes del contexto pueden producir mejoras mucho más fuertes en todos los casos, especialmente cuando no se usa retroalimentación. Todas las mejoras sobre el modelo de coincurrencia son estadísticamente significativas (esto no se muestra en la tabla). Las grandes diferencias entre los dos tipos de relación muestran claramente que las relaciones dependientes del contexto son más apropiadas para la expansión de la consulta. Esto confirma la hipótesis que hicimos, que al incorporar la información de contexto en las relaciones, podemos determinar mejor las relaciones apropiadas para aplicar y así evitar la introducción de términos de expansión inapropiados. The following example can further confirm this observation, where we show the strongest expansion terms suggested by both types of relation for the query #384 space station moon: Co-occurrence Relations: year 0.016552 power 0.013226 time 0.010925 1 0.009422 develop 0.008932 offic 0.008485 oper 0.0084082 0.007875 Earth 0.007843 Trabajo 0.007801 Radio 0.007701 Sistema 0.007627 Construcción 0.007451 000 0.007403 incluyendo 0.007377 Estado 0.007076 Programa 0.007062 nación 0.006937 abierto 0.006889 Servic 0.006809 Air 0.006734 Space 0.66685 Nation 410 Compani 0.006262 Peopl 0.006244 Proyecto 0.006147 Unidad 0.006114 General 0.006036 DAI 0.006029 Contexto-Relaciones dependientes: Espacio 0.053913 Mar 0.046589 Earth 0.041786 Man 0.0377770 Programa 0.033077 Proyecto 0.026901 Base 0.025213 órbita 0.025190 Build 0.025042 Misión 0.023974 Llama 0.022573 Explor 0.021601 Lanzamiento de 0.019574 Develop 66 Plan 0.016641 Vuelo 0.016169 Estación 0.016045 pasante 0.016002 Energi 0.015556 Oper 0.014536 potencia 0.014224 transporte 0.012944 construcción0.012160 NASA 0.011985 Nation 0.011855 Perman 0.011521 Japón 0.011433 Apollo 0.010997 lunar 0.010898 en comparación con el modelo de línea de base con retroalimentación (pestaña.3), vemos que las mejoras realizadas solo por el modelo de conocimiento son ligeramente más bajas. Sin embargo, cuando ambos modelos se combinan, hay mejoras adicionales sobre el modelo de retroalimentación, y estas mejoras son estadísticamente significativas en 2 casos de 3. Esto demuestra que los impactos producidos por la retroalimentación y las relaciones a términos son diferentes y complementarios.7.4 Modelos de dominio En esta sección, probamos varias estrategias para crear y usar modelos de dominio, explotando la información de dominio de la consulta establecida de varias maneras. Estrategias para crear modelos de dominio: C1: con los documentos relevantes para las consultas de dominio: esta estrategia simula el caso en el que tenemos un directorio existente en el que se incluyen documentos relevantes para el dominio. C2: con los 100 documentos superiores recuperados con las consultas intermedias: esta estrategia simula el caso en el que el usuario especifica un dominio para sus consultas sin juzgar la relevancia del documento, y el sistema recopila documentos relacionados de su historial de búsqueda. Estrategias para usar modelos de dominio: U1: el usuario determina el modelo de dominio manualmente. U2: el modelo de dominio está determinado por el sistema.7.4.1 Creación de modelos de dominio Probamos estrategias C1 y C2. En esta serie de pruebas, cada una de las consultas 51-150 se usa a su vez como la consulta de prueba, mientras que las otras consultas y sus documentos relevantes (C1) o documentos recuperados (C2) de primer nivel se utilizan para crear modelos de dominio. El mismo método se usa en las consultas 1-50 para ajustar los parámetros. Tabla 3. Modelos de línea de base Modelo Unigram Coll. Medente sin FB con FB AVGP 0.1570 0.2344 (+49.30%) Recuerde /48 355 15 711 19 513 Disks 1-3 P@10 0.4050 0.5010 AVGP 0.1656 0.2176 (+31.40%) Recuerdos /4 674 2 237 2 777TREC7 P@10 0.3420 0.3860AVGP 0.2387 0.2909 (+21.87%) Recuerde /4 728 2 764 3 237Tec8 P@10 0.4340 0.4860 Tabla 4. Modelos de conocimiento Co-Occurrence Modelo de conocimiento Coll. Medida sin FB con FB sin FB con FB AVGP 0.1884 (+20.00%) ++ 0.2432 (+3.75%) ** 0.2164 (+37.83%) ++ 0.2463 (+5.08%) ** Recuerdos /48 355 17 430 020 02018 944 20 260 discos1-3 p@10 0.4640 0.5160 0.5050 0.5120 AVGP 0.1823 (+10.08%) ++ 0.2350 (+8.00%)* 0.2157 (+30.25%) ++ 0.2401 (+10.34%)2 329 2 933 2 709 2 985 trec7 p@10 0.3780 0.3760 0.3900 0.3900 AVGP 0.2519 (+5.53%) 0.2926 (+0.58%) 0.2724 (+14.12%)279 3 090 3 338 TREC8 P@10 0.4360 0.4940 0.4720 0.5000 (la columna sin FB se compara con el modelo de referencia sin retroalLa línea de base sin retroalimentación, a nivel de p <0.01 y p <0.05, respectivamente. ** y * son similares pero en comparación con el modelo de referencia con retroalimentación). Tabla 5. Modelos de dominio con documentos relevantes (C1) Subdominio de dominio Coll. Medida sin FB con FB sin FB con FB AVGP 0.1700 (+8.28%) ++ 0.2454 (+4.69%) ** 0.1918 (+22.17%) ++ 0.2461 (+4.99%) ** Recuerdo /48 355 16 517 20 14117 872 20 212 Discos1-3 (U1) P@10 0.4370 0.5130 0.4490 0.5150 AVGP 0.1715 (+3.56%) ++ 0.2389 (+9.79%)* 0.1842 (+11.23%) ++ 0.2408 (+10.66%) ** Record/4 674 2 270 2 965 2 428 2 987 TREC7 (U2) P@10 0.3720 0.3740 0.3880 0.3760 AVGP 0.2442 (+2. 30%) 0.2957 (+1.65%) 0.2563 (+7.37%) 0.2967 (+1.99%) Recarsion/4 728 2 796 3 308 2 873 3 302 TREC8 (U2) P@10 0.4420 0.5000 0.4280 0.5020 Tabla 6. Modelos de dominio con el subdominio de dominio de los 100 documentos (C2) Coll. Medida sin FB con FB sin FB con FB AVGP 0.1718 (+9.43%) ++ 0.2456 (+4.78%) ** 0.1799 (+14.59%) ++ 0.2452 (+4.61%) ** Recuerdo /48 355 16 558 20 13117 341 20 155 discos1-3 (U1) P@10 0.4300 0.5140 0.4220 0.5110 AVGP 0.1765 (+6.58%) ++ 0.2395 (+10.06%) ** 0.1785 (+7.79%) ++ 0.2393 (+9.97%) **RECUERDO /4 674 2 319 2 969 2 254 2 968 TREC7 (U2) P@10 0.3780 0.3820 0.3820 0.3820 AVGP 0.2434 (+1.97%) 0.2949 (+1.38%) 0.2441 (+2.26%) 0.2961 (+1.79%) Recall / / / / / / /4 728 2 772 3 318 2 734 3 311 TREC8 (U2) P@10 0.4380 0.4960 0.4280 0.5020 También comparamos los modelos de dominio creados con todos los documentos de indominio (dominio) y solo con los 10 documentos recuperados en el dominio con elconsulta (subdominio). En estas pruebas, utilizamos la identificación manual del dominio de consulta para los discos 1-3 (U1), pero la identificación automática para TREC7 y 8 (U2). Primero, es interesante notar que la incorporación de modelos de dominio generalmente puede mejorar la efectividad de la recuperación en todos los casos. Las mejoras en los discos 1-3 y TREC7 son estadísticamente significativas. Sin embargo, las escalas de mejora son más pequeñas que el uso de modelos de retroalimentación y relación. Al observar la distribución de los dominios (Fig. 1), esta observación no es sorprendente: para muchos dominios, solo tenemos pocas consultas de entrenamiento, por lo tanto, pocos documentos de indoma para crear modelos de dominio. Además, los temas en el mismo dominio pueden variar mucho, en particular en grandes dominios como ciencia y tecnología, política internacional, etc. En segundo lugar, observamos que los dos métodos para crear modelos de dominio funcionan igualmente bien (Tab. 6 vs. Tab. 5). En otras palabras, proporcionar juicios de relevancia para consultas no agrega mucha ventaja con el fin de crear modelos de dominio. Esto puede parecer sorprendente. Un análisis muestra inmediatamente la razón: un modelo de dominio (en la forma en que creamos) solo captura la distribución de términos en el dominio. Los documentos relevantes para todas las consultas internos varían mucho. Por lo tanto, en algunos dominios grandes, los términos característicos tienen efectos variables en las consultas. Por otro lado, como solo usamos la distribución de términos, incluso si los documentos superiores recuperados para las consultas en el dominio son irrelevantes, aún pueden contener términos característicos de dominio de manera similar a los documentos relevantes. Por lo tanto, ambas estrategias producen efectos muy similares. Este resultado abre la puerta para un método más simple que no requiere juicios de relevancia, por ejemplo, utilizando el historial de búsqueda. Tercero, sin modelo de retroalimentación, los modelos de subdominio construidos con documentos relevantes funcionan mucho mejor que los modelos de dominio completos (Tab. 5). Sin embargo, una vez que se usa el modelo de retroalimentación, la ventaja desaparece. Por un lado, esto confirma nuestra hipótesis anterior de que un dominio puede ser demasiado grande para poder sugerir términos relevantes para nuevas consultas en el dominio. Valida indirectamente nuestra primera hipótesis de que un solo modelo de usuario o perfil puede ser demasiado grande, por lo que se prefieren modelos de dominio más pequeños. Por otro lado, los modelos de subdominios capturan características similares al modelo de retroalimentación. Entonces, cuando se usa este último, los modelos de subdominio se vuelven superfluos. Sin embargo, si los modelos de dominio se construyen con documentos de alto rango (Tab. 6), los modelos de subdominios hacen muchas menos diferencias. Esto puede explicarse por el hecho de que los dominios construidos con documentos de alto rango tienden a ser más uniformes que los documentos relevantes con respecto a la distribución del término, ya que los documentos recuperados superiores generalmente tienen una correspondencia estadística más fuerte con las consultas que los documentos relevantes.7.4.2 Determinación del dominio de consulta automáticamente No es realista pedir siempre a los usuarios que especifiquen un dominio para sus consultas. Aquí, examinamos la posibilidad de identificar automáticamente los dominios de consultas. La Tabla 7 muestra los resultados con esta estrategia utilizando ambas estrategias para la construcción del modelo de dominio. Podemos observar que la efectividad es solo ligeramente menor que las producidas con la identificación manual del dominio de consulta (tab. 5 y 6, modelos de dominio). Esto muestra que la identificación de dominio automático es una forma de seleccionar el modelo de dominio tan efectivo como la identificación manual. Esto también demuestra la viabilidad de usar modelos de dominio para consultas cuando no se proporciona información de dominio. Sin embargo, observando la precisión de la identificación de dominio automático, es sorprendentemente bajo: para las consultas 51-150, solo el 38% de los dominios determinados corresponden a las identificaciones manuales. Esto es mucho más bajo que las tasas anteriores del 80% reportadas en [18]. Un análisis detallado revela que la razón principal es la cercanía de varios dominios en las consultas TREC (p. Ej. Relaciones internacionales, política internacional, política). Sin embargo, en esta situación, los dominios incorrectos asignados a las consultas no siempre son irrelevantes e inútiles. Por ejemplo, incluso cuando una consulta en las relaciones internacionales se clasifica en la política internacional, el último dominio aún puede sugerir términos útiles para la consulta. Por lo tanto, la precisión de clasificación relativamente baja no significa baja utilidad de los modelos de dominio.7.5 Modelos completos Los resultados con el modelo completo se muestran en la Tabla 8. Este modelo integra todos los componentes descritos en este documento: modelo de consulta original, modelo de retroalimentación, modelo de dominio y modelo de conocimiento. Hemos probado ambas estrategias para crear modelos de dominio, pero las diferencias entre ellos son muy pequeñas. Por lo tanto, solo informamos los resultados con los documentos relevantes. Nuestra primera observación es que los modelos completos producen los mejores resultados. Todas las mejoras sobre el modelo de referencia (con retroalimentación) son estadísticamente significativas. Este resultado confirma que la integración de factores contextuales es efectiva. En comparación con los otros resultados, vemos mejoras consistentes, aunque pequeñas, en algunos casos, sobre todos los modelos parciales. Al observar los pesos de la mezcla, que pueden reflejar la importancia de cada modelo, observamos que la mejor configuración en todas las colecciones varía en los siguientes rangos: 0.1≤α0 ≤0.2, 0.1≤αdom ≤0.2, 0.1≤αK ≤0.2 y 0.5≤αf ≤0.6. Vemos que el factor más importante es el modelo de retroalimentación. Este es también el factor único que produjo las mejoras más altas sobre el modelo de consulta original. Esta observación parece indicar que este modelo tiene la mayor capacidad para capturar la información que necesita detrás de la consulta. Sin embargo, incluso con pesos más bajos, los otros modelos tienen fuertes impactos en la efectividad final. Esto demuestra el beneficio de integrar más factores contextuales en IR. Tabla 7. Identificación de dominio de consulta automática (U2) DOM.con Rel.doc.(C1) Dom.con Top-100 Doc.(C2) Coll. Mida sin FB con FB sin FB con FB AVGP 0.1650 (+5.10%) ++ 0.2444 (+4.27%) ** 0.1670 (+6.37%) ++ 0.2449 (+4.48%) ** Recuerda 16 343 20 061 16 414 20 20090 discos 1-3 (U2) P@10 0.4270 0.5100 0.4090 0.5140 Tabla 8. Modelos completos (C1) Todos los doc. Dominio col. Medir el hombre.Dom.identificación.(U1) Auto.Dom.identificación.(U2) AVGP 0.2501 (+6.70%) ** 0.2489 (+6.19%) ** Recuerdo /48 355 20 514 20 367 Discos 1-3 P@10 0.5200 0.5230 AVGP 0.2462 (+13.14%) ** RECURS3 014TREC7 P@10 N/A 0.3960 AVGP 0.3029 (+4.13%) ** RECUERDO/4 728 3 321TREC8 P@10 N/A 0.5020 8. Conclusiones Los enfoques IR tradicionales generalmente consideran la consulta como el único elemento disponible para la información del usuario que necesita. Muchos estudios anteriores han investigado la integración de algunos factores contextuales en los modelos IR, típicamente al incorporar un perfil de usuario. En este documento, argumentamos que un solo perfil de usuario (o modelo) puede contener una variedad demasiado grande de temas diferentes para que las nuevas consultas puedan ser sesgadas incorrectamente. De manera similar a algunos estudios anteriores, proponemos modelar dominios de temas en lugar del usuario. Investigaciones previas sobre el contexto se centraron en factores alrededor de la consulta. Mostramos en este documento que los factores dentro de la consulta también son importantes: ayudan a seleccionar las relaciones de término apropiadas para aplicar en la expansión de la consulta. Hemos integrado los factores contextuales anteriores, junto con el modelo de retroalimentación, en un solo modelo de lenguaje. Nuestros resultados experimentales confirman fuertemente el beneficio de usar contextos en IR. Este trabajo también muestra que el marco de modelado de idiomas es apropiado para integrar muchos factores contextuales. Este trabajo puede mejorarse aún más en varios aspectos, incluidos otros métodos para extraer relaciones a términos, integrar más palabras de contexto en condiciones e identificar los dominios de consulta. También sería interesante probar el método en la búsqueda web utilizando el historial de búsqueda de usuarios. Investigaremos estos problemas en nuestra investigación futura.9. Referencias [1] Bai, J., Nie, J.Y., Cao, G., Relaciones de término dependientes del contexto para la recuperación de información, EMNLP06, pp. 551-559, 2006. [2] Belkin, N.J., Interacción con textos: Recuperación de informacióncomo comportamiento de búsqueda de información, recuperación de información93: von der Modellierung Zu Anwendung, pp. 55-66, Konstanz: Krause & Womser-Hacker, 1993. [3] Berger, A., Lafferty, J., Recuperación de información como traducción estadística, Sigir99, págs. 222-229, 1999. [4] Bouchard, H., Nie, J.Y., Modèles de Langue Appliques à la Rechen Dinformation Contextuelle, conf.En Recherche DinFormation et Applications (Coria), Lyon, 2006. [5] Chirita, P.A., Paiu, R., Nejdl, W., Kohlschütter, C., utilizando metadatos ODP para personalizar la búsqueda, Sigir, pp. 178-185,2005. [6] Church, K. W., Hanks, P., Normas de asociación de palabras, información mutua y lexicografía. ACL, pp. 22-29, 1989. [7] Croft, W. B., Cronen-Townsend, S., Lavrenko, V., Comentarios de relevancia y personalización: una perspectiva de modelado de idiomas, en: El taller de Delos-NSF sobre personalización y recomendaciónBibliotecas de Sistemas Digital, pp. 49-54, 2006. [8] Croft, W. B., Wei, X., Modelos de temas basados en el contexto para la modificación de la consulta, CIIR Technical Report, University of Massachusetts, 2005. [9] Dumais, S., CUTRELL, E., Cadiz, J., Jancke, G., Sarin, R., Robbins, D. C., Stuff ive Vistent: Un sistema para recuperación y reutilización de información personal, Sigir03, pp. 72-79, 2003.[10] Fang, H., Zhai, C., Matricción de términos semánticos en enfoques axiomáticos para la recuperación de información, Sigir06, pp.115-122, 2006. [11] Gao, J., Qi, H., Xia, X., Nie, J.-Y., modelo discriminativo lineal para la recuperación de información. Sigir05, pp. 290-297, 2005. [12] GOOLE Search Personalized, http://www.google.com/psearch.[13] Hipp, J., Guntzer, U., Nakhaeizadeh, G., Algoritmos para la minería de reglas de asociación: una encuesta general y comparación. Sigkdd Explorations, 2 (1), págs. 58-64, 2000. [14] Ingwersen, P., Jäverlin, K., Recuperación de información en contexto: Irix, Foro de Sigir, 39: pp. 31-39, 2004. [[15] Kim, H.-R., Chan, P.K., Ranking personalizado de resultados de búsqueda con jerarquías de interés de usuario aprendidas de marcadores, Webkdd05 Workshop en ACM-KDD, pp. 32-43, 2005. [16] Lavrenko, V.,Croft, W. B., Modelos de idiomas basados en relevancia, Sigir01, pp. 120-127, 2001. [17] Lau, R., Bruza, P., Song, D., Revisión de creencias para la recuperación de información adaptativa, Sigir04, pp. 130-137, 2004. [18] Liu, F., Yu, C[19] Liu, X., Croft, W. B., Recuperación basada en clúster utilizando modelos de idiomas, Sigir 04, pp. 186-193, 2004. [20] Morris, R.C., hacia un servicio de información centrado en el usuario, Jasis, 45:pp. 20-30, 1994. [21] Park, T.K., Hacia una teoría de la relevancia basada en el usuario: una llamada para un nuevo paradigma de investigación, Jasis, 45: pp. 135-141, 1994. [22] Peng,F., Schuurmans, D., Wang, S. Aumento de los clasificadores ingenuos de Bayes con modelos de lenguaje estadístico. Inf. RECR.7 (3-4): pp. 317-345, 2004. [23] Pitkow, J., Schütze, H., Cass, T., Cooley, R., Turnbull, D., Edmonds, A., Adar,E., Breuel, T., Búsqueda personalizada, Comunicaciones de ACM, 45: pp. 50-55, 2002. [24] Qiu, Y., Frei, H.P. Expansión de consultas basada en el concepto. Sigir93, pp.160-169, 1993. [25] Sanderson, M., Recuperando con buen sentido, Inf. Ret., 2 (1): pp. 49-69, 2000. [26] Schamber, L., Eisenberg, M.B., Nilan, M.S., una reexaminación de relevancia: hacia una definición dinámica y situacional, procesamiento y gestión de la información, 26(6): pp. 755-774, 1990. [27] Schütze, H., Pedersen J.O., un tesauro basado en la coincurrencia y dos aplicaciones para la recuperación de información, procesamiento y gestión de información, 33 (3): pp. 307-318, 1997. [28] Shen, D., Pan, R., Sun, J-T., Pan, J.J., Wu, K., Yin, J., Yang, Q. Enriquecimiento de consultas para la clasificación de cuidias web. ACMTOIS, 24 (3): pp. 320-352, 2006. [29] Shen, X., Tan, B., Zhai, C., Recuperación de información sensible al contexto utilizando retroalimentación implícita, Sigir05, pp. 43-50,2005. [30] Teevan, J., Dumais, S.T., Horvitz, E., Personalización de la búsqueda a través del análisis automatizado de intereses y actividades, Sigir05, pp. 449-456, 2005. [31] Voorhees, E., Expansión de consultas utilizandoRelaciones léxicas semánticas. Sigir94, pp. 61-69, 1994. [32] Xu, J., Croft, W.B., Expansión de consultas utilizando el análisis de documentos locales y globales, Sigir96, pp. 4-11, 1996. [33] Yarowsky, D. Word Unspervado UnspervadoDesambiguación de sentido rivalizando métodos supervisados. ACL, pp. 189-196.1995. [34] Zhou X., Hu X., Zhang X., Lin X., Song I-Y., Context Semántico Semántico para el enfoque de modelado de lenguaje para Genomic IR, Sigir06, pp. 170-177, 2006. [35]Zhai, C., Lafferty, J., Comentarios basados en modelos en el enfoque de modelado de idiomas para la recuperación de información, CIKM01, pp. 403-410, 2001. [36] Zhai, C., Lafferty, J., Un estudio de suavizadoMétodos para modelos de idiomas aplicados a la recuperación de información ad-hoc. Sigir, pp.334-342, 2001.