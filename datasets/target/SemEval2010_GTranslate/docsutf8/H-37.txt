SVMS en línea relajados para el filtrado de spam D. Sculley Tufts University Departamento de Ciencias de la Computación 161 College Ave., Medford, MA USA DSCulleycs.tufts.edu Gabriel M. Wachman Tufts University Departamento de Ciencias de la Computación 161 College Ave., Medford, MA Gwachm01cs.Tufts.Edu Abstract Spam es un problema clave en la comunicación electrónica, incluidos los sistemas de correo electrónico a gran escala y el creciente número de blogs. El filtrado basado en el contenido es un método confiable para combatir esta amenaza en sus diversas formas, pero algunos investigadores académicos y profesionales industriales no están de acuerdo sobre la mejor manera de filtrar el spam. Los primeros han abogado por el uso de máquinas de vectores de soporte (SVM) para el filtrado basado en el contenido, ya que esta metodología de aprendizaje automático ofrece un rendimiento de última generación para la clasificación de texto. Sin embargo, aún no se han demostrado ganancias de rendimiento similares para el filtrado de spam en línea. Además, los profesionales citan el alto costo de las SVM como razón para preferir métodos bayesianos más rápidos (aunque menos estadísticamente robustos). En este artículo, ofrecemos una resolución a esta controversia. Primero, mostramos que los SVM en línea de hecho brindan un rendimiento de clasificación de última generación en el filtrado de spam en línea en grandes conjuntos de datos de referencia. En segundo lugar, mostramos que un rendimiento casi equivalente puede lograrse mediante un SVM en línea relajado (ROSVM) a un costo computacional muy reducido. Nuestros resultados se verifican experimentalmente en el correo electrónico spam, el spam de blog y las tareas de detección de Splog. Categorías y descriptores de sujetos H.3.3 [Algoritmos 1 de almacenamiento y recuperación de información]: Búsqueda y recuperación de información - Medición de términos generales de spam, experimentación, algoritmos 1. Introducción La comunicación electrónica está cada vez más plagada de contenido no deseado o dañino conocido como spam. La forma más conocida de spam es el correo electrónico spam, que sigue siendo un problema importante para los grandes sistemas de correo electrónico. Otras formas de spam también se están volviendo problemáticas, incluido el spam del blog, en el que los spammers publican comentarios no deseados en los blogs [21], y Splogs, que son blogs falsos construidos para permitir el enlace spam con la esperanza de aumentar la importancia medida de una página web dada enLos ojos de los motores de búsqueda automatizados [17]. Existen una variedad de métodos para identificar estas muchas formas de spam, incluida la compilación de listas negras de spammers conocidos y realizar análisis de enlaces. El enfoque del análisis de contenido ha mostrado una promesa y generalidad particular para combatir el spam. En el análisis de contenido, el texto del mensaje real (a menudo incluye hiper-texto y meta-texto, como HTML y encabezados) se analiza utilizando técnicas de aprendizaje automático para la clasificación de texto para determinar si el contenido dado es spam. El análisis de contenido se ha aplicado ampliamente al detectar el correo electrónico spam [11], y también se ha utilizado para identificar el spam del blog [21] y Splogs [17]. En este documento, no exploramos el problema relacionado del spam de enlace, que actualmente se combina mejor mediante análisis de enlaces [13].1.1 Una controversia anti-Spama La comunidad anti-Spama se ha dividido en la elección del mejor método de aprendizaje automático para la detección de spam basada en el contenido. Los investigadores académicos han tendido a favorecer el uso de Máquinas de vectores de soporte (SVM), un método de aprendizaje automático estadísticamente robusto [7] que produce el rendimiento del estado de la clasificación de texto general [14]. Sin embargo, las SVM generalmente requieren un tiempo de entrenamiento cuadrático en el número de ejemplos de capacitación, y no son prácticos para los sistemas de correo electrónico a gran escala. Los profesionales que requieren filtrado de spam basado en el contenido generalmente han elegido usar el método de aprendizaje automático más rápido (aunque menos robusto) de la clasificación de texto de Naive Bayes [11, 12, 20]. Este método bayesiano solo requiere tiempo de capacitación lineal, y se implementa fácilmente en un entorno en línea con actualizaciones incrementales. Esto permite que un sistema implementado se adapte fácilmente a un entorno cambiante con el tiempo. Otros métodos rápidos para el filtrado de spam incluyen modelos de compresión [1] y regresión logística [10]. Todavía no se ha demostrado empíricamente que las SVM brindan un rendimiento mejorado sobre estos métodos en una configuración de detección de spam en línea [4].1.2 Contribuciones En este documento, abordamos la controversia contra el SPAM y ofrecemos una resolución potencial. Primero demostramos que los SVM en línea de hecho proporcionan detección de spam de última generación a través de pruebas empíricas en varios conjuntos de datos de referencia grandes de correo no deseado. Luego analizamos el efecto del parámetro de compensación en la función objetivo SVM, que muestra que la costosa metodología SVM puede, de hecho, ser exagerada para la detección de spam. Reducimos el costo computacional del aprendizaje SVM relajando este requisito en el margen máximo en la configuración en línea, y creamos un SVM en línea relajado, ROSVM, apropiado para el filtrado de spam basado en el contenido de alto rendimiento en entornos a gran escala.2. SPAM y SVM en línea La controversia entre académicos y profesionales en el filtrado de spam se centra en el uso de SVM. Los primeros abogan por su uso, pero aún no han demostrado un fuerte rendimiento con los SVM en el filtrado de spam en línea. De hecho, los resultados de [4] muestran que, cuando se usan con parámetros predeterminados, los SVM en realidad funcionan peor que otros métodos. En esta sección, revisamos el funcionamiento básico de las SVM y describimos un algoritmo SVM en línea simple. Luego mostramos que las SVM en línea de hecho logran un rendimiento de última generación en el filtrado de spam por correo electrónico, spam de comentarios de blog y SPLOG, siempre que el parámetro C de compensación C esté establecido en un alto valor. Sin embargo, el costo de las estafas en línea resulta ser prohibitiva para aplicaciones a gran escala. Estos hallazgos motivan nuestra propuesta de SVM en línea relajados en la siguiente sección.2.1 Antecedentes: SVMS SVMS es una metodología de aprendizaje automático robusto que se ha demostrado que produce un rendimiento de última generación en la clasificación de texto [14].Al encontrar un hiperplano que separe dos clases de datos en el espacio de datos al tiempo que maximiza el margen entre ellos. Utilizamos la siguiente notación para describir SVMS, que se basa en [23]. Un conjunto de datos X contiene n vectores de ejemplo etiquetados {(x1, y1)...(xn, yn)}, donde cada Xi es un vector que contiene características que describe el ejemplo I, y cada Yi es la etiqueta de clase para ese ejemplo. En la detección de spam, a las clases de spam y jamón (es decir, no spam) se les asigna las etiquetas de clase numérica +1 y −1, respectivamente. Los SVM lineales que empleamos en este documento usan un vector de hipótesis W y BIAS Término B para clasificar un nuevo ejemplo X, generando una etiqueta de clase predicha F (x): f (x) = signo (<w, x> +b)SVMS Encuentre la hipótesis W, que define el hiperplano de separación, minimizando la siguiente función objetivo sobre todos los n ejemplos de entrenamiento: τ (w, ξ) = 1 2 || w || 2 + c nx i = i ξi bajo las limitaciones que∀i = {1..n}: yi (<w, xi> +b) ≥ 1 - ξi, ξi ≥ 0 En esta función objetivo, cada variable floja ξi muestra la cantidad de error que el clasificador hace en un ejemplo dadoxi. Minimizar la suma de las variables flojas corresponde a minimizar la función de pérdida en los datos de entrenamiento, mientras que minimizar el término 1 2 || w || 2 corresponde a maximizar el margen entre las dos clases [23]. Estos dos objetivos de optimización a menudo están en conflicto;El parámetro de compensación C determina cuánta importancia dar cada una de estas tareas. SVMS lineal explota la escasez de datos para clasificar una nueva instancia en el tiempo O (S), donde S es el número de características distintas de cero. Este es el mismo tiempo de clasificación que otro lineal dado: conjunto de datos x = (x1, y1) ,..., (xn, yn), c, m: inicializar w: = 0, b: = 0, seendata: = {} para cada xi ∈ X do: clasificar xi usando f (xi) = signo (<w, xi> +b) Si yif (xi) <1 encuentra w, b usando Smo en Seendata, usando W, B como hipótesis de semillas. Agregue Xi a SEENDATA realizado Figura 1: Pseudo Código para SVM en línea.clasificadores, y como clasificación bayesiana ingenua. La capacitación de SVM, sin embargo, generalmente lleva el tiempo O (N2), para N ejemplos de capacitación. Recientemente se propuso una variante para las SVM lineales en qué trenes en el tiempo O (NS) [15], pero debido a que este método tiene una constante alta, no lo exploramos aquí.2.2 SVM en línea En muchas aplicaciones tradicionales de aprendizaje automático, los SVM se aplican en modo por lotes. Es decir, un SVM está entrenado en un conjunto completo de datos de entrenamiento, y luego se prueba en un conjunto separado de datos de prueba. El filtrado de spam generalmente se prueba e implementa en una configuración en línea, que procede de forma incremental. Aquí, el alumno clasifica un nuevo ejemplo, se dice si su predicción es correcta, actualiza su hipótesis en consecuencia y luego espera un nuevo ejemplo. El aprendizaje en línea permite que un sistema implementado se adapte en un entorno cambiante. Re-capitando un SVM desde cero en todo el conjunto de datos vistos anteriormente para cada nuevo ejemplo es el costo prohibitivo. Sin embargo, el uso de una hipótesis antigua como punto de partida para volver a capacitar reduce este costo considerablemente. Se propuso un método de aprendizaje SVM incremental y decremental en [2]. Debido a que solo nos preocupa el aprendizaje incremental, aplicamos un algoritmo más simple para convertir un alumno de SVM por lotes en un SVM en línea (ver Figura 1 para el pseudocódigo), que es similar al enfoque de [16]. Cada vez que el SVM en línea se encuentra con un ejemplo que estaba mal clasificado, se vuelve a conectar con la antigua hipótesis como punto de partida. Tenga en cuenta que debido a las condiciones de Karush-Kuhn-Tucker (KKT), no es necesario volver a entrenar en ejemplos bien clasificados que están fuera de los márgenes [23]. Utilizamos el algoritmo SMO PLATTS [22] como un solucionador SVM central, ya que es un método iterativo que es adecuado para converger rápidamente de una buena hipótesis inicial. Debido a que el trabajo previo (y nuestras propias pruebas iniciales) indica que los valores de características binarias dan los mejores resultados para el filtrado de spam [20, 9], optimizamos nuestra implementación de la SMO en línea para explotar los productos internos rápidos con vectores binarios.1 2.3 Mapeo de características Contenido de spam Extracción de las características de aprendizaje automático del texto se pueden hacer de varias maneras, especialmente cuando ese texto puede incluir hipercontente y meta-contenido, como HTML y información de encabezado. Sin embargo, investigaciones anteriores han demostrado que los métodos simples de la clasificación de texto, como los vectores de palabras y las n-gramos superpuestas a nivel de caracteres, pueden lograr resultados fuertes [9]. Formalmente, una bolsa de palabras vector es un vector X con una dimensión única para cada uno posible 1 nuestro código fuente está disponible gratuitamente en www.cs.tufts.edu/∼dsculley/onlinesmo.1 0.999 0.995 0.99 0.985 0.98 0.1 1 10 100 1000 ROCAREA C 2 gramos 3 gramos 4 gramos Palabras Figura 2: Ajustar el parámetro de compensación C. Las pruebas se realizaron con SMO en línea, utilizando vectores de características binarias, en el conjunto de datos de Spamassin del conjunto de datos de spamassin del conjunto de datos de spamassin del conjunto de datos de spamassin de6034 ejemplos. Gráficos gráficos C versus área debajo de la curva ROC.Palabra, definida como una subcadena contigua de caracteres no blancos. Un vector N-Gram es un vector X con una dimensión única para cada posible subcadena de N Total caracteres. Tenga en cuenta que los N-Grams pueden incluir espacios en blanco y se superponen. Utilizamos la puntuación de características binarias, que se ha demostrado que es más efectiva para una variedad de métodos de detección de spam [20, 9]. Normalizamos los vectores con la norma euclidiana. Además, con los datos de correo electrónico, reducimos el impacto de los mensajes largos (por ejemplo, con archivos adjuntos) considerando solo los primeros 3.000 caracteres de cada cadena. Para los comentarios del blog y Splogs, consideramos todo el texto, incluidos cualquier meta-datos, como etiquetas HTML, como se indica. No se utilizó otra selección de características o conocimiento del dominio.2.4 Ajuste del parámetro de compensación, c El parámetro de compensación SVM C debe ajustarse para equilibrar los objetivos (potencialmente conflictivos) de maximizar el margen y minimizar el error de entrenamiento. El trabajo temprano en la detección de spam basada en SVM [9] mostró que los valores altos de C dan el mejor rendimiento con las características binarias. El trabajo posterior no siempre ha seguido este plomo: se usó una configuración (baja) predeterminada de C en la detección de SPLOG [17], y también en correo no deseado [4]. Después de la práctica estándar de aprendizaje automático, sintonizamos C en datos de sintonización separados que no se usan para pruebas posteriores. Utilizamos el conjunto de datos de spam de correo electrónico de SpamassAnsin disponibles públicamente y creamos una tarea de aprendizaje en línea intercalando aleatoriamente todos los mensajes etiquetados 6034 para crear un solo conjunto ordenado. Para el ajuste, realizamos una búsqueda de parámetros grueso para C usando poderes de diez de .0001 a 10000. Utilizamos el SVM en línea descrito anteriormente y probamos tanto los vectores de la bolsa binaria de las palabras y los vectores N-Gram con n = {2, 3, 4}. Utilizamos los primeros 3000 caracteres de cada mensaje, que incluía información de encabezado, cuerpo del correo electrónico y posiblemente archivos adjuntos. Después de la recomendación de [6], utilizamos el área bajo la curva ROC como nuestra medida de evaluación. Los resultados (ver Figura 2) están de acuerdo con [9]: hay una meseta de alto rendimiento lograda con todos los valores de C ≥ 10, y el rendimiento se degrada bruscamente con C <1. Para el resto de nuestros experimentos con SVM en este documento, establecemos C = 100. Volveremos a la observación de que los valores muy altos de C no degradan el rendimiento como soporte para la intuición de que las SVM relajadas deben funcionar bien en el spam. Tabla 1: Resultados para el filtrado de spam por correo electrónico con SVM en línea en conjuntos de datos de referencia. La puntuación reportada es (1-Roca)%, donde 0 es óptimo.TREC05P-1 TREC06P ONSVM: palabras 0.015 (.011-.022) 0.034 (.025-.046) 3 gramos 0.011 (.009-.015) 0.025 (.017-.035) 4 gramos 0.008 (.007-.011) 0.023 (.017-.032) SPAMPROBE 0.059 (.049-.071) 0.092 (.078-.110) Bogofilter 0.048 (.038-.062) 0.077 (.056-.105) TREC ganadores 0.019 (.015-.023) 0.054 (.034-.085) 53-confirmación 0.007 (.005-.008) 0.020 (.007-.050) Tabla 2: Resultados para la detección de spam de comentarios de blog usando SVMS y deje una validación cruzada. Reportamos las mismas medidas de rendimiento que en el trabajo anterior para una comparación significativa.precisión precisión recordar SVM C = 100: palabras 0.931 0.946 0.954 3 gramos 0.951 0.963 0.965 4 gramos 0.949 0.967 0.956 Mejor mejor método 0.83 0.874 0.874 2.5 Spam de correo electrónico y SVM en línea con C Añedado en un conjunto de ajuste separado, luego probamos el rendimiento del rendimientode SVM en línea en detección de spam. Utilizamos dos grandes conjuntos de datos de referencia de correo electrónico spam como nuestros corpus de prueba. Estos conjuntos de datos son el conjunto de datos públicos TREC 2005 TREC05P-1 de 92,189 mensajes, y los conjuntos de datos públicos TREC 2006, TREC06P, que contienen 37,822 mensajes en inglés.(No informamos nuestros fuertes resultados en el Corpus TREC06C de los mensajes chinos, ya que se han planteado preguntas sobre la validez de este conjunto de pruebas). Utilizamos el pedido canónico proporcionado con cada uno de estos conjuntos de datos para una comparación justa. Los resultados para estos experimentos, con la bolsa de vectores de palabras y los vectores N-Gram aparecen en la Tabla 1. Para comparar nuestros resultados con puntajes anteriores en estos conjuntos de datos, utilizamos la misma medida de% (1-ROCA) descrita en [6], que es menos el área bajo la curva ROC, expresada como un porcentaje. Esta medida muestra el porcentaje de posibilidades de error cometido por un clasificador que afirma que es más probable que un mensaje sea spam que otro. Estos resultados muestran que los SVM en línea brindan una actuación de última generación en el correo electrónico spam. El único sistema conocido que supera los SVM en línea en el conjunto de datos TREC05P-1 es un clasificador de conjunto reciente que combina los resultados de 53 filtros de spam únicos [19]. Hasta donde sabemos, el SVM en línea ha superado a cualquier otro filtro único en estos conjuntos de datos, incluidos los que usan métodos bayesianos [5, 3], modelos de compresión [5, 3], regresión logística [10] y variantes de perceptrones [3], los ganadores de la competencia TREC [5, 3], y los filtros de correo electrónico de código abierto de código abierto Bogofilter V1.1.5 y SPAMProbe v1.4d.2.6 Comentarios del blog Spam y SVMS Comment Spam es similar al correo no deseado por correo electrónico en muchos aspectos, y se han propuesto métodos basados en contenido para detectar estos comentarios de spam [21]. Sin embargo, los grandes conjuntos de datos de referencia de los comentarios de blog etiquetados no existen spam. Por lo tanto, ejecutamos experimentos en el único conjunto de datos disponible públicamente que conocemos, que se utilizó en el blog basado en contenido Tabla 3: Resultados para Splog vs. Detección de blogs usando SVMS y deja una validación cruzada. Reportamos las mismas medidas de evaluación que en el trabajo anterior para una comparación significativa.Características RECUERDO DE PRECISIÓN F1 SVM C = 100: Palabras 0.921 0.870 0.895 3 gramos 0.904 0.866 0.885 4 gramos 0.928 0.876 0.901 SVM previo con: palabras 0.887 0.864 0.875 4 gramos 0.867 0.844 0.855 palabras+urls 0.893 0.869[21]. Debido al pequeño tamaño del conjunto de datos, y debido a que los investigadores anteriores no realizaron sus experimentos en un entorno en línea, probamos el rendimiento de las SVM lineales utilizando la validación cruzada de licencia, con SVM-Light, un estándar abierto-Source SVM Implementación [14]. Usamos la configuración de parámetros C = 100, con las mismas asignaciones de espacio de características que las anteriores. Reportamos precisión, precisión y recuerdo para compararlos con los resultados dados en los mismos datos establecidos por [21]. Estos resultados (ver Tabla 2) muestran que los SVM dan un rendimiento superior en este conjunto de datos en la metodología anterior.2.7 Splogs y SVMS Al igual que con el spam de comentarios del blog, aún no hay un gran corpus de referencia disponible públicamente de datos de prueba de detección Splog etiquetados. Sin embargo, los autores de [17] nos proporcionaron amablemente el conjunto de datos etiquetado de 1.389 blogs y SPLOG que usaron para probar la detección de SPLOG basada en el contenido utilizando SVM. La única diferencia entre nuestra metodología y la de [17] es que utilizaron los parámetros predeterminados para C, que SVM-Light establece en 1 AVG || x || 2.(Para vectores normalizados, este valor predeterminado se establece c = 1.) También probaron varias asignaciones de características informadas por el dominio, como dar características especiales a las etiquetas de URL. Para nuestros experimentos, utilizamos las mismas asignaciones de características que anteriormente, y probamos el efecto de establecer C = 100. Al igual que con la metodología de [17], realizamos una validación cruzada de dejar uno para la comparación de manzanas a manzanas en estos datos. Los resultados (ver Tabla 3) muestran que un alto valor de C produce un mayor rendimiento para las mismas asignaciones de espacio de características, e incluso permite que el mapeo simple de 4 gramos supera el mejor mapeo anterior que incorporó el conocimiento del dominio mediante el uso de palabras y URL..2.8 Costo computacional Los resultados presentados en esta sección demuestran que LinFeatures TREC06P TREC05P-1 Palabras 12196S 66478S 3-Grams 44605S 128924S 4-Grams 87519s 242160S Corpus Size 32822 92189 Tabla 4: Tiempo de ejecución en línea para SVMS en línea SEPS SEPM Detections. Estos tiempos no incluyen el tiempo dedicado a las cadenas de mapeo para presentar vectores. El número de ejemplos en cada conjunto de datos se da en la última fila como tamaño del corpus. A B Figura 3: Visualizar el efecto del hiperplano de C. A maximiza el margen mientras acepta una pequeña cantidad de error de entrenamiento. Esto corresponde a establecer C a un valor bajo. El hiperplano B acepta un margen más pequeño para reducir el error de entrenamiento. Esto corresponde a establecer C a un valor alto. El filtrado de spam basado en el contenido parece funcionar mejor con altos valores de C. SVM de EAR brinda un rendimiento de última generación en el filtrado de spam basado en el contenido. Sin embargo, este rendimiento tiene un precio. Aunque los conjuntos de datos de Spam y Splog de comentarios del blog son demasiado pequeños para que el tiempo de entrenamiento cuadrático de SVMS parezca problemático, los conjuntos de datos de correo electrónico son lo suficientemente grandes como para ilustrar los problemas del costo de entrenamiento cuadrático. La Tabla 4 muestra el tiempo de cálculo versus el tamaño del conjunto de datos para cada una de las tareas de aprendizaje en línea (en el mismo sistema). El costo de capacitación de SVM es prohibitivo para la detección de spam basada en contenido a gran escala, o un gran anfitrión de blogs. En la siguiente sección, reducimos este costo relajando los costosos requisitos de las SVM.3. SVMS en línea relajado (ROSVM) Uno de los principales beneficios de las SVM es que encuentran un hiperplano de decisión que maximiza el margen entre las clases en el espacio de datos. Maximizar el margen es costoso, que generalmente requiere un tiempo de entrenamiento cuadrático en el número de ejemplos de entrenamiento. Sin embargo, como vimos en la sección anterior, la tarea de detección de spam basada en el contenido se logra mejor mediante SVM con un alto valor de C. establecer C a un alto valor para este dominio implica que minimizar la pérdida de entrenamiento es más importante que maximizar elmargen (ver Figura 3). Por lo tanto, mientras que los SVM crean filtros de spam de alto rendimiento, aplicarlos en la práctica es exagerado. La característica de maximización del margen completo que proporcionan es innecesaria, y relajar este requisito puede reducir el costo computacional. Proponemos tres formas de relajar las SVM en línea: • Reduzca el tamaño del problema de optimización solo optimizando en los últimos ejemplos de P.• Reduzca el número de actualizaciones de capacitación solo en capacitación en errores reales.• Reduzca el número de iteraciones en la SVM iterativa dada: conjunto de datos x = (x1, y1) ,..., (xn, yn), c, m, p: inicializar w: = 0, b: = 0, seendata: = {} para cada xi ∈ X do: clasificar xi usando f (xi) = signo (<w, xi> +b) Si yif (xi) <m encuentra w, b con Smo en seendata, usando w, b como hipótesis de semillas.Establecer (W, B): = (W, B) If Size (Seendata)> P Eliminar el ejemplo más antiguo de Seendata Agregar Xi a Seendata realizado Figura 4: Pseudo-código para SVM en línea relajado.solucionador permitiendo una solución aproximada al problema de optimización. Como describimos en el resto de esta subsección, todos estos métodos intercambian robustez estadística por un costo computacional reducido. Los resultados experimentales informados en la siguiente sección muestran que equivalen o abordan el rendimiento de las SVM en línea completas en la detección de spam basada en el contenido.3.1 Reducción del tamaño del problema En los SVM en línea completos, re-óptimos en el conjunto completo de datos vistos en cada actualización, que se vuelve costosa a medida que crece el número de puntos de datos vistos. Podemos limitar este gasto solo considerando los ejemplos más recientes para la optimización (consulte la Figura 4 para el pseudo-código). Tenga en cuenta que esto no es equivalente a capacitar a un nuevo clasificador SVM desde cero en los ejemplos más recientes de P, porque cada problema de optimización sucesivo se sembra con la hipótesis anterior W [8]. Esta hipótesis puede contener valores para características que no ocurren en ningún lugar de los ejemplos más recientes, y estos no se cambiarán. Esto permite que la hipótesis recuerde características raras (pero informativas) que se aprendieron más allá de los ejemplos de P en el pasado. Formalmente, el problema de optimización ahora se define más claramente en la forma dual [23]. En este caso, el SVM original SoftMargin se calcula maximizando en el ejemplo n: w (α) = nx i = 1 αi - 1 2 nx I, j = 1 αiαjyiyj <xi, xj>, sujeto a las restricciones anteriores [23]: ∀i ∈ {1 ,..., n}: 0 ≤ αi ≤ c y nx i = 1 αiyi = 0 A esto, agregamos la restricción de búfer de retroceso adicional ∀j ∈ {1 ,..., (n - p)}: αJ = CJ donde CJ es una constante, fijada como el último valor encontrado para αJ mientras j> (n - p). Por lo tanto, no se garantiza que el margen encontrado por una optimización sea uno que maximice el margen para el conjunto de datos globales de ejemplos {x1 ,..., xn)}, pero más bien uno que satisfaga un requisito relajado de que el margen se maximice sobre los ejemplos {x (n - p+1) ,..., xn}, sujeto a las restricciones fijas en el hiperplano que se encontraron en optimizaciones anteriores sobre ejemplos {x1 ,..., x (n - p)}.(Para completar, cuando p ≥ n, defina (n - p) = 1.) Este conjunto de restricciones reduce el número de variables libres en el problema de optimización, reduciendo el costo computacional.3.2 Reducción del número de actualizaciones Como se señaló anteriormente, las condiciones de KKT muestran que un ejemplo bien clasificado no cambiará la hipótesis;Por lo tanto, no es necesario volver a entrenar cuando encontramos tal ejemplo. Según las condiciones de KKT, un ejemplo Xi se considera bien clasificado cuando YIF (xi)> 1. Si volvemos a entrenar en cada ejemplo que no está bien clasificado, nuestro hiperplano se garantizará que sea óptimo en cada paso. El número de actualizaciones de re-entrenamiento se puede reducir relajando la definición de bien clasificado. Un ejemplo Xi ahora se considera bien clasificado cuando Yif (xi)> m, para unos 0 ≤ m ≤ 1. Aquí, cada actualización todavía produce un hiperplano óptimo. El alumno puede encontrar un ejemplo que se encuentra dentro de los márgenes, pero más lejos de los márgenes que M. Tal ejemplo significa que la hipótesis ya no es globalmente óptima para el conjunto de datos, pero se considera lo suficientemente bueno para el uso continuo sin reentrenamiento inmediato. Este procedimiento de actualización es similar al utilizado por las variantes del algoritmo Perceptron [18]. En el caso extremo, podemos establecer M = 0, lo que crea un SVM en línea impulsado por errores. En la sección experimental, mostramos que esta versión de SVM en línea, que se actualiza solo en errores reales, no degrada significativamente el rendimiento en la detección de spam basada en el contenido, pero reduce significativamente los costos.3.3 Reducción de iteraciones como solucionador iterativo, SMO realiza pases repetidos sobre el conjunto de datos para optimizar la función objetivo. SMO tiene un bucle principal, que puede alternarse entre pasar todo el conjunto de datos, o el conjunto activo más pequeño de vectores de soporte actual [22]. Las iteraciones sucesivas de este bucle acercan el hiperplano a un valor óptimo. Sin embargo, es posible que estas iteraciones proporcionen menos beneficio de lo que justifica sus gastos. Es decir, una primera aproximación cercana puede ser lo suficientemente buena. Introducimos un parámetro t para controlar el número máximo de iteraciones que permitimos. Como veremos en la sección experimental, este parámetro se puede establecer tan bajo como 1 con poco impacto en la calidad de los resultados, proporcionando ahorros computacionales.4. Experimentos En la Sección 2, argumentamos que el fuerte rendimiento en la detección de spam basada en el contenido con SVM con un alto valor de C muestra que los criterios de margen máximo son excesivos, incurrir en un costo computacional innecesario. En la Sección 3, propusimos ROSVM para abordar este problema, ya que ambos métodos intercambian garantías en el hiperplano de margen máximo a cambio de un costo computacional reducido. En esta sección, probamos estos métodos en los mismos conjuntos de datos de referencia para ver si estos métodos menos costosos pueden lograrse. Encontramos que ROSVM es capaz de lograr estos altos niveles de rendimiento con un costo muy reducido. Nuestras pruebas principales sobre la detección de spam basada en el contenido se realizan en grandes conjuntos de datos de referencia de datos de correo electrónico. Luego aplicamos estos métodos en los conjuntos de datos más pequeños de los comentarios de comentarios y blogs de comentarios, con un rendimiento similar.4.1 Pruebas de ROSVM En la Sección 3, propusimos tres enfoques para reducir el costo computacional de la SMO en línea: reduciendo el Prob0.005 0.01 0.025 0.05 0.1 10 100 1000 10000 100000 (1-Roca) Tamaño del tampón TREC05P-1 TREC06P 0 50000 100000 150000200000 250000 10 100 1000 10000 100000 CPUSEC. Tamaño del búfer TREC05P-1 TREC06P Figura 5: Pruebas de tamaño reducido.Tamaño de LEM, reduciendo el número de iteraciones de optimización y reduciendo el número de actualizaciones de capacitación. Cada uno de estos enfoques relaja los criterios de margen máximo en el conjunto global de datos previamente vistos. Aquí probamos el efecto que cada uno de estos métodos tiene tanto en efectividad como en eficiencia. En cada una de estas pruebas, utilizamos los grandes conjuntos de datos de correo electrónico de referencia, TREC05P-1 y TREC06P.4.1.1 Pruebas de tamaño reducido para nuestra primera prueba ROSVM, experimentamos el efecto de reducir el tamaño del problema de optimización al considerar solo los ejemplos más recientes, como se describe en la sección anterior. Para esta prueba, utilizamos las mismas asignaciones de 4 gramos que para los experimentos de referencia en la Sección 2, con el mismo valor C = 100. Probamos un rango de valores P en una búsqueda de cuadrícula gruesa. La Figura 5 informa el efecto del tamaño del búfer P en relación con la medida de rendimiento (1-Roca)% (superior) y el número de segundos de CPU requeridos (abajo). Los resultados muestran que los valores de P <100 dan como resultado un rendimiento degradado, aunque se evalúan muy rápidamente. Sin embargo, los valores de P de 500 a 10,000 funcionan casi tan bien como la SMO en línea original (representada aquí como P = 100, 000), a un costo computacional dramáticamente reducido. Estos resultados son importantes para hacer que el rendimiento de última generación sea práctica de detección de spam basada en el contenido a gran escala con SVM en línea. Por lo general, el tiempo de entrenamiento crecería cuadráticamente con el número de ejemplos vistos. Sin embargo, arreglar un valor de P asegura que el tiempo de entrenamiento sea independiente del tamaño del conjunto de datos. Además, un búfer de apariencia permite que el filtro se ajuste a la deriva del concepto.0.005 0.01 0.025 0.05 0.1 10521 (1-ROCA)% máximo de iteradores.TREC06P TREC05P-1 50000 100000 150000 200000 250000 10521 CPUSEC. Max iters.TREC06P TREC05P-1 Figura 6: Pruebas de iteraciones reducidas.4.1.2 Pruebas de reducción de iteraciones en la segunda prueba ROSVM, experimentamos reduciendo el número de iteraciones. Nuestras pruebas iniciales mostraron que el número máximo de iteraciones utilizadas por SMO en línea rara vez era mucho mayor que 10 en la detección de spam basada en el contenido;Así probamos valores de t = {1, 2, 5, ∞}. Otros parámetros fueron idénticos a las pruebas SVM en línea originales. Los resultados en esta prueba fueron sorprendentemente estables (ver Figura 6). Reducir el número máximo de iteraciones SMO por actualización no tuvo impacto esencialmente en el rendimiento de la clasificación, pero sí dio como resultado un aumento moderado en la velocidad. Esto sugiere que cualquier iteración adicional se gastan intentando encontrar mejoras en un hiperplano que ya esté muy cerca de óptimo. Estos resultados muestran que para la detección de spam basada en el contenido, podemos reducir el costo computacional al permitir una sola iteración SMO (es decir, t = 1) con un rendimiento efectivamente equivalente.4.1.3 Pruebas de actualizaciones reducidas para nuestro tercer experimento ROSVM, evaluamos el impacto de ajustar el parámetro M para reducir el número total de actualizaciones. Como se señaló anteriormente, cuando M = 1, el hiperplano es globalmente óptimo en cada paso. La reducción de M permite que un hiperplano ligeramente inconsistente persista hasta que encuentre un ejemplo para el cual es demasiado inconsistente. Probamos valores de M de 0 a 1, a incrementos de 0.1.(Tenga en cuenta que usamos P = 10000 para disminuir el costo de evaluar estas pruebas). Los resultados para estas pruebas aparecen en la Figura 7, y muestran que hay una ligera degradación en el rendimiento con valores reducidos de M, y que esta degradación en el rendimiento se acompaña de un aumento de la eficiencia. Valores de 0.005 0.01 0.025 0.05 0.1 0 0.2 0.4 0.6 0.8 1 (1-ROCA)% M TREC05P-1 TREC06P 5000 10000 15000 20000 25000 30000 35000 40000 0 0.2 0.4 0.6 0.6 0.8 1 Cpusec. M TREC05P-1 TREC06P Figura 7: Pruebas de actualizaciones reducidas. M> 0.7 Da un rendimiento efectivamente equivalente como M = 1, y aún reduce el costo.4.2 SVMS en línea y ROSVM ahora comparamos ROSVM con SVM en línea en el correo no deseado, spam de comentarios de blog y tareas de detección de Splog. Estos experimentos muestran un rendimiento comparable en estas tareas, a costos radicalmente diferentes. En la sección anterior, el efecto de los diferentes métodos de relajación se probó por separado. Aquí, probamos estos métodos juntos para crear una implementación completa de ROSVM. Elegimos los valores p = 10000, t = 1, m = 0.8 para las tareas de detección de spam por correo electrónico. Tenga en cuenta que estos valores de parámetros se seleccionaron como aquellos que permiten a ROSVM lograr resultados de rendimiento comparables con SVM en línea, para probar la diferencia total en el costo computacional. Los conjuntos de datos SPLOG y blog fueron mucho más pequeños, por lo que establecemos P = 100 para estas tareas para permitir comparaciones significativas entre el tamaño reducido y los problemas de optimización de tamaño completo. Debido a que estos valores no se ajustaron a mano, tanto el rendimiento de la generalización como los resultados del tiempo de ejecución son significativos en estos experimentos.4.2.1 Configuración experimental Comparamos SVM en línea y ROSVM en el correo electrónico spam, spam de comentarios de blog y detección de Splog. Para el correo electrónico spam, utilizamos los dos grandes corpus de referencia, TREC05P-1 y TREC06P, en el pedido estándar en línea. Ordenamos al azar tanto el blog Spam Corpus y el Corpus Splog para crear tareas de aprendizaje en línea. Tenga en cuenta que esta es una configuración diferente a la tarea de validación cruzada de licencia una presentada en estos corpus en la Sección 2: los resultados no son directamente comparables. Sin embargo, este diseño experimental Tabla 5: Datos de referencia de spam por correo electrónico. Estos resultados comparan SVM y ROSVM en línea en la detección de spam por correo electrónico, utilizando un espacio de características binarias de 4 gramos. La puntuación reportada es (1-Roca)%, donde 0 es óptimo.TREC05P-1 TREC05P-1 TREC06P TREC06P (1-ROC)% CPU (1-ROC)% CPU ONSVM 0.0084 242,160 0.0232 87,519 ROSVM 0.0090 24,720 0.0240 18,541 Tabla 6: Blog Comentario Spam. Estos resultados que comparan SVM y ROSVM en línea en la detección de spam de comentarios de comentarios de blog utilizando un espacio de características binarias de 4 gramos. Accado Prec. Recarga F1 CPU ONSVM 0.926 0.930 0.962 0.946 139 ROSVM 0.923 0.925 0.965 0.945 11 permite una comparación significativa entre nuestros dos métodos en línea en estas tareas de detección de spam basadas en el contenido. Ejecutamos cada método en cada tarea e informamos los resultados en las Tablas 5, 6 y 7. Tenga en cuenta que el tiempo de CPU informado para cada método se generó en el mismo sistema informático. Esta vez refleja solo el tiempo necesario para completar el aprendizaje en línea en datos tokenizados. No informamos el tiempo necesario para tokenizar los datos en 4 gramos binarios, ya que esta es la misma constante aditiva para todos los métodos en cada tarea. En todos los casos, ROSVM fue significativamente menos costoso computacionalmente.4.3 Discusión Los resultados de comparación que se muestran en las Tablas 5, 6 y 7 son sorprendentes de dos maneras. Primero, muestran que el rendimiento de los SVM en línea puede ser igualado e incluso superado por métodos de margen relajado. En segundo lugar, muestran una disparidad dramática en el costo computacional. ROSVM es un orden de magnitud más eficiente que el SVM en línea normal, y ofrece resultados comparables. Además, el búfer fijo de retroceso asegura que el costo de cada actualización no dependa del tamaño del conjunto de datos ya visto, a diferencia de los SVM en línea. Tenga en cuenta que los conjuntos de datos del blog y Splog son relativamente pequeños, y los resultados en estos conjuntos de datos deben considerarse preliminares. En general, estos resultados muestran que no hay necesidad de pagar el alto costo de las SVM para lograr este nivel de rendimiento en la detección basada en el contenido de SPAM. Rosvms ofrece una alternativa mucho más barata con poca o ninguna pérdida de rendimiento.5. Conclusiones En el pasado, los investigadores académicos y los profesionales industriales no están de acuerdo sobre el mejor método para la detección de spam basada en el contenido en línea en la web. Hemos presentado una resolución a este debate. Los SVM en línea sí, de hecho, Protable 7: Splog Data Set. Estos resultados comparan SVM y ROSVM en línea en la detección de Splog utilizando un espacio de características binarias de 4 gramos. Accado Prec. Recuerde F1 CPU ONSVM 0.880 0.910 0.842 0.874 29353 ROSVM 0.878 0.902 0.849 0.875 1251 Duce el rendimiento de vanguardia en esta tarea con un ajuste adecuado del parámetro C de compensación, pero con costo que crece cuadráticamente con el tamaño del establecimiento de datos. Los altos valores de C requeridos para el mejor rendimiento con SVM muestran que la maximización del margen de las SVM en línea es exagerada para esta tarea. Por lo tanto, hemos propuesto una alternativa menos costosa, ROSVM, que relaja este requisito de margen máximo y produce resultados casi equivalentes. Estos métodos son lo suficientemente eficientes para el filtrado a gran escala de spam basado en contenido en sus muchas formas. Es natural preguntar por qué la tarea de detección de spam basada en el contenido obtiene un fuerte rendimiento de ROSVM. Después de todo, no todos los datos permiten la relajación de los requisitos de SVM. Conjeturamos que el correo electrónico spam, el spam de comentarios del blog y SPLOG comparten la característica de que un subconjunto de características es particularmente indicativo de que el contenido es spam o no spam. Estas características indicativas pueden estar escasamente representadas en el conjunto de datos, debido a los métodos de spam, como la ofuscación de palabras, en la que las palabras spam comunes se escriben mal intencionalmente en un intento de reducir la efectividad de la detección de spam basada en palabras. Maximizar el margen puede hacer que estas características escasamente representadas se ignoren, creando una reducción general en el rendimiento. Parece que los datos de spam son altamente separables, lo que permite que ROSVM tenga éxito con altos valores de C y se dan poco esfuerzo para maximizar el margen. El trabajo futuro determinará cuán aplicables son las SVM relajadas para el problema general de la clasificación de texto. Finalmente, observamos que el éxito de los métodos SVM relajados para la detección de spam basada en el contenido es un resultado que depende de la naturaleza de los datos de spam, que está potencialmente sujeto a cambios. Aunque actualmente es cierto que el jamón y el spam son linealmente separables dado un espacio de características apropiado, esta suposición puede estar sujeta a ataque. Si bien nuestros métodos actuales parecen robustos contra ataques primitivos en este sentido, como el buen ataque de palabras [24], debemos explorar la viabilidad de ataques más sofisticados.6. Referencias [1] A. Bratko y B. Filipic. Filtrado de spam usando modelos de compresión. Informe técnico IJS-DP-9227, Departamento de Sistemas Inteligentes, Instituto Jozef Stefan, L Jobljana, Eslovenia, 2005. [2] G. Cauwenberghs y T. Poggio. Apoyo incremental y disminución de aprendizaje automático de vectores. En NIPS, páginas 409-415, 2000. [3] G. V. Cormack. Descripción general de la pista de spam TREC 2006. Aparecer en: La Decimocuarta Conferencia de Recuperación de Textos (TREC 2006) Actas, 2006. [4] G. V. Cormack y A. Bratko. Comparación de filtro de spam lotes y en línea. En Actas de la tercera conferencia sobre correo electrónico y anti-SPAM (CEAS), 2006. [5] G. V. Cormack y T. R. Lynam. Descripción general de la pista de spam TREC 2005. En la Decimocuarta Conferencia de Recuperación de Textos (TREC 2005) Actas, 2005. [6] G. V. Cormack y T. R. Lynam. Evaluación de filtro de spam supervisado en línea. Informe técnico, David R. Cheriton School of Computer Science, Universidad de Waterloo, Canadá, febrero de 2006. [7] N. Cristianini y J. Shawe-Taylor. Una introducción a las máquinas de vectores de soporte. Cambridge University Press, 2000. [8] D. Decoste y K. Wagstaff. Sembrado alfa para máquinas de vectores de soporte. En KDD 00: Actas de la Sexta Conferencia Internacional de ACM Sigkdd sobre descubrimiento de conocimiento y minería de datos, páginas 345-349, 2000. [9] H. Drucker, V. Vapnik y D. Wu. Máquinas de vectores de soporte para la categorización de spam. Transacciones IEEE en redes neuronales, 10 (5): 1048-1054, 1999. [10] J. Goodman y W. Yin. Capacitación de filtro de spam discriminativo en línea. En Actas de la tercera conferencia sobre correo electrónico y anti-Spama (CEAS), 2006. [11] P. Graham. Un plan para el spam.2002. [12] P. Graham. Mejor filtrado bayesiano.2003. [13] Z. Gyongi y H. García-Molina. SPAM: Ya no es solo para bandejas de entrada. Computadora, 38 (10): 28-34, 2005. [14] T. Joachims. Categorización de texto con máquinas vectoriales de soporte: aprendizaje con muchas características relevantes. En ECML 98: Actas de la décima Conferencia Europea sobre Aprendizaje Autor, páginas 137-142, 1998. [15] T. Joachims. Entrenamiento SVM lineal en tiempo lineal. En KDD 06: Actas de la 12ª Conferencia Internacional SIGKDD SIGKDD sobre descubrimiento de conocimiento y minería de datos, páginas 217-226, 2006. [16] J. Kivinen, A. Smola y R. Williamson. Aprendizaje en línea con núcleos. En Avances en Sistemas de Procesamiento de Información Neural 14, páginas 785-793. MIT Press, 2002. [17] P. Kolari, T. Finin y A. Joshi. SVMS para la blogósfera: identificación de blog y detección de Splog. Simposio de primavera AAAI sobre enfoques computacionales para analizar los weblogs, 2006. [18] W. Krauth y M. M´zard. Algoritmos de aprendizaje con estabilidad óptima en redes neuronales. Journal of Physics A, 20 (11): 745-752, 1987. [19] T. Lynam, G. Cormack y D. Cheriton. Fusión de filtro de spam en línea. En Sigir 06: Actas de la 29a Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 123-130, 2006. [20] V. Metsis, I. Androutsopoulos y G. Paliouras. Filtrado de spam con Bayes ingenuos: ¿qué bayes ingenuos? Tercera conferencia sobre correo electrónico y anti-spam (CEAS), 2006. [21] G. Mishne, D. Carmel y R. Lempel. Bloqueo del spam del blog con desacuerdo del modelo de idioma. Actas del primer taller internacional sobre recuperación de información adversa en la web (AirWeb), mayo de 2005. [22] J. Platt. Optimización mínima secuencial: un algoritmo rápido para el entrenamiento de máquinas de vectores de soporte. En B. Scholkopf, C. Burges y A. Smola, editores, Avances en los métodos del núcleo - Apoyo al aprendizaje del vector. MIT Press, 1998. [23] B. Scholkopf y A. Smola. Aprendizaje con núcleos: soporte de máquinas vectoriales, regularización, optimización y más allá. MIT Press, 2001. [24] G. L. Wittel y S. F. Wu. Sobre atacar filtros de spam estadísticos. CEAS: Primera conferencia sobre correo electrónico y anti-Spama, 2004.