Hacia la asignación de recursos basada en agentes autoorganizados en un entorno de múltiples servidores Tino Schlegel1, Ryszard Kowalczyk2 Swinburne Facultad de Tecnología de la Información y Tecnologías de Comunicación Hawthorn, 3122 Victoria, Australia {Tschlegel1, Rkowalczyk2 }@ict.swin.edu.au.Las aplicaciones distribuidas requieren técnicas distribuidas para una asignación eficiente de recursos. Estas técnicas deben tener en cuenta la heterogeneidad y la posible falta de fiabilidad de los recursos y los consumidores de recursos en entornos distribuidos. En este artículo proponemos un algoritmo distribuido que resuelva el problema de asignación de recursos en sistemas multiagentes distribuidos. Nuestra solución se basa en la autoorganización de los agentes, que no requiere ningún facilitador o capa de gestión. La asignación de recursos en el sistema es un efecto puramente emergente. Presentamos los resultados del mecanismo de asignación de recursos propuesto en el entorno de servidor múltiple estático y dinámico simulado. Categorías y descriptores de sujetos I.2.11 [Inteligencia artificial distribuida]: Coherencia y Coordinación Términos generales Algoritmos 1. Introducción Con la creciente popularidad de las tecnologías informáticas distribuidas como la red [12] y los servicios web [20], Internet se está convirtiendo en una poderosa plataforma informática donde diferentes pares de software (por ejemplo, agentes) pueden usar recursos informáticos existentes para realizar tareas. En este sentido, cada agente es un consumidor de recursos que adquiere una cierta cantidad de recursos para la ejecución de sus tareas. Es difícil para un mecanismo de asignación de recursos centrales recopilar y administrar la información sobre todos los recursos compartidos y los consumidores de recursos para realizar efectivamente la asignación de recursos. Por lo tanto, se requieren soluciones distribuidas del problema de asignación de recursos. Los investigadores han reconocido estos requisitos [10] y técnicas propuestas para la asignación de recursos distribuidos. Un tipo prometedor de enfoques distribuidos se basa en modelos de mercado económico [4], inspirados en principios de los mercados de valores reales. Incluso si esos enfoques se distribuyen, generalmente requieren un facilitador para los precios, el descubrimiento de recursos y el envío de trabajos a recursos [5, 9]. Otro problema principalmente sin resolver de esos enfoques es el ajuste de precios y tiempo, limitaciones presupuestarias para permitir una asignación eficiente de recursos en sistemas grandes y dinámicos [22]. En este artículo proponemos una solución distribuida del problema de asignación de recursos basado en la autoorganización de los consumidores de recursos en un sistema con recursos limitados. En nuestro enfoque, los agentes asignan dinámicamente tareas a servidores que proporcionan una cantidad limitada de recursos. En nuestro enfoque, los agentes seleccionan de forma autónoma la plataforma de ejecución para la tarea en lugar de pedirle a un corredor de recursos que realice la asignación. Todo el control necesario para nuestro algoritmo se distribuye entre los agentes del sistema. Optimizan el proceso de asignación de recursos continuamente durante su vida a los cambios en la disponibilidad de recursos compartidos al aprender de las decisiones de asignación pasadas. La única información disponible para todos los agentes es la información de éxito de recursos y la asignación de la información de éxito de las asignaciones de recursos pasados. La información de carga de recursos adicional sobre los servidores no se difunde. El concepto básico de nuestra solución está inspirado en el razonamiento inductivo y la racionalidad limitada introducida por W. Brian Arthur [2]. El mecanismo propuesto no requiere una autoridad de control central, una capa de gestión de recursos o introducir comunicación adicional entre los agentes para decidir qué tarea se asigna en qué servidor. Demostramos que este mecanismo realiza sistemas dinámicos bien con una gran cantidad de tareas y se puede adaptar fácilmente a varios tamaños del sistema. Además, el rendimiento general del sistema no se ve afectado en caso de que los agentes o servidores fallen o no estén disponibles. El enfoque propuesto proporciona una manera fácil de implementar la asignación distribuida de recursos y tiene en cuenta las tendencias del sistema múltiple hacia la autonomía, la heterogeneidad y la falta de fiabilidad de los recursos y los agentes. Esta técnica propuesta puede complementarse fácilmente mediante técnicas para hacer cola o rechazar las solicitudes de asignación de recursos de los agentes [11]. Dichas capacidades de autogestión de los agentes de software permiten una asignación confiable de recursos incluso en un entorno con proveedores de recursos poco confiables. Esto se puede lograr mediante las interacciones mutuas entre los agentes aplicando técnicas de la teoría del sistema complejo. La autoorganización de todos los agentes conduce a una autoorganización de los 74 978-81-904262-7-5 (RPS) c 2007 IFAAMAS System Resources y es una propiedad emergente del sistema [21]. El resto del documento está estructurado de la siguiente manera: la siguiente sección ofrece una visión general del trabajo relacionado ya realizado en el área de equilibrio de carga, asignación de recursos o programación. La Sección 3 describe el modelo de un entorno de múltiples agentes que se utilizó para realizar simulaciones para una evaluación de rendimiento. Las secciones 4 y 5 describen el algoritmo de asignación de recursos distribuidos y presenta varios resultados experimentales. Un resumen, conclusión y perspectiva para el trabajo futuro terminan este documento.2. La asignación de recursos laborales relacionados es un problema importante en el área de la informática. En los últimos años, los diferentes grupos de investigación han propuesto soluciones basadas en diferentes supuestos y restricciones [7, 3, 15, 10]. En términos generales, la asignación de recursos es un mecanismo o política para la gestión eficiente y efectiva del acceso a un recurso limitado o un conjunto de recursos por parte de sus consumidores. En el caso más simple, los consumidores de recursos solicitan a un corredor o despachador central los recursos disponibles donde se asignará al consumidor de recursos. El corredor generalmente tiene pleno conocimiento sobre todos los recursos del sistema. Todas las solicitudes entrantes están dirigidas al corredor que es el único tomador de decisiones. En esos enfoques, el consumidor de recursos no puede influir en el proceso de decisión de asignación. El equilibrio de carga [3] es un caso especial del problema de asignación de recursos utilizando un corredor que intenta ser justo con todos los recursos al equilibrar la carga del sistema por igual entre todos los proveedores de recursos. Este mecanismo funciona mejor en un sistema homogéneo. Una técnica distribuida simple para la gestión de recursos es la planificación de la capacidad al rechazar o hacer cola a los agentes entrantes para evitar la sobrecarga de recursos [11]. Desde la perspectiva del propietario de los recursos, esta técnica es importante para evitar la sobrecarga en el recurso, pero no es suficiente para una asignación efectiva de recursos. Esta técnica solo puede proporcionar un buen suplemento para los mecanismos de asignación de recursos distribuidos. La mayoría de las técnicas de hoy para la asignación de recursos en los kits de herramientas de computación de la red como Globus [12] o Condor-G [13] coordinan la asignación de recursos con un subastador, árbitro, despachador, programador o gerente. Esos coordinadores generalmente necesitan tener conocimiento global sobre el estado de todos los recursos del sistema. Un ejemplo de un algoritmo de asignación de recursos dinámicos es el proyecto Cactus [1] para la asignación de trabajos computacionales muy caros. La investigación ha reconocido el valor de las soluciones distribuidas para el problema de asignación de recursos [10]. Inspirados por los principios en los mercados de valores, se han desarrollado modelos de mercado económico para la negociación de recursos para la regulación de la oferta y la demanda en la red. Estos enfoques utilizan diferentes estrategias de precios, como modelos de precios publicados, diferentes métodos de subastas o un modelo de mercado de productos básicos. Los usuarios intentan comprar recursos baratos necesarios para ejecutar el trabajo, mientras que los proveedores intentan obtener la mayor cantidad de ganancias posible y operar los recursos disponibles a plena capacidad. Una colección de diferentes técnicas de asignación de recursos distribuidos basadas en modelos de mercado se presenta en Clearwater [10]. Buyya et al.desarrolló un marco de asignación de recursos basado en la regulación de la oferta y la demanda [4] para Nimrod-G [6] con el enfoque principal en los plazos de trabajo y las limitaciones presupuestarias. El Modelo de asignación de recursos basado en agentes (ARAM) para cuadrículas está diseñado para programar trabajos computacionales costosos utilizando agentes. El inconveniente de este modelo es el uso extenso del intercambio de mensajes entre agentes para el monitoreo periódico y el intercambio de información dentro de la estructura jerárquica. Las subtareas de un trabajo migran a través de la red hasta que encuentran un recurso que cumpla con las limitaciones de precios. El itinerario de migración de empleos está determinado por los recursos para conectarlos en diferentes topologías [17]. El mecanismo propuesto en este documento elimina la necesidad de un intercambio de información periódico sobre las cargas de recursos y no necesita una topología de conexión entre los recursos. Ha habido un trabajo considerable sobre técnicas descentralizadas de asignación de recursos utilizando la teoría de juegos publicada en los últimos años. La mayoría de ellos están formulados como juegos repetitivos en un entorno idealista y simplificado. Por ejemplo, Arthur [2] introdujo el llamado problema de la barra de El Farol que no permite una solución perfecta, lógica y racional. Es un problema de decisión mal definido que asume y modela el razonamiento inductivo. Es probablemente uno de los ejemplos más estudiados de sistemas adaptativos complejos derivados de la forma humana de decidir problemas mal definidos. Una variación del problema de El Farol es el llamado juego minoritario [8]. En este juego de decisión repetitivo, un número impar de agentes debe elegir entre dos recursos basados en la información de éxito pasada que intenta asignarse en el recurso con la minoría. Galstyan et al.[14] estudiaron una variación con más de dos recursos, cambiando las capacidades de recursos e información de los agentes vecinos. Mostraron que los agentes pueden adaptarse de manera efectiva a las capacidades cambiantes en este entorno utilizando un conjunto de tablas de búsqueda (estrategias) simples por agente. Otra técnica distribuida que se emplea para resolver el problema de asignación de recursos se basa en el aprendizaje de refuerzo [18]. Similar a nuestro enfoque, un conjunto de agentes compiten por un número limitado de recursos basados solo en experiencia individual previa. En este documento, el objetivo del sistema es maximizar el rendimiento del sistema al tiempo que garantiza la equidad con los recursos, medido como el tiempo de procesamiento promedio por unidad de trabajo. En [16] se presenta un enfoque de asignación de recursos para redes de sensores basado en técnicas de autoorganización y aprendizaje de refuerzo con el enfoque principal en la optimización del consumo de energía de los nodos de red. [19] propusimos un enfoque de equilibrio de carga autoorganizado para un solo servidor con enfoque en optimizar los costos de comunicación de los agentes móviles. Un agente móvil rechazará una migración a un servidor de agente remoto, si espera que el servidor de destino ya esté sobrecargado por otros agentes o tareas del servidor. Los agentes toman sus decisiones por sí mismos en función de los pronósticos de la utilización del servidor. En este documento, se presenta una solución para un entorno de servidor múltiple sin tener en cuenta los costos de comunicación o migración.3. Descripción del modelo Modelo Un sistema distribuido de múltiples agentes como una red de servidores l = {L1 ,..., lm}, agentes a = {a1 ,..., an} y tareas t = {t1, ..., tm}. Cada agente tiene una serie de tareas TI que deben ejecutarse durante su vida. Una tarea TI requiere recursos U (Ti, T) para su ejecución en el momento t independiente de su servidor de ejecución. Los recursos para la ejecución de tareas son proporcionados por cada servidor LI. La ubicación de ejecución de tareas en general es especificada por el mapa L: T × T → L. Un agente debe saber sobre la existencia de recursos del servidor para asignar tareas a esos recursos. Escribimos ls (ai) el sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 75 Sysytem Resources Host L4Host L3Host L2 2A 3A 4A A Host L1 1A 6A5 T1 T2 T3 T4 T5 T6 Figura 1: Una ilustración de nuestro modelo multiserver con recursos exclusivos y compartidos parala ejecución del agente.Para abordar el conjunto de recursos conocidos por el Agente AI. Los recursos en el sistema pueden ser utilizados por todos los agentes para la ejecución de tareas. La cantidad de recursos proporcionados C (Li, T) de cada servidor puede variar con el tiempo. La utilización de recursos de un servidor LI en el momento t se calcula utilizando la Ecuación 1, agregando el consumo de recursos u (TJ, t) de cada tarea TJ que se ejecuta en el recurso en el momento t.Todas las unidades de recursos utilizadas en nuestro modelo representan métricas reales, como los ciclos de memoria o procesador. U (li, t) = n j = 1 u (tj, t) |L (tj, t) = li (1) adicional al caso de que la cantidad total de recursos del sistema es suficiente para ejecutar todas las tareas, también estamos interesados en el caso de que no se proporcionen suficientes recursos del sistema para cumplir con todas las solicitudes de asignación. Es decir, la capacidad general de recursos compartidos es menor que la cantidad de recursos solicitados por los agentes. En este caso, algunos agentes deben esperar con su solicitud de asignación hasta que se esperen recursos gratuitos. El modelo de sistema de múltiples agentes utilizado para nuestras simulaciones se ilustra en la Fig. 1. 4. Asignación de recursos autoorganizantes El algoritmo de asignación de recursos como se describe en esta sección se integra en cada agente. La única información requerida para tomar una decisión de asignación de recursos para una tarea es la utilización del servidor a partir de asignaciones de tareas completadas en esos servidores. No existe una difusión de información adicional sobre la utilización de recursos del servidor o la información sobre los recursos gratuitos. Nuestra solución demuestra que los agentes pueden autoorganizarse en un entorno dinámico sin información de monitoreo activo que causa una gran cantidad de sobrecarga de tráfico de red. Además, no tenemos ninguna autoridad de control central. Todo el comportamiento que conduce a la asignación de recursos es creado por la competencia efectiva de los agentes para los recursos compartidos y es un efecto puramente emergente. Los agentes en nuestro sistema de múltiples agentes compiten por recursos o un conjunto de recursos para ejecutar tareas. La acción colectiva de estos agentes cambia el entorno y, a medida que pasa el tiempo, tienen que adaptarse a estos cambios para competir de manera más efectiva en el entorno recién creado. Nuestro enfoque se basa en diferentes creencias de agentes, representadas por predictores e información diferente sobre su entorno. Los agentes prefieren una asignación de tareas en un servidor con recursos gratuitos. Sin embargo, no hay forma de estar seguro de la cantidad de recursos gratuitos del servidor por adelantado. Todos los agentes tienen las mismas preferencias y un agente asignará una tarea en un servidor si espera suficientes recursos gratuitos para su ejecución. No hay comunicación entre los agentes. Las acciones tomadas por los agentes influyen indirectamente en las acciones de otros agentes. El mecanismo aplicado está inspirado en el razonamiento inductivo y los principios de racionalidad limitados [2]. Se deriva de la forma humana de decidir problemas mal definidos. Los humanos tienden a tener en cuenta muchas hipótesis y actúan sobre la más plausible. Por lo tanto, cada agente realiza un seguimiento del rendimiento de una colección privada de sus predictores y selecciona la que actualmente es más prometedor para la toma de decisiones.4.1 Algoritmo de asignación de recursos Esta sección describe el mecanismo de decisión para nuestra asignación de recursos de autoorganización. Todo el control necesario está integrado en los propios agentes. No existe una mayor autoridad de control, capa de gestión para el apoyo a la decisión o la distribución de información. Todos los agentes tienen un conjunto de predictores para cada recurso para pronosticar la utilización futura de recursos de estos servidores para la asignación de tareas potenciales. Para hacerlo, los agentes usan información histórica de asignaciones de tareas pasadas en esos recursos. Basado en la utilización de recursos previstas, el agente tomará su decisión de asignación de recursos. Una vez que la tarea ha terminado su ejecución y devolvió los resultados al agente, se evalúan los rendimientos predictores y se actualiza la información del historial. El algoritmo 1 muestra el algoritmo de asignación de recursos para cada agente. El agente primero predice la carga de recursos de los siguientes pasos para cada servidor con información histórica (línea 3-7). Si la carga de recursos prevista más el consumo de recursos de tareas está por debajo de la última capacidad de servidor conocida, este servidor se agrega a la lista de candidatos para la asignación. Luego, el agente evalúa si se espera algún recurso compartido gratuito para la asignación de tareas. En el caso, no se esperan recursos gratuitos (línea 9), el agente explorará los recursos asignando la tarea en un servidor seleccionado al azar de todos los servidores no predecibles para recopilar información de carga de recursos. Este es el caso estándar al comienzo del ciclo de vida del agente, ya que no hay información sobre el entorno disponible. La predicción de carga de recursos en sí utiliza un conjunto de predictores R P (A, L): = {PI | 1 ≤ I ≤ R} por servidor. Un predictor pa ∈ P de cada conjunto se llama predictor activo, que pronostica la carga de recursos de los siguientes pasos. Cada predictor es una función P: H → ℵ+ ∪ {0} Desde el espacio de los datos de la historia H a un entero no negativo, que es el valor previsto. Por ejemplo, un predictor podría pronosticar una carga de recursos igual a la cantidad promedio de recursos ocupados durante la última ejecución en este recurso. Un historial de información de carga de recursos es una lista de los elementos de Historial de hasta M HI = (XI, YI), que comprende la fecha de observación XI y el valor observado yi. El elemento de la historia más reciente es H0. Hm (li) = ((x0, y0), ..., (xk, yk)) |0 ≤ k <m (2) Nuestro algoritmo utiliza un conjunto de predictores en lugar de solo uno, para evitar que todos los agentes tomen la misma decisión basada en el valor predicho que conduce a una invalidación de sus creencias. Imagine que solo un recurso compartido es conocido por varios agentes que usan un predictor que pronostica el 76 el sexto intl. Conf.sobre agentes autónomos y sistemas de múltiples agentes (AAMAS 07) Tiempo de recursos (a) Predictor6 Predictor7 Predictor 8 Predictor9 Predictor9 Predictor2 Predictor 4 Predictor 3 Predictor5 Predictor1 (B) Figura 2: (A) Recolectó la información de carga de recursos de las alociones de tareas anteriores de las tareas que se utilizan que se utilizan que se utilizan que se utilizan que se utilizan que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utiliza que se utilizapara futuras predicciones.(b) Distribución de probabilidad de predictores para seleccionar el nuevo predictor activo.El mismo valor que la última utilización de recursos del servidor conocido. Todos los agentes que asignaron una tarea en un servidor que estaba ligeramente sobrecargado descartaría otra asignación en este servidor, ya que esperan que el servidor se sobrecargue nuevamente en función de las predicciones. Como resultado, el servidor tendría una gran cantidad de recursos gratuitos. Un conjunto de diferentes predictores que predicen diferentes valores evita esta situación de invalidar las creencias de los agentes [19]. Un ejemplo de una información de carga de recursos recopilada de las últimas 5 visitas de un agente en un recurso compartido se puede ver en la Fig. 2 (a). Muestra que el recurso fue visitado con frecuencia, lo que significa que los recursos gratuitos para la ejecución estaban disponibles y una exploración de otros servidores era innecesaria. Esto puede cambiar en el futuro a medida que la carga de recursos ha aumentado significativamente recientemente. En el caso de que el conjunto de servidores predicho que tiene recursos gratuitos disponibles no está vacío (línea 13), el agente selecciona uno de ellos para la asignación. Hemos implementado dos algoritmos alternativos para la selección de un servidor para la asignación de tareas. Algoritmo 1 Algoritmo de asignación de recursos de un agente 1 l ← ∅ // servidor con recursos gratuitos 2 u ← u (t, t + 1) // Consumo de recursos de tareas 3 para todos los p (a, l) | l ∈ Ls (a)do 4 u (l) ← Resourceloadpredicción (p (a, l), t + 1) 5 si u (l) + u ≤ c (l) entonces 6 l ← l ∪ {p (a, l)} 7 final si8 Fin para 9 si l = ∅ entonces 10 // Todos los recursos compartidos impredecibles 11 E ← LS /{L ∈ LS (a) | P (A, L) ∈ L} 12 Allocationserver ← Un elemento aleatorio de E 13 más 14 AllocationServerver← La elección del servidor (l) 15 final si 16 algoritmo de retorno de asignación 2 muestra el primer método, que es una selección no determinista de acuerdo con la previsibilidad de la utilización de recursos del servidor. Una distribución de probabilidad se calcula a partir de los niveles de confianza de las predicciones de recursos. El nivel de confianza depende de tres factores: la precisión del predictor activo, la cantidad de información histórica sobre el servidor y la edad promedio de la información del historial (ver Ec. 3. El servidor con el nivel de confianza más alto tiene la mayor oportunidad de ser seleccionado como servidor activo. G (p) = w1 · tamaño (h) m + w2 · edad (h) máx.- Número de datos en la historia M - Número máximo de valores del historial Edad (H) - Edad promedio de los datos históricos G (P) - Ver Eq.4 Algoritmo 2 Elección de servidores (l)- Mejor servidor predecible 1 para todos p (a, l) ∈ L do 2 Calcule g (p) 3 extremo para 4 transformar todo g (p) en una distribución de probabilidad 5 return l ∈ Ls seleccionado segúnal algoritmo de distribución de probabilidad 3 selección de servidores (l): la mayoría de los recursos libres 1 para todos p (a, l) ∈ L do 2 c (l) ← c (l) - ul 3 extremo para 4 retorno l ∈ Ls | c (l) es máximo El segundo método de selección alternativa de un servidor del conjunto de servidores predichos con recursos libres es determinista y se muestra en el Algoritmo 3. Se elige el servidor con la mayoría de los recursos gratuitos esperados del Set L del servidor con los recursos gratuitos esperados. En el caso de que todos los agentes predicen los recursos más gratuitos para un servidor en particular, todos los agentes asignarán la tarea en este servidor, lo que invalidará las creencias de los agentes. Sin embargo, nuestros experimentos muestran que la información de la historia individual diferente y la selección del predictor activo no determinista generalmente impiden esta situación. En el caso, el algoritmo de asignación de recursos no devuelve ningún servidor (Alg. 1, línea 16), la asignación en un recurso no recomendado. El agente no asignará la tarea en un recurso. Este caso ocurre solo si es posible una predicción de carga de recursos para todos los servidores, pero no se esperan recursos gratuitos. Una vez que la ejecución del agente ha terminado, se realiza el proceso de evaluación descrito en el Algoritmo 4. Este proceso se divide en tres casos. Primero, la tarea no se asignó en un recurso. En este caso, el agente no puede decidir si la decisión de no asignar la tarea era correcta o no. El agente luego elimina los viejos datos históricos. Esto es necesario para una adaptación exitosa en el futuro. Si el agente no eliminara la información histórica antigua, la predicción siempre pronosticaría que no hay recursos gratuitos disponibles. El agente nunca asignaría una tarea en uno de los recursos en el futuro. La información histórica antigua se elimina del historial de recursos de los agentes utilizando una tasa de descomposición. La tasa de descomposición es una función de distribución acumulativa que calcula la probabilidad de que un elemento de historial se elimine después de que haya alcanzado un cierto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 77 Edad del historial Datos Decayrate 0 1 Figura más antigua 3: Tasa de descomposición de la edad de información histórica. La implementación actual utiliza una función de densidad de probabilidad constante en un dominio configurable. La Figura 3 muestra un ejemplo de dicha función de distribución acumulativa para la tasa de descomposición. Dependiendo del entorno, la función de densidad de probabilidad debe ser alterada. Si el número de servidor potencial por agente es alto, la información histórica debe mantenerse más tiempo para evitar la exploración de recursos inexplorados. Además, un entorno dinámico requiere información más actualizada para hacer predicciones más confiables. El segundo caso en el proceso de evaluación (Alg. 4, línea 5) describe las acciones tomadas después de que se visitó un servidor por primera vez. El agente crea un nuevo conjunto de predictor para este servidor y registra la información histórica. Todos los predictores para este conjunto se eligen al azar de algún conjunto predefinido.g (p) = l i = 0 ri (4) donde: ri = ⎧ ⎨ ⎩ ⎩ 1 Si es una decisión correcta 0 si es un resultado desconocido −1 si es una decisión incorrecta, el caso general (Alg. 4, línea 8) es la evaluación después deEl agente asignó la tarea en un recurso. El agente evalúa todos los predictores del conjunto de predictor para este recurso prediciendo la carga de recursos con todos los predictores basados en los datos históricos antiguos. Los predictores que hicieron una predicción correcta, lo que significa que la asignación de recursos era correcta, recibirá una calificación positiva. Este es el caso de que el recurso no estaba sobrecargado y se predijeron recursos gratuitos para la ejecución, o el recurso se sobrecargó y este predictor habría evitado la asignación. Todos los predictores que predijeron valores que conducirían a decisiones incorrectas recibirán calificaciones negativas. En todos los demás casos, que incluyen que no fue posible predicción, se otorga una calificación neutral a los predictores. Según estas calificaciones de rendimiento, los niveles de confianza se calculan utilizando la Ecuación 4. La confianza para todos los predictores que no pueden predecir con la información histórica actual sobre el servidor se establece en cero para evitar la selección de ellos como el nuevo predictor activo. Estos valores se transforman en una distribución de probabilidad. De acuerdo con esta distribución de probabilidad, se elige el nuevo predictor activo, implementado como una selección de ruedas de ruleta. La Figura 2 (b) ilustra las probabilidades de un conjunto de 10 predictores, que se han calculado a partir de los niveles de confianza del predictor. Incluso si el predictor 9 tiene la mayor probabilidad de selección, no fue elegido por el proceso de selección de la rueda de la ruleta como predictor activo. Esta selección predictor no determinista evita la invalidación de las creencias de los agentes en el caso de que los agentes tengan el mismo conjunto de predictores. La precisión de la predicción que es el error de la predicción en comparación con el valor observado no se tiene en cuenta. Supongamos que el predictor activo predice ligeramente por encima de la capacidad de recursos que no lleva a una asignación de recursos. De hecho, suficientes recursos para la ejecución estarían disponibles. Una predicción menos precisa que está muy por debajo de la capacidad conduciría a la decisión correcta y, por lo tanto, se prefiere. La última acción del algoritmo de evaluación (Alg. 4, línea 22) actualiza el historial con la última información de carga de recursos del servidor. Los datos del historial más antiguos se sobrescriben si ya se registran los valores de Historial M para el servidor. Algoritmo 4 Evaluación de decisión 1 Si l ∈ LE entonces 2 para todos p (a, l) | l ∈ Ls (a) HACE 3 Evaporar datos históricos antiguos 4 End para 5 más si p (a, l) = nulo entonces 6 crea (P (a, l)) 7 Actualización H (l) 8 más 9 Para todas las p ∈ P (A, L) Do 10 pred ← Resourceloadpredicción (p) 11 if (u (l) ≤ c (l) y pred + u(a, t) ≤ c (l)) o (u (l)> c (l) y pred + u (a, t)> c (l)) Entonces 12 addPositiverating (p) 13 más si u (l)≤ c (l) y pred + u (a, t)> c (l) o u (l) ≤ c (l) y pred + u (a, t)> c (l) luego 14 addnegativerating (p) 15else 16 addneutrating (p) 17 final si 18 terminan para 19 calcule todo g (p);g (p) ← 0, si P no funciona 20 transforma todo G (p) en una distribución de probabilidad 21 Pa ← P ∈ P (A, L) se selecciona de acuerdo con esta Distribución de probabilidad 22 Actualización H (l) 23 Fin si4.2 Observaciones y limitación del enfoque Nuestro mecanismo de predicción utiliza varios tipos diferentes de predictores simples en lugar de un predictor sofisticado. Este método asegura que los agentes puedan competir de manera más efectiva en un entorno cambiante. Los diferentes tipos de predictores son adecuados para diferentes situaciones y entornos. Por lo tanto, todos los predictores se están evaluando después de cada decisión y se selecciona el predictor activo. Este no determinista del nuevo predictor activo respalda que las creencias de los agentes no se invalidarán, lo que ocurre en el caso de que todos los predictores están tomando la misma decisión. Especialmente si solo hay un recurso compartido disponible y todos los agentes solo tienen la opción de ir este recurso compartido o no [19]. Nuestro enfoque autoorganizado es robusto contra las fallas de recursos o agentes en el sistema. Si se unen o se van, el sistema puede autoorganizarse rápidamente y adaptarse a las nuevas condiciones. No hay un cuello de botella clásico o un único punto de falla como en mecanismos centralizados. Las limitaciones son la dependencia de la información de utilización de recursos históricos sobre otros servidores. Un pronóstico de la utilización de recursos de un servidor remoto solo es posible si un agente tiene una serie de información histórica sobre un recurso compartido. Si el número de servidores por agente es muy grande, no hay una forma eficiente de recopilar información histórica sobre servidores remotos. Este problema ocurre si la cantidad de recursos compartidos proporcionados 78 el sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) es limitado y no es suficiente para todos los consumidores de recursos. En este caso, el agente un agente intentaría aleatoriamente todos los servidores conocidos hasta que encuentre uno con recursos gratuitos o no hay nadie. En el peor de los casos, para probar todos los servidores, la información histórica de los servidores ya está desactualizada.5. Evaluación experimental La primera parte de esta sección ofrece una breve descripción de la configuración de nuestro entorno de simulación. En el resto de la sección, se presentan y discuten los resultados de los experimentos. Todos los experimentos se llevan a cabo en un Bed de prueba especial que simula y modela un sistema de múltiples agentes. Hemos implementado este lecho de prueba en el lenguaje de programación de Java, independientemente de cualquier kit de herramientas de agente específico. Permite una variedad de experimentos en entornos estables y dinámicos con un número configurable de agentes, tareas y servidores. Se utiliza un modelo basado en eventos para desencadenar todas las actividades en el sistema. Para todas las simulaciones, limitamos el número de datos de historial para cada servidor a 10, el número de calificaciones de rendimiento por predictor a 10 y asignamos 10 predictores a cada conjunto de predictor para cada agente. Todos los predictores se eligen al azar de un conjunto predefinido arbitrario de 32 predictores del siguiente tipo. Los predictores difieren en diferentes ciclos o tamaños de ventana.-predictor de ciclo N: P (n) = yn usa el valor de historial en nth -last -predictor de n -mean: p (n) = 1 n · n i = 1 yi usa el valor medio de los valores de historial n -last -n n -n-La predictor de regresión lineal: p (n, t) = a · t+b usa el valor de regresión lineal de los últimos n valores de historial donde a, b se calculan utilizando regresión lineal con mínimos cuadrados que se ajustan bajo la consideración de los últimos n datos del historial.- Predictor de N-Distribución: utiliza un valor aleatorio de la distribución de frecuencia de los N valores de N Últimos Historia- N-Mirror Predictor: P (N) = 2 · H- Yn usa la imagen del espejo alrededor de la media de todos los valores de historia del enésimoLast History Value La eficiencia de nuestra asignación de recursos autoorganizado propuesta se evalúa mediante el desarrollo de la carga de recursos de cada servidor a través de la simulación, así como el desarrollo total de la carga de recursos acumulado en todos los recursos compartidos. Las cargas de recursos para cada servidor se calculan utilizando la Ecuación 1 como la suma del consumo de recursos de todos los agentes ejecutados actualmente en este servidor. La carga total de recursos del sistema se calcula como la suma de la carga de recursos de todos los recursos. El algoritmo de asignación de recursos autoorganizado tiene elementos aleatorios. Por lo tanto, los resultados presentados muestran valores medios y derivación estándar calculada en 100 experimentos repetidos.5.1 Configuración experimental Los siguientes parámetros tienen un impacto en el proceso de asignación de recursos. Damos una descripción general de los parámetros y una breve descripción.- Agentes: el número de agentes involucrados en la asignación de recursos. Este número varía en los experimentos entre 650 y 750 que dependen de la cantidad total de recursos del sistema disponibles.- Consumo de recursos: cada tarea consume recursos del servidor para su ejecución. El consumo de recursos se asigna aleatoriamente a cada tarea antes de su asignación desde un intervalo. El consumo de recursos se especifica en unidades de recursos que corresponden a métricas del mundo real como los ciclos de memoria o procesador.- Agente Servidor Home: todos los agentes están ubicados en un servidor de agente local. Los recursos de esos servidores no se consideran en nuestra simulación y no afectan el rendimiento de asignación de recursos.- Recursos del servidor: los experimentos utilizan servidores con una cantidad diferente de recursos compartidos disponibles. El primer experimento se realiza en un entorno de servidor estático que proporciona la misma cantidad de recursos compartidos, mientras que el otro experimento varía el recurso del servidor disponible durante la simulación. La cantidad total de recursos permanece constante en ambos experimentos.- Tiempo de ejecución: el tiempo de ejecución de una tarea para la ejecución, independiente de la plataforma de ejecución. Para este momento, la tarea consume la cantidad asignada de recursos del servidor. Este parámetro se asigna aleatoriamente antes de la ejecución.- Tiempo de creación de tareas: el tiempo antes de la próxima tarea se crea después de una finalización exitosa o no exitosa. Este parámetro influye en la edad de la información histórica sobre los recursos y tiene una gran influencia en la duración de la fase de adaptación inicial. Este parámetro se asigna aleatoriamente después de que se completó la tarea.5.2 Resultados experimentales Esta sección muestra resultados de experimentos seleccionados que demuestran el rendimiento de nuestro mecanismo de asignación de recursos propuesto. El primer experimento muestra el rendimiento en un entorno estable donde varios agentes asignan tareas a servidores que proporcionan una cantidad constante de recursos. El segundo experimento se realizó en un entorno de servidor dinámico con un número constante de agentes. El primer experimento muestra nuestro modelo en un entorno estable de 3 servidores que proporcionan una cantidad total de 7000 unidades de recursos. La capacidad de recursos de cada servidor permanece constante sobre el experimento. Utilizamos 650 agentes con los parámetros del tiempo de ejecución entre 1 y 15 unidades horarias y un tiempo de creación de tareas en las unidades de tiempo de intervalo [0 - 30]. El consumo de recursos de tareas se asigna aleatoriamente desde las unidades de recursos de intervalo [1 - 45]. La Figura 4 muestra los resultados de 100 repeticiones de este experimento. La Figura 4 (a) muestra que la cantidad total de recursos proporcionados es mayor que la demanda de recursos en promedio. Al comienzo del experimento, todos los agentes asignan sus tareas al azar en uno de los servidores disponibles y exploran las capacidades disponibles y las utilizaciones de recursos para aproximadamente 150 unidades horarias. Esta fase de exploración inicial muestra que la carga promedio de recursos de cada servidor tiene un nivel similar. Esto causa una situación de sobrecarga en el servidor 1 debido a su baja capacidad de recursos compartidos y una gran cantidad de recursos gratuitos en el servidor 2. Los agentes que asignaron tareas al servidor 1 detectan la situación de sobrecarga y exploran al azar otros servidores disponibles. Encuentran recursos gratuitos en el servidor 2. Después del período de aprendizaje, los agentes se han autoorganizado en este entorno estable y encuentran una solución estable para la asignación del sexto INTL. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 79 0 250 500 750 1,000 1,250 1,500 Tiempo 0 1,000 2,000 3,000 4.000 5,000 6,000 7,000 ResourCeload (a) Carga total de recursos versus Capacidad total de recursos compartidos 0 250 500 750 1,000 1,250 1,500 Tiempo 0 Tiempo 0 Tiempo 0500 1,000 1,500 2,000 2,500 ResourCelOad (b) Servidor de carga de recursos 0 0 250 500 750 1,000 1,250 1,500 Tiempo 0 500 1,000 1,500 2,000 2,500 ResourCeload (c) Servidor de carga de recursos 1 0 250 500 750 1,000 1,250 1,500 Tiempo 0 500 1,000 1,500 2,000 2,500 3,000 3,0003,500 4,000 Resourceload (D) Servidor de carga de recursos 2 Figura 4: Resultados del Experimento 1 en un entorno estático de 3 servidores promediado más de 100 repeticiones.todas las tareas. La desviación estándar de las cargas de recursos es pequeña para cada servidor, lo que indica que nuestro enfoque distribuido encuentra soluciones estables en casi todas las ejecuciones. Este experimento utilizó el Algoritmo 2 para la selección del servidor activo. También ejecutamos el mismo experimento con el mecanismo de selección de recursos más gratuito para seleccionar el servidor activo. La asignación de recursos para cada servidor es similar. La cantidad absoluta de recursos gratuitos por servidor es casi la misma. El experimento 2 se realizó en un entorno dinámico de 3 servidores con varios 750 agentes. La cantidad de recursos del servidor 0 y el servidor 1 cambia periódicamente, mientras que la cantidad total de recursos disponibles permanece constante. El servidor 0 tiene una capacidad inicial de 1000 unidades, el servidor 1 comienza con una capacidad de 4000 unidades. El cambio en la capacidad comienza después de 150 unidades de tiempo, que es aproximadamente el final de la fase de aprendizaje. La Figura 5 (B, C, D) muestra el comportamiento de nuestra asignación de recursos autoorganizados en este entorno. Todos los agentes usan el mecanismo de selección de recursos gratuitos deterministas para seleccionar el servidor activo. Se puede ver en la Fig. 5 (b) y 5 (c) que el número de recursos asignados al servidor 0 y el servidor 1 cambia periódicamente con la cantidad de recursos proporcionados. Esto muestra que los agentes pueden detectar recursos disponibles en este entorno dinámico y pueden adaptarse a esos cambios. El desarrollo de carga de recursos del servidor 2 (ver Fig. 5 (d)) muestra un cambio periódico porque a algún agente intentan ser tareas asignadas a este servidor en caso de que su servidor previamente favorecido reduzca la cantidad de recursos compartidos. La carga total de recursos de todos los recursos compartidos es constante sobre los experimentos, lo que indica que todos los agentes asignan sus tareas a uno de los recursos compartidos (comp. Fig. 4 (a)).6. Conclusiones y trabajo futuro en este documento se presentó una técnica de asignación de recursos distribuidos autoorganizados para sistemas de múltiples agentes. Permitimos a los agentes seleccionar la plataforma de ejecución para sus tareas en sí mismas antes de cada ejecución en tiempo de ejecución. En nuestro enfoque, los agentes compiten por una asignación en uno de los 0 500 1,000 1,000 1,500 2,000 Tiempo 0 2,500 5,000 7,500 ResourCelsoad (a) Carga total de recursos versus Capacidad total de recursos compartidos 0 500 1,000 1,000 1,500 2,000 Tiempo 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 4,000ResourCelOad (b) Servidor de carga de recursos 1 0 500 1,000 1,500 2,000 Tiempo 0 500 1,000 1,000 1,500 2,000 2,500 3,000 3,500 4,000 ResourceCelsoad (C) Servidor de carga de recursos 2 0 500 1,000 1,500 2,000 Tiempo 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 Resource Celload (D)Servidor de carga de recursos 3 Figura 5: Resultados del Experimento 2 en un entorno de servidor dinámico promedió más de 100 repeticiones.Recurso compartido disponible. Los agentes sienten el entorno de su servidor y adoptan su acción para competir más eficiente en el nuevo entorno creado. Este proceso es adaptativo y tiene una fuerte retroalimentación, ya que las decisiones de asignación influyen indirectamente en las decisiones de otros agentes. La asignación de recursos es un efecto puramente emergente. Nuestro mecanismo demuestra que la asignación de recursos puede ser realizada por la competencia efectiva de los agentes individuales y autónomos. Tampoco necesitan coordinación o información de una autoridad superior ni se requiere una comunicación directa adicional entre los agentes. Este mecanismo se inspiró en el razonamiento inductivo y los principios de racionalidad limitados que permiten a los agentes adaptar sus estrategias competir de manera efectiva en un entorno dinámico. En el caso de que un servidor no esté disponible, los agentes pueden adaptarse rápidamente a esta nueva situación explorando nuevos recursos o permanecer en el servidor doméstico si no es posible una asignación. Especialmente en entornos dinámicos y escalables como sistemas de cuadrícula, se requiere un mecanismo robusto y distribuido para la asignación de recursos. Nuestro enfoque de asignación de recursos autoorganizados se evaluó con una serie de experimentos de simulación en un entorno dinámico de agentes y recursos del servidor. Los resultados presentados para este nuevo enfoque para la optimización de migración estratégica son muy prometedores y justifican una investigación adicional en un entorno de sistema real de múltiples agentes. Es una política distribuida, escalable y fácil de entender para la regulación de la oferta y la demanda de recursos. Todo el control se implementa en los agentes. Un mecanismo de decisión simple basado en diferentes creencias del agente crea un comportamiento emergente que conduce a una asignación efectiva de recursos. Este enfoque puede extenderse o apoyarse fácilmente por mecanismos de equilibrio/cola de recursos proporcionados por los recursos. Nuestro enfoque se adapta a los cambios en el medio ambiente, pero no es evolutivo. No hay descubrimiento de nuevas estrategias por parte de los agentes. El conjunto de predictores permanece igual durante toda la vida. De hecho, creemos que esto podría mejorar aún más el comportamiento de los sistemas durante un período a largo plazo y podría ser 80 el sexto INTL. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) investigados en el futuro. La evolución sería muy lenta y selectiva y no influirá en el comportamiento del sistema en un período a corto plazo cubierto por nuestros resultados experimentales. En el futuro cercano investigaremos si una adaptación automática de la tasa de descomposición de información histórica, nuestro algoritmo es posible y puede mejorar el rendimiento de la asignación de recursos. La tasa de descomposición actualmente está predefinida y debe modificarse manualmente dependiendo del medio ambiente. Una gran cantidad de recursos compartidos requieren información histórica más antigua para evitar una exploración de recursos con demasiada frecuencia. Por el contrario, un entorno dinámico con capacidades variables requiere información más actualizada para hacer predicciones más confiables. Somos conscientes de la larga fase de aprendizaje en entornos con una gran cantidad de recursos compartidos conocidos por cada agente. En el caso de que los agentes soliciten más recursos que todos los servidores proporcionan más recursos, todos los agentes explorarán aleatoriamente todos los servidores conocidos. Este proceso de adquisición de información de carga de recursos sobre todos los servidores puede llevar mucho tiempo en el caso de que no se proporcionen suficientes recursos compartidos para todas las tareas. En el peor de los casos, para explorar todos los servidores, la información histórica de algunos servidores ya podría estar desactualizado y la exploración comienza nuevamente. En esta situación, es difícil para un agente recopilar eficientemente información histórica sobre todos los servidores remotos. Este problema necesita más investigación en el futuro.7. Referencias [1] G. Allen, W. Benger, T. Dramlitsch, T. Goodale, H.-C.Hege, G. Lanfermann, A. Merzky, T. Radke, E. Seidel y J. Shalf. Herramientas de cactus para aplicaciones de cuadrícula. En Cluster Computing, Volumen 4, páginas 179-188, Hingham, MA, EE. UU., 2001. Kluwer Publishers Academic.[2] W. B. Arthur. Razonamiento inductivo y racionalidad limitada. American Economic Review (documentos y procedimientos), 84 (2): 406-411, mayo de 1994. [3] T. Bourke. Balanceo de carga del servidor. Oreilly Media, 1 edición, agosto de 2001. [4] R. Buyya. Gestión y programación de recursos distribuidos basados en económicos para la informática de la red. Tesis doctoral, Universidad de Monash, Melbourne, Australia, mayo de 2002. [5] R. Buyya, D. Abramson, J. Giddy y H. Stockinger. Modelos económicos para la gestión y programación de recursos en la informática de la red. Número especial sobre entornos de computación de la red de la revista Concurrencia y computación, 13-15 (14): 1507-1542, 2002. [6] R. Buyya, S. Chapin y D. Dinucci. Modelos arquitectónicos para la gestión de recursos en la red. En Actas del primer taller internacional sobre computación de la red, páginas 18-35. Springer LNCS, 2000. [7] T. L. Casavant y J. G. Kuhl. Una taxonomía de programación en sistemas informáticos distribuidos de uso general. Transacciones IEEE en Ingeniería de Software, 14 (2): 141-154, febrero de 1988. [8] D. Challet e Y. Zhang. Aparición de cooperación y organización en un juego evolutivo. Physica A, 407 (246), 1997. [9] K.-P.Chow y Y.-K.Kwok. En el equilibrio de carga para la computación multiagente distribuida. En transacciones IEEE en sistemas paralelos y distribuidos, volumen 13, páginas 787-801. IEEE, agosto de 2002. [10] S. H. Clearwater. Control basado en el mercado. Un paradigma para la asignación de recursos distribuidos. World Scientific, Singapur, 1996. [11] C. Fl¨us. Planificación de capacidad de sistemas de agentes móviles que diseñan aplicaciones de intranet eficientes. Tesis doctoral, Universit¨at Duisburg-Essen (Alemania), febrero de 2005. [12] I. Foster y C. Kesselman. Globus: un kit de herramientas de infraestructura metacomputación. Revista Internacional de Aplicaciones de Supercomputación, 11 (2): 115-129, 1997. [13] J. Frey, T. Tannenbaum, I. Foster, M. Livny y S. Tuecke. Condor-G: un agente de gestión de computación para cuadrículas multiinstitucionales. Cluster Computing, 5 (3): 237-246, 2002. [14] A. Galstyan, S. Kolar y K. Lerman. Juegos de asignación de recursos con capacidades de recursos cambiantes. En Actas de la Segunda Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas Multiagentes, páginas 145 - 152, Melbourne, Australia, 2003. ACM Press, Nueva York, NY, EE. UU.[15] C. Georgousopoulos y O. F. Rana. Combinando enfoques basados en estados y modelos para el equilibrio de carga de agentes móviles. En SAC 03: Actas del Simposio ACM de 2003 sobre computación aplicada, páginas 878-885, Nueva York, NY, EE. UU., 2003. ACM Press.[16] G. Continente, D. C. Parkes y M. Welsh. Asignación descentralizada de recursos adaptativos para redes de sensores. En Actas del 2º Simposio de Usenix sobre el diseño e implementación de sistemas de red (NSDI 05), mayo de 2005. [17] S. manvi, M. Birje y B. Prasad. Un modelo de asignación de recursos basado en agentes para cuadrículas computacionales. Sistemas de cuadrícula y multiagente: una revista internacional, 1 (1): 17-27, 2005. [18] A. Schaerf, Y. Shoham y M. Tennenholtz. Equilibrio de carga adaptativa: un estudio en aprendizaje de múltiples agentes. En Journal of Artificial Intelligence Research, Volumen 2, páginas 475-500, 1995. [19] T. Schlegel, P. Braun y R. Kowalczyk. Hacia agentes móviles autónomos con comportamiento de migración emergente. En Actas de la Quinta Conferencia Internacional Conjunta sobre Agentes Autónomos y Sistemas de Agentes Múltiples (AAMAS 2006), Hakodate (Japón), páginas 585-592. ACM Press, mayo de 2006. [20] W3C. Actividad de servicios web, 2002. http://www.w3.org/2002/ws - Última visitado 23.10.2006.[21] M. M. Waldrop. Complejidad: la ciencia emergente al borde del orden y el caos. Simon & Schuster, 1ª edición, 1992. [22] R. Wolsk, J. S. Plank, J. Brevik y T. Bryan. Análisis de estrategias de asignación de recursos basadas en el mercado para la red computacional. En International Journal of High Performance Computing Aplications, Volumen 15, páginas 258-281. Sage Science Press, 2001. El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 81