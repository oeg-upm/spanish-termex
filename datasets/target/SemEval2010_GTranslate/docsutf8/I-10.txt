Sonrisa: aprendizaje incremental de múltiples agentes sonoros;-) ∗ Gauvain Bourgne Lamsade, UMR 7024 CNRS, University Paris-Dauphine, 75775 Paris Cedex 16 Amal el Fallah Segrouchni Lip6, UMR 7606 CNRS, University Paris 6, 104, av. Du Pr´esident Kennedy, 75116 Paris Henry Soldano Lipn, UMR 7030 CNRS, University Paris-Nord, 99 av. J-B Clement, 93430, Villetaneuse Resumen Este artículo se ocupa del problema del aprendizaje colaborativo en un sistema de múltiples agentes. Aquí cada agente puede actualizar incrementalmente sus creencias B (la representación conceptual) para que de alguna manera se mantenga consistente con todo el conjunto de información K (los ejemplos) que ha recibido del entorno u otros agentes. Extendemos esta noción de consistencia (o solidez) a todo el MAS y discutimos cómo obtener eso, en cualquier momento, una misma representación conceptual consistente está presente en cada agente. El protocolo correspondiente se aplica al concepto de aprendizaje supervisado. La sonrisa del método resultante (que representa el aprendizaje incremental multiagente de sonido) se describe y experimenta aquí. Sorprendentemente, algunas fórmulas booleanas difíciles se aprenden mejor, dado el mismo conjunto de aprendizaje, por un sistema de agentes múltiples que por un solo agente. Categorías y descriptores de temas I.2.6 [Inteligencia artificial]: aprendizaje de concepto de aprendizaje;I.2.11 [Inteligencia artificial]: Sistema de inteligencia artificial distribuido Sistema de Multiagente Términos generales Experimentación, algoritmos, medición, rendimiento 1. Introducción Este artículo se ocupa del problema del aprendizaje de concepto colaborativo en un sistema de múltiples agentes.[6] introduce una caracterización del aprendizaje en el sistema de múltiples agentes de acuerdo con el nivel de conciencia de los agentes. En el nivel 1, los agentes aprenden ∗ El autor principal de este documento es un estudiante.en el sistema sin tener en cuenta la presencia de otros agentes, excepto a través de la modificación presentada en el entorno por su acción. El nivel 2 implica la interacción directa entre los agentes, ya que pueden intercambiar mensajes para mejorar su aprendizaje. El nivel 3 requeriría que los agentes tengan en cuenta las competencias de otros agentes y puedan aprender de la observación del comportamiento de los otros agentes (mientras los consideran como entidades independientes y no una parte del medio ambiente como en el nivel 1). Nos centramos en este documento en el Nivel 2, estudiando la interacción directa entre los agentes involucrados en un proceso de aprendizaje. Se supone que cada agente puede aprender de forma incremental de los datos que recibe, lo que significa que cada agente puede actualizar su conjunto de creencias B para mantenerlo consistente con todo el conjunto de información K que ha recibido del entorno o de otros agentes. En tal caso, diremos que es consistente. Aquí, el conjunto de creencias B representa el conocimiento hipotético que, por lo tanto, se puede revisar, mientras que el conjunto de información K representa cierto conocimiento, que consiste en observaciones y hechos no revisables. Además, suponemos que al menos una parte BC de las creencias de cada agente es común para todos los agentes y debe mantenerse así. Por lo tanto, una actualización de este conjunto común BC por el Agente R debe provocar una actualización de BC para toda la comunidad de agentes. Nos lleva a definir cuál es la consistencia masa de un agente con respecto a la comunidad. El proceso de actualización de las creencias de la comunidad cuando uno de sus miembros obtiene nueva información se puede definir como el proceso de mantenimiento de consistencia que garantiza que cada agente de la comunidad se mantenga masconsistente. Este proceso de mantenimiento de consistencia MAS de un agente que obtiene nueva información le da el papel de un alumno e implica la comunicación con otros agentes que actúan como críticos. Sin embargo, los agentes no son especializados y, a su vez, pueden ser alumnos o críticos, ninguno de ellos se mantiene a un papel específico. Las piezas de información se distribuyen entre los agentes, pero pueden ser redundantes. No hay memoria central. El trabajo descrito aquí tiene su origen en un trabajo anterior sobre el aprendizaje en un sistema intencional de múltiples agentes utilizando un formalismo BDI [6]. En ese trabajo, los agentes tenían planes, cada uno de ellos asociado con un contexto que define en qué condiciones se puede activar. Los planes (cada uno de ellos tenía su propio contexto) eran comunes a todo el conjunto de agentes en la comunidad. Los agentes tuvieron que adaptar los contextos de su plan dependiendo del fracaso o el éxito de los planes ejecutados, utilizando un mecanismo de aprendizaje y solicitando ejemplos a otros agentes (éxitos o fallas de planes). Sin embargo, este trabajo carecía de un protocolo de aprendizaje colectivo que permitía una autonomía real del sistema de múltiples agentes. El estudio de dicho protocolo es el objeto del presente documento. En la Sección 2 definimos formalmente la consistencia MAS de un mecanismo de actualización para todo el MAS y proponemos un mecanismo de actualización genérico demostrado como MAS consistente. En la Sección 3 describimos Smile, un alumno de concepto de agente múltiple incremental que aplica nuestro mecanismo de actualización consistente de MAS al aprendizaje conceptual colaborativo. La Sección 4 describe varios experimentos sobre la sonrisa y discute varios temas, incluida la forma en que la precisión y la simplicidad de la hipótesis actual varían al comparar el aprendizaje de un solo agente y el aprendizaje MAS. En la Sección 5 presentamos brevemente algunos trabajos relacionados y luego concluimos en la Sección 6 discutiendo más investigaciones sobre el aprendizaje consistente de MAS.2. Definiciones y marco del modelo 2.1 formal En esta sección, presentamos una formulación general del aprendizaje incremental colectivo en un sistema cognitivo de agente múltiple. Representamos un MAS como un conjunto de agentes R1, ..., Rn. Cada agente RI tiene un conjunto de creencias que consiste en todo el conocimiento revisable que tiene. Parte de estos conocimientos debe compartirse con otros agentes. La parte de BI que es común a todos los agentes se denota como BC. Esta parte común provoca una dependencia entre los agentes. Si un agente RI actualiza su creencia establece BI a BI, cambiando en el proceso BC en BC, todos los demás agentes RK deben actualizar su creencia establecida BK en BK para que BC ⊆ BK. Además, cada agente RI ha almacenado cierta información KI. Suponemos que el agente mismo puede verificar una propiedad de consistencia (BI, KI) entre sus creencias BI y su información KI. Como se dijo antes, BI representa el conocimiento que podría revisarse, mientras que KI representa hechos observados, tomados como verdaderos, y que posiblemente puede contradecir BI. Definición 1. La consistencia A de un agente Un agente RI es una consistencia de las contras de IFF (BI, KI) es verdadera. Ejemplo 1. El Agente R1 tiene un conjunto de planes que se encuentran en la parte común BC de B1. Cada plan P tiene un contexto desencadenante D (P) (que actúa como una condición previa) y un cuerpo. Alguna información K podría ser el plan P, desencadenada en la situación S, ha fallado a pesar de que S es una instancia de D (P). Si esta información se agrega a K1, entonces el Agente R1 ya no es consistente: contras (B1, K1 ∪ K) es falso. También queremos definir alguna noción de consistencia para todo el MAS dependiendo de los conjuntos de creencias e información de sus elementos constituyentes. Primero definiremos la consistencia de un agente RI con respecto a su conjunto de creencias BI y su propia información establecida KI junto con todos los conjuntos de información K1 ... KN de los otros agentes del MAS. Simplemente lo haremos considerando cuál sería la consistencia A del agente si tiene la información de todos los demás agentes. Llamamos a esta noción la consistencia mas: definición 2. consistencia masa de un agente un agente ri es mas consistente iff contraciones (bi, ki ∪ k) es verdadera, donde k = ∪j∈ {1, .., n} - {i} kj 1 es el conjunto de toda la información de otros agentes del MAS.1 Notaremos esto ∪ KJ cuando el contexto es similar. Ejemplo 2. Usando el ejemplo anterior, suponga que la información K está incluida en la información K2 del Agente R2. Mientras la información no se transmitiera a R1, y por lo tanto se agregó a K1, R1 sigue siendo consistente. Sin embargo, R1 no es consistente con MAS, ya que K está en el conjunto K de toda la información del MAS. La consistencia global del MAS es simplemente la consistencia MAS de todos sus agentes. Definición 3. Consistencia de un mas a mas r1, ..., rn es consistente si todos sus agentes ri son masconsistentes. Ahora definimos las propiedades requeridas para un mecanismo de revisión m actualización de un agente RI cuando obtiene una información k.A continuación, supondremos que: • La actualización siempre es posible, es decir, un agente siempre puede modificar su creencia establecida BI para recuperar su consistencia A. Diremos que cada agente es localmente eficiente.• Teniendo en cuenta dos conjuntos de contras de información (BI, K1) y contras (BI, K2), también tenemos contras (BI, K1 ∪ K2). Es decir, una consistencia de los agentes es aditiva.• Si un pedazo de información k con respecto al conjunto común BC es consistente con un agente, es consistente con todos los agentes: para todos los agentes (RI, RJ) de tal manera que los contras (BI, KI) y los contras (BJ, KJ)son verdaderos, tenemos, para toda la información k: contras (bi, ki ∪ k) iff cons (bj, kj ∪ k). En tal caso, diremos que el MAS es coherente. Esta última condición simplemente significa que el conjunto de creencias común BC es independiente de las posibles diferencias entre los establecidos de creencias BI de cada agente RI. En el caso más simple, b1 = ... = bn = bc. M también se verá como un mecanismo de aprendizaje incremental y se representará como una aplicación que cambia de BI en BI. A continuación, notaremos RI (BI, KI) para RI cuando sea útil. Definición 4. A una consistencia de una revisión Un mecanismo de actualización m es una IFF consistente para cualquier agente RI y cualquier información que llegue a RI, la consistencia A de este agente se conserva. En otras palabras, IFF: Ri (Bi, Ki) Con-Consistente ⇒ Ri (Bi, Ki) A-Consistente, donde Bi = M (Bi) y Ki = Ki ∪ k es el conjunto de toda la información de otros agentes delMas. De la misma manera, definimos la consistencia MAS de un mecanismo de revisión como la consistencia A de este mecanismo si los agentes eliminan toda la información en el MAS. A continuación, observaremos, si es necesario, RI (Bi, Ki, K) para el Agente RI en MAS R1...rn. Definición 5. Consistencia MAS de una revisión Un mecanismo de actualización MS es MAS consistente en IFF para todos los agentes RI y todas las piezas de información que alcanzan RI, se conserva la masconsistencia de este agente. En otras palabras, IF: ri (bi, ki, k) mas consistente ⇒ ri (bi, ki, k) mas consistente, donde bi = ms (bi), ki = ki ∪ k y k = ∪kj is is is isEl conjunto de toda la información del MAS. El sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 165 por fin, cuando un agente aplica un mecanismo consistente en MAS que obtiene una nueva información, un efecto secundario deseable del mecanismo debe ser que todos los agentes sigan siendo consistentes mas consistentesDespués de cualquier modificación de la parte común BC, es decir, el MAS en sí debería volverse consistente nuevamente. Esta propiedad se define de la siguiente manera: Definición 6. La sólida consistencia MAS de una revisión Un mecanismo de actualización MS es fuertemente consistente en MAS-MS es consistente con MAS, y-la aplicación de MS por un agente conserva la consistencia del MS.2.2 Un mecanismo de actualización muy consistente con MAS La idea general es que, dado que la información se distribuye entre todos los agentes del MAS, debe haber alguna interacción entre el agente del alumno y los otros agentes en un mecanismo de actualización muy consistente de MAS Sra. Para garantizar su consistencia MAS, la EM estará constituida de aplicaciones reiteradas por el agente del alumno RI de un mecanismo interno consistente M, seguido de algunas interacciones entre RI y los otros agentes, hasta que RI recupere su massistencia. Describimos a continuación dicho mecanismo, primero con una descripción de una interacción, luego una iteración y finalmente una declaración de la condición de terminación del mecanismo. El mecanismo es activado por un agente RI al recibir una información k que interrumpe la consistencia MAS. Notaremos m (bi) el conjunto de creencias del agente del alumno RI después de una actualización, porque la parte común modificada por RI y el conjunto de creencias de otro agente RJ inducido por la modificación de su parte común BC en BC. Una interacción I (RI, RJ) entre el agente del alumno RI y otro agente RJ, que actúa como crítico se constituye de los siguientes pasos: • El agente RI envía la actualización BC de la parte común de sus creencias. Habiendo aplicado su mecanismo de actualización, RI es consistente.• El agente RJ verifica la modificación BJ de sus creencias inducidas por la actualización BC. Si esta modificación preserva su consistencia A, RJ adopta esta modificación.• El agente RJ envía una aceptación de BC o una negación junto con una (o más) pieza (s) de información k de tal manera que los contras (BJ, k) son falsos. Luego, una iteración de la EM se compusirá de: • La recepción del agente del alumno RI de una información y la actualización M (BI) restaurando su aconsistencia • Un conjunto de interacciones I (RI, RJ) (en la que varios agentes críticosPosiblemente pueda participar). Si al menos una información que K se transmite a RI, la adición de K necesariamente hará que Ri sea incrustante y se producirá una nueva iteración. Este mecanismo MS termina cuando ningún agente puede proporcionar dicha información k. Cuando es el caso, se restaura la masconsistencia del agente del alumno RI. Proposición 1. Sea R1, ..., RN un MAS consistente en el que el Agente RI recibe una información que rompa su aconsistencia, y en un mecanismo de actualización interna consistente. El mecanismo de actualización MS descrito anteriormente es fuertemente consistente en mas. Prueba. La prueba deriva directamente de la descripción del mecanismo. Este mecanismo asegura que cada vez que un agente reciba un evento, su consistencia mas se restablezca. Como todos los otros agentes adoptan la actualización final BC, todos son consistentes en MAS, y el MAS es consistente. Por lo tanto, MS es un mecanismo de actualización muy consistente. En el mecanismo que MS describió anteriormente, el agente del alumno es el único que recibe y memoriza información durante la ejecución del mecanismo. Asegura que la MS termine. Las piezas de información transmitidas por otros agentes y memorizadas por el agente del alumno son redundantes ya que ya están presentes en el MAS, más precisamente en la memoria de los agentes críticos que los transmitieron. Tenga en cuenta que el mecanismo MS propuso aquí no indica explícitamente el orden ni el alcance de las interacciones. A continuación, consideraremos que la propuesta de modificación BC se envía secuencialmente a los diferentes agentes (mecanismo sincrónico). Además, la respuesta de un agente crítico solo contendrá una información inconsistente con la modificación propuesta. Diremos que la respuesta del agente es mínima. Este mecanismo MS, siendo sincrónico con una respuesta mínima, minimiza la cantidad de información transmitida por los agentes. Ahora lo ilustraremos en el caso del aprendizaje conceptual de múltiples agentes.3. SoundMulti-Agentincremental Learning 3.1 La tarea de aprendizaje Experimentamos el mecanismo propuesto anteriormente en el caso del aprendizaje de concepto MAS incremental. Consideramos aquí un lenguaje de hipótesis en el que una hipótesis es una disyunción de los términos. Cada término es una conjunción de átomos de un conjunto A. Un ejemplo está representado por una etiqueta + o - y una descripción 2 compuesta de un subconjunto de átomos e ⊆ A. Un término cubre un ejemplo si sus átomos constituyentes se incluyen en el ejemplo. Una hipótesis cubre un ejemplo si uno de su término lo cubre. Esta representación se utilizará a continuación para aprender fórmulas booleanas. Los literales negativos están representados aquí por átomos adicionales, como no - a. Las fórmulas booleanas F = (a ∧ b) ∨ (b ∧ ¬c) se escribirán (a ∧ b) ∨ (b ∧ no - c). Un ejemplo positivo de f, como {no - a, b, no - c}, representa un modelo para f.3.2 Proceso de aprendizaje incremental El proceso de aprendizaje es un mecanismo de actualización que, dada una hipótesis actual H, una memoria E = E+ ∪ E− llena con los ejemplos recibidos anteriormente, y un nuevo ejemplo positivo o negativo E, produce una nueva hipótesis actualizada. Antes de esta actualización, la hipótesis dada está completa, lo que significa que cubre todos los ejemplos positivos de E+, y 2 cuando no es posible confusión, el ejemplo de la palabra se utilizará para referirse al par (etiqueta, descripción), así como la descripción sola.166 El sexto intl. Conf.En agentes autónomos y sistemas de múltiples agentes (AAMAS 07) coherentes, lo que significa que no cubre ningún ejemplo negativo de E-. Después de la actualización, la nueva hipótesis debe ser completa y coherente con el nuevo estado de memoria E ∪ {E}. Describimos a continuación nuestro mecanismo de actualización de agente único, inspirado en un trabajo anterior sobre aprendizaje incremental [7]. A continuación, una hipótesis H para la fórmula F objetivo es una lista de términos H, cada uno de ellos es una conjunción de átomos. H es coherente si todos los términos H son coherentes, y H está completo si cada elemento de E+ está cubierto por al menos un término H de H. Cada término es por construcción el LGG (generalización menos general) de un subconjunto de instancias positivas {E1, ..., en} [5], ese es el término más específico que cubre {e1, ..., en}. El operador LGG se define considerando ejemplos como términos, por lo que denotamos como LGG (e) el término más específico que cubre E, y como LGG (H, E) el término más específico que es más general que H y que cubre e.Restringir el término a LGG es la base de muchos algoritmos de aprendizaje ascendente (por ejemplo [5]). En la tipología propuesta por [9], nuestro mecanismo de actualización es un alumno incremental con memoria de instancia completa: el aprendizaje se realiza mediante actualizaciones sucesivas y se almacenan todos los ejemplos. El mecanismo de actualización depende de la hipótesis en curso H, los ejemplos en curso E+ y E-, y el nuevo ejemplo e.Hay tres casos posibles: • E es positivo y H cubre E, o E es negativo y H no cubre e.No se necesita actualización, H ya es completa y coherente con E ∪ {E}.• E es positivo y H no cubre e: e se denota como un contraejemplo positivo de H. Luego buscamos generalizar a su vez los términos H de H. tan pronto como se encuentra una generalización correcta H = LGG (H, E), H reemplaza H en H. Si hay un término que es menos general de que H, se descarte. Si ninguna generalización es correcta (lo que significa aquí coherente), H ∪ lgg (e) reemplaza a H. • E es negativa y H cubre E: E se denota como un contraejemplo negativo de H. Cada término H cubriendo e luego se descarta de H yreemplazado por un conjunto de términos {h1, ...., hn} es decir, en su conjunto, coherente con e- ∪ {e} y eso cubre los ejemplos de e+ descubierto por h - {h}. Los términos de la hipótesis final h que son menos generales que otros se descartan de H. Ahora describiremos el caso donde E = E− es un ejemplo negativo cubierto. Aquí se usan las siguientes funciones: • BUSTONLYBY (H, E+) da el subconjunto de E+ cubierto por H y ningún otro término de H. • Best Cover (H1, H2) da H1 si H1 cubre más ejemplos de descubridos que H2, de lo contrarioda H2.• cubierto (h) da los elementos de descubrimiento cubierto por h.// Especialización de cada h cubriendo e- para cada h de h de h cubriendo e -do h = h - {h} descubrido = cubierto (h, e+) ar = átomos que no están ni en e - ni en h (descubrido = ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅ ∅) do // Buscando la mejor especialización de h hc = h best = ⊥ // ⊥ Cubre ningún ejemplo para cada una de AR DO HC = H ∧ A Best = BestCover (HC, Best) Endfor AR = AR− {Best} Hola= lgg (cubierto (mejor)) h = h ∪ {hi} descubrimiento = descubrimiento de descubrimiento - cubierto (mejor) finalización a medida que los términos de h que son menos generales que otros se descartan. Tenga en cuenta que este mecanismo tiende a hacer una actualización mínima de la hipótesis actual y minimizar el número de términos en la hipótesis, en particular al descartar términos menos generales que otros después de actualizar una hipótesis.3.3 Aprendizaje colectivo Si H es la hipótesis actual, ei la memoria de ejemplo actual del agente ri y e el conjunto de todos los ejemplos recibidos por el sistema, la notación de la sección 2 se convierte en bi = bc = h, ki = ei y k = e. Las contras (H, EI) establecen que H es completa y coherente con EI. En tal caso, RI es consistente. La información K recibida por el Agente RI es simplemente un ejemplo E junto con su etiqueta. Si E es tal que la hipótesis actual H no es completa o coherente con EI ∪ {E}, E contradice h: ri se vuelve incrustante y, por lo tanto, el MAS ya no es consistente. La actualización de una hipótesis cuando llega un nuevo ejemplo es un mecanismo consistente. Siguiendo la Proposición 1 Este mecanismo se puede utilizar para producir un mecanismo fuerte consistente con MAS: al recepción de un nuevo ejemplo en el MAS por un agente R, es posible que se necesite una actualización y, después de un conjunto de interacciones entre R y los otros agentes,Resulta en una nueva hipótesis compartida por todos los agentes y que restaura la consistencia del MAS, que es completa y coherente con los conjuntos de todos los ejemplos presentes en el MAS. Está claro que al minimizar el número de modificaciones de hipótesis, este mecanismo sincrónico y mínimo minimiza el número de ejemplos recibidos por el alumno de otros agentes y, por lo tanto, el número total de ejemplos almacenados en el sistema.4. Experimentos A continuación, aprenderemos una fórmula booleana que es una prueba difícil para el método de aprendizaje: el 11-multiplexor (ver [4]). Se refiere a 3 abordar los atributos booleanos A0, A1, A2 y 8 Atributos booleanos de datos D0, ..., D7. Las fórmulas F11 se satisfacen si el número codificado por los 3 atributos de la dirección es el número de un atributo de datos cuyo valor es 1. Su fórmula es la siguiente: F11 = (A0 ∧A1 ∧A2 ∧D7) ∨ (A0 ∧A1 ∧¬A2 ∧D6) ∨ (A0 ∧¬A1 ∧ A2 ∧D5) ∨ (A0 ∧¬A1 ∧¬A2 ∧D4) ∨ (¬A0 ∧A1 ∧A2 ∧D3) ∨ (¬A0 ∧ A1 ∧¬A2 ∧D2) ∨ (¬A0 ∧¬A1 ∧A2 ∧D1) ∨ (¬A0 ∧¬A1 ∧¬A2 ∧D0). Hay 2048 = 211 posibles ejemplos, la mitad de los cuales son positivos (lo que significa que satisfacen F11) mientras que la otra mitad es negativa. Un experimento generalmente se compone de 50 ensayos. Cada ejecución corresponde a una secuencia de 600 ejemplos que son aprendidos incrementalmente por un sistema de agentes múltiples con agentes n el sexto INTL. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 167 (N-MAS). Se registra una serie de variables como la precisión (es decir, la frecuencia de clasificación correcta de un conjunto de ejemplos invisibles), el tamaño de la hipótesis (es decir, el número de términos en la fórmula actual) o el número de ejemplos almacenados, cada vez que se reciben 25 ejemplos.por el sistema durante esas ejecuciones. En el protocolo que se usa aquí, se envía un nuevo ejemplo a un agente aleatorio cuando el MAS es consistente. El siguiente ejemplo se enviará a su vez a otro agente cuando la consistencia MAS se habrá sido restaurada. De tal manera, simulamos un tipo de aprendizaje lento: la frecuencia de las llegadas de ejemplo es lenta en comparación con el tiempo tomado por una actualización.4.1 Eficiencia del aprendizaje conceptual de MAS 4.1.1 Tiempo de ejecución discutimos brevemente el tiempo de ejecución del aprendizaje en el MAS. Tenga en cuenta que todo el conjunto de acción e interacción en el MAS se simula en un solo procesador. La Figura 1 muestra que el tiempo linealmente depende del número de agentes. Al final de la parte más activa del aprendizaje (200 ejemplos), un 16MAS ha tomado 4 veces más tiempo de aprendizaje que 4-MAS. Este tiempo de ejecución representa todo el conjunto de aprendizaje y Figura 1: tiempo de ejecución de un N-MAS (de n = 2 en la parte inferior a n = 20 en la parte superior).Actividad de comunicación y sugerencias al costo de mantener una hipótesis de aprendizaje consistente en un MAS compuesto de agentes autónomos.4.1.2 Redundancia en la memoria MAS Estudiamos ahora la distribución de los ejemplos en la memoria MAS. La redundancia se escribe rs = ns/ne, donde ns es el número total de ejemplos almacenados en el MAS, es decir, la suma de los tamaños de los agentes ejemplos de recuerdos ei, y ne es el número total de ejemplos recibidos del entorno en el mas. En la Figura 2, comparamos redundancias en 2 a 20 agentes MAS. Hay un pico, que se mueve lentamente de 80 a 100 ejemplos, que representa el número de ejemplos para los cuales el aprendizaje es más activo. Para 20 agentes, la redundancia máxima no es más de 6, que es mucho menor que el valor teórico máximo de 20. Tenga en cuenta que cuando el aprendizaje se vuelve menos activo, la redundancia tiende hacia su valor mínimo 1: cuando no hay más actualizaciones, los ejemplos son solo Figura 2: redundancia de ejemplos almacenados en un NMAS (desde n = 2 en la parte inferior a n = 20 en elarriba) .almacenado por el agente que los recibe.4.1.3 Un N-MAS selecciona una solución más simple que un solo agente, el mecanismo propuesto tiende a minimizar el número de términos en la hipótesis seleccionada. Durante el aprendizaje, el tamaño de la hipótesis actual crece más allá del óptimo y luego disminuye cuando el MAS converge. En el multiplexor 11 Testbed, el número óptimo de términos es 8, pero también existen fórmulas equivalentes con más términos. Es interesante observar que en este caso el 10-mas converge hacia una solución exacta más cercana al número óptimo de términos (aquí 8) (ver Figura 3). Después de que se han presentado 1450 ejemplos, tanto 1-mas como 10-mas han aprendido exactamente el concepto (las precisiones respectivas son 0.9999 y 1) pero el agente único expresa en promedio el resultado como un DNF de 11.0 términos, mientras que el 10-mas expresa comoun términos de 8.8 DNF. Sin embargo, para otras funciones booleanas, encontramos que durante el aprendizaje 1-mas siempre produce hipótesis más grandes que 10-MAS, pero que ambos MAS convergen a hipótesis con resultados de tamaño similares.4.1.4 Un N-MAS es más preciso que un solo agente La Figura 4 muestra la mejora traída por un MAS con agentes N en comparación con un solo agente. Esta mejora no fue especialmente esperada, porque si tenemos uno o n agentes, cuando se otorgan n ejemplos al MAS, tiene acceso a la misma cantidad de información, mantiene solo una hipótesis en curso y utiliza el mismo algoritmo de revisión básica cuando un agente tienepara modificar la hipótesis actual. Tenga en cuenta que si la precisión de 1, 2, 4 y 10 mas es significativamente diferente, mejorando a medida que aumenta el número de agentes, no hay una diferencia clara más allá de este punto: la curva de precisión de los 100 agentes MAS está muy cerca delUno de los 10 agentes MAS.4.1.4.1 Fórmulas booleanas. Para evaluar esta mejora de la precisión, hemos experimentado nuestro protocolo en otros problemas del aprendizaje de la función booleana, como en el caso multiplexor-11, estas funciones 168 la sexta intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) Figura 3: Tamaño de la hipótesis construida por 1 y 10MAS: el caso M11. Figura 4: Precisión de un N-MAS: el caso M11 (de abajo hacia arriba, n = 1, 2, 4, 10, 100).se aprenden en la forma de DNF3 más o menos sintácticamente complejo (es decir, con términos más o menos conjuntivos en el DNF), pero también son más o menos difíciles de aprender, ya que puede ser difícil avanzar en el espacio de hipótesis para alcanzara ellos. Además, la presencia en la descripción de los atributos irrelevantes (es decir, atributos que no pertenecen al DNF objetivo) dificulta el problema. Se han seleccionado los siguientes problemas para experimentar nuestro protocolo: (i) el multiplexor-11 con 9 atributos irrelevantes: M11 9, (ii) el 20-multiplexor M20 (con 4 bits de dirección y 16 bits de datos), (iii) un difícilProblema de paridad (ver [4]) El XORP M: Debe haber un número impar de bits con valor 1 en los primeros atributos de P para que el caso sea positivo, los otros bits son irrelevantes y (iv) una fórmula DNF simple(A ∧ B ∧ C) ∨ (C ∧ D ∧ E) (E ∧ F ∧ G) ∧ (G ∧ H ∧ I) con 19 atributos irrelevantes. La siguiente tabla resume alguna información sobre estos problemas, dando el número total de atributos, incluidos los irrelevantes, el número de 3 atributos de formularios normales irrelevantes, el número mínimo de términos del DNF correspondiente y el número de ejemplos de aprendizaje utilizados. PB Att.Irre.att.Términos Ej. M11 11 0 8 200 M11 9 20 9 8 200 M20 20 0 16 450 XOR3 25 28 25 4 200 XOR5 5 10 5 16 180 XOR5 15 20 15 16 600 Simple4-9 19 28 19 4 200 A continuación se dan los resultados de precisión de nuestros nuestrosMecanismo de aprendizaje con un solo agente y un MAS de 10 agentes, junto con los resultados de dos algoritmos estándar implementados con el entorno de aprendizaje Weka [16]: JRIP (una implementación de Ripper [2]) e ID3 [12]. Para los experimentos con JRIP e ID3, medimos la precisión media en 50 ensayos, cada vez que separa al azar ejemplos en un conjunto de aprendizaje y un conjunto de pruebas. Los parámetros JRIP e ID3 son parámetros predeterminados, excepto que JRIP se usa sin podar. The following table shows the results: Pb JRip Id3 Sm 1 Sm 10 M11 88.3 80.7 88.7 95.5 M11 9 73.4 67.9 66.8 83.5 M20 67.7 62.7 64.6 78.2 Xor3 25 54.4 55.2 71.4 98.5 Xor5 5 52.6 60.8 71.1 78.3 Xor5 15 50.9 51.93 62.4 96.1 Simple4-9 19 99.9 92.3 87.89 98.21 Está claro que los problemas difíciles se resuelven mejor con más agentes (ver, por ejemplo, Xor5 15). Creemos que estos beneficios, que pueden ser importantes con un número cada vez mayor de agentes, se deben al hecho de que cada agente realmente memoriza solo parte del número total de ejemplos, y esta parte es seleccionada en parte por otros agentes como ejemplos de contra.Causa un mayor número de actualizaciones de hipótesis actuales y, por lo tanto, una mejor exploración del espacio de hipótesis.4.1.4.2 Ml Problemas de la base de datos. También hicimos experimentos con algunos problemas no booleanos. Consideramos solo dos problemas (positivos/negativos), tomados de la base de datos de problemas de aprendizaje de UCIS [3]. En todos estos problemas, los ejemplos se describen como un vector de parejas (atributo, valor). Los dominios de valor pueden ser booleanos, numéricos (conjunto totalmente ordenado) o nominal (conjunto no ordenado). Se debe constituir un conjunto adecuado de átomos A para cada problema. Por ejemplo, si A es un atributo numérico, definimos como máximo K umbral K Si, dando intervalos K+1 de densidad uniforme4. Por lo tanto, cada umbral distinto SI le da a dos átomos a ≤ Si y A> Si. En nuestros experimentos, tomamos un número máximo de umbral K = 8. Por ejemplo, en el caso del problema de IONO, hubo 34 atributos numéricos, y se describe una instancia con 506 átomos. A continuación se presentan los resultados de precisión de nuestro sistema junto con resultados anteriores. La columna nb ex.Consulte el 4 La probabilidad de que el valor de A esté en cualquier intervalo es constante el sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 169 Número de ejemplos utilizados para el aprendizaje5. La columna (1) representa valores de precisión mínimos y máximos para los treinta y tres clasificadores probados en [8]. La columna (2) representa los resultados de [13], donde se comparan varios métodos de aprendizaje con los métodos de aprendizaje de conjunto utilizando conjuntos de clasificadores ponderados. La columna S-1 y S-10 da la precisión de la sonrisa con respectivamente 1 y 10 agentes. PB NB EX.(1) (2) S-1 S-10 TTT 862/574 // 76.2-99.7 99.7 99.9 KR-VS-KP 2876/958 // 91.4-99.4 96.8 97.3 Iono 315 // 88.0-91.8 87.2 88.1 Bupa 310 57-72 58-69.3 62.5 63.3 Breastw 614 91-97 94.3-97.3 94.7 94.7 Voto 391 94-96 95.3-96 91.9 92.6 Pima 691 // 71.5- 73.4 65.0 65.0 Heart 243 66-86 77.1-84.1 69.5 70.7 Esta tabla muestra esta tabla esta tabla muestra esta tabla de esta tabla.El algoritmo incremental correspondiente al caso de un solo agente proporciona resultados honorables relativamente a métodos clásicos no incrementales que utilizan hipótesis más grandes y más complejas. En algunos casos, hay una mejora de precisión con 10 agentes MAS. Sin embargo, con tales datos de referencia, que a menudo son ruidosos, la dificultad realmente no proviene de la forma en que se explora el espacio de búsqueda y, por lo tanto, la mejora observada no siempre es significativa. Se ha observado el mismo tipo de fenómeno con métodos dedicados a problemas booleanos duros [4].4.2 Sincronización de MAS Aquí consideramos que los n solteros aprenden sin interacciones y en un momento dado comienzan a interactuar así formando un MAS. El propósito es observar cómo los agentes aprovechan la colaboración cuando comienzan con diferentes estados de creencias y recuerdos. Comparamos en esta sección un 1-mas, un 10-mas (ref) y un 10-mas (100sync) cuyos agentes no se comunicaron durante la llegada de los primeros 100 ejemplos (10 por agentes). Las tres curvas de precisión se muestran en la Figura 5. Al comparar la curva de agente único y el 10-MAS sincronizado, podemos observar que después del comienzo de la sincronización, es decir, en 125 ejemplos, las precisiones son idénticas. Esto se esperaba ya que tan pronto como un ejemplo E recibido por el MAS contradice la hipótesis actual del agente RA que lo recibe, este agente realiza una actualización y su nueva hipótesis se propone a los otros agentes por críticas. Por lo tanto, este primer ejemplo contradictorio lleva al MAS a alcanzar la consistencia en relación con todo el conjunto de ejemplos presentes en los recuerdos de los agentes. Más tarde se obtiene una mayor precisión, correspondiente a un 10-MAS, del 175 ° ejemplo. En otras palabras, el beneficio de una mejor exploración del espacio de investigación se obtiene ligeramente más tarde en el proceso de aprendizaje. Tenga en cuenta que esta sincronización ocurre naturalmente en todas las situaciones en las que los agentes tienen, por alguna razón, una divergencia entre su hipótesis y la memoria del sistema. Esto incluye la fusión de dos MAS a una sola o la llegada de nuevos agentes a una MAS existente.4.3 Experimentos sobre el aprendizaje asincrónico: el efecto de una gran secuencia de datos 5 para TTT y KR-VS-KP, nuestro protocolo no usó más que los ejemplos de aprendizaje más respectivamente 574 y 958, por lo que ponemos otro número en la columna. Figura 5: precisiones de un 1-mas, un 10 mas y un 10-mas sincronizado después de 100 ejemplos. En este experimento relajamos nuestro modo de aprendizaje lento: los ejemplos se envían a un ritmo determinado al MAS. La secuencia de ejemplo resultante se mide en MS -1, y representa el número de ejemplos enviados a la MAS cada MS. Cada vez que la corriente es demasiado grande, el MAS no puede alcanzar la consistencia MAS en la recepción de un ejemplo del entorno antes de que llegue un nuevo ejemplo. Esto significa que el proceso de actualización, iniciado por el Agente R0 cuando recibió un ejemplo, puede estar inacabado cuando R0 u otro agente recibe un nuevo ejemplo. Como resultado, un agente crítico puede tener en el instante T para enviar contra yramples de hipótesis enviadas por varios agentes. Sin embargo, en cuanto a los agentes, en nuestro entorno, memoriza todos los ejemplos que reciben cuando termina la corriente, el MAS necesariamente alcanza la consistencia MAS con respecto a todos los ejemplos recibidos hasta ahora. En nuestros experimentos, aunque su curva de aprendizaje se ralentiza durante la fase de aprendizaje intensa (correspondiente a la baja precisión de las hipótesis actuales), el MAS todavía alcanza una hipótesis satisfactoria más adelante, ya que hay menos y menos contraejemplos en la corriente de ejemplo. En la Figura 6 comparamos las precisiones de dos 11-mas respectivamente sometidos a flujos de ejemplo de diferentes tasas al aprender la fórmula M11. La curva de aprendizaje del MAS que recibe un ejemplo a una tasa de 1/33 ms - 1 casi no está alterada (ver Figura 4), mientras que el 1/16 ms - 1 MAS primero se ralentiza severamente antes de ponerse al día con el primero.5. Trabajos relacionados desde 96 [15], se han realizado varios trabajos en el aprendizaje en MAS, pero más bien en el aprendizaje conceptual. En [11], el MAS realiza una forma de aprendizaje conjunto en el que los agentes son estudiantes perezosos (no se mantiene una representación explícita) y vende ejemplos inútiles a otros agentes. En [10] cada agente observa todos los ejemplos pero solo percibe una parte de su representación. En el aprendizaje de concepto en línea mutuo [14], los agentes convergen a una hipótesis única, pero cada agente produce ejemplos de su propia representación conceptual, lo que resulta en un tipo de sincronización en lugar de en el aprendizaje conceptual puro.170 El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) Figura 6: precisiones de dos tasas de ejemplo asincrónicas de 11 (1/33MS-1 y 1/16MS-1).6. Conclusión Hemos presentado aquí y experimentado un protocolo para el aprendizaje conceptual en línea MAS. La característica principal de este mecanismo de aprendizaje colaborativo es que mantiene una propiedad de consistencia: aunque durante el proceso de aprendizaje, cada agente solo recibe y tiendas, con cierta redundancia limitada, parte de los ejemplos recibidos por el MAS, en cualquier momento la hipótesis actual es consistentecon todo el conjunto de ejemplos. Las hipótesis de nuestros experimentos no abordan los problemas de MAS distribuidos, como fallas (por ejemplo, los mensajes podrían perderse o dañarse) u otras fallas en general (bloqueo, fallas bizantinas, etc.). Sin embargo, nuestro marco está abierto, es decir, los agentes pueden abandonar el sistema o ingresarlo mientras se preserva el mecanismo de consistencia. Por ejemplo, si presentamos un mecanismo de tiempo de espera, incluso cuando un agente crítico se bloquea u omite responder, se implica la consistencia con los otros críticos (dentro de los agentes restantes). En [1], se ha aplicado un enfoque similar a los problemas de abducción de MAS: las hipótesis para mantener, dada una información incompleta, son entonces hechos o declaraciones. El trabajo adicional se refiere al primer acoplamiento de la inducción y la abducción para realizar el aprendizaje de conceptos colaborativos cuando cada agente solo observa parcialmente los ejemplos, y en segundo lugar, investigando el aprendizaje de memoria parcial: cómo se preserva el aprendizaje cuando un agente o todo el MAS olvida algunos ejemplos seleccionados. Conocimientos de conocimiento Estamos muy agradecidos con Dominique Bouthinon por implementar modificaciones tardías en Smile, tan aliviando nuestros experimentos. Parte de este trabajo se ha realizado durante la visita de los primeros autores al Atelier de Bioinformatique de la Universidad de París VI, Francia.7. Referencias [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Dalt-2006, mayo de 2006. [2] W. W. Cohen. Inducción de reglas efectiva rápida. En ICML, páginas 115-123, 1995. [3] C. B. D.J. Newman, S. Hettich y C. Merz. Repositorio de UCI de bases de datos de aprendizaje automático, 1998. [4] S. Esmeir y S. Markovitch. Algoritmos con sede en Lookhead para la inducción en cualquier momento de los árboles de decisión. En ICMLO4, páginas 257-264. Morgan Kaufmann, 2004. [5] J. F¨urnkranz. Una patología de la escalada ascendente en el aprendizaje inductivo de reglas. En ALT, volumen 2533 de LNCS, páginas 263-277. Springer, 2002. [6] A. Guerra-Hern´andoz, A. Elfallah-Sehrouchni y H. Soldano. Aprendizaje en sistemas BDI de múltiples agentes. En Clima IV, volumen 3259, páginas 218-233. Springer Verlag, 2004. [7] M. Henniche. MGI: un algoritmo de abajo hacia arriba incremental. En IEEE Aust.y la Conferencia de Nueva Zelanda sobre Sistemas de Información Inteligente, páginas 347-351, 1994. [8] T.-S.Lim, W.-Y. Loh y Y.-S.Shih. Una comparación de la precisión de la predicción, la complejidad y el tiempo de entrenamiento de treinta y tres algoritmos de clasificación antiguos y nuevos. Aprendizaje automático, 40 (3): 203-228, 2000. [9] M. A. Maloof y R. S. Michalski. Aprendizaje incremental con memoria de instancia parcial. Arte. Intell., 154 (1-2): 95-126, 2004. [10] P. J. Modi y W.-M.Shen. Aprendizaje multiagente colaborativo para tareas de clasificación. En Agentes 01, páginas 37-38. ACM Press, 2001. [11] S. Onta˜non y E. Plaza. Datos de reciclaje para aprendizaje de múltiples agentes. En ICML 05, páginas 633-640. ACM Press, 2005. [12] J. R. Quinlan. Inducción de árboles de decisión. Aprendizaje automático, 1 (1): 81-106, 1986. [13] U. R¨uckert y S. Kramer. Hacia límites estrechos para el aprendizaje de reglas. En ICML 04 (Conferencia Internacional sobre Aprendizaje Autor), página 90, Nueva York, NY, EE. UU., 2004. ACM Press.[14] J. Wang y L. Gasser. Aprendizaje de concepto en línea mutuo para múltiples agentes. En Aamas, páginas 362-369. ACM Press, 2002. [15] G. Weiß y S. Sen, editores. Adaptación y aprendizaje en sistemas de múltiples agentes, volumen 1042 de las notas de conferencias en informática. Springer, 1996. [16] I. H. Witten y E. Frank. Minería de datos: herramientas y técnicas prácticas de aprendizaje automático con implementaciones de Java. Morgan Kaufmann, octubre de 1999. El sexto intl. Conf.en agentes autónomos y sistemas de múltiples agentes (AAMAS 07) 171