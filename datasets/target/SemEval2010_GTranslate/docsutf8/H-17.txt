Políticas de poda para un índice invertido de dos niveles con garantía de corrección Alexandros ntoulas ∗ Microsoft Search Labs 1065 La Avenida Mountain View, CA 94043, EE. UU. Antoulas@microsoft.com Junghoo Cho † UCLA Computer Science Dept. Boelter Hall Los Ángeles, CA 90095, EE. UU. Cho@cs.ucla.edu Resumen Los motores de búsqueda web mantienen índices invertidos a gran escala que son consultados miles de veces por segundo por los usuarios ansiosos por la información. Para hacer frente a las grandes cantidades de cargas de consulta, los motores de búsqueda podan su índice para mantener documentos que probablemente se devuelvan como resultados principales, y usen este índice podado para calcular los primeros lotes de resultados. Si bien este enfoque puede mejorar el rendimiento al reducir el tamaño del índice, si calculamos los resultados principales solo del índice podado, podemos notar una degradación significativa en la calidad de los resultados: si un documento debía estar en los mejores resultados pero no se incluyó enEl índice podado, se colocará detrás de los resultados calculados a partir del índice podado. Dada la feroz competencia en el mercado de búsqueda en línea, este fenómeno es claramente indeseable. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de los resultados debido a la optimización del rendimiento basada en la poda, al tiempo que nos damos cuenta de la mayor parte de su beneficio. Nuestra contribución es una serie de modificaciones en las técnicas de poda para crear el índice podado y un nuevo algoritmo de cálculo de resultados que garantiza que las páginas de coincidencia superior siempre se colocan en los mejores resultados de búsqueda, a pesar de que estamos calculando el primer lote de la poda de la podaíndice la mayor parte del tiempo. También mostramos cómo determinar el tamaño óptimo de un índice podado y evaluamos experimentalmente nuestros algoritmos en una colección de 130 millones de páginas web. Categorías y descriptores de sujetos H.3.1 [Almacenamiento y recuperación de información]: análisis e indexación de contenido;H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información Algoritmos de términos generales, medición, rendimiento, diseño, experimentación 1. Introducción La cantidad de información en la Web está creciendo a un ritmo prodigioso [24]. Según un estudio reciente [13], se estima que la web actualmente consta de más de 11 mil millones de páginas. Debido a esta inmensa cantidad de información disponible, los usuarios se están volviendo cada vez más dependientes de los motores de búsqueda web para localizar información relevante en la web. Por lo general, los motores de búsqueda web, similares a otras aplicaciones de recuperación de información, utilizan una estructura de datos llamada Inverted Index. Un índice invertido proporciona la recuperación eficiente de los documentos (o páginas web) que contienen una palabra clave particular. En la mayoría de los casos, una consulta que los problemas del usuario pueden tener miles o incluso millones de documentos coincidentes. Para evitar abrumar a los usuarios con una gran cantidad de resultados, los motores de búsqueda presentan los resultados en lotes de 10 a 20 documentos relevantes. Luego, el usuario mira a través del primer lote de resultados y, si no encuentra la respuesta que está buscando, podría solicitar ver el próximo lote o decidir emitir una nueva consulta. Un estudio reciente [16] indicó que aproximadamente el 80% de los usuarios examinan como máximo los primeros 3 lotes de los resultados. Es decir, el 80% de los usuarios generalmente ven como máximo 30 a 60 resultados para cada consulta que emiten a un motor de búsqueda. Al mismo tiempo, dado el tamaño de la web, el índice invertido que mantienen los motores de búsqueda pueden crecer muy grandes. Dado que los usuarios están interesados en un pequeño número de resultados (y, por lo tanto, están viendo una pequeña porción del índice para cada consulta que emiten), utilizando un índice que sea capaz de devolver todos los resultados para una consulta puede constituir un desperdicio significativo enTérminos de tiempo, espacio de almacenamiento y recursos computacionales, que seguramente empeorarán a medida que la web aumente con el tiempo [24]. Una solución natural a este problema es crear un pequeño índice en un subconjunto de los documentos que probablemente se devuelvan como los principales resultados (mediante el uso, por ejemplo, las técnicas de poda en [7, 20]) y calculen el primer lotede respuestas usando el índice podado. Si bien se ha demostrado que este enfoque ofrece una mejora significativa en el rendimiento, también conduce a una degradación notable en la calidad de los resultados de búsqueda, porque las respuestas principales se calculan solo del índice podado [7, 20]. Es decir, incluso si una página debe colocarse como la página de coincidencia superior de acuerdo con una métrica de clasificación de motores de búsqueda, la página puede colocarse detrás de las contenidas en el índice podado si la página no se convirtió en parte del índice podado para variosrazones [7, 20]. Dada la feroz competencia entre los motores de búsqueda hoy, esta degradación es claramente indeseable y debe abordarse si es posible. En este artículo, estudiamos cómo podemos evitar cualquier degradación de la calidad de búsqueda debido a la optimización del rendimiento anterior y al mismo tiempo nos damos cuenta de la mayor parte de su beneficio. Es decir, presentamos una serie de cambios simples (pero importantes) en las técnicas de poda para crear el índice podado. Nuestra principal contribución es un nuevo algoritmo de cálculo de respuestas que garantiza que las páginas de coincidencia superior (de acuerdo con la métrica de clasificación de los motores de búsqueda) siempre se colocan en la parte superior de los resultados de búsqueda, a pesar de que estamos calculando el primer lote de respuestas de la poda de las podas de las podas de las podas de las podas.índice la mayor parte del tiempo. Estas técnicas de poda mejoradas y algoritmos de computación de respuestas se exploran en el contexto de la arquitectura de clúster comúnmente empleadas por los motores de búsqueda de hoy. Finalmente, estudiamos y presentamos cómo los motores de búsqueda pueden minimizar el costo operativo de responder consultas al tiempo que proporcionan resultados de búsqueda de alta calidad. Si si si if si if if ip ip ip ip ip ip ip 5000 consultas/seg 5000 consultas/seg: 1000 consultas/seg: 1000 consultas/seg 2nd nivel 1er nivel (a) (b) Figura 1: (a) Replica el motor de búsqueda replicasu índice completo si aumentará la capacidad de consulta y respuesta.(b) En el primer nivel, los pequeños pindexes IP manejan la mayoría de las consultas. Cuando IP no puede responder una consulta, se redirige al segundo nivel, donde el índice completo si se usa para calcular la respuesta.2. La arquitectura de clúster y el ahorro de costos de un índice podado, un motor de búsqueda descarga documentos de la web y mantiene un índice invertido local que se utiliza para responder consultas rápidamente. Índices invertidos. Suponga que hemos recopilado un conjunto de documentos d = {d1 ,..., Dm} y que hemos extraído todos los términos t = {t1 ,..., tn} de los documentos. Para cada término ti ∈ T mantenemos una lista I (ti) de ID de documento que contienen Ti. Cada entrada en I (Ti) se llama publicación y se puede extender para incluir información adicional, como cuántas veces aparece Ti en un documento, las posiciones de TI en el documento, si Ti es audaz/cursiva, etc. El conjunto de todas las listas i = {i (t1) ,..., I (tn)} es nuestro índice invertido.2.1 Los motores de búsqueda de arquitectura de índice de dos niveles aceptan una enorme cantidad de consultas todos los días de usuarios ansiosos que buscan información relevante. Por ejemplo, se estima que Google responde más de 250 millones de consultas de usuarios por día. Para hacer frente a esta gran carga de consulta, los motores de búsqueda generalmente replican su índice en un gran clúster de máquinas como lo ilustra el siguiente ejemplo: Ejemplo 1 considere un motor de búsqueda que mantiene un clúster de máquinas como en la Figura 1 (a). El tamaño de su índice invertido completo si es más grande de lo que se puede almacenar en una sola máquina, por lo que cada copia de IF se almacena en cuatro máquinas diferentes. También suponemos que una copia de IF puede manejar la carga de consulta de 1000 consultas/seg. Suponiendo que el motor de búsqueda obtenga 5000 consultas/seg, debe replicarse si cinco veces para manejar la carga. En general, el motor de búsqueda necesita mantener 4 × 5 = 20 máquinas en su clúster.2 Mientras replica completamente todo el índice si varias veces es una forma directa de escalar a una gran cantidad de consultas, las cargas de consultas típicas en los motores de búsqueda exhiben ciertas localidades, lo que permite una reducción significativa en el costo al replicar solo una pequeña porción del índice completo. En principio, esto generalmente se hace podando un índice completo si crear un índice más pequeño y podado (o índice P) IP, que contiene un subconjunto de los documentos que probablemente se devuelven como resultados principales. Dado el índice P, los motores de búsqueda operan empleando una arquitectura de índice de dos años como mostramos en la Figura 1 (b): todas las consultas entrantes se dirigen primero a uno de los índices P que se mantienen en el primer nivel. En los casos en que un índice P no puede calcular la respuesta (por ejemplo, no pudo encontrar suficientes documentos para regresar al usuario), la consulta se responde redirigiéndola al segundo nivel, donde mantenemos un índice completo si. El siguiente ejemplo ilustra la posible reducción en el costo de procesamiento de consultas al emplear esta arquitectura de índice de dos niveles. Ejemplo 2 Suponga la misma configuración de parámetros que en el Ejemplo 1. Es decir, el motor de búsqueda obtiene una carga de consulta de 5000 consultas/algoritmo de seg 2.1 Cálculo de respuesta con entrada de garantía de corrección q = ({t1, ..., tn}, [i, i + k]) donde {t1 ,..., TN}: Palabras clave en la consulta [i, i + k]: rango del procedimiento de respuesta para devolver (1) (a, c) = computteanswer (q, ip) (2) if (c = 1) entonces (3) Devuelve a (4) else (5) a = CopeAnswer (Q, If) (6) Devuelve una Figura 2: Calculando la respuesta debajo de la arquitectura de dos niveles con la garantía de corrección de resultados.y cada copia de un índice (tanto el IP y el IP-índice P) puede manejar hasta 1000 consultas/seg. También suponga que el tamaño de IP es un cuarto de IF y, por lo tanto, se puede almacenar en una sola máquina. Finalmente, supongamos que los índices P pueden manejar el 80% de las consultas de los usuarios por sí mismas y solo reenviar las consultas del 20% restantes a IF. En esta configuración, dado que las consultas de usuario de 5000/seg se dirigen primero a un índice P, se necesitan cinco copias de IP en el primer nivel. Para el segundo nivel, dado que se reenvían el 20% (o 1000 consultas/seg), necesitamos mantener una copia de IF para manejar la carga. En general, necesitamos un total de 9 máquinas (cinco máquinas para las cinco copias de IP y cuatro máquinas para una copia de IF). En comparación con el Ejemplo 1, esta es una reducción de más del 50% en el número de máquinas.2 El ejemplo anterior demuestra el ahorro potencial de costos logrado mediante el uso de un índice P. Sin embargo, la arquitectura de dos niveles puede tener un inconveniente significativo en términos de calidad de resultados en comparación con la replicación completa de IF;Dado el hecho de que el índice P contiene solo un subconjunto de los datos del índice completo, es posible que, para algunas consultas, el índice P pueda no contener el documento mejor clasificado de acuerdo con los criterios de clasificación particulares utilizados por elEl motor de búsqueda y no lo devuelven como la página superior, lo que lleva a una notable degradación de calidad en los resultados de búsqueda. Dada la feroz competencia en el mercado de búsqueda en línea, los operadores de motores de búsqueda intentan desesperadamente evitar cualquier reducción en la calidad de búsqueda para maximizar la satisfacción del usuario.2.2 Garantía de corrección bajo arquitectura de dos niveles ¿Cómo podemos evitar la degradación potencial de la calidad de búsqueda bajo la arquitectura de dos niveles? Nuestra idea básica es sencilla: usamos el resultado de Top-K del índice P solo si sabemos con certeza que el resultado es el mismo que el resultado de Top-K del índice completo. El algoritmo en la Figura 2 formaliza esta idea. En el algoritmo, cuando calculamos el resultado de IP (paso 1), calculamos no solo el resultado de Top-K, sino también la función del indicador de corrección C definida de la siguiente manera: Definición 1 (función del indicador de corrección) dada una consulta Q,La IP del índice P devuelve la respuesta A junto con una función indicadora de corrección C. C se establece en 1 si se garantiza que A es idéntica (es decir, los mismos resultados en el mismo orden) al resultado calculado a partir del índice completo si. Si es posible que A sea diferente, C se establece en 0. 2 Tenga en cuenta que el algoritmo devuelve el resultado de IP (paso 3) solo cuando es idéntico al resultado de IF (condición C = 1 en el paso 2). De lo contrario, el algoritmo recomputa y devuelve el resultado del índice completo si (Paso 5). Por lo tanto, se garantiza que el algoritmo devolverá el mismo resultado que la replicación completa de todo el tiempo. Ahora, el verdadero desafío es averiguar (1) cómo podemos calcular la función del indicador de corrección C y (2) cómo debemos podar el índice para asegurarnos de que la mayoría de las consultas sean manejadas solo por IP. Pregunta 1 ¿Cómo podemos calcular la función del indicador de corrección C? Una forma directa de calcular C es calcular la respuesta de Top-K tanto desde IP como de IF y compararla. Sin embargo, esta solución ingenua incurre en un costo incluso más alto que la replicación completa de si porque las respuestas se calculan dos veces: una vez de IP y una vez de IF. ¿Hay alguna forma de calcular la función del indicador de corrección c solo desde IP sin calcular la respuesta de IF? Pregunta 2 ¿Cómo debemos podar si IP para realizar el ahorro máximo de costos? La efectividad del algoritmo 2.1 depende críticamente de la frecuencia con la que se evalúa la función del indicador de corrección C como 1. Si C = 0 para todas las consultas, por ejemplo, las respuestas a todas las consultas se calcularán dos veces, una vez desde IP (Paso 1) y una vez desde IF (Paso 5), por lo que el rendimiento será peor que la replicación completa de IF. ¿Cuál será la forma óptima de podar si a IP, de modo que c = 1 para una gran fracción de consultas? En las siguientes secciones, intentamos abordar estas preguntas.3. Tamaño óptimo del índice P intuitivamente, existe una compensación clara entre el tamaño de IP y la fracción de consultas que IP puede manejar: cuando la IP es grande y tiene más información, podrá manejar más consultas, pero el costoPara mantener y buscar IP será mayor. Cuando la IP es pequeña, por otro lado, el costo para la IP será más pequeño, pero se enviarán más consultas a si, requeriendo que mantengamos más copias de IF. Dada esta compensación, ¿cómo debemos determinar el tamaño óptimo de IP para maximizar el ahorro de costos? Para encontrar la respuesta, comenzamos con un ejemplo simple. Ejemplo 3 Nuevamente, considere un escenario similar al Ejemplo 1, donde la carga de consulta es de 5000 consultas/seg, cada copia de un índice puede manejar 1000 consultas/seg, y el índice completo se extiende en 4 máquinas. Pero ahora, supongamos que si podamos en un 75% a IP 1 (es decir, el tamaño de IP 1 es el 25% de IF), IP 1 puede manejar el 40% de las consultas (es decir, C = 1 para el 40% delconsultas). También suponga que si se poda en un 50% a IP 2, IP 2 puede manejar el 80% de las consultas. ¿Cuál de las IP 1, IP 2 es preferible para el índice de primer nivel? Para averiguar la respuesta, primero calculamos el número de máquinas necesarias cuando usamos IP 1 para el primer nivel. En el primer nivel, necesitamos 5 copias de IP 1 para manejar la carga de consulta de 5000 consultas/seg. Dado que el tamaño de IP 1 es del 25% de IF (eso requiere 4 máquinas), una copia de IP 1 requiere una máquina. Por lo tanto, el número total de máquinas requeridas para el primer nivel es 5 × 1 = 5 (5 copias de IP 1 con 1 máquina por copia). Además, dado que IP 1 puede manejar el 40% de las consultas, el segundo nivel tiene que manejar 3000 consultas/seg (60% de las 5000 consultas/seg), por lo que necesitamos un total de 3 × 4 = 12 máquinas para el segundo nivel(3 copias de IF con 4 máquinas por copia). En general, cuando usamos IP 1 para el primer nivel, necesitamos 5 + 12 = 17 máquinas para manejar la carga. Podemos hacer un análisis similar cuando usamos IP 2 y ver que se necesitan un total de 14 máquinas cuando se usa IP 2. Dado este resultado, podemos concluir que el uso de IP 2 es preferible.2 El ejemplo anterior muestra que el costo de la arquitectura de dos niveles depende de dos parámetros importantes: el tamaño del índice P y la fracción de las consultas que pueden manejar solo el índice de primer nivel. Usamos S para denotar el tamaño del índice P en relación con IF (es decir, si S = 0.2, por ejemplo, el índice P es el 20% del tamaño de IF). Usamos F (s) para denotar la fracción de las consultas que un índice P de tamaño S puede manejar (es decir, si F (s) = 0.3, el 30% de las consultas devuelve el valor C = 1 de IP). En general, podemos esperar que F (S) aumente a medida que S se hace más grande porque IP puede manejar más consultas a medida que crece su tamaño. En la Figura 3, mostramos un gráfico de ejemplo de F (s) sobre s.Dada la notación, podemos establecer el problema de la optimización del tamaño del índice P de la siguiente manera. Al formular el problema, suponemos que el número de máquinas requeridas para operar una arquitectura de dos niveles 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 fracción de la fracción garantizada-F (s) de la fracción de índice de consultas garantizadas por fracción de la fracción de la fracción deTamaño óptimo del índice S = 0.16 Figura 3: Función de ejemplo que muestra la fracción de consultas garantizadas F (S) en un tamaño S dado S del índice P.es aproximadamente proporcional al tamaño total de los índices necesarios para manejar la carga de consulta. Problema 1 (tamaño de índice óptimo) Dada una carga de consulta Q y la función F (s) F (s), encuentre el tamaño óptimo del índice P que minimiza el tamaño total de los índices necesarios para manejar la carga Q. 2 El siguiente teorema muestra cómopuede determinar el tamaño óptimo del índice. Teorema 1 El costo para manejar la carga de consulta Q es mínimo cuando el tamaño del índice p, s, satisface d f (s) d s = 1. 2 prueba de la prueba de esto y los siguientes teoremas se omiten debido a limitaciones de espacio. Este teorema muestra que el punto óptimo es cuando la pendiente de la curva F (S) es 1. Por ejemplo, en la Figura 3, el tamaño óptimo es cuando S = 0.16. Tenga en cuenta que la forma exacta del gráfico F (S) puede variar según la carga de consulta y la política de poda. Por ejemplo, incluso para el mismo índice P, si la carga de consulta cambia significativamente, menos (o más) consultas pueden ser manejadas por el índice P, disminuyendo (o aumentando) F (s) F (s). Del mismo modo, si utilizamos una política de poda efectiva, IP manejará más consultas que cuando usamos una política de poda ineficaz, aumentando F (S). Por lo tanto, la función f (s) y el tamaño del índice óptimo pueden cambiar significativamente dependiendo de la carga de consulta y la política de poda. Sin embargo, en nuestros experimentos posteriores, encontramos que a pesar de que la forma del gráfico F (S) cambia notablemente entre los experimentos, el tamaño óptimo del índice se encuentra constantemente entre 10% y 30% en la mayoría de los experimentos.4. Políticas de poda En esta sección, mostramos cómo debemos podar el índice completo si a IP, de modo que (1) podamos calcular la función del indicador de corrección C de IP en sí y (2) podemos manejar una gran fracción de consultas por IP. Al diseñar las políticas de poda, observamos las siguientes dos localidades en el comportamiento de búsqueda de usuarios: 1. Localidad de palabras clave: aunque hay muchas palabras diferentes en la recopilación de documentos que el motor de búsqueda índice, algunas palabras clave populares constituyen la mayoría de las cargas de consulta. Esta localidad de palabras clave implica que el motor de búsqueda podrá responder una fracción significativa de consultas de usuarios, incluso si puede manejar solo estas pocas palabras clave populares.2. Localidad de documentos: incluso si una consulta tiene millones de documentos coincidentes, los usuarios generalmente solo miran los primeros resultados [16]. Por lo tanto, mientras los motores de búsqueda puedan calcular las primeras respuestas de Top-K correctamente, los usuarios a menudo no notarán que el motor de búsqueda en realidad no ha calculado la respuesta correcta para los resultados restantes (a menos que los usuarios los soliciten explícitamente). Según las dos localidades anteriores, ahora investigamos dos tipos diferentes de políticas de poda: (1) una política de poda de palabras clave, que aprovecha la localidad de palabras clave al podar toda la lista invertida I (TI) para palabras clave impopulares TI y (2)Una política de poda de documentos, que aprovecha la localidad de documentos al mantener solo unas pocas publicaciones en cada lista I (TI), que probablemente se incluya en los resultados de Top-K. Como discutimos antes, necesitamos poder calcular la función indicadora de corrección del índice podado solo para proporcionar la garantía de corrección. Dado que el cálculo de la función del indicador de corrección puede depender críticamente de la función de clasificación particular utilizada por un motor de búsqueda, primero aclaramos nuestros supuestos en la función de clasificación.4.1 Suposiciones sobre la función de clasificación Considere una consulta q = {t1, t2 ,..., tw} que contiene un subconjunto de los términos de índice. El objetivo del motor de búsqueda es devolver los documentos que son más relevantes para la consulta q. Esto se hace en dos pasos: primero usamos el índice invertido para encontrar todos los documentos que contienen los términos en la consulta. En segundo lugar, una vez que tenemos los documentos relevantes, calculamos el rango (o puntaje) de cada uno de los documentos con respecto a la consulta y volvemos al usuario los documentos que clasifican el más alto. La mayoría de los principales motores de búsqueda de hoy devuelven documentos que contienen todos los términos de consulta (es decir, usan y semántico). Para hacer que nuestras discusiones sean más concisas, también asumiremos lo popular y semántico mientras respondemos una consulta. Es sencillo extender nuestros resultados a o semánticos también. La función de clasificación exacta que emplean los motores de búsqueda es un secreto estrechamente guardado. Sin embargo, lo que se sabe es que los factores para determinar la clasificación de documentos se pueden clasificar aproximadamente en dos clases: relevancia dependiente de la consulta. Este factor particular de relevancia captura cuán relevante es la consulta para cada documento. En un nivel alto, dado un documento D, para cada término TI, un motor de búsqueda asigna una puntuación de relevancia de término TR (D, TI) a D. dados los puntajes TR (D, Ti) para cada TI, entonces la relevancia dependiente de la consultade D a la consulta, observada como TR (D, Q), se puede calcular combinando los valores de relevancia del término individual. Una forma popular para calcular la relevancia de consulta es representar tanto el documento D como la consulta Q utilizando el modelo de espacio vectorial TF.IDF [29] y emplear una métrica de distancia de coseno. Dado que la forma exacta de TR (D, Ti) y TR (D, Q) difiere según el motor de búsqueda, no nos restringiremos a ninguna forma particular;En cambio, para que nuestro trabajo sea aplicable en el caso general, haremos la suposición genérica de que la relevancia dependiente de la consulta se calcula en función de los valores de relevancia del término individual en la consulta: tr (d, q) = ftr (TR (D, T1), ..., TR (D, TW)) (1) Calidad del documento independiente de la consulta. Este es un factor que mide la calidad general de un documento D independiente de la consulta particular emitida por el usuario. Las técnicas populares que calculan la calidad general de una página incluyen PageRank [26], éxitos [17] y la probabilidad de que la página sea una página de spam [25, 15]. Aquí, usaremos Pr (D) para denotar esta parte independiente de la consulta de la función de clasificación final para el documento D. El puntaje de clasificación final R (D, Q) de un documento dependerá tanto de la consulta como de la consulta como independiente de la consultaPartes de la función de clasificación. La combinación exacta de estas partes se puede hacer de varias maneras. En general, podemos suponer que el puntaje de clasificación final de un documento es una función de sus puntajes de relevancia dependiente de la consulta e independiente de la consulta. Más formalmente: r (d, q) = fr (tr (d, q), pr (d)) (2) Por ejemplo, fr (tr (d, q), pr (d)) puede tomar la forma fr (tr (d, q), pr (d)) = α · tr (d, q) + (1-α) · pr (d), dando así α a la parte dependiente de la consulta y el peso 1-α ala parte independiente de la consulta. En las ecuaciones 1 y 2, la forma exacta de FR y FTR puede variar según el motor de búsqueda. Por lo tanto, para que nuestra discusión sea aplicable independientemente de la función de clasificación particular utilizada por los motores de búsqueda, en este documento, solo haremos la suposición genérica de que la función de clasificación R (D, Q) es monotónica en sus parámetros TR (D, T1),..., tr (d, tw) y pr (d).T1 → D1 D2 D3 D4 D5 D6 T2 → D1 D2 D3 T3 → D3 D5 D7 D8 T4 → D4 D10 T5 → D6 D8 D9 Figura 4: Pruning de palabras clave y documentos. Algoritmo 4.1 Cálculo de C para el procedimiento de poda de palabras clave (1) c = 1 (2) foreach ti ∈ Q (3) if (i (ti) /∈ Ip) Entonces c = 0 (4) return c Figura 5: Garantía de resultado enpoda de palabras clave. Definición 2 Una función F (α, β, ..., ω) es monotónica si ∀α1 ≥ α2, ∀β1 ≥ β2 ,...∀Ω1 ≥ ω2 sostiene que: F (α1, β1, ..., ω1) ≥ F (α2, β2, ..., ω2). Aproximadamente, la monotonicidad de la función de clasificación implica que, entre dos documentos D1 y D2, si D1 tiene una mayor relevancia de consulta que D2 y también una puntuación independiente de consulta más alta que D2, entonces D1 debe clasificarse más alta que D2, lo que creemos que ISuna suposición razonable en la mayoría de los entornos prácticos.4.2 Pruning de palabras clave Dadas nuestras suposiciones en la función de clasificación, ahora investigamos la política de poda de palabras clave, que poda el índice invertido si es horizontalmente eliminando todo el I (Ti) S correspondiente a los términos menos frecuentes. En la Figura 4 mostramos una representación gráfica de la poda de palabras clave, donde eliminamos las listas invertidas para T3 y T5, suponiendo que no aparecen a menudo en la carga de consulta. Tenga en cuenta que después de la poda de palabras clave, si todas las palabras clave {T1 ,..., tn} En la consulta Q aparece en IP, el índice P tiene la misma información que mientras se preocupe Q. En otras palabras, si todas las palabras clave en Q aparecen en IP, la respuesta calculada desde IP se garantiza que es la misma que la respuesta calculada de IF. La Figura 5 formaliza esta observación y calcula la función del indicador de corrección C para una IP de índice privado de palabras clave. Es sencillo demostrar que la respuesta de IP es idéntica a la de si C = 1 en el algoritmo anterior. Ahora consideramos el problema de optimizar la IP de manera que pueda manejar la mayor fracción de consultas. Este problema se puede establecer formalmente de la siguiente manera: Problema 2 (poda de palabras clave óptimas) dada la carga de consulta Q y un tamaño de índice de meta S · | if |Para el índice podado, seleccione las listas invertidas IP = {I (T1) ,..., I (th)} tal que | ip |≤ s · | if |y se maximiza la fracción de consultas que IP puede responder (expresada por F (s)).2 Desafortunadamente, la solución óptima al problema anterior es intratable como podemos mostrar reduciendo la mochila (omitimos la prueba completa). Teorema 2 El problema de calcular la poda de palabras clave óptimas es NP-HARD.2 Dada la intratabilidad de la solución óptima, necesitamos recurrir a una solución aproximada. Un enfoque común para problemas de mochila similares es adoptar una política codiciosa manteniendo los artículos con el beneficio máximo por costo unitario [9]. En nuestro contexto, el beneficio potencial de una lista invertida I (TI) es el número de consultas que puede ser respondida por IP cuando I (TI) se incluye en IP. Aproximamos este número por la fracción de consultas en la carga de consulta Q que incluyen el término Ti y lo representan como P (Ti). Por ejemplo, si 100 de 1000 consultas contienen el término computadora, algoritmo 4.2 Procedimiento de Pruning HS de palabras clave codiciosas (1) ∀Ti, Calcule HS (Ti) = P (Ti) | I (Ti) |.(2) Incluya las listas invertidas con los valores más altos de HS (TI) de tal manera que | IP |≤ s · | if |. Figura 6: Algoritmo de aproximación para la poda de palabras clave óptima. Algoritmo 4.3 Pruning de documentos globales V SG Procedimiento (1) Ordene todos los documentos DI según PR (DI) (2) Encuentre el valor umbral τp, de modo que solo la fracción de los documentos tiene PR (di)> τp (4) Mantenga DIEn las listas invertidas si PR (DI)> τp Figura 7: Pruning de documentos globales basados en PR.Entonces P (computadora) = 0.1. El costo de incluir i (ti) en el pindex es su tamaño | i (ti) |. Por lo tanto, en nuestro enfoque codicioso en la Figura 6, incluimos I (Ti) s en el orden decreciente de P (Ti)/| I (Ti) |Mientras | IP |≤ s · | if |. Más adelante en nuestra sección del experimento, evaluamos qué fracción de consultas puede ser manejada por IP cuando empleamos esta política codiciosa de las palabras clave.4.3 Pruning de documentos a un alto nivel, la poda de documentos intenta aprovechar la observación de que la mayoría de los usuarios están principalmente interesados en ver las pocas respuestas principales a una consulta. Dado esto, es innecesario mantener todas las publicaciones en una lista invertida I (TI), porque los usuarios no mirarán la mayoría de los documentos de la lista de todos modos. Representamos el diagrama conceptual de la política de poda de documentos en la Figura 4. En la figura, podamos verticalmente las publicaciones correspondientes a D4, D5 y D6 de T1 y D8 de T3, suponiendo que es poco probable que estos documentos formen parte de las respuestas de Top-K a las consultas de los usuarios. Nuevamente, nuestro objetivo es desarrollar una política de poda de tal manera que (1) podamos calcular la función del indicador de corrección C solo con IP y (2) podemos manejar la mayor fracción de consultas con IP. En las siguientes secciones, discutimos algunos enfoques alternativos para la poda de documentos.4.3.1 Pruning global basada en relaciones públicas Primero investigamos la política de poda que comúnmente utiliza los motores de búsqueda existentes. La idea básica para esta política de poda es que el puntaje de calidad independiente de la consulta PR (D) es un factor muy importante para calcular la clasificación final del documento (p. Ej. Se sabe que PageRank es uno de los factores más importantes que determinan la clasificación general en los resultados de búsqueda), por lo que construimos el índice P al mantener solo aquellos documentos cuyos valores de PR son altos (es decir, PR (D)> τp para un umbralvalor τp). La esperanza es que es probable que la mayoría de los resultados mejor clasificados tengan altos valores de PR (D), por lo que es probable que la respuesta calculada a partir de este índice P sea similar a la respuesta calculada a partir del índice completo. La Figura 7 describe esta política de poda de manera más formal, donde ordenamos todos los documentos por sus respectivos valores de PR (DI) y mantenemos una DI en el índice P cuando su algoritmo 4.4 Pruning de documentos locales V SL n: Tamaño máximo de una sola lista de publicacionesProcedimiento (1) foreach i (ti) ∈ if (2) clasificar dis en i (ti) basado en pr (di) (3) si | i (ti) |≤ n Luego mantenga todos los dis (4) de lo contrario Mantenga el DIS superior con el PR (DI) más alto Figura 8: Pruning de documentos locales basada en PR. Algoritmo 4.5 Procedimiento de poda de documento de palabras clave extendida (1) para cada i (ti) (2) Mantenga d ∈ I (Ti) si PR (D)> τpi o TR (D, Ti)> τti Figura 9: Palabra clave extendida-poda de documentos específico basada en PR y TR.El valor PR (DI) es más alto que el valor umbral global τp. Nos referimos a esta política de poda como poda basada en relaciones públicas (GPR). Las variaciones de esta política de poda son posibles. Por ejemplo, podemos ajustar el valor umbral τp localmente para cada lista invertida I (Ti), de modo que mantengamos al menos un cierto número de publicaciones para cada lista invertida I (TI). Esta política se muestra en la Figura 8. Nos referimos a esta política de poda como poda local basada en relaciones públicas (LPR). Desafortunadamente, la mayor parte de esta política es que podemos demostrar que no podemos calcular la función de corrección C solo de IP cuando IP se construye de esta manera. Teorema 3 No hay podas de documentos basada en PR puede proporcionar la garantía de resultados.2 Prueba Suponga que creamos IP en función de la política GPR (generalizar la prueba de LPR es sencilla) y que cada documento D con PR (D)> τp se incluye en IP. Suponga que la entrada KTH en los resultados de Top-K tiene una puntuación de clasificación de R (DK, Q) = FR (TR (DK, Q), PR (DK)). Ahora considere otro documento DJ que fue podado de IP porque PR (DJ) <τp. Aun así, todavía es posible que el valor de los documentos tr (DJ, Q) sea muy alto que R (DJ, Q) = FR (Tr (DJ, Q), PR (DJ))> R (DK, Q). Por lo tanto, bajo una política de poda basada en PR, la calidad de la respuesta calculada a partir de IP puede ser significativamente peor que la de si y no es posible detectar esta degradación sin calcular la respuesta de IF. En la siguiente sección, proponemos cambios simples pero esenciales en esta política de poda que nos permite calcular la función de corrección C solo con IP.4.3.2 Pruning de palabras clave extendida El principal problema de las políticas globales de poda de documentos basadas en relacionesUn puntaje de clasificación más alto que los que regresaron de IP debido a sus puntajes de TR altos. Aquí, proponemos una nueva política de poda, llamada poda de documentos específicas de palabras clave extendidas (EKS), que evita este problema al podar no solo en función de la puntuación PR (D) independiente de la consulta, sino también basada en el término Relevancia TR (D, ti) puntaje. Es decir, para cada lista invertida I (Ti), elegimos dos valores de umbral, τpi para PR y τti para TR, de modo que si un documento d ∈ I (Ti) satisface PR (D)> τpi o TR (D, Ti)> τti, lo incluimos en i (ti) de IP. De lo contrario, lo podamos de IP. La Figura 9 describe formalmente este algoritmo. Los valores umbral, τpi y τti, pueden seleccionarse de varias maneras diferentes. Por ejemplo, si PR y TR tienen el mismo peso en la clasificación final y si queremos mantener en la mayoría de las publicaciones n en cada lista invertida I (Ti), es posible que deseemos establecer los dos valores de umbral iguales a τi (τpi = τti = =τi) y ajustar τi de modo que las publicaciones n permanezcan en i (ti). Esta nueva política de poda, cuando se combina con una función de puntuación monotónica, nos permite calcular la función del indicador de corrección C del índice podado. Usamos el siguiente ejemplo para explicar cómo podemos calcular C. Ejemplo 4 Considere la consulta q = {T1, T2} y una función de clasificación monotónica, F (PR (D), Tr (D, T1), Tr (D, T2)). Hay tres escenarios posibles sobre cómo aparece un documento D en el IP de índice podado.1. D aparece tanto en I (T1) como en I (T2) de IP: dado que la información completa de D aparece en IP, podemos calcular el algoritmo exacto 4.6 Respuesta informática de la consulta de entrada IP Q = {T1 ,..., TW} Salida A: resultado de Top-K, C: Procedimiento de función del indicador de corrección (1) para cada di ∈ I (t1) ∪ · · · ∪ I (tw) (2) para cada tm ∈ Q (3)∈ I (tm) (4) tr ∗ (di, tm) = tr (di, tm) (5) else (6) tr ∗ (di, tm) = τtm (7) f (di) = f (pr (pr (Di), tr ∗ (di, t1), ..., tr ∗ (di, tn)) (8) a = top-k dis con valores más altos de f (di) (9) c = j 1 si todo di ∈A aparece en todo i (ti), ti ∈ Q 0 Figura 10: Ranking basado en los umbrales TRτ (Ti) y PRτ (Ti).puntaje de D basado en valores PR (D), TR (D, T1) y TR (D, T2) en IP: F (PR (D), TR (D, T1), TR (D, T2)).2. D aparece solo en I (T1) pero no en I (T2): dado que D no aparece en I (T2), no conocemos TR (D, T2), por lo que no podemos calcular su puntaje de clasificación exacta. Sin embargo, a partir de nuestros criterios de poda, sabemos que TR (D, T2) no puede ser mayor que el valor umbral τt2. Por lo tanto, de la monotonicidad de F (definición 2), sabemos que el puntaje de clasificación de D, F (PR (D), TR (D, T1), TR (D, T2)), no puede ser mayor que F (PR (PR(D), tr (d, t1), τt2).3. D no aparece en ninguna lista: dado que D no aparece en absoluto en IP, no conocemos ninguno de los valores PR (D), TR (D, T1), TR (D, T2). Sin embargo, a partir de nuestros criterios de poda, sabemos que PR (D) ≤ τp1 y ≤ τp2 y que TR (D, T1) ≤ τt1 y TR (D, T2) ≤ τt2. Por lo tanto, a partir de la monotonicidad de F, sabemos que el puntaje de clasificación de D, no puede ser más grande que F (min (τp1, τp2), τt1, τt2).2 El ejemplo anterior muestra que cuando un documento no aparece en una de las listas invertidas I (Ti) con ti ∈ Q, no podemos calcular su puntaje de clasificación exacta, pero aún podemos calcular su puntaje de límite superior utilizando el valor umbral τtipara los valores faltantes. Esto sugiere el algoritmo en la Figura 10 que calcula el resultado de Top-K de A de IP junto con la función indicadora de corrección C.En todas las listas invertidas I (Ti) con ti ∈ Q, por lo que conocemos su puntaje exacto. En este caso, debido a que estos documentos tienen puntajes más altos que las puntuaciones límite superiores de cualquier otro documento, sabemos que ningún otro documento puede aparecer en Top-K. El siguiente teorema prueba formalmente la corrección del algoritmo. En [11] Fagin et al., Proporcionan una prueba similar en el contexto del middleware multimedia. Teorema 4 Dado un índice IP invertido podado por el algoritmo en la Figura 9, una consulta q = {t1 ,..., TW} y una función de clasificación monotónica, el resultado de Top-K de IP calculado por el algoritmo 4.6 es el mismo que el resultado de Top-K de IF IF C = 1. 2 Prueba supongamos que DK es el documento clasificado KTH calculado desde IPSegún el algoritmo 4.6. Para cada documento di ∈ Si eso no está en el resultado de Top-K de IP, hay dos escenarios posibles: Primero, DI no está en la respuesta final porque fue podada de todas las listas invertidas I (TJ), 1 ≤ J ≤W, en IP. En este caso, sabemos que PR (di) ≤ min1≤j≤wτpj <pr (dk) y que tr (di, tj) ≤ τtj <tr (dk, tj), 1 ≤ j ≤ w.De la suposición de monotonicidad, se deduce que el puntaje de clasificación de DI es R (DI) <R (DK). Es decir, la puntuación DIS nunca puede ser más grande que la de DK. En segundo lugar, Di no está en la respuesta porque DI se poda de algunas listas invertidas, digamos, I (T1) ,..., I (TM), en IP. Supongamos ¯r (di) = f (pr (di), τt1, .., τtm, tr (di, tm+1), .., tr (di, tw)). Luego, de TR (Di, Tj) ≤ τtj (1 ≤ J ≤ M) y el supuesto de monotonicidad, 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.3 0.3 0.40.5 0.6 0.7 0.8 0.9 1 fracción de las personas garantizadas-f (s) Fracción del índice-s fracción de consultas garantizadas por fracción de consultas de índice garantizado Figura 11: fracción de consultas garantizadas F (s) respondida en un iníndico P de tamaño clave de tamaño clave S de tamaño S.Sabemos que r (di) ≤ ¯r (di). Además, el algoritmo 4.6 establece C = 1 solo cuando los documentos de Top-K tienen puntajes más grandes que ¯R (DI). Por lo tanto, R (Di) no puede ser más grande que R (DK).5. Evaluación experimental Para realizar pruebas realistas para nuestras políticas de poda, implementamos un prototipo de motor de búsqueda. Para los experimentos en este documento, nuestro motor de búsqueda indexó alrededor de 130 millones de páginas, se arrastró de la web durante marzo de 2004. El rastreo comenzó desde la página de inicio de los directores abiertos [10] y se procedió de manera amplia. En general, el tamaño total sin comprimir de nuestras páginas web rastreadas es de aproximadamente 1.9 TB, lo que produce un índice invertido completo si es de aproximadamente 1.2 TB. Para los experimentos informados en esta sección, utilizamos un conjunto real de consultas emitidas a Lookmart [22] a diario durante abril de 2003. Después de mantener solo las consultas que contenían palabras clave que estaban presentes en nuestro índice invertido, nos quedamos con un conjunto de aproximadamente 462 millones de consultas. Dentro de nuestro conjunto de consultas, el número promedio de términos por consulta es del 2 y el 98% de las consultas contienen como máximo 5 términos. Algunos experimentos requieren que usemos una función de clasificación particular. Para estos, utilizamos la función de clasificación similar a la utilizada en [20]. Más precisamente, nuestra función de clasificación R (D, Q) es R (D, Q) = Prnorm (D) + Trnorm (D, Q) (3) donde Prnorm (D) es el Pagerank normalizado de D calculado a partir de las páginas descargadasy Trnorm (D, Q) es la distancia de coseno TF.IDF normalizada de d a q. Esta función es claramente más simple que las funciones reales empleadas por los motores de búsqueda comerciales, pero creemos que para nuestra evaluación esta función simple es adecuada, porque no estamos estudiando la efectividad de una función de clasificación, sino la efectividad de las políticas de poda.5.1 Pruning de palabras clave En nuestro primer experimento estudiamos el rendimiento de la poda de palabras clave, descrita en la Sección 4.2. Más específicamente, aplicamos el algoritmo HS de la Figura 6 a nuestro índice completo si y creamos una IP de índice P de palabras clave de tamaño S.Para la construcción de nuestro índice P de palabras clave, utilizamos las frecuencias de consulta observadas durante los primeros 10 días de nuestro conjunto de datos. Luego, utilizando la carga de consulta de 20 días restante, medimos F (s) F (s), la fracción de consultas manejadas por IP. Según el algoritmo de la Figura 5, IP puede manejar una consulta (es decir, c = 1) si IP incluye las listas invertidas para todas las palabras clave de consultas. Hemos repetido el experimento para diferentes valores de S, eligiendo las palabras clave con avidez como se discutió en la Sección 4.2. El resultado se muestra en la Figura 11. El eje horizontal denota el tamaño S del índice P como una fracción del tamaño de IF. El eje vertical muestra la fracción F (s) de las consultas que el índice p del tamaño S puede responder. Los resultados de la Figura 11 son muy alentadores: podemos responder una fracción significativa de las consultas con una pequeña fracción del índice original. Por ejemplo, aproximadamente el 73% de las consultas pueden responderse utilizando el 30% del índice original. Además, encontramos que cuando usamos la política de poda de palabras clave solamente, el tamaño óptimo del índice es S = 0.17.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 fracción de la fracción garantizada-F (s) Fracción de la fracción de índice-S de consultas garantizadas para la fracción superior de la fracción de índice de las preguntas garantizadas (EKS) Figura 12: Fracción de consultas garantizadas F (s) respondida en un índice P de TAMAÑO SIEMBRE PREMIO DE DOCUMENTO.0 0 0.1 0.2 0.2 0.3 0.4 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.4 0.5 0.6 0.7 0.7 0.8 0.9 1 fracción de la fracción Tamaño del índice transparente - S Fracción de consultas respondidas para 20 por fracción del índice GPR LPR EKS Figura 13: Fracción de las consultas respondidas enUn índice P de tamaño de documento de tamaño s.5.2 Pruning de documentos Continuamos nuestra evaluación experimental estudiando el rendimiento de las diversas políticas de poda de documentos descritas en la Sección 4.3. Para los experimentos en la poda de documentos informados aquí, trabajamos con una muestra de 5.5% de todo el conjunto de consultas. La razón detrás de esto es simplemente práctica: dado que tenemos muchas menos máquinas en comparación con un motor de búsqueda comercial, nos tomaría aproximadamente un año de cálculo procesar las 462 millones de consultas. Para nuestro primer experimento, generamos un índice P de TAMAÑO SIEMPRE PRIMA DE DOCUMENTO utilizando la poda específica de palabras clave extendida (EKS) en la Sección 4. Dentro del índice P medimos la fracción de consultas que se pueden garantizar (según el teorema 4) para que sea correcta. Hemos realizado el experimento para diferentes tamaños de índice S y el resultado se muestra en la Figura 12. Según esta cifra, podemos ver que nuestro algoritmo de poda de documentos funciona bien en la escala de los tamaños de índice S: Para todos los tamaños de índice superiores al 40%, podemos garantizar la respuesta correcta para aproximadamente el 70% de las consultas. Esto implica que nuestro algoritmo EKS puede identificar con éxito las publicaciones necesarias para calcular los resultados de los 20 mejores para el 70% de las consultas utilizando al menos el 40% del tamaño completo del índice. De la figura, podemos ver que el tamaño óptimo del índice S = 0.20 cuando usamos EK como nuestra política de poda. Podemos comparar los dos esquemas de poda, a saber, la poda de palabras clave y EKS, contrastando las figuras 11 y 12. Nuestra observación es que, si tuviéramos que elegir una de las dos políticas de poda, entonces las dos políticas parecen ser más o menos equivalentes para los tamaños del índice P ≤ 20%. Para los tamaños de índice P> 20%, la poda de palabras clave hace un trabajo mucho mejor, ya que proporciona un mayor número de garantías en cualquier tamaño de índice dado. Más adelante en la Sección 5.3, discutimos la combinación de las dos políticas. En nuestro próximo experimento, estamos interesados en comparar EKS con las políticas de poda basadas en relaciones públicas descritas en la Sección 4.3. Con este fin, aparte de EKS, también generamos Pindexes premedidos de documentos para la poda basada en relaciones públicas globales (GPR) y las políticas locales de poda PRBased (LPR). Para cada una de las políticas creamos índices P de documento de diferentes tamaños s.Dado que GPR y LPR no pueden proporcionar una garantía de corrección, compararemos la fracción de consultas de cada política que son idénticas (es decir, los mismos resultados en el mismo orden) con los resultados de Top-K calculados a partir del índice completo. Aquí, informaremos nuestros resultados para K = 20;Los resultados son similares para otros valores de k.Los resultados se muestran en la Figura 13. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.4 0.5 0.6 0.7 0.8 0.9 1 promedio de medidasLPR EKS Figura 14: Fracción promedio de los resultados de los 20 mejores del índice P con el tamaño S contenido en los resultados de los 20 mejores del índice completo. Fracción de consultas garantizadas para top -20 por fracción del índice, usando la palabra clave y documento 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.7 0.9 1 1 fracción de palabras clave del índice - sh 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 documento fracción del índice -SV 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Fracción de consultas garantizadas - F (s) Figura 15: Combinando la palabra clave y la poda de documentos. El eje horizontal muestra el tamaño S del índice P;El eje vertical muestra la fracción F (s) de las consultas cuyos resultados de los 20 mejores son idénticos a los resultados de los 20 mejores del índice completo, para un tamaño dado.Al observar la Figura 13, podemos ver que GPR realiza lo peor de las tres políticas. Por otro lado, EKS, recoge temprano, respondiendo una gran fracción de consultas (aproximadamente 62%) correctamente con solo el 10% del tamaño del índice. La fracción de consultas que LPR puede responder permanece por debajo de la de EK hasta aproximadamente S = 37%. Para cualquier tamaño de índice mayor al 37%, LPR funciona mejor. En el experimento de la Figura 13, aplicamos la definición estricta de que los resultados del índice P deben estar en el mismo orden que los del índice completo. Sin embargo, en un escenario práctico, puede ser aceptable tener algunos de los resultados fuera de servicio. Por lo tanto, en nuestro próximo experimento mediremos la fracción de los resultados provenientes de un índice P que se contiene dentro de los resultados del índice completo. El resultado del experimento se muestra en la Figura 14. El eje horizontal es, nuevamente, el tamaño S del índice P;El eje vertical muestra la fracción promedio de los resultados comunes de los 20 mejores con los resultados de los 20 mejores del índice completo. En general, la Figura 14 muestra que EKS y LPR identifican la misma fracción alta (≈ 96%) de resultados en promedio para cualquier tamaño s ≥ 30%, con GPR no muy lejos.5.3 Combinación de palabras clave y poda de documentos en las Secciones 5.1 y 5.2 Estudiamos el rendimiento individual de nuestros esquemas de poda de palabras y documentos. Sin embargo, una pregunta interesante es ¿cómo funcionan estas políticas en combinación? ¿Qué fracción de consultas podemos garantizar si aplicamos tanto la palabra clave como la poda de documentos en nuestro índice completo si? Para responder a esta pregunta, realizamos el siguiente experimento. Comenzamos con el índice completo si y aplicamos la poda de palabras clave para crear un índice ih p de tamaño sh · 100% de IF. Después de eso, aplicamos además la poda de documentos a IH P, y creamos nuestra IP final de Pindex de tamaño SV · 100% de IH P. Luego calculamos la fracción de consultas garantizadas en IP. Repetimos el experimento para diferentes valores de SH y SV. El resultado se muestra en la Figura 15. El eje X muestra el tamaño del índice SH después de aplicar la poda de palabras clave;El eje Y muestra el tamaño del índice SV después de aplicar la poda de documentos;El eje z muestra la fracción de consultas garantizadas después de las dos podas. Por ejemplo, el punto (0.2, 0.3, 0.4) significa que si aplicamos la poda de palabras clave y mantenemos el 20% de IF, y posteriormente en el índice resultante, aplicamos la poda de documentos manteniendo el 30% (creando así un pindex de tamaño 20% · 30%= 6% de si) podemos garantizar el 40% de las consultas. Al observar la Figura 15, podemos ver que para los tamaños de índice P más pequeños al 50%, nuestra poda combinada funciona relativamente bien. Por ejemplo, al realizar un 40% de palabras clave y una poda de documentos del 40% (que se traduce en un índice podado con S = 0.16) podemos proporcionar una garantía para aproximadamente el 60% de las consultas. En la Figura 15, también observamos una meseta para SH> 0.5 y SV> 0.5. Para esta política de poda combinada, el tamaño óptimo del índice es en S = 0.13, con SH = 0.46 y SV = 0.29.6. El trabajo relacionado [3, 30] proporciona una buena visión general de la indexación invertida en motores de búsqueda web y sistemas IR. Los estudios experimentales y los análisis de varios esquemas de partición para un índice invertido se presentan en [6, 23, 33]. Los algoritmos de poda que hemos presentado en este documento son independientes del esquema de partición utilizado. Las obras en [1, 5, 7, 20, 27] son las más relacionadas con las nuestras, ya que describen técnicas de poda basadas en la idea de mantener las publicaciones que más contribuyen en la clasificación final. Sin embargo, [1, 5, 7, 27] no consideran ninguna calidad independiente de la consulta (como PageRank) en la función de clasificación.[32] presenta un marco genérico para calcular respuestas aproximadas de Top-K con algunos límites probabilísticos en la calidad de los resultados. Nuestro trabajo se extiende esencialmente [1, 2, 4, 7, 20, 27, 31] al proponer mecanismos para proporcionar la garantía de corrección a los resultados calculados de Top-K. Los motores de búsqueda utilizan varios métodos de almacenamiento en caché como medio para reducir el costo asociado con las consultas [18, 19, 21, 31]. Este hilo de trabajo también es ortogonal para el nuestro porque un esquema de almacenamiento en caché puede funcionar además de nuestro índice P para minimizar el costo de cálculo de respuesta. Las funciones de clasificación exactas empleadas por los motores de búsqueda actuales son secretos estrechamente guardados. En general, sin embargo, las clasificaciones se basan en la relevancia dependiente de la consulta y la calidad de los documentos de consulta. La relevancia dependiente de la consulta se puede calcular de varias maneras (ver [3, 30]). Del mismo modo, hay una serie de obras que miden la calidad de los documentos, generalmente capturados a través del análisis basado en enlaces [17, 28, 26]. Dado que nuestro trabajo no asume una forma particular de función de clasificación, es complementario a este cuerpo de trabajo. Ha habido un gran cuerpo de trabajo en el cálculo de los resultados de Top-K. La idea principal es detener el recorrido de las listas invertidas temprano o reducir las listas podando publicaciones de las listas [14, 4, 11, 8]. Nuestra prueba de la función indicadora de corrección se inspiró principalmente en [12].7. Observaciones finales Los motores de búsqueda web generalmente podan sus índices invertidos a gran escala para escalar enormes cargas de consultas. Si bien este enfoque puede mejorar el rendimiento, al calcular los resultados principales de un índice podado, podemos notar una degradación significativa en la calidad de los resultados. En este documento, proporcionamos un marco para las nuevas técnicas de poda y los algoritmos de cálculo de respuesta que garantizan que las páginas coincidentes superiores siempre se colocan en la parte superior de los resultados de búsqueda en el orden correcto. Estudiamos dos técnicas de poda, a saber, la poda basada en palabras clave y basada en documentos, así como su combinación. Nuestros resultados experimentales demostraron que nuestros algoritmos pueden usarse de manera efectiva para podar un índice invertido sin degradación en la calidad de los resultados. En particular, un índice premiado por palabras clave puede garantizar el 73% de las consultas con un tamaño del 30% del índice completo, mientras que un índice de documento previsto puede garantizar el 68% de las consultas con el mismo tamaño. Cuando combinamos los dos algoritmos de poda, podemos garantizar el 60% de las consultas con un tamaño de índice del 16%. Esperamos que nuestro trabajo ayude a los motores de búsqueda a desarrollar índices mejores, más rápidos y más eficientes y, por lo tanto, proporcione una mejor experiencia de búsqueda de usuarios en la web.8. Referencias [1] V. N. Anh, O. de Kretser y A. Moffat. Ranking vectorial con terminación temprana efectiva. En Sigir, 2001. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas en modo mixto. En Cikm, 2006. [3] R. A. Baeza-Yates y B. A. Ribeiro-Neto. Recuperación de información moderna. ACM Press / Addison-Wesley, 1999. [4] N. Bruno, L. Gravano y A. Marian. Evaluación de consultas Top-K sobre bases de datos accesibles para la web. En ICDE, 2002. [5] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índice estático en los sistemas de recuperación de texto. En Cikm, 2006. [6] B. Cahoon, K. S. McKinley y Z. Lu. Evaluación del rendimiento de las arquitecturas distribuidas para la recuperación de la información utilizando una variedad de cargas de trabajo. ACM Tois, 18 (1), 2000. [7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek y A. Soffer. Poda de índice estático para sistemas de recuperación de información. En Sigir, 2001. [8] S. Chaudhuri y L. Gravano. Optimización de consultas sobre repositorios multimedia. En Sigmod, 1996. [9] T. H. Cormen, C. E. Leiserson y R. L. Rivest. Introducción a los algoritmos, 2ª edición. MIT Press/McGraw Hill, 2001. [10] Directorio abierto.http://www.dmoz.org.[11] R. Fagin. Combinando información difusa: una descripción general. En Sigmod Record, 31 (2), 2002. [12] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para el middleware. En Pods, 2001. [13] A. Gulli y A. Signorini. La web indexable es de más de 11.5 mil millones de páginas. En www, 2005. [14] U. Guntzer, G. Balke y W. Kiessling. Hacia consultas multiformes eficientes en entornos heterogéneos. En ITCC, 2001. [15] Z. Gy¨ongyi, H. García-Molina y J. Pedersen. Combatir el spam web con Trustrank. En VLDB, 2004. [16] B. J. Jansen y A. Spink. Un análisis de documentos web recuperados y vistas. En International conf.en Internet Computing, 2003. [17] J. Kleinberg. Fuentes autorizadas en un entorno hipervínculos. Journal of the ACM, 46 (5): 604-632, septiembre de 1999. [18] R. Lempel y S. Moran. El almacenamiento en caché predictivo y la captación previa de la consulta resulta en motores de búsqueda. En www, 2003. [19] R. Lempel y S. Moran. Optimización de los resultados previa en los motores de búsqueda web con índices segmentados. ACM Trans. Enterrar. Tech., 4 (1), 2004. [20] X. Long y T. Suel. Ejecución de consulta optimizada en grandes motores de búsqueda con pedidos de página global. En VLDB, 2003. [21] X. Long y T. Suel. El almacenamiento en caché de tres niveles para un procesamiento de consultas eficiente en grandes motores de búsqueda web. En www, 2005. [22] Lookmart Inc.http://www.looksmart.com.[23] S. Melnik, S. Raghavan, B. Yang y H. García-Molina. Construyendo un índice de texto completo distribuido para la web. ACM TOIS, 19 (3): 217-241, 2001. [24] A. Ntoulas, J. Cho, C. Olston. ¿Qué hay de nuevo en la web? La evolución de la web desde una perspectiva del motor de búsqueda. En www, 2004. [25] A. Ntoulas, M. Najork, M. Manasse y D. Fetterly. Detección de páginas web de spam a través del análisis de contenido. En www, 2006. [26] L. Page, S. Brin, R. Motwani y T. Winograd. Ranking de citas de PageRank: traer orden a la web. Informe técnico, Universidad de Stanford.[27] M. Persin, J. Zobel y R. Sacks-Davis. Recuperación de documentos filtrados con índices clasificados con frecuencia. Journal of the American Society of Information Science, 47 (10), 1996. [28] M. Richardson y P. Domingos. El surfista inteligente: combinación probabilística de información de enlace e contenido en PageRank. En Avances en Sistemas de Procesamiento de Información Neural, 2002. [29] S. Robertson y K. Sp¨arck-Jones. Ponderación de relevancia de los términos de búsqueda. Journal of the American Society for Information Science, 27: 129-46, 1976. [30] G. Salton y M. J. McGill. Introducción a la recuperación de información moderna. McGraw-Hill, Primera edición, 1983. [31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca y B. Riberio-Neto. El almacenamiento en caché de dos niveles para preservar el rango para motores de búsqueda escalables. En Sigir, 2001. [32] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas de Top-K con garantías probabilísticas. En VLDB, 2004. [33] A. Tomásico y H. García-Molina. Rendimiento de índices invertidos en sistemas de recuperación de información de documentos de texto distribuidos de texto compartido. En Paralelo y Sistemas de Información Distribuido, 1993.