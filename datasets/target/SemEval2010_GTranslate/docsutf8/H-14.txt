Studying the Use of Popular Destinations to Enhance Web Search Interaction Ryen W. White Microsoft Research One Microsoft Way Redmond, WA 98052 ryenw@microsoft.com Mikhail Bilenko Microsoft Research One Microsoft Way Redmond, WA 98052 mbilenko@microsoft.com Silviu Cucerzan Microsoft Research OneMicrosoft Way Redmond, WA 98052 silviu@microsoft.com Resumen Presentamos una nueva función de interacción de búsqueda en la web que, para una consulta dada, proporciona enlaces a sitios web visitados con frecuencia por otros usuarios con necesidades de información similares. Estos destinos populares complementan los resultados de búsqueda tradicionales, lo que permite la navegación directa a recursos autorizados para el tema de la consulta. Los destinos se identifican utilizando el historial de comportamiento de búsqueda y navegación de muchos usuarios durante un período de tiempo prolongado, cuyo comportamiento colectivo proporciona una base para la autoridad de la fuente informática. Describimos un estudio de usuario que comparó la sugerencia de destinos con la sugerencia previamente propuesta de consultas relacionadas, así como con la búsqueda web tradicional y sin ayuda. Los resultados muestran que la búsqueda mejorada por las sugerencias de destino supera a otros sistemas para tareas exploratorias, con el mejor rendimiento obtenido de la extracción del comportamiento del usuario pasado en granularidad a nivel de consultoría. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información - Proceso de búsqueda. Términos generales Factores humanos, experimentación.1. Introducción El problema de mejorar las consultas enviadas a los sistemas de recuperación de información (IR) se ha estudiado ampliamente en la investigación IR [4] [11]. Las formulaciones de consultas alternativas, conocidas como sugerencias de consulta, se pueden ofrecer a los usuarios después de una consulta inicial, lo que les permite modificar la especificación de sus necesidades proporcionadas al sistema, lo que lleva a un mejor rendimiento de la recuperación. La reciente popularidad de los motores de búsqueda web ha habilitado sugerencias de consultas que se basan en el comportamiento de reformulación de consultas de muchos usuarios para hacer recomendaciones de consulta basadas en interacciones previas del usuario [10]. Aprovechar los procesos de toma de decisiones de muchos usuarios para la reformulación de consultas tiene sus raíces en la indexación adaptativa [8]. En los últimos años, la aplicación de tales técnicas se ha vuelto posible a una escala mucho mayor y en un contexto diferente al que se propuso en el trabajo temprano. Sin embargo, los enfoques basados en interacción para la sugerencia de consulta pueden ser menos potentes cuando la necesidad de la información es exploratoria, ya que una gran proporción de la actividad del usuario para tales necesidades de información puede ocurrir más allá de las interacciones del motor de búsqueda. En los casos en que la búsqueda dirigida es solo una fracción del comportamiento de búsqueda de información de los usuarios, la utilidad de otros usuarios hace clic sobre el espacio de los resultados de alto rango puede ser limitada, ya que no cubre el comportamiento de navegación posterior. Al mismo tiempo, la navegación del usuario que sigue las interacciones del motor de búsqueda proporciona un respaldo implícito de los recursos web preferidos por los usuarios, lo que puede ser particularmente valioso para las tareas de búsqueda exploratorias. Por lo tanto, proponemos explotar una combinación de la búsqueda del usuario de búsqueda y navegación del pasado para mejorar las interacciones de búsqueda web de los usuarios. Los complementos del navegador y los registros de servidor proxy proporcionan acceso a los patrones de navegación de los usuarios que trascienden las interacciones del motor de búsqueda. En trabajos anteriores, dichos datos han sido utilizados para mejorar la clasificación de los resultados de la búsqueda por Agichtein et al.[1]. Sin embargo, este enfoque solo considera estadísticas de visitas de página independientemente entre sí, sin tener en cuenta las páginas de posiciones relativas en las rutas de navegación posteriores a la quirera. Radlinski y Joachims [13] han utilizado dicha inteligencia colectiva de usuarios para mejorar la precisión de la recuperación mediante el uso de secuencias de reformulaciones consecutivas de consultas, sin embargo, su enfoque no considera las interacciones de los usuarios más allá de la página de resultados de búsqueda. En este artículo, presentamos un estudio de usuario de una técnica que explota el comportamiento de búsqueda y navegación de muchos usuarios para sugerir páginas web populares, denominadas destinos en adelante, además de los resultados de búsqueda regulares. Los destinos pueden no estar entre los resultados de arriba, pueden no contener los términos consultados, o ni siquiera pueden ser indexados por el motor de búsqueda. En cambio, son páginas en las que otros usuarios terminan con frecuencia después de enviar consultas iguales o similares y luego navegar de los resultados de búsqueda inicialmente haciendo clic. Conjeturamos que los destinos populares en una gran cantidad de usuarios pueden capturar la experiencia colectiva del usuario para las necesidades de información, y nuestros resultados respaldan esta hipótesis. En trabajos anteriores, Oday y Jeffries [12] identificaron la teletransportación como una estrategia de búsqueda de información empleada por los usuarios que saltan a sus objetivos de información previamente visitados, mientras que Anderson et al.[2] aplicó principios similares para admitir la rápida navegación de sitios web en dispositivos móviles. En [19], Wexelblat y los MAES describen un sistema para admitir la navegación dentro del dominio basada en los senderos de navegación de otros usuarios. Sin embargo, no somos conscientes de que tales principios se aplican a la búsqueda web. La investigación en el área de los sistemas de recomendación también ha abordado problemas similares, pero en áreas como la pregunta de respuesta [9] y comunidades en línea relativamente pequeñas [16]. Quizás la instanciación más cercana de la teletransportación es que la oferta de motores de búsqueda de varios atajos dentro del dominio por debajo del título de un resultado de búsqueda. Si bien estos pueden basarse en el comportamiento del usuario y posiblemente la estructura del sitio, el usuario guarda como máximo un clic de esta característica. Por el contrario, nuestro enfoque propuesto puede transportar a los usuarios a ubicaciones muchos clics más allá del resultado de la búsqueda, ahorrando tiempo y dándoles una perspectiva más amplia sobre la información relacionada disponible. El estudio de usuario realizado investiga la efectividad de incluir enlaces a destinos populares como una característica de interfaz adicional en las páginas de resultados del motor de búsqueda. Comparamos dos variantes de este enfoque con la sugerencia de consultas relacionadas y búsqueda web sin ayuda, y buscamos respuestas a las preguntas sobre: (i) Preferencia del usuario y efectividad de búsqueda para tareas de búsqueda exploratorias y conocidas, y (ii) la distancia preferida entreconsulta y destino utilizados para identificar destinos populares de registros de comportamiento pasados. Los resultados indican que sugerir destinos populares a los usuarios que intentan tareas exploratorias proporcionan los mejores resultados en aspectos clave de la experiencia de búsqueda de información, al tiempo que proporcionar sugerencias de refinamiento de consultas es más deseable para las tareas de elementos conocidos. El resto del documento está estructurado de la siguiente manera. En la Sección 2 describimos la extracción de senderos de búsqueda y navegación de los registros de actividades del usuario, y su uso para identificar los principales destinos para nuevas consultas. La Sección 3 describe el diseño del estudio del usuario, mientras que las secciones 4 y 5 presentan los hallazgos del estudio y su discusión, respectivamente. Concluimos en la Sección 6 con un resumen.2. Senderos de búsqueda y destinos utilizamos registros de actividad web que contienen actividad de búsqueda y navegación recopilada con permiso de cientos de miles de usuarios durante un período de cinco meses entre diciembre de 2005 y abril de 2006. Cada entrada de registro incluía un identificador de usuario anónimo, una marca de tiempo, un identificador de ventana de navegador único y la URL de una página web visitada. Esta información fue suficiente para reconstruir secuencias ordenadas temporalmente de páginas vistas a las que nos referimos como senderos. En esta sección, resumimos la extracción de senderos, sus características y destinos (puntos de finalización). La descripción en profundidad y el análisis de la extracción de senderos se presentan en [20].2.1 Extracción de senderos Para cada usuario, los registros de interacción se agruparon en función de la información del identificador del navegador. Dentro de cada instancia del navegador, la navegación del participante se resumió como una ruta conocida como un sendero del navegador, desde la primera hasta la última página web visitada en ese navegador. Ubicados en algunos de estos senderos se encontraban senderos de búsqueda que se originaron con una presentación de consultas a un motor de búsqueda comercial como Google, Yahoo!, Windows Live Search y Ask. Son estos senderos de búsqueda los que usamos para identificar destinos populares. Después de originarse con una presentación de consulta a un motor de búsqueda, los senderos proceden hasta un punto de terminación donde se supone que el usuario ha completado su actividad de búsqueda de información. Los senderos deben contener páginas que sean: páginas de resultados de búsqueda, páginas de inicio del motor de búsqueda o páginas conectadas a una página de resultados de búsqueda a través de una secuencia de hipervínculos que hacen clic. Extraer senderos de búsqueda utilizando esta metodología también va en alguna forma de manejar multitarea, donde los usuarios realizan múltiples búsquedas simultáneamente. Dado que los usuarios pueden abrir una nueva ventana (o pestaña) del navegador para cada tarea [18], cada tarea tiene su propio rastro de navegador y un rastro de búsqueda distinto correspondiente. Para reducir la cantidad de ruido de las páginas no relacionadas con la tarea de búsqueda activa que puede contaminar nuestros datos, los senderos de búsqueda se terminan cuando ocurre uno de los siguientes eventos: (1) Un usuario regresa a su página de inicio, verifica el correo electrónico, inicia sesión.Un servicio en línea (por ejemplo, MySpace o Del.ico.us), escribe una URL o visita una página marcada;(2) Se ve una página durante más de 30 minutos sin actividad;(3) El usuario cierra la ventana del navegador activo. Si una página (en el paso I) cumple con cualquiera de estos criterios, se supone que el sendero termina en la página anterior (es decir, el paso I - 1). Hay dos tipos de senderos de búsqueda que consideramos: senderos de sesión y senderos de consulta. Los senderos de sesión trascienden múltiples consultas y terminan solo cuando se satisfacen uno de los tres criterios de terminación anteriores. Los senderos de consulta utilizan los mismos criterios de terminación que los senderos de sesión, pero también terminan al enviar una nueva consulta a un motor de búsqueda. Se extrajeron aproximadamente 14 millones de senderos de consulta y 4 millones de senderos de sesión de los troncos. Ahora describimos algunas características del sendero.2.2 Análisis de Trail y Destino La Tabla 1 presenta estadísticas resumidas para los senderos de consulta y sesión. Las diferencias en la interacción del usuario entre el último dominio en el sendero (dominio n) y todos los dominios visitados anteriormente (dominios 1 a (n - 1)) son particularmente importantes, porque destacan la riqueza de los datos de comportamiento del usuario no capturados por registros de motor de búsquedainteracciones. Las estadísticas son promedios para todos los senderos con dos o más pasos (es decir, aquellos senderos donde se hizo clic en el menos un resultado de búsqueda). Tabla 1. Estadísticas resumidas (promedios medios) para senderos de búsqueda. Medidas Pasos de consulta Portos de sesión Número de dominios únicos 2.0 4.3 Vistas de página totales Todos los dominios 4.8 16.2 Dominios 1 a (N - 1) 1.4 10.1 Dominio N (Destino) 3.4 6.2 Tiempo total Pasado (SEC) Todos los dominios 172.6 621.8 Dominios 1 a (n (N- 1) 70.4 397.6 Dominio N (destino) 102.3 224.1 Las estadísticas sugieren que los usuarios generalmente navegan lejos de la página de resultados de búsqueda (es decir, alrededor de 5 pasos), y visitan una gama de dominios durante el curso de su búsqueda. En promedio, los usuarios visitan 2 dominios únicos (sin motor) por sendero de consulta, y poco más de 4 dominios únicos por sendero de sesión. Esto sugiere que los usuarios a menudo no encuentran toda la información que buscan en el primer dominio que visitan. Para los senderos de consulta, los usuarios también visitan más páginas, y gastan significativamente más tiempo, en el último dominio en el sendero en comparación con todos los dominios anteriores combinados.1 Estas distinciones de los últimos dominios en los senderos pueden indicar el interés del usuario, la utilidad de la página o la relevancia de la página.2 2.3 Predicción de destino Para consultas frecuentes, los destinos más populares identificados a partir de registros de actividades web podrían simplemente almacenarse para una búsqueda futura en el tiempo de búsqueda. Sin embargo, hemos encontrado que durante el período de seis meses cubierto por nuestro conjunto de datos, el 56.9% de las consultas son únicas, y el 97% de consultas ocurren 10 o menos veces, lo que representa el 19.8% y el 66.3% de todas las búsquedas respectivamente (estos números son comparablesa los reportados en estudios anteriores de registros de consultas de motores de búsqueda [15,17]). Por lo tanto, un enfoque basado en la búsqueda nos impediría sugerir de manera confiable destinos para una gran fracción de búsquedas. Para superar este problema, utilizamos un modelo de predicción simple basado en términos. Como se discutió anteriormente, extraemos dos tipos de destinos: destinos de consulta y destinos de sesión. Para ambos tipos de destino, obtenemos un corpus de pares de consultas-destino y lo usamos para construir la representación del vector de término de destinos que es análogo a la representación clásica del documento TF.IDF en el IR tradicional [14]. Luego, dada una nueva consulta Q que consta de K términos t1 ... TK, identificamos destinos de mayor puntaje utilizando la siguiente función de similitud: 1 medidas independientes T-t-test: t (~ 60m) = 3.89, p <.001 2 La relevancia tópicade los destinos se probó para un subconjunto de alrededor de diez mil consultas para las cuales tuvimos juicios humanos. La calificación promedio de la mayoría de los destinos yacía entre lo bueno y excelente. La inspección visual de aquellos que no se encontraban en este rango revelaron que muchos eran relevantes pero no tenían juicios, o estaban relacionados pero tenían una asociación de consultas indirectas (por ejemplo, petfooddirect.com para consulta [perros]).,: Donde la consulta y el término de destino, un calculado utilizando la ponderación estándar de TF.IDF y la ponderación de TF.IDF de TF.IDF de la sesión normalizada, explorando algoritmos alternativos para el destino P sigue siendo un desafío interesante para el trabajo futuro, el estudio de Resu descrito en las secciones posterioresDemostrar que el enfoque proporciona resultados robustos y efectivos.3. Estudio para examinar la utilidad de los destinos, contenemos el estudio que investiga las percepciones y el rendimiento en cuatro sistemas de búsqueda web, dos con los sistemas de destino SUG 3.1 Se utilizaron cuatro sistemas en este estudio: una red inicial sin soporte explícito para el refinamiento de consultas (sistema base con conUn método de sugerencia de consulta que compromete consultas (consulta sugestión) y dos sistemas que augh buscan en la web con sugerencias de destino utilizando senderos de consulta (consulta) o puntos finales de (sessionDestination). 3.1.1 Sistema 1: línea de base para establecer el rendimiento de línea de base contraque se compararán, desarrollamos una interfaz enmascarada para un motor P sin soporte adicional en la formulación del sistema Q presentó la consulta construida por el usuario a los diez documentos de rango superior recuperados por T eliminar el sesgo potencial que puede haber sido causado por percepciones, nosotros, nosotros, nosotroseliminó todos los logotipos del motor de información de identificación y las características de la interfaz distintiva. 3.1.2 Sistema 2: QuerySugestion Además de la funcionalidad de búsqueda básica ofrecida que QuerySugestion proporciona sugerencias sobre los refinamientos F que los buscadores pueden hacer después de una presentación. Estas sugerencias se calculan usando el registro de consultas de motor sobre el plazo utilizado para el seguimiento de cada consulta de destino, recuperamos dos conjuntos de SU candidato que contienen la consulta de destino como subcadena. Un conjunto es COM más frecuente de tales consultas, mientras que el segundo conjunto contiene consultas frecuentes que siguieron la consulta de destino en la consulta del candidato que luego se califica multiplicando su frecuencia SM por su frecuencia suavizada de seguir TH en sesiones de búsqueda anteriores, utilizando suavizado laplacio. Los puntajes B, se devuelven seis sugerencias de consulta de alto rango.Se encuentran seis sugerencias, el retroceso iterativo es por sufijos progresivamente más largos de la consulta objetivo;Un SI se describe en [10]. Se ofrecieron sugerencias en un cuadro ubicado en la página de resultados T, adyacente a los resultados de búsqueda. Posición de la figura de las sugerencias en la página. Figura 1B SH Vista de la parte de la página de resultados que contiene la th ofrecida para la consulta [Telescopio Hubble]. A la izquierda y, son de manera muy y asertiva. Mientras que la tarea de predicción se convierte en el sombrero de usuario, este simple usó un usuario de 36 gestiones de sujetos.Línea del sistema de búsqueda), una búsqueda finaliza los puntos finales de referencia de la línea de base adicional de los senderos de sesión, los sistemas ER pueden las consultas de búsqueda populares. Este motor de búsqueda el motor. A los sujetos anteriores, como la búsqueda D por línea de base, consulta adicional y consulta la consulta inicial en la Enisentación de búsqueda. Para sugerencias que compusieron 100 veces 100 la mayoría de los registros ERY. Cada muy en general se dirigió a la consulta basada en ellas. Si menos de lo que se realiza utilizando la estrategia de la parte superior del 1A de la 1A muestra las sugerencias HE HE zoom de cada consulta (a) Posición de sugerencias (b) Zoo Figura 1. La presentación de sugerencia de consulta en sugerencia es un ícono similar a una popularidad normalizada del progreso B. Haga clic en una sugerencia R Resultados para esa consulta.3.1.3 Sistema 3: QueryDestination QueryDestination utiliza una interfaz similar T sin embargo, en lugar de mostrar la consulta de refinamentos de consulta, QueryDestination sugiere hasta seis DES visitado por otros usuarios que presentaron consultas S uno, y calculado como se describe en el anterior muestra la posición de la posición de la parte de laPágina de sugerencia de destino. La Figura 2b muestra una vista con zoom de los destinos de la página P sugeridos para la consulta [Hubb (A) Posición de los destinos (B) Zoo Figura 2. Presentación de destino en que para mantener la interfaz despejada, el título de la página se muestra en el desplazamiento sobre la URL de la página (que se muestra al nombre de destino, hay un icono que se puede hacer clic para ejecutar una búsqueda del dominio WI de consulta actual que se muestra. Mostramos los destinos como un rango de resultado de búsqueda, ya que se desvía de la consulta original (por ejemplo, esos temas o no que contienen los términos de consulta originales 3.1.4 Sistema 4: SessionDestination La funcionalidad de la interfaz en SessionDestinat QueryDestination. La única diferencia entre la definición de puntos finales de trail para consultas usa destinos. QueryDestination ordena a los usuarios que terminen para el SessionDestination de Que Session activo o similar dirige a los usuarios a los dominios al final de la sesión de búsqueda que sigue a las consultas. Esto degrada el efecto de múltiples (es decir, solo nos preocupamos donde los usuarios terminan después de un sub en lugar de dirigir a los buscadores que potencialmente Irre pueden preceder a una reformulación de consulta. 3.2 Preguntas de investigación que estábamos interesados en determinar el valor de P para hacer esto que intentamos responderEl siguiente re 3 para mejorar la confiabilidad, de manera similar a las consultas, solo se muestran si su popularidad excede una consulta de consulta de Med Frequen Med.3 Figura 2a en la parte de los resultados de búsqueda de los resultados le telescopio]. Destinos medios erydestination. E de cada destino en la Figura 2b). Siguiente n que permite al usuario en el destino una lista separada, sino que se centran tópicamente en S relacionadas).La ción es análoga a n. Los dos sistemas se editan en la computación superior a los dominios otros ries. Por el contrario, los otros usuarios visitan las iteraciones de consultas activas o similares de IPle con todas las consultas), dominios elevados que destinos populares.PREGUNTAS DE ESOLCA: Sugerencia, umbral de destinos ncy. RQ1: son los destinos populares preferibles y más efectivos que las sugerencias de refinamiento de consultas y la búsqueda web sin ayuda de: a.¿Buscas que estén bien definidas (tareas de elementos conocidos)?b.¿Búsquedas que están mal definidas (tareas exploratorias)? RQ2: ¿Se deben tomar destinos populares desde el final de los senderos de consulta o el final de los senderos de sesión?3.3 sujetos 36 sujetos (26 hombres y 10 mujeres) participaron en nuestro estudio. Fueron reclutados a través de un anuncio de correo electrónico dentro de nuestra organización, donde ocupan una variedad de puestos en diferentes divisiones. La edad promedio de los sujetos fue de 34.9 años (máx = 62, min = 27, SD = 6.2). Todos están familiarizados con la búsqueda web y realizan 7.5 búsquedas por día en promedio (SD = 4.1). Treinta y un sujetos (86.1%) informaron una conciencia general de los refinamientos de consulta ofrecidos por los motores de búsqueda web comerciales.3.4 Tareas Dado que la tarea de búsqueda puede influir en el comportamiento de búsqueda de información [4], hicimos que el tipo de tarea sea una variable independiente en el estudio. Construimos seis tareas de ítems conocidas y seis tareas exploratorias abiertas que se rotaron entre sistemas y sujetos como se describe en la siguiente sección. La Figura 3 muestra ejemplos de los dos tipos de tareas. La tarea de ítems conocida identifica tres tormentas tropicales (huracanes y tifones) que han causado daños a la propiedad y/o pérdida de vidas. Tarea exploratoria Usted está considerando comprar un teléfono de Voice Over Internet Protocol (VOIP). Desea obtener más información sobre la tecnología VoIP y los proveedores que ofrecen el servicio, y seleccionar el proveedor y el teléfono que mejor le convenga. Figura 3. Ejemplos de tareas de ítems y exploratorios conocidos. Las tareas exploratorias se redactaron como situaciones de tareas de trabajo simuladas [5], es decir, escenarios de búsqueda breves que fueron diseñados para reflejar las necesidades de información de la vida real. Estas tareas generalmente requerían que los sujetos recopilen información de antecedentes sobre un tema o recopilen información suficiente para tomar una decisión informada. Las tareas de búsqueda de elementos conocidos requerían buscar elementos particulares de información (por ejemplo, actividades, descubrimientos, nombres) para los cuales el objetivo fue bien definido. Una clasificación de tareas similar se ha utilizado con éxito en trabajos anteriores [21]. Las tareas se tomaron y se adaptaron de la pista interactiva de la Conferencia de recuperación de texto (TREC) [7], y las preguntas planteadas en las comunidades de respuesta de preguntas (Yahoo! Respuestas, respuestas de Google y QNA de Windows Live). Para motivar a los sujetos durante sus búsquedas, les permitimos seleccionar dos tareas exploratorias y dos tareas exploratorias al comienzo del experimento de las seis posibilidades para cada categoría, antes de ver cualquiera de los sistemas o que se les describiera el estudio. Antes del experimento, todas las tareas se probaron piloto con un pequeño número de sujetos diferentes para ayudar a garantizar que fueran comparables en dificultad y selección (es decir, la probabilidad de que una tarea se elija dadas las alternativas). El análisis post-hoc de la distribución de tareas seleccionadas por los sujetos durante el estudio completo no mostró preferencia por ninguna tarea en ninguna categoría.3.5 Diseño y metodología El estudio utilizó un diseño experimental dentro de los sujetos. El sistema tenía cuatro niveles (correspondientes a los cuatro sistemas experimentales) y las tareas de búsqueda tenían dos niveles (correspondientes a los dos tipos de tareas). El sistema y el orden de tipo tarea se contrarrestaron de acuerdo con un diseño cuadrado de greco-latina. Los sujetos se probaron de forma independiente y cada sesión experimental duró hasta una hora. Nos adhirimos al siguiente procedimiento: 1. A su llegada, se pidió a los sujetos que seleccionaran dos tareas de ítems conocidas y dos exploratorias de las seis tareas de cada tipo.2. Los sujetos recibieron una visión general del estudio en forma escrita que el experimentador les leyó en voz alta.3. Los sujetos completaron un cuestionario demográfico centrado en aspectos de la experiencia de búsqueda.4. Para cada una de las cuatro condiciones de la interfaz: a. Los sujetos recibieron una explicación de la funcionalidad de la interfaz que duró alrededor de 2 minutos.b. Los sujetos recibieron instrucciones de intentar la tarea en el sistema asignado que buscaba en la web, y se les asignó hasta 10 minutos para hacerlo.C.Al finalizar la tarea, se pidió a los sujetos que completaran un cuestionario posterior a la búsqueda.5. Después de completar las tareas en los cuatro sistemas, los sujetos respondieron a un cuestionario final comparando sus experiencias en los sistemas.6. Los sujetos fueron agradecidos y compensados. En la siguiente sección presentamos los hallazgos de este estudio.4. Hallazgos En esta sección utilizamos los datos derivados del experimento para abordar nuestras hipótesis sobre las sugerencias de consultas y los destinos, proporcionando información sobre el efecto del tipo de tarea y la familiaridad del tema cuando sea apropiado. Las pruebas estadísticas paramétricas se usan en este análisis y el nivel de significación se establece en <0.05, a menos que se indique lo contrario. Todas las escalas Likert y los diferenciales semánticos utilizaron una escala de 5 puntos donde una calificación más cercana a una significa más acuerdo con la declaración de actitud.4.1 Percepciones de sujeto En esta sección presentamos hallazgos sobre cómo los sujetos percibieron los sistemas que usaron. Las respuestas a los cuestionarios posteriores a la búsqueda (por sistema) y los cuestionarios finales se utilizan como base para nuestro análisis.4.1.1 Proceso de búsqueda para abordar la primera pregunta de investigación quería una idea de las percepciones de los sujetos de la experiencia de búsqueda en cada uno de los cuatro sistemas. En los cuestionarios posteriores a la búsqueda, le pedimos a los sujetos que completen cuatro diferenciales semánticos de 5 puntos que indican sus respuestas a la declaración de actitud: la búsqueda que le pedimos que realicara fue. Los estímulos emparejados ofrecidos como respuestas fueron: relajante/estresante, interesante/aburrido, relajante/agotador y fácil/difícil. Los valores diferenciales obtenidos promedio se muestran en la Tabla 1 para cada sistema y cada tipo de tarea. El valor correspondiente al diferencial representa la media de los tres diferenciales, proporcionando una medida general de los sentimientos de los sujetos. Tabla 1. Percepciones del proceso de búsqueda (más bajo = mejor). Diferencial Elimento exploratorio B QS QD SD B QS QD SD Easy 2.6 1.6 1.7 2.3 2.5 2.6 1.9 2.9 RESTFULS 2.8 2.3 2.4 2.6 2.8 2.8 2.4 Interesante 2.4 2.2 1.7 2.2 2.2 1.8 1.8 2 Relajación 2.6 1.9 2 2.2 2.5 2.8 2.3 2.9 Todos todos todos todos todos todos2.6 2 1.9 2.3 2.5 2.5 2.1 2.7 Cada celda de la Tabla 1 resume las respuestas de los sujetos para 18 pares de sistemas de tareas (18 sujetos que realizaron una tarea de ítems conocida en el inicio (b), 18 sujetos que realizaron una tarea exploratoria en Querysugestion (QS), etc..). La respuesta más positiva en todos los sistemas para cada par de tareas diferenciales se muestra en negrita. Aplicamos el análisis de varianza bidireccional (ANOVA) a cada diferencial en los cuatro sistemas y dos tipos de tareas. Los sujetos encontraron la búsqueda más fácil en la consulta de consulta y la consulta Destinación que los otros sistemas para tareas conocidas.fueron más estresantes (es decir, menos relajantes) que las tareas conocidas.Una nueva característica de interfaz, como consulta o sugerencias de destino.4.1.2 Soporte de la interfaz Solicitamos opiniones de los sujetos sobre el soporte de búsqueda ofrecido por QuerySuggion, QueryDestination y SessionDestination. Se utilizaron las siguientes escalas Likert y diferenciales semánticos: • Escala de Likert: Uso de este sistema mejora mi efectividad para encontrar información relevante.(Efectividad) 7 • Escala Likert B: Las consultas/destinos sugeridos me ayudaron a acercarme a mi objetivo de información.(Closetogoal) • Escala Likert C: Reutilizaría las consultas/destinos sugeridos si encontré una tarea similar en el futuro (reutilización) • Diferencial semántico A: las consultas/destinos sugeridos por el sistema fueron: relevantes/irrelevantes, útil/inútil, apropiado/inapropiado. No incluimos estos en el cuestionario posterior a la búsqueda cuando los sujetos usaban el sistema de referencia, ya que se refieren a las opciones de soporte de interfaz que la línea de base no ofrecía. La Tabla 2 presenta las respuestas promedio para cada una de estas escalas y diferenciales, utilizando las etiquetas después de cada una de las tres primeras escalas Likert en la lista de balas anteriores. Los valores para los tres diferenciales semánticos se incluyen en la parte inferior de la tabla, al igual que su promedio general en todos. Tabla 2. Percepciones del soporte del sistema (más bajo = mejor). Escala / Diferencial Etemo exploratorio exploratorio QD SD QS QD SD Efectividad 2.7 2.5 2.6 2.8 2.3 2.8 Closetogoal 2.9 2.7 2.8 2.7 2.2 3.1 Vuelva2.1 3.1 3 apropiado 2.6 2.4 2.5 2.4 2.4 2.6 Todos {1,2,3} 2.6 2.6 2.6 2.6 2.3 2.9 Los resultados muestran que los tres sistemas experimentales mejoraron las percepciones de sujetos de su efectividad de búsqueda sobre la línea de base, aunque solo la investigación de la consulta lo hizo significativamente.8Un examen más adicional del tamaño del efecto (medido usando Cohens d) reveló que la destimación de la consulta afecta la efectividad de la búsqueda más positivamente.9 Consulta la prueba de consulta también parece acercar a los sujetos a su objetivo de información (closetogoal) que QuerySuggion o 4 fácil: F (3,136) = 4.71, p.= .0037;Pruebas post-hoc de Tukey: todas p ≤ .008 5 fácil: F (3,136) = 3.93, p = .01;Pruebas post-hoc de Tukey: todas las P ≤ .012 6 Relajante: F (1,136) = 6.47, p = .011 7 Esta pregunta estaba condicionada en los sujetos uso de la línea de base y sus experiencias de búsqueda web anteriores.8 F (3,136) = 4.07, p = .008;Pruebas post-hoc de Tukey: todas p ≤ .002 9 QS: D (k, e) = (.26, .52);Qd: d (k, e) = (.77, 1.50);SD: D (k, e) = (.48, .28) SessionDestination, aunque solo para tareas de búsqueda exploratoria.10 Comentarios adicionales sobre QuerySugestion transmitieron que los sujetos lo vieron como una conveniencia (para salvarlos escribiendo una reformulación) en lugar de una forma depara influir dramáticamente en el resultado de su búsqueda. Para las búsquedas exploratorias, los usuarios se beneficiaron más de ser señalados a fuentes de información alternativas que de sugerencias para refinamientos iterativos de sus consultas. Nuestros hallazgos también muestran que nuestros sujetos consideraron que la dedición de consultación produjo sugerencias más relevantes y útiles para tareas exploratorias que los demás sistemas.11 Todas las demás diferencias observadas entre los sistemas no fueron estadísticamente significativas.12 La diferencia entre el rendimiento de la medydestination y la detección de sesiones se explica por lasEnfoque utilizado para generar destinos (descritos en la Sección 2). Las recomendaciones de SessionDestinations provienen del final de los senderos de sesión de los usuarios que a menudo trascienden múltiples consultas. Esto aumenta la probabilidad de que los cambios de tema afecten negativamente su relevancia.4.1.3 Clasificación del sistema En el cuestionario final que siguió a la finalización de todas las tareas en todos los sistemas, se pidió a los sujetos que clasificaran los cuatro sistemas en orden descendente en función de sus preferencias. La Tabla 3 presenta el rango promedio medio asignado a cada uno de los sistemas. Tabla 3. Ranking relativo de sistemas (más bajo = mejor). Sistemas Bas basal Qsuggest QDest SDest Ranking 2.47 2.14 1.92 2.31 Estos resultados indican que los sujetos prefieren la consulta y la consulta en general. Sin embargo, ninguna de las diferencias entre las clasificaciones de sistemas es significativa.13 Una posible explicación para que estos sistemas estén calificados más altos podría ser que, aunque los sistemas de destino populares funcionan bien para las búsquedas exploratorias, mientras que QuerySugestion se desempeñó bien para las búsquedas de elementos conocidos, una clasificación general se fusiona con estosdos actuaciones. Esta clasificación relativa refleja las percepciones generales de los sujetos, pero no las separa para cada categoría de tareas. En todas las tareas, parecía haber una ligera preferencia por la dedición de consultas, pero como muestran otros resultados, el efecto del tipo de tarea en las percepciones de los sujetos es significativo. El cuestionario final también incluyó preguntas abiertas que hicieron a los sujetos para explicar su clasificación de sistema, y describir lo que les gustó y no le gustaba sobre cada sistema: Base: Sujetos que preferían la línea de base comentaron sobre la familiaridad del sistema (por ejemplo, era familiar y no lo hice.Termine usando sugerencias (S36)). Aquellos que no preferían este sistema no le gustaba la falta de soporte para la formulación de consultas (pueden ser difíciles si no elige buenos términos de búsqueda (S20)) y dificultad para localizar documentos relevantes (por ejemplo, difícil encontrar lo que estaba buscando (S13);Tecnología actual torpe (S30)). QUERYSUGNION: Los sujetos que calificaron QuerySuggion más alto comentaron sobre el apoyo rápido para la formulación de la consulta (por ejemplo, fue útil en (1) ahorrar tipificación (2) presentando nuevas ideas para la expansión de la consulta (S12); me ayuda a mejorar el término de búsqueda (S24); hizo mi próxima consulta más fácil (S21)). Aquellos que no preferían este sistema criticaron la calidad de sugerencia (por ejemplo, no relevantes (S11); popular 10 F (2,102) = 5.00, p = .009; Pruebas post-hoc de Tukey: todas las P ≤ .012 11 F (2,102) =4.01, p = .01; α = .0167 12 Pruebas post-hoc de Tukey: Todas las p ≥ .143 13 ANOVA de medidas repetidas unidireccionales: F (3,105) = 1.50, p = .22 consultas no eran lo que estaba buscando (S18)) y la calidad de los resultados a los que condujeron (por ejemplo, los resultados (después de hacer clic en sugerencias) fueron de baja calidad (S35); finalmente inútil (S1)). QueryDestination: los sujetos que preferían este sistema comentaron principalmente sobre el soporte para acceder a nuevas fuentes de información (por ejemplo, proporcionaron áreas / dominios potencialmente útiles y nuevos para ver (S27)) y sin pasar la necesidad de navegar a estas páginas (útil para tratar de cortarChase y van donde otros pueden haber encontrado respuestas al tema (S3)). Aquellos que no preferían este sistema comentaron la falta de especificidad en los dominios sugeridos (deberían vincularse solo a la consulta específica del sitio, no al sitio en sí (S16); los sitios no eran muy específicos (S24); demasiado general/vago (S28)14), y la calidad de las sugerencias (no relevantes (S11); irrelevante (S6)). SessionDestination: los sujetos que preferían este sistema comentaron sobre la utilidad de los dominios sugeridos (las sugerencias tienen mucho sentido al proporcionar asistencia de búsqueda y parecían ayudar muy bien (S5)). Sin embargo, más sujetos comentaron sobre la irrelevancia de las sugerencias (por ejemplo, no parecían confiables, no mucha ayuda (S30); irrelevante, no mi estilo (S21), y la necesidad relacionada de incluir explicaciones sobre por qué se ofrecieron las sugerencias (p. Ej., Resultados de baja calidad, no se presentó suficiente información (S35)). Estos comentarios demuestran una amplia gama de perspectivas sobre diferentes aspectos de los sistemas experimentales. Obviamente, se necesita trabajo para mejorar la calidad de las sugerencias en todos los sistemas, pero los sujetos parecían distinguir la configuración cuando cada uno de estos sistemas puede ser útil. A pesar de que todos los sistemas a veces pueden ofrecer sugerencias irrelevantes, los sujetos parecían preferir tenerlos en lugar de no (por ejemplo, un sujeto comentó que las sugerencias fueron útiles en algunos casos e inofensivos en todos (S15)).4.1.4 Resumen Los hallazgos obtenidos de nuestro estudio sobre las percepciones de los sujetos de los cuatro sistemas indican que los sujetos tienden a preferir consultación para las tareas exploratorias y consultas para las búsquedas de elementos conocidos. Los buscadores pueden preferir las sugerencias para refinar incrementalmente la consulta actual sobre tareas de elementos conocidos cuando pueden haber perdido su objetivo de información. Sin embargo, cuando la tarea es más exigente, los buscadores aprecian sugerencias que tienen el potencial de influir dramáticamente en la dirección de una búsqueda o mejorar en gran medida la cobertura de temas.4.2 Tareas de búsqueda Para obtener una mejor comprensión de cómo se realizaron los sujetos durante el estudio, analizamos los datos capturados en sus percepciones de integridad de la tarea y el tiempo que les llevó completar cada tarea.4.2.1 Percepciones de sujetos En el cuestionario posterior a la búsqueda, se pidió a los sujetos que indicaran en una escala Likert de 5 puntos en la medida en que estuvieron de acuerdo con la siguiente declaración de actitud: Creo que he tenido éxito en mi desempeño de esta tarea (éxito). Además, se les pidió que completaran tres diferenciales semánticos de 5 puntos que indican su respuesta a la declaración de actitud: la tarea que le pedimos que realicara fue: los estímulos emparejados ofrecidos como posibles respuestas fueron claras/poco claras, simples/complejas y familiares//desconocido. La Tabla 4 presenta la respuesta promedio media a estas declaraciones para cada sistema y tipo de tarea.14 Aunque los sistemas de destino proporcionaron soporte para la búsqueda dentro de un dominio, los sujetos eligieron principalmente ignorar esto. Tabla 4. Percepciones de la tarea y el éxito de la tarea (más bajo = mejor). Escala de Itemo Exploratorio B QS QD SD B QS QD SD SCUESTO 2.0 1.3 1.4 1.4 2.8 2.3 1.4 2.6 1 Clear 1.2 1.1 1.1 1.1 1.6 1.5 1.5 1.6 2 Simple 1.9 1.4 1.8 1.8 2.4 2.9 2.4 3 3 Familiar 2.2 1.9 2.0 2.2 2.6 2.5 2.52.7 2.7 Todos {1,2,3} 1.8 1.4 1.6 1.8 2.2 2.2 2.2 2.3 Las respuestas de los sujetos demuestran que los usuarios consideraron que sus búsquedas habían tenido más éxito utilizando consultación para tareas exploratorias que con los otros tres sistemas (es decir, hubo dos dosforma de interacción entre estas dos variables) .15 Además, los sujetos percibieron una sensación significativamente mayor de finalización con tareas conocidas que con las tareas exploratorias.16 Los sujetos también consideraron que las tareas de elementos conocidas son más simples, claras y familiares.17 Estas respuestas confirman las diferencias en la naturaleza de las tareas que habíamos previsto al planificar el estudio. Como se ilustra en los ejemplos de la Figura 3, las tareas de ítems conocidas requerían que los sujetos recuperen un conjunto finito de respuestas (por ejemplo, encuentre tres cosas interesantes que hacer durante una visita de fin de semana a Kyoto, Japón). Por el contrario, las tareas exploratorias fueron multifacéticas y exigieron a los sujetos para obtener más información sobre un tema o encontrar suficiente información para tomar una decisión. El punto final en tales tareas estaba menos bien definido y puede haber afectado las percepciones de los sujetos de cuándo habían completado la tarea. Dado que no hubo diferencia en las tareas intentadas en cada sistema, teóricamente la percepción de la simplicidad, claridad y familiaridad de las tareas debería haber sido la misma para todos los sistemas. Sin embargo, observamos un claro efecto de interacción entre el sistema y la percepción de los sujetos de las tareas reales.4.2.2 Tiempo de finalización de la tarea Además de pedirle a los sujetos que indiquen hasta qué punto sentían que la tarea se completaba, también monitoreamos el tiempo que les llevó indicar al experimentador que habían terminado. El tiempo transcurrido desde que el sujeto comenzó a emitir su primera consulta hasta que cuando indicaron que se hicieron fue monitoreado utilizando un cronómetro y se registró para un análisis posterior. Se usó un cronómetro en lugar del registro del sistema para esto, ya que queríamos registrar el tiempo independientemente de las interacciones del sistema. La Figura 4 muestra el tiempo promedio de finalización de la tarea para cada sistema y cada tipo de tarea. Figura 4. Tiempo promedio promedio de finalización de la tarea (± SEM).15 F (3,136) = 6.34, p = .001 16 F (1,136) = 18.95, p <.001 17 F (1,136) = 6.82, p = .028;Las tareas de elementos conocidos también fueron más simples en Qs (F (3,136) = 3.93, p = .01; prueba post-hoc de Tukey: p = .01);α = .167 Exploratorio de elementos conocidos 0 100 200 300 400 500 600 Categorías de tareas Tiempo de línea de base (segundos) Sistemas 348.8 513.7 272.3 467.8 232.3 474.2 359.8 472.2 SDestination QDestination como se puede ver en la figura anterior, los tiempos de finalización de la tarea para los tiempos de finalización de tareas conocidos para los conocidos los tiempos de finalización de la tarea para los conocidos los tiempos de finalización conocidos para los conocidos para los tiempos de finalización conocidos para los conocidos para los tiempos de finalización conocidos.-Las tareas de ítem difieren enormemente entre los sistemas.18 Sujetos que intentan estas tareas en consultación y consulta el sugestión las completan en menos tiempo que los sujetos en la línea de base y la resistencia de la sesión.19 Como se discutió en la sección anterior, los sujetos estaban más familiarizados con las tareas conocidas y sentidasEran más simples y claros. La línea de base puede haber tardado más que los otros sistemas ya que los usuarios no tenían soporte adicional y tuvieron que formular sus propias consultas. Los sujetos generalmente sintieron que las recomendaciones ofrecidas por SessionDestination eran de baja relevancia y utilidad. En consecuencia, el tiempo de finalización aumentó ligeramente entre estos dos sistemas, tal vez, ya que los sujetos evaluaron el valor de las sugerencias propuestas, pero obtuvo poco beneficio de ellos. Los tiempos de finalización de la tarea para las tareas exploratorias fueron aproximadamente iguales en los cuatro sistemas20, aunque el tiempo en la línea de base fue ligeramente más alto. Dado que estas tareas no tenían criterios de terminación claramente definidos (es decir, el sujeto decidió cuándo habían recopilado información suficiente), los sujetos generalmente pasaron más tiempo buscando y consultaron una gama más amplia de fuentes de información que en las tareas de elementos conocidos.4.2.3 Análisis resumido de la percepción de los sujetos de las tareas de búsqueda y aspectos de la finalización de la tarea muestra que el sistema de consulta hizo que los sujetos se sintieran más exitosos (y la tarea más simple, clara y familiar) para las tareas de elementos conocidos. Por otro lado, se demostró que ConsulyDestination conduce a mayores percepciones del éxito de la búsqueda y la facilidad de la tarea, la claridad y la familiaridad para las tareas exploratorias. Los tiempos de finalización de la tarea en ambos sistemas fueron significativamente más bajos que en los otros sistemas para tareas de elementos conocidos.4.3 Interacción del sujeto Ahora enfocamos nuestro análisis en las interacciones observadas entre buscadores y sistemas. Además de obtener comentarios sobre cada sistema de nuestros sujetos, también registramos varios aspectos de su interacción con cada sistema en archivos de registro. En esta sección, analizamos tres aspectos de interacción: iteraciones de consulta, clics de resultados de búsqueda y participación del sujeto con las características de interfaz adicionales ofrecidas por los tres sistemas no básicos.4.3.1 Consultas y resultados Los buscadores de clics generalmente interactúan con los sistemas de búsqueda enviando consultas y haciendo clic en los resultados de búsqueda. Aunque nuestro sistema ofrece posibilidades de interfaz adicionales, comenzamos esta sección analizando el comportamiento de consultas y clics de nuestros sujetos para comprender mejor cómo realizaron actividades de búsqueda centrales. La Tabla 5 muestra el número promedio de iteraciones de consulta y los resultados de búsqueda haciendo clic para cada par de tareas del sistema. El valor promedio en cada celda se calcula para 18 sujetos en cada tipo de tarea y sistema. Tabla 5. Iteraciones de consulta promedio y clics de resultados (por tarea). Escala de información exploratoria conocida B QS QD SD B QS QD SD SD Consultas 1.9 4.2 1.5 2.4 3.1 5.7 2.7 3.5 Resultado Clicks 2.6 2 1.7 2.4 3.4 4.3 2.3 5.1 Sujetos Enviaron menos consultas y hicieron clic en menos resultados de búsqueda en consultación que en cualquiera en cualquiera de los demásSistemas.21 AS 18 F (3,136) = 4.56, P = .004 19 Pruebas post-hoc de Tukey: todas p ≤ .021 20 F (3,136) = 1.06, p = .37 21 consultas: F (3,443) = 3.99;p = .008;Pruebas post-hoc de Tukey: todas p ≤ .004;Sistemas: F (3,431) = 3.63, p = .013;Pruebas post-hoc de Tukey: todas las P ≤ .011 discutidas en la sección anterior, los sujetos que usan este sistema se sintieron más exitosos en sus búsquedas, pero exhibieron menos de las interacciones tradicionales y de clic en el clic requerido para el éxito de búsqueda en los sistemas de búsqueda tradicionales. Puede ser el caso de que los sujetos consulten en este sistema fueran más efectivos, pero es más probable que interactúen menos con el sistema a través de estos medios y eligieran usar los destinos populares. En general, los sujetos presentaron la mayoría de las consultas en QuerySugestion, lo que no es sorprendente ya que este sistema alienta activamente a los buscadores a re-suscribir consultas refinadas iterativamente. Los sujetos interactuaron de manera similar con los sistemas de referencia y prueba de sesions, tal vez debido a la baja calidad de los destinos populares en este último. Para investigar esto y los problemas relacionados, analizaremos el uso de las sugerencias sobre los tres sistemas no básicos.4.3.2 Uso de sugerencias Para determinar si los sujetos encontraron funciones adicionales útiles, medimos hasta qué punto se usaron cuando se les proporcionó. El uso de sugerencias se define como la proporción de consultas presentadas para las cuales se ofrecieron sugerencias y se hizo clic al menos una sugerencia. La Tabla 6 muestra el uso promedio de cada sistema y categoría de tareas. Tabla 6. La absorción de sugerencias (los valores son porcentajes). Medida de QS Exploratory QS QD SD QS QD SD USAGE 35.7 33.5 23.4 30.0 35.2 25.3 Los resultados indican que la sugestión de consultas se usó más para tareas conocidas que SessionDestination22, y la investigación de la consulta se usó más que todos los demás sistemas para las tareas exploratorias.23 para bien especificadas especificadasLos objetivos en la búsqueda de elementos conocidos, los sujetos parecían usar el refinamiento de consultas más. En contraste, cuando los sujetos estaban explorando, parecían beneficiarse más de la recomendación de fuentes de información adicionales. Los sujetos seleccionaron casi el doble de destinos por consulta cuando se usan consultación en comparación con SessionDestination.24 Como se discutió anteriormente, esto puede explicarse por la menor relevancia percibida y la utilidad de los destinos recomendados por SessionDestination.4.3.3 Análisis resumido de los datos de interacción de registro recopilados durante el estudio indica que aunque los sujetos presentaron menos consultas y hicieron clic en menos resultados de búsqueda en la dedición de consultas, su compromiso con las sugerencias fue más alta en este sistema, particularmente para tareas de búsqueda exploratorias. Las consultas refinadas propuestas por Querysugestion se usaron más para las tareas de elementos conocidos. Parece haber una división clara entre los sistemas: se prefirió que QuerySugestion se prefiera para las tareas de elementos conocidos, mientras que laDestination proporcionó el apoyo más utilizado para las tareas exploratorias.5. Discusión e implicaciones Los hallazgos prometedores de nuestro estudio sugieren que los sistemas que ofrecen destinos populares conducen a una búsqueda más exitosa y eficiente en comparación con la sugerencia de consultas y la búsqueda web sin ayuda. Los sujetos parecían preferir la consulta de sugestión de las tareas de ítems conocidas donde el objetivo de búsqueda de información estaba bien definido. Si la consulta inicial no recupera la información relevante, entonces los sujetos 22 F (2,355) = 4.67, p = .01;Pruebas post-hoc de Tukey: P = .006 23 Pruebas post-hoc: todas las P ≤ .027 24 QD: MK = 1.8, ME = 2.1;Sd: mk = 1.1, me = 1.2;F (1,231) = 5.49, p = .02;Pruebas post-hoc de Tukey: todas p ≤ .003;(M representa el promedio medio).Aprecie el apoyo al decidir qué refinamientos hacer a la consulta. A partir del examen de las consultas que los sujetos ingresaron para las búsquedas de elementos conocidos en todos los sistemas, parecían usar la consulta inicial como punto de partida, y suman o restan los términos individuales dependiendo de los resultados de búsqueda. El cuestionario posterior a la búsqueda pidió a los sujetos que seleccionaran de una lista de explicaciones propuestas (u ofrecen sus propias explicaciones) sobre por qué utilizaron refinamientos de consulta recomendados. Tanto para las tareas de elementos conocidos como para las tareas exploratorias, alrededor del 40% de los sujetos indicaron que seleccionaron una sugerencia de consulta porque querían ahorrar tiempo escribiendo una consulta, mientras que menos del 10% de los sujetos lo hicieron porque las sugerencias representaban nuevas ideas. Por lo tanto, los sujetos parecían ver la sugestión de la consulta como una conveniencia que ahorra el tiempo, en lugar de una forma de afectar drásticamente la efectividad de la búsqueda. Las dos variantes de recomendación de destinos que consideramos, consultación y sesionDestination, ofrecieron sugerencias que diferían en su proximidad temporal a la consulta actual. La calidad de los destinos parecía afectar las percepciones de los sujetos de ellos y el rendimiento de su tarea. Como se discutió anteriormente, los dominios que residen al final de una sesión de búsqueda completa (como en SessionDestination) tienen más probabilidades de no estar relacionados con la consulta actual y, por lo tanto, es menos probable que constituyan sugerencias valiosas. Los sistemas de destino, en particular, la deestinación, se desempeñaron mejor para las tareas de búsqueda exploratoria, donde los sujetos pueden haberse beneficiado de la exposición a fuentes de información adicionales cuya relevancia tópica para la consulta de búsqueda es indirecta. Al igual que con Querysuggación, se pidió a los sujetos que ofrecieran explicaciones sobre por qué seleccionaron destinos. En ambos tipos de tareas, sugirieron que los destinos se hicieron clic porque captaron su atención (40%), representaban nuevas ideas (25%) o que los usuarios no pudieron encontrar lo que estaban buscando (20%). Las respuestas menos populares se buscaban ahorrar tiempo escribiendo la dirección (7%) y el destino era popular (3%). La respuesta positiva a las sugerencias de destino de los sujetos de estudio proporciona instrucciones interesantes para los refinamientos de diseño. Nos sorprendió saber que los sujetos no encontraron las barras de popularidad útiles, o apenas utilizaron la funcionalidad de búsqueda dentro del sitio, invitando al rediseño de estos componentes. Los sujetos también comentaron que les gustaría ver resúmenes basados en la consulta para cada destino sugerido para admitir una selección más informada, así como la categorización de destinos con capacidad de desglose para cada categoría. Dado que QuerySugestion y QueryDestination funcionan bien en distintos escenarios de tareas, integrarse tanto en un solo sistema es una dirección futura interesante. Esperamos implementar algunas de estas ideas a escala web en sistemas futuros, lo que permitirá la evaluación basada en registros en grandes grupos de usuarios.6. Conclusiones presentamos un enfoque novedoso para mejorar la interacción de búsqueda web de los usuarios al proporcionar enlaces a sitios web visitados con frecuencia por buscadores anteriores con necesidades de información similares. Se realizó un estudio de usuario en el que evaluamos la efectividad de la técnica propuesta en comparación con un sistema de refinamiento de consulta y búsqueda web sin ayuda. Los resultados de nuestro estudio revelaron que: (i) los sistemas que sugieren que los refinamientos de consulta eran preferidos para las tareas de ítems conocidas, (ii) los sistemas que ofrecen destinos populares se preferían para tareas de búsqueda exploratorias, y (iii) los destinos deben extraerse desde el final de los senderos de consulta, no senderos de sesión. En general, las sugerencias de destino popular influyeron estratégicamente en las búsquedas de una manera que no se pueden lograr con los enfoques de sugerencias de consultas al ofrecer una nueva forma de resolver problemas de información y mejorar la experiencia de búsqueda de información para muchos buscadores web.7. Referencias [1] Agichtein, E., Brill, E. y Dumais, S. (2006). Mejora de la clasificación de búsqueda web incorporando información de comportamiento del usuario. En Proc. Sigir, 19-26.[2] Anderson, C. et al.(2001). Navegación web adaptativa para dispositivos inalámbricos. En Proc. IJCAI, 879-884.[3] Anick, P. (2003). Uso de comentarios terminológicos para el refinamiento de búsqueda web: un estudio basado en registros. En Proc. Sigir, 88-95.[4] Beaulieu, M. (1997). Experimentos con interfaces para admitir la expansión de la consulta. J. Doc.53, 1, 8-19.[5] Borlund, P. (2000). Componentes experimentales para la evaluación de sistemas de recuperación de información interactiva. J. Doc.56, 1, 71-90.[6] Downey et al.(2007). Modelos de búsqueda y navegación: idiomas, estudios y aplicaciones. En Proc. IJCAI, 1465-72.[7] Dumais, S.T.& Belkin, N.J. (2005). Las pistas interactivas TREC: poner al usuario en la búsqueda. En Voorhees, E.M. y Harman, D.K.(eds.) TREC: Experimento y evaluación en la recuperación de la información. Cambridge, MA: MIT Press, 123-153.[8] Furnes, G. W. (1985). Experiencia con un esquema de indexación adaptativa. En Proc. Chi, 131-135.[9] Hickl, A. et al.(2006). Hurto: Interactive WawdAnwering para entornos del mundo real. En Proc.de Coling/ACL, 25-28.[10] Jones, R., et al.(2006). Generación de sustituciones de consulta. En Proc. Www, 387-396.[11] Koenemann, J. y Belkin, N. (1996). Un caso para la interacción: un estudio del comportamiento y efectividad de recuperación de información interactiva. En Proc. Chi, 205-212.[12] Oday, V. y Jeffries, R. (1993). Orientación en un panorama de información: cómo los buscadores de información llegan de aquí a allá. En Proc. Chi, 438-445.[13] Radlinski, F. y Joachims, T. (2005). Cadenas de consulta: Aprender a clasificarse a partir de comentarios implícitos. En Proc. KDD, 239-248.[14] Salton, G. y Buckley, C. (1988) Enfoques de peso de término en la recuperación de texto automático. Inf. Proc. Administrar.24, 513-523.[15] Silverstein, C. et al.(1999). Análisis de un registro de consulta de motores de búsqueda de búsqueda muy grande. Sigir Forum 33, 1, 6-12.[16] Smyth, B. et al.(2004). Explotando la repetición de la consulta y la regularidad en un motor de búsqueda web adaptativo basado en la comunidad. Mod de usuario. Adaptar el usuario. En t.14, 5, 382-423.[17] Spink, A. et al.(2002). Tendencias de búsqueda web de EE. UU. Versus europeas. Sigir Forum 36, 2, 32-38.[18] Spink, A., et al.(2006). Multitarea durante las sesiones de búsqueda web. Inf. Proc. Manage., 42, 1, 264-275.[19] Wexelblat, A. y Maes, P. (1999). Huellas: herramientas ricas en historia para la búsqueda de información. En Proc. Chi, 270-277.[20] White, R.W. y Drucker, S.M.(2007). Investigar la variabilidad del comportamiento en la búsqueda web. En Proc. Www, 21-30.[21] White, R.W. y Marchionini, G. (2007). Examinando la efectividad de la expansión de consultas en tiempo real. Inf. Proc. Administrar.43, 685-704.