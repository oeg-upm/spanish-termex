Nueva detección de eventos basada en el árbol de indexación y la entidad nombrada Zhang Kuo tsinghua University Beijing, 100084, China 86-10-62771736 zkuo99@mails.tsinghua.edu.cn li Juan zi tsinghua University Beijing, 100084, China 86-10-62781414141 LiJzzze Beijing, 100084, China 86-10-62781414141@keg.cs.tsinghua.edu.cn Wu Gang Tsinghua University Beijing, 100084, China 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn Resumen New Detection (NED) para detectar de una o múltiples transmisionesde noticias que se informan sobre un nuevo evento (es decir ,. no se informó anteriormente). Con el abrumador volumen de noticias disponibles en la actualidad, existe una creciente necesidad de un sistema NED que pueda detectar nuevos eventos de manera más eficiente y precisa. En este artículo proponemos un nuevo modelo NED para acelerar la tarea NED mediante el uso de la indexación de noticias dinámicamente. Además, en base a la observación de que los términos de diferentes tipos tienen diferentes efectos para la tarea NED, se proponen enfoques de re -peso de dos términos para mejorar la precisión de NED. En el primer enfoque, proponemos ajustar los pesos de los términos basados dinámicamente en los grupos de historias anteriores y en el segundo enfoque, proponemos emplear estadísticas sobre datos de capacitación para aprender el modelo de reweapting de entidad nombrado para cada clase de historias. Los resultados experimentales en dos conjuntos de datos del consorcio de datos lingüísticos (LDC) TDT2 y TDT3 muestran que el modelo propuesto puede mejorar significativamente la eficiencia y la precisión de la tarea NED, en comparación con el sistema de referencia y otros sistemas existentes. Categorías y descriptores de sujetos H.3.3 [Sistemas de información]: Búsqueda y recuperación de información;H.4.2 [Aplicaciones de sistemas de información]: Tipos de soporte de SystemsDecision. Algoritmos de términos generales, rendimiento, experimentación 1. Introducción El programa de detección y seguimiento de temas (TDT) tiene como objetivo desarrollar técnicas que puedan organizar, buscar y estructurar materiales de texto de noticias de manera efectiva de una variedad de medios de comunicación y transmisión [1]. La nueva detección de eventos (NED) es una de las cinco tareas en TDT. Es la tarea de la identificación en línea del primer informe para cada tema tan pronto como ese informe llega en la secuencia de documentos. Un tema se define como un evento o actividad seminal, junto con eventos y actividades directamente relacionados [2]. Un evento se define como algo (no trivial) que ocurre en cierto lugar en un momento determinado [3]. Por ejemplo, cuando una bomba explota en un edificio, la explosión es el evento seminal que desencadena el tema, y otras historias sobre el mismo tema serían aquellos que discuten los esfuerzos de recuperación, la búsqueda de perpetradores, arrestos y juicio, etc. La información de noticias útil generalmente se entierra en una masa de datos generados todos los días. Por lo tanto, los sistemas NED son muy útiles para las personas que necesitan detectar información novedosa del flujo de noticias en tiempo real. Estas necesidades de la vida real a menudo ocurren en dominios como mercados financieros, análisis de noticias y recopilación de inteligencia. En la mayoría de los sistemas NED de última generación (actualmente), cada noticia disponible se compara con todas las historias recibidas anteriores. Si todas las similitudes entre ellos no exceden un umbral, entonces la historia desencadena un nuevo evento. Por lo general, están en forma de similitud cosena o métrica de similitud de Hellinger. El problema central de NED es identificar si dos historias están sobre el mismo tema. Obviamente, estos sistemas no pueden aprovechar la información del tema. Además, no es aceptable en aplicaciones reales debido a la gran cantidad de cálculo requerida en el proceso NED. Otros sistemas organizan historias anteriores en grupos (cada clúster corresponde a un tema), y se compara una nueva historia con los grupos anteriores en lugar de las historias. Esta manera puede reducir significativamente los tiempos de comparación. Sin embargo, se ha demostrado que esta manera es menos precisa [4, 5]. Esto se debe a que a veces las historias dentro de un tema se alejan del otro, lo que podría llevar una baja similitud entre una historia y su tema. Por otro lado, algunos sistemas NED propuestos intentaron mejorar la precisión al hacer un mejor uso de las entidades nombradas [10, 11, 12, 13]. Sin embargo, ninguno de los sistemas ha considerado los términos de diferentes tipos (p. Ej. Nombre de sustantivo, verbo o persona) tiene diferentes efectos para diferentes clases de historias para determinar si dos historias están sobre el mismo tema. Por ejemplo, los nombres de los candidatos electorales (nombre de la persona) son muy importantes para las historias de clase electoral;Las ubicaciones (nombre de ubicación) donde ocurrieron los accidentes son importantes para las historias de la clase de accidentes. Entonces, en NED, todavía existe después de tres problemas a investigar: (1) ¿Cómo acelerar el procedimiento de detección mientras no disminuye la precisión de la detección?(2) ¿Cómo hacer un buen uso de la información del clúster (tema) para mejorar la precisión?(3) Cómo obtener una mejor representación de noticias mediante una mejor comprensión de las entidades nombradas. Impulsados por estos problemas, hemos propuesto tres enfoques en este documento.(1) Para hacer el procedimiento de detección más rápido, proponemos un nuevo procedimiento NED basado en el árbol de indexación de noticias creado dinámicamente. El árbol de la indexación de historias se crea reuniendo historias similares para formar grupos de noticias en diferentes jerarquías de acuerdo con sus valores de similitud. Las comparaciones entre la historia actual y los clústeres anteriores podrían ayudar a encontrar la historia más similar en los tiempos menos comparantes. El nuevo procedimiento puede reducir la cantidad de tiempos de comparación sin dañar la precisión.(2) Usamos los grupos del primer piso en el árbol de indexación como temas de noticias, en los que los pesos de término se ajustan dinámicamente de acuerdo con la distribución de términos en los grupos. En este enfoque, la información del clúster (tema) se usa correctamente, por lo que se evita el problema de la descentralización del tema.(3) Basado en las observaciones sobre las estadísticas obtenidas de los datos de capacitación, encontramos que los términos de diferentes tipos (p. Ej. Sustantivo y verbo) tienen diferentes efectos para diferentes clases de historias para determinar si dos historias están sobre el mismo tema. Y proponemos usar estadísticas para optimizar los pesos de los términos de diferentes tipos en una historia de acuerdo con la clase de noticias a la que pertenece la historia. En el conjunto de datos TDT3, el nuevo modelo NED solo usa el 14.9% de comparación de tiempos del modelo básico, mientras que su costo normalizado mínimo es 0.5012, que es 0.0797 mejor que el modelo básico, y también mejor que cualquier otro resultado informado previamente para este conjunto de datos [8, 13]. El resto del documento está organizado de la siguiente manera. Comenzamos este documento resumiendo el trabajo anterior en NED en la Sección 2. La Sección 3 presenta el modelo básico para NED que usan la mayoría de los sistemas actuales. La Sección 4 describe nuestro nuevo procedimiento de detección basado en el árbol de indexación de noticias. En la Sección 5, se proponen métodos de rewesavo de dos términos para mejorar la precisión de NED. La Sección 6 proporciona nuestras métricas experimentales de datos y evaluación. Finalmente terminamos con los resultados experimentales en la Sección 7, y las conclusiones y el trabajo futuro en la Sección 8. 2. Trabajo relacionado Papka et al.Agrupación de paso único propuesto en NED [6]. Cuando se encontró una nueva historia, se procesó inmediatamente para extraer características de términos y se construye una representación de consulta del contenido de las historias. Luego se comparó con todas las consultas anteriores. Si el documento no activó ninguna consulta al exceder un umbral, se marcó como un nuevo evento. Lam et al construyen representaciones de consultas anteriores de grupos de historias, cada uno de los cuales corresponde a un tema [7]. De esta manera, las comparaciones ocurren entre historias y grupos. Los últimos años, la mayoría de los trabajos se centran en proponer mejores métodos en la comparación de historias y representación de documentos. Brants et al.[8] extendió un modelo básico de TF-IDF incremental para incluir modelos específicos de fuentes, normalización de la puntuación de similitud basada en promedios específicos de documentos, normalización de puntaje de similitud basada en promedios específicos de pares de origen, reescribencia de término basado en frecuencias de eventos inversas y segmentación de documentos. Se mostraron buenas mejoras en las marcas de banco TDT. Stokes et al.[9] utilizó una combinación de evidencia de dos representaciones distintas de un contenido de documentos. Una de las representaciones fue el vector de texto libre habitual, el otro hizo uso de cadenas léxicas (creadas usando WordNet) para construir otro vector de término. Luego, las dos representaciones se combinan de manera lineal. Se logró un aumento marginal en la efectividad cuando se usó la representación combinada. Se han realizado algunos esfuerzos sobre cómo utilizar entidades nombradas para mejorar NED. Yang et al.Dio ubicación entidades nombradas cuatro veces peso que otros términos y entidades nombradas [10]. Doremi Research Group combinó similitudes semánticas de nombres de personas, nombres de ubicación y tiempo junto con similitud textual [11] [12]. UMass [13] El grupo de investigación dividió la representación del documento en dos partes: entidades nombradas y entidades no nombradas. Y se descubrió que algunas clases de noticias podrían lograr un mejor rendimiento utilizando la representación de entidad nombrada, mientras que otras clases de noticias podrían lograr un mejor rendimiento utilizando la representación de la entidad no nombrada. Tanto [10] como [13] utilizaron la técnica de categorización de texto para clasificar las noticias de antemano. En [13], las noticias se clasifican automáticamente al principio, y luego prueban las sensibilidades de los nombres y los términos no name para NED para cada clase. En [10] los términos frecuentes para cada clase se eliminan de la representación del documento. Por ejemplo, la elección de palabras no ayuda a identificar diferentes elecciones. En su trabajo, no se investigan la efectividad de diferentes tipos de nombres (o términos con diferentes POS) para NED en diferentes clases de noticias. Utilizamos el análisis estadístico para revelar el hecho y lo usamos para mejorar el rendimiento de NED.3. Modelo básico En esta sección, presentamos el nuevo modelo básico de detección de eventos que es similar a lo que se aplican la mayoría de los sistemas actuales. Luego, proponemos nuestro nuevo modelo extendiendo el modelo básico. Los nuevos sistemas de detección de eventos utilizan la transmisión de noticias como entrada, en la que las historias están estrictamente ordenadas por el tiempo. Solo las historias recibidas anteriormente están disponibles cuando se trata de la historia actual. El resultado es una decisión de si la historia actual está en un nuevo evento o no y la confianza de la decisión. Por lo general, un modelo NED consta de tres partes: representación de la historia, cálculo de similitud y procedimiento de detección.3.1 Se necesita preprocesamiento de la representación de la historia antes de generar la representación de la historia. Para el preprocesamiento, tokenizamos las palabras, reconocemos abreviaturas, normalizamos las abreviaturas, agregamos etiquetas de parte de voz, eliminamos las palabras de parada incluidas en la lista de paradas utilizadas en la investigación [14], reemplace las palabras con sus tallos utilizando el algoritmo de K-SIM [15] yLuego genere Word Vector para cada noticia. Utilizamos el modelo TF-IDF incremental para el cálculo de peso a término [4]. En un modelo TF-IDF, la frecuencia de término en un documento de noticias se pone en peso de la frecuencia de documentos inversos, que se genera a partir del corpus de capacitación. Cuando se produce un nuevo término en el proceso de prueba, hay dos soluciones: simplemente ignore el nuevo término o establezca DF del término como un constante constante (por ejemplo, DF = 1). El nuevo término recibe un peso demasiado bajo en la primera solución (0) y un peso demasiado alto en la segunda solución. En el modelo TF-IDF incremental, las frecuencias de documentos se actualizan dinámicamente en cada paso de tiempo T: 1 () () () T T D TDF W DF W DF W- = + (1) Donde DT representa el conjunto de noticias de noticias recibidas en el tiempo T,y DFDT (W) significa que el número de documentos que el término W ocurre en, y DFT (W) significa el número total de documentos que el término W ocurre antes del tiempo t.En este trabajo, cada ventana de tiempo incluye 50 noticias. Por lo tanto, cada historia d recibida en t se representa de la siguiente manera: 1 2 {(,,), (,,), ..., (,,)} Nd peso d t w peso d t w peso d t w → donde n significa el número de distintoTérminos en la historia d, y (,,) peso d t w significa el peso del término w en la historia d en el tiempo t: log ((,) 1) log ((1) /(() 0.5)) (,,) log ((,) 1) log (((1) /(() 0.5)) t t t t t w w d tf d w n df w peso d t w tf d w n df w ∈ + + + = + + + ∑ (2) donde nt significa el número total de noticiasHistorias antes del tiempo T, y TF (D, W) significa cuántas veces ocurre el término W en la noticia d.3.2 Similarity Calculation We use Hellinger distance for the calculation of similarity between two stories, for two stories d and d at time t, their similarity is defined as follows: , ( , , ) ( , , ) * ( , , ) w d d sim d d tpeso d t w peso d t w ∈ = ∑ (3) 3.3 Procedimiento de detección para cada historia D recibida en el paso de tiempo t, el valor () () () ((,)) Tiempo D Tiempo D N D MAX SIM D D T <= (4) ISUna puntuación utilizada para determinar si D es una historia sobre un nuevo tema y al mismo tiempo es una indicación de la confianza en nuestra decisión [8].El tiempo (d) significa el tiempo de publicación de la historia d.Si el puntaje excede el umbral θ nuevo, entonces existe un documento suficientemente similar, por lo tanto, D es una historia antigua, de lo contrario, no hay un documento anterior suficientemente similar, por lo que D es una nueva historia.4. Nuevo procedimiento NED Los sistemas NED tradicionales se pueden clasificar en dos tipos principales sobre el aspecto del procedimiento de detección: (1) Tipo S-S, en el que la historia disponible se compara con cada historia recibida anteriormente, y utilice la mayor similitud para determinar si la historia actualse trata de un nuevo evento;(2) Tipo S-C, en el que la historia disponible se compara con todos los grupos anteriores, cada uno de los cuales representa un tema, y la mayor similitud se usa para la decisión final para la historia actual. Si la mayor similitud excede el umbral, entonces, entonces es una historia antigua y la pone en el clúster más similar;De lo contrario, es una nueva historia y crea un nuevo clúster. El trabajo anterior muestra que la primera manera es más precisa que la segunda [4] [5]. Dado que a veces las historias dentro de un tema se alejan del otro, una historia puede tener muy baja similitud con su tema. Por lo tanto, usar similitudes entre historias para determinar una nueva historia es mejor que usar similitudes entre la historia y los clústeres. Sin embargo, la primera manera necesita mucho más tiempos de comparación, lo que significa que la primera manera es de baja eficiente. Proponemos un nuevo procedimiento de detección que utiliza comparaciones con grupos anteriores para ayudar a encontrar la historia más similar en los tiempos de comparación menos, y la nueva decisión del evento final se toma de acuerdo con la historia más similar. Por lo tanto, podemos obtener tanto la precisión de los métodos de tipo S-S como la eficiencia de los métodos de tipo S-C. El nuevo procedimiento crea un árbol de indexación de noticias dinámicamente, en el que se elaboran historias similares para formar una jerarquía de grupos. Indexamos historias similares juntas por su antepasado común (un nodo de clúster). Las historias diferentes se indexan en diferentes grupos. Cuando se acerca una historia, utilizamos comparaciones entre la historia actual y los grupos jerárquicos anteriores para ayudar a encontrar la historia más similar que sea útil para la nueva decisión de eventos. Después de tomar la nueva decisión del evento, la historia actual se inserta en el árbol de indexación para la siguiente detección. El árbol de indexación de noticias se define formalmente de la siguiente manera: s-tree = {r, nc, ns, e} donde r es la raíz de s-tree, nc es el conjunto de todos los nodos de clúster, ns es el conjunto de toda la historiaNodos, y E es el conjunto de todos los bordes en S-Tree. Definimos un conjunto de restricciones para un árbol S: ⅰ., es un nodo no terminal en el treec i i n i∀ ∈ → ⅱ., es un nodo terminal en los árboles i i n i∀ ∈ → ⅲ., grado de IS al menos 2c i i n i∀ ∈ → ⅳ., se representa como el centroide de sus desendantsc i i in∀ ∈ → Para una noticia DI, el procedimiento de comparación y el procedimiento de inserción basado en el árbol de indexación se definen de la siguiente manera. Un ejemplo se muestra en la Figura 1 y la Figura 2. Figura 1. Procedimiento de comparación Figura 2. Procedimiento del procedimiento de inserción Procedimiento de comparación: Paso 1: Compare DI con todos los nodos infantiles directos de R y seleccione los nodos λ con las más altas similitudes, por ejemplo, C1 2 y C1 3 en la Figura 1. Paso 2: para cada nodo seleccionado en el último paso, p. C1 2, compare DI con todos sus nodos infantiles directos y seleccione los nodos λ con las más altas similitudes, p. C2 2 y D8. Repita el paso 2 para todos los nodos no terminales. Paso 3: Registre el nodo terminal con la mayor similitud para hacer, p.S5, y el valor de similitud (0.20). Insertando DI al árbol S con R como raíz: Encuentre el nodo n que es un niño directo de R en la ruta de R al nodo terminal con la mayor similitud S, p. C1 2. Si S es más pequeño que θ init+(h-1) δ, entonces agregue DI al árbol como un hijo directo de r.De lo contrario, si N es un nodo terminal, cree un nodo de clúster en lugar de N, y agregue N y DI como sus hijos directos;Si N es un nodo no terminal, repita este procedimiento e inserte DI en el sub-árbol con N como raíz de recursiva. Aquí H es la longitud entre N y la raíz del árbol S. Cuanto más sean las historias en un clúster similares entre sí, mejor será el clúster las historias en él. Por lo tanto, no agregamos restricciones sobre el máximo de altura y grado de un nodo. Por lo tanto, no podemos dar la complejidad de este procedimiento basado en el árbol de indexación. Pero daremos el número de tiempos de comparación necesarios por el nuevo procedimiento en nuestros experimentos en la Sección 7.5. Métodos de reweaptheing de término En esta sección, se proponen métodos de rewesavo de dos términos para mejorar la precisión de NED. En el primer método, se explora una nueva forma para un mejor uso de la información de clúster (tema). El segundo encuentra una mejor manera de hacer uso de entidades nombradas basadas en la clasificación de noticias.5.1 El reescalentamiento a término basado en la distancia de distribución TF-IDF es el modelo más frecuente utilizado en los sistemas de recuperación de información. La idea básica es que los menos documentos en los que aparecen un término, cuanto más importante sea el término en la discriminación de los documentos (relevantes o no relevantes para una consulta que contiene el término). Sin embargo, en el dominio TDT, necesitamos discriminar documentos con respecto a los temas en lugar de las consultas. Intuitivamente, el uso de vectores de clúster (tema) para comparar con las noticias posteriores debe superar a los vectores de la historia. Desafortunadamente, los resultados experimentales no respaldan esta intuición [4] [5]. Basado en la observación de los datos, encontramos que la razón es que un tema de noticias generalmente contiene muchos eventos relacionados directa o indirectamente, mientras que todos tienen sus propios subconjetos que generalmente son diferentes entre sí. Tome el tema descrito en la Sección 1 como un ejemplo, eventos como la explosión y el salvamento tienen similitudes muy bajas con eventos sobre el juicio penal, por lo tanto, las historias sobre el juicio tendrían poca similitud con el vector del tema construido en sus eventos anteriores. Esta sección se centra en cómo utilizar de manera efectiva la información del tema y al mismo tiempo evitar el problema de la descentralización del contenido. Al principio, clasificamos los términos en 5 clases para ayudar a análisis de las necesidades del modelo modificado: Término Clase A: Términos que ocurren con frecuencia en todo el corpus, por ejemplo, año y personas. Los términos de esta clase deben tener bajos pesos porque no ayudan mucho para la discriminación del tema. Término Clase B: Términos que ocurren con frecuencia dentro de una categoría de noticias, por ejemplo, elección, tormenta. Son útiles para distinguir dos historias en diferentes categorías de noticias. Sin embargo, no pueden proporcionar información para determinar si dos historias están en los mismos o diferentes temas. En otras palabras, las elecciones a término y la tormenta no son útiles para diferenciar dos campañas electorales y dos desastres de tormentas. Por lo tanto, los términos de esta clase se les debe asignar pesos más bajos. Término Clase C: Términos que ocurren con frecuencia en un tema, y con poca frecuencia en otros temas, por ejemplo, el nombre de un avión de choque, el nombre de un huracán específico. Las noticias que pertenecen a diferentes temas rara vez tienen términos de superposición en esta clase. Cuanto más frecuentemente aparezca un término en un tema, más importante es el término para una historia que pertenece al tema, por lo tanto, el término debe establecerse con mayor peso. Término Clase D: Términos que aparecen en un tema exclusivamente, pero no con frecuencia. Por ejemplo, el nombre de un bombero que le fue muy bien en una acción de salvamento, que puede aparecer en solo dos o tres historias pero nunca apareció en otros temas. Los términos de este tipo deben recibir más pesos que en el modelo TF-IDF. Sin embargo, dado que no son populares en el tema, no es apropiado darles pesos demasiado altos. Término Clase E: Términos con baja frecuencia de documentos y aparecen en diferentes temas. Los términos de esta clase deben recibir pesos más bajos. Ahora analizamos si el modelo TF-IDF puede dar los pesos adecuados a las cinco clases de términos. Obviamente, los términos de clase A tienen un peso de baja en el modelo TF-IDF, que es conforme con el requisito descrito anteriormente. En el modelo TF-IDF, los términos de la clase B dependen en gran medida con el número de historias en una clase de noticias. El modelo TF-IDF no puede proporcionar pesos bajos si la historia que contiene el término pertenece a una clase relativa de noticias pequeña. Para un término de clase C, cuanto más frecuentemente aparece en un tema, menos peso TFIDF le da el modelo TFIDF. Esto en conflicto fuertemente con el requisito de los términos en la clase C. para los términos de la clase D, el modelo TF-IDF les da altos pesos correctamente. Pero para los términos de clase E, el modelo TF-IDF les da altos pesos que no son conformes con el requisito de pesos bajos. Para resumir, los términos de la clase B, C, E no pueden ponderarse adecuadamente en el modelo TF-IDF. Entonces, proponemos un modelo modificado para resolver este problema. Cuando θ init y θ new se establecen de cerca, suponemos que la mayoría de las historias en un clúster de primer nivel (un nodo infantil directo del nodo raíz) están en el mismo tema. Por lo tanto, utilizamos un clúster de primer nivel para capturar la distribución de términos (DF para todos los términos dentro del clúster) dentro del tema dinámicamente. Divergencia KL de la distribución del término en un clúster de primer nivel y todo el conjunto de la historia se usa para ajustar los pesos de los términos: (,,) * (1 * (||) (,,) (,,) * (1 * (||)) cw tw cw tw w d d peso d t w w kl p p peso d t w peso d t w kl p p γ γ ∈ + = + ∑ (5) Where () () () () 1, CW CW C C C DF W DF W P Y P Y N = = = =- (6) () () () () 1, t t t tw t t t t df w df w p y p y n n = = - (7) donde dfc (w) es el número de documentos que contienen el término w dentro del clúster c, y nc es elNúmero de documentos en el clúster C, y NT es el número total de documentos que llegan antes del tiempo, paso t.γ es un parámetro const, ahora se establece manualmente 3. La divergencia de KL se define de la siguiente manera [17]: () (||) () log () x p x kl p q p x q x = ∑ (8) La idea básica es: para una historia en un tema, cuanto más ocurre un término dentro del tema, y cuanto menos ocurre en otros temas, se le debe asignar pesos más altos. Obviamente, el modelo modificado puede cumplir con todos los requisitos de las cinco clases de términos enumeradas anteriormente.5.2 Término de rewesaveo basado en el tipo de término y la clase de historia El trabajo anterior descubrió que algunas clases de noticias podrían lograr buenas mejoras al dar peso adicional a las entidades nombradas. Pero encontramos que los términos de diferentes tipos deberían tener una cantidad diferente de peso adicional para diferentes clases de noticias. Utilizamos Open-NLP1 para reconocer los tipos de entidades nombrados y las etiquetas de parte del habla para los términos que aparecen en las noticias. Los tipos de entidad nombrados incluyen el nombre de la persona, el nombre de la organización, el nombre de la ubicación, la fecha, la hora, el dinero y el porcentaje, y los cinco POSS se seleccionan: Ninguno (NN), verbo (VB), Adjetivo (JJ), Adverb (RB) y número cardinal (CD). El análisis estadístico muestra tipos de términos discriminativos a nivel de tema para diferentes clases de historias. En aras de la conveniencia, las etiquetas de tipo de entidad nombradas y las etiquetas de parte del discurso se llaman uniformemente el tipo de término en secciones posteriores. Determinar si dos historias son sobre el mismo tema es un componente básico para la tarea NED. Entonces, al principio usamos 2 χ estadísticos para calcular las correlaciones entre términos y temas. Para un término t y un tema t, se deriva una tabla de contingencia: Tabla 1. Un número de documento de la tabla de contingencia 2 × 2 pertenece al tema t no pertenece al tema t incluido t a b no incluye t c d la estadística 2 χ para un término t específico con respecto al tema t se define como [16]: 2 2 (,,) () * () () * () * () * () W T A B C D AD CB A C B D A B C D χ = + + + - + + + + (9) Los temas de noticias para la tarea TDT se clasifican aún más en 11 reglas de interpretaciones (Rois) 2. El ROI puede verse como una clase de historias de nivel superior. La correlación promedio entre un tipo de término y un ROI de tema se calcula como: 2 avg 2 (,) ((,)) k m m km kt r w p w tp r p w t r p χ χ ∈ ∈ ∑ ∑ （,） = 1 K K= 1 ... k, m = 1 ... m (10) donde k es el número de tipos de términos (establecido 12 constantemente en el documento). M es el número de clases de noticias (ROI, establecidas 11 en el periódico). PK representa el conjunto de todos los términos de tipo K, y RM representa el conjunto de todos los temas de la clase M, P (t, t) significa la probabilidad de que T ocurra en el tema T. debido a la limitación del espacio, solo partes del términoLos tipos (9 tipos de términos) y las partes de las clases de noticias (8 clases) se enumeran en la Tabla 2 con los valores de correlación promedio entre ellos. Las estadísticas se derivan de datos etiquetados en el corpus TDT2.(Los resultados en la Tabla 2 ya están normalizados por conveniencia en comparación). Las estadísticas en la Tabla 2 indican la utilidad de los diferentes tipos de términos en la discriminación de temas con respecto a diferentes clases de noticias. Podemos ver que el nombre de la ubicación es el tipo de término más útil para tres clases de noticias: desastres naturales, violencia o guerra, finanzas. Y para otras tres categorías, las elecciones, casos legales/penales, ciencia y descubrimiento, el nombre de la persona es el tipo de término más discriminativo. Para escándalos/audiencias, la fecha es la información más importante para la discriminación de temas. Además, los casos legales/penales y los temas financieros tienen una mayor correlación con los términos del dinero, mientras que la ciencia y el descubrimiento tienen una correlación más alta con términos porcentuales. Los términos no nombrados son más estables para diferentes clases.1.http://opennlp.sourceforge.net/ 2.http://projects.ldc.upenn.edu/tdt3/guide/label.html Del análisis de la Tabla 2, es razonable ajustar el peso del término de acuerdo con su tipo de término y la clase de noticias a la que pertenece la historia. El nuevo término los pesos se vuelven a ver de la siguiente manera: () () () () (,,) * (,) (,,) * Clase D D Type W T Clase D D Tipo W W W W W W W W W W PESO D T W PESO D T W α α ∈= ∑ (11) donde el tipo (W) representa el tipo de término W, y la clase (d) representa la clase de la historia D, C Kα es el parámetro de re -peso para la clase de noticias C y el tipo de término K.En el trabajo, simplemente usamos estadísticas en la Tabla 2 como parámetros de re -peso. Incluso el pensamiento utilizando las estadísticas directamente puede no ser la mejor opción, no discutimos cómo obtener automáticamente los mejores parámetros. Intentaremos usar técnicas de aprendizaje automático para obtener los mejores parámetros en el trabajo futuro. En el trabajo, utilizamos Boostexter [20] para clasificar todas las historias en uno de los 11 ROI. Boostexter es un programa de aprendizaje automático basado en el aumento, que crea una serie de reglas simples para construir un clasificador para datos de texto o valores de atributos. Utilizamos el peso a término generado utilizando el modelo TF-IDF como función para la clasificación de la historia. Entrenamos al modelo en las 12000 historias de inglés juzgadas en TDT2, y clasificamos el resto de las historias en TDT2 y todas las historias en TDT3. Los resultados de la clasificación se utilizan para el peso de término en la fórmula (11). Dado que las etiquetas de clase de las historias de temas no se dan en los conjuntos de datos TDT, no podemos dar la precisión de la clasificación aquí. Por lo tanto, no discutimos los efectos de la precisión de clasificación al rendimiento de NED en el documento.6. Configuración experimental 6.1 conjuntos de datos utilizamos dos conjuntos de datos LDC [18] TDT2 y TDT3 para nuestros experimentos. TDT2 contiene noticias de enero a junio de 1998. Contiene alrededor de 54,000 historias de fuentes como ABC, Associated Press, CNN, New York Times, Public Radio International, Voice of America, etc. Solo se consideraron historias inglesas en la colección. TDT3 contiene aproximadamente 31,000 historias de inglés recopiladas de octubre a diciembre de 1998. Además de las fuentes utilizadas en TDT2, también contiene historias de transmisiones de TV NBC y MSNBC. Utilizamos versiones transcritas de las transmisiones de televisión y radio además de noticias textuales. El conjunto de datos TDT2 está etiquetado con aproximadamente 100 temas, y aproximadamente 12,000 historias de inglés pertenecen a al menos uno de estos temas. El conjunto de datos TDT3 está etiquetado con aproximadamente 120 temas, y aproximadamente 8000 historias en inglés pertenecen a al menos uno de estos temas. Todos los temas se clasifican en 11 reglas de interpretación: (1) elecciones, (2) escándalos/audiencias, (3) casos legales/penales, (4) desastres naturales, (5) accidentes, (6) violencia o guerra en curso,(7) Noticias de ciencia y descubrimiento, (8) Finanzas, (9) Nueva ley, (10) Noticias deportivas, (11) Misc. Noticias.6.2 Metric de evaluación TDT utiliza un CDET de la función de costo que combina las probabilidades de perder una nueva historia y una falsa alarma [19]: * * * * * Det Miss Miss Target Fa fa Nontargetc C P P P P P = + (12) Tabla 2. Correlación promedio entre los tipos de términos y las clases de noticias donde CMISS significa el costo de perder una nueva historia, PMISS significa la probabilidad de perder una nueva historia y PTARGET significa la probabilidad de ver una nueva historia en los datos;CFA significa el costo de una falsa alarma, PFA significa la probabilidad de una falsa alarma y PnonTarget significa la probabilidad de ver una historia antigua. El Costo CDET se normaliza de tal manera que un sistema perfecto obtiene 0 y un sistema trivial, que es el mejor de Mark todas las historias como nuevas o antiguas, puntajes 1: (( *, *)) det Det Det Miss Target Fa NonTarget C Norm C N Norm CMin C P C P = (13) El nuevo sistema de detección de eventos ofrece dos salidas para cada historia. La primera parte es sí o no indicar si la historia desencadena un nuevo evento o no. La segunda parte es un puntaje que indica la confianza de la primera decisión. Los puntajes de confianza se pueden usar para trazar la curva Det, es decir, curvas que trazan falsas alarmas versus probabilidades de falla. Se puede determinar un costo mínimo normalizado si se eligió un umbral óptimo en la puntuación.7. Resultados experimentales 7.1 Resultados principales Para probar los enfoques propuestos en el modelo, implementamos y probamos cinco sistemas: System-1: este sistema se usa como línea de base. Se implementa en función del modelo básico descrito en la Sección 3, es decir, utilizando el modelo TF-IDF incremental para generar pesos de términos y usar la distancia de Hellinger para calcular la similitud del documento. La normalización de la puntuación de similitud también se emplea [8]. Se utiliza el procedimiento de detección S-S. Sistema-2: Este sistema es el mismo que el System-1, excepto que se utiliza el procedimiento de detección S-C. Sistema-3: Este sistema es el mismo que el System-1, excepto que utiliza el nuevo procedimiento de detección que se basa en el árbol de indexación. Sistema-4: Implementado basado en el enfoque presentado en la Sección 5.1, es decir, los términos se vuelven a ver de acuerdo con la distancia entre las distribuciones de términos en un clúster y todas las historias. Se utiliza el nuevo procedimiento de detección. Sistema-5: Implementado basado en el enfoque presentado en la Sección 5.2, es decir, los términos de diferentes tipos se vuelven a ver de acuerdo con la clase de noticias utilizando parámetros capacitados. Se utiliza el nuevo procedimiento de detección. Los siguientes son otros sistemas NED: System-6: [21] Para cada par de historias, calcula tres valores de similitud para entidad nombrada, entidad no nombrada y todos los términos respectivamente. Y emplee la máquina de vectores de soporte para predecir la nueva o antigua utilizando los valores de similitud como características. System-7: [8] Extendió un modelo básico de TF-IDF incremental para incluir modelos específicos de fuente, normalización de puntaje de similitud basada en promedios específicos de documentos, normalización de puntaje de similitud basada en promedios específicos de pares de origen, etc. Sistema-8: [13] Distiró la representación del documento en dos partes: entidades nombradas y entidades no nombradas, y elija una parte efectiva para cada clase de noticias. La Tabla 3 y la Tabla 4 muestran costos normalizados ponderados por el tema y comparación de tiempos en conjuntos de datos TDT2 y TDT3, respectivamente. Dado que no había un conjunto de datos retenidos para ajustar el umbral θ nuevo estaba disponible para experimentos en TDT2, solo informamos costos normalizados mínimos para nuestros sistemas en la Tabla 3. El sistema-5 supera a todos los demás sistemas, incluido el System-6, y realiza solo 2.78E+8 de comparación de tiempos en el procedimiento de detección que es solo el 13.4% del sistema-1. Tabla 3. Resultados de NED en los sistemas TDT2 Min Norma (CDET) CMP Times System-1 0.5749 2.08E+9 Sistema-2① 0.6673 3.77e+8 Sistema-3② 0.5765 2.81E+8 Sistema-4② 0.5431 2.99e+8 Sistema-5② 0.5089 2.78E 2.78E+8 Sistema -6 0.5300 -① θ nuevo = 0.13 ② θ init = 0.13, λ = 3, Δ = 0.15 Al evaluar los costos normalizados en TDT3, utilizamos los umbrales óptimos obtenidos del conjunto de datos TDT2 para todos los sistemas. El sistema-2 reduce los tiempos de comparación a 1.29E+9, que es solo el 18.3% del sistema-1, pero al mismo tiempo también obtiene un costo mínimo normalizado deteriorado que es 0.0499 más alto que el sistema-1. System-3 utiliza el nuevo procedimiento de detección basado en el árbol de indexación de noticias. Requiere aún menos tiempos de comparación que el sistema-2. Esto se debe a que las comparaciones de la historia de la historia generalmente producen mayores similitudes que las de la historia de la historia, por lo que las historias tienden a ser combinadas de ubicación de la persona Fecha de la organización porcentual porcentaje NN JJ CD Elecciones 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 Escandals/audiencias 0.66 0.62 0.28 1 0.111110.02 0.27 0.13 0.05 casos legales/penales 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 desastres naturales 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 Violencia o guerra 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 ciencia y descubrimiento0.08 0.03 finanzas 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 deportes 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 juntos en el sistema-3. Y System-3 es básicamente equivalente a System-1 en resultados de precisión. El sistema-4 ajusta los pesos de términos en función de la distancia de las distribuciones de términos entre todo el conjunto de historias de corpus y clúster, lo que produce una buena mejora en 0.0468 en comparación con el sistema-1. El mejor sistema (System-5) tiene un costo mínimo normalizado 0.5012, que es 0.0797 mejor que System-1, y también mejor que cualquier otro resultado informado previamente para este conjunto de datos [8, 13]. Además, el sistema-5 solo necesita 1.05E+8 tiempos de comparación que son el 14.9% del sistema-1. Tabla 4. Resultados de NED en la norma de sistemas TDT3 (CDET) Min Norm (CDET) CMP Times System-1 0.6159 0.5809 7.04e+8 Sistema-2① 0.6493 0.6308 1.29E+8 Sistema-3② 0.6197 0.5868 1.03e+8 Sistema-4② 0.5601 0.5341 1.03e+8 Sistema-5② 0.5413 0.5012 1.05e+8 Sistema-7-0.5783 -System-8-0.5229 -① θ nuevo = 0.13 ② θ init = 0.13, λ = 3, Δ = 0.15 Figura 5 muestra las cinco curvas para detects para las curvas paraNuestros sistemas en el conjunto de datos TDT3. El sistema 5 logra el costo mínimo a una tasa de alarma falsa de 0.0157 y una tasa de fallas de 0.4310. Podemos observar que System4 y System-5 obtienen una menor probabilidad de Miss en regiones de probabilidades de baja alarma falsa. La hipótesis es que, más valor de peso se transfiere a términos clave de temas de términos no clave. El puntaje de similitud entre dos historias que pertenecen a diferentes temas son más bajos que antes, porque sus términos superpuestos generalmente no son términos clave de sus temas.7.2 Selección de parámetros para la detección del árbol de indexación La Figura 3 muestra los costos mínimos normalizados obtenidos por System-3 en TDT3 utilizando diferentes parámetros. El parámetro Init θ se prueba en seis valores que abarcan de 0.03 a 0.18. Y el parámetro λ se prueba en cuatro valores 1, 2, 3 y 4. Podemos ver que, cuando dθ init se establece en 0.12, que es el más cercano a dar nuevo, los costos son más bajos que otros. Esto es fácil de explicar, porque cuando las historias que pertenecen al mismo tema se colocan en un clúster, es más razonable que el clúster represente las historias en él. Cuando el parámetro λ se establece en 3 o 4, los costos son mejores que otros casos, pero no hay mucha diferencia entre 3 y 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ Mincost 0.6 0.65 0.650.7 0.75 0.8 0.85 0.9 Figura 3. Costo mínimo en TDT3 (Δ = 0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ comparando tiempos 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 Figura 4. Comparar tiempos en TDT3 (Δ = 0.15) La Figura 4 proporciona los tiempos de comparación utilizados por System-3 en TDT3 con los mismos parámetros que la Figura 3. Los tiempos de comparación dependen fuertemente de INIT. Debido a que el Init Greaterθ es, cuanto menos historias combinadas juntas, se necesitan más tiempos de comparación para la decisión de nuevos eventos. Entonces usamos θ init = 0.13, λ = 3, δ = 0.15 para el sistema-3, 4 y 5. En esta configuración de parámetros, podemos obtener bajos costos mínimos normalizados y menos tiempos de comparación.8. Conclusión Hemos propuesto un procedimiento de detección basado en el árbol de indexación de noticias en nuestro modelo. Reduce los tiempos de comparación con aproximadamente un séptimo método tradicional sin dañar la precisión de NED. También hemos presentado dos extensiones al modelo BASIC TF-IDF. La primera extensión se realiza mediante pesos de término ajustados en función de las distribuciones de términos entre todo el corpus y un conjunto de historias de clúster. Y la segunda extensión al modelo BASIC TF-IDF es el mejor uso de los tipos de términos (tipos de entidades nombrados y parte de la velocidad) de acuerdo con las categorías de noticias. Nuestros resultados experimentales en los conjuntos de datos TDT2 y TDT3 muestran que ambas extensiones contribuyen significativamente a la mejora en la precisión. No consideramos la información del tiempo de noticias como una pista para la tarea NED, ya que la mayoría de los temas duran mucho tiempo y los conjuntos de datos TDT solo se extienden durante un período relativo (no más de 6 meses). Para el trabajo futuro, queremos recopilar un conjunto de noticias que se extiendan por un período más largo de Internet e integrar la información de tiempo en la tarea NED. Dado que el tema es un clúster de noticias relativo de grano grueso, también queremos refinar la granularidad del clúster al nivel de eventos e identificar diferentes eventos y sus relaciones dentro de un tema. Agradecimientos Este trabajo es apoyado por la Fundación Nacional de Ciencias Naturales de China bajo la subvención No. 90604025. Cualquier opinión, hallazgos y conclusiones o recomendaciones expresadas en este material son los autores y no reflejan necesariamente las del patrocinador.9. Referencias [1] http://www.nist.gov/speech/tests/tdt/index.htm [2] En la detección y seguimiento de temas. Organización de información basada en eventos. Kluwer Academic Publishers, 2002.Curva ponderada Sistema1 Min Norma (Costo) Sistema2 Tema Curva ponderada Sistema2 Norma min Norma (Costo) Sistema de tema Curva ponderada Sistema3 Min Norma (Costo) Sistema4 Tema Curva ponderada Sistema4 Min Norma (Costo) Sistema 5 Curva ponderada Sistema 5 Min Norma (Costo) Rendimiento aleatorio) ¡Rendimiento aleatorio) AleatorioFigura 5. Det curvas en TDT3 [3] Y. Yang, J. Carbonell, R. Brown, T. Pierce, B.T. Archibald y X. Liu. Enfoques de aprendizaje para detectar y rastrear eventos de noticias. En IEEE Intelligent Systems, número especial sobre aplicaciones de recuperación de información inteligente, Volumen 14 (4), 1999, 32-43.[4] Y. Yang, T. Pierce y J. Carbonell. Un estudio sobre detección de eventos retrospectivos y en línea. En Actas de Sigir-98, Melbourne, Australia, 1998, 28-36.[5] J. Allan, V. Lavrenko, D. Malin y R. Swan. Detecciones, límites y plazos: UMass y TDT-3. En Actas del Taller de detección y seguimiento de temas (TDT-3), Viena, VA, 2000, 167-174.[6] R. Papka y J. Allan. Detección de eventos en línea en línea con Título de la agrupación de un solo pase2:. Informe técnico UM-CS1998-021, 1998. [7] W. Lam, H. Meng, K. Wong y J. Yen. Uso del análisis contextual para la detección de eventos de noticias. Revista Internacional sobre Sistemas Inteligentes, 2001, 525-546.[8] B. Thorsten, C. Francine y F. Ayman. Un sistema para la nueva detección de eventos. En Actas de la 26ª Conferencia Internacional ACM Sigir de ACM, Nueva York, NY, EE. UU. ACM Press.2003, 330-337.[9] S. Nicola y C. Joe. Combinando clasificadores de documentos semánticos y sintácticos para mejorar la detección de la primera historia. En Actas de la 24ª Conferencia Internacional ACM Sigir anual, Nueva York, NY, EE. UU. ACM Press.2001, 424425. [10] Y. Yang, J. Zhang, J. Carbonell y C. Jin. Detección de novedad acondicionada con temas. En Actas de la 8ª Conferencia Internacional SIGKDD ACM, ACM Press.2002, 688-693.[11] M. Juha, A.M.Helena y S. Marko. Aplicación de clases semánticas en detección y seguimiento de eventos. En Actas de la Conferencia Internacional sobre Procesamiento del Lenguaje Natural (Icon 2002), 2002, páginas 175-183.[12] M. Juha, A.M.Helena y S. Marko. Semántica simple en la detección y seguimiento de temas. Recuperación de información, 7 (3-4): 2004, 347-368.[13] K. Giridhar y J. Allan. Clasificación de texto y entidades nombradas para la nueva detección de eventos. En Actas de la 27ª Conferencia Internacional ACM Sigir, Nueva York, NY, EE. UU. ACM Press.2004, 297-304.[14] J. P. Callan, W. B. Croft y S. M. Harding. El sistema de recuperación de la investigación. En Actas de Dexa-92, tercera conferencia internacional sobre bases de datos y aplicaciones de sistemas expertos, 1992, 78-83.[15] R. Krovetz. Ver la morfología como un proceso de inferencia. En Actas de ACM Sigir93, 1993, 61-81.[16] Y. Yang y J. Pedersen. Un estudio comparativo sobre la selección de características en la categorización de texto. En J. D. H. Fisher, Editor, La Decimocuarta Conferencia Internacional sobre Aprendizaje Autor (ICML97), Morgan Kaufmann, 1997, 412-420.[17] T. M. Cover y J.A. Thomas. Elementos de la teoría de la información. Wiley.1991. [18] El consorcio de datos lingüísticos, http: //www.ldc,upenn.edu/.[19] El plan de evaluación y definición de tareas TDT 2001, http://www.nist.gov/speech/tests/tdt/tdt2001/evalplan.htm.[20] R. E. Schapire e Y. Cantante. BoostExter: un sistema basado en el refuerzo para la categorización de texto. En el aprendizaje automático 39 (2/3): 1, Kluwer Academic Publishers, 2000, 35-168.[21] K. Giridhar y J. Allan.2005. Uso de nombres y temas para la nueva detección de eventos. En Actas de la Conferencia de Tecnología Humana y Conferencia sobre Métodos Empíricos en Lenguaje Natural, Vancouver, 2005, 121-128