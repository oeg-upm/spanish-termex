Una máquina del tiempo para la búsqueda de texto Klaus Berberich Srikanta Bedathur Thomas Neumann Gerhard Weikum Max-Planck Instituto de Informática Saarbr¨ucken, Alemania {Kberberi, Bedathur, Neumann, Weikum}@mpi-inf.mpg.de Resumen de texto Abierto sobre colecciones documentadas con versión temporalcomo los archivos web ha recibido poca atención como problema de investigación. Como consecuencia, no existe una solución escalable y de principios para buscar dicha colección a partir de un tiempo especificado t.En este trabajo, abordamos esta deficiencia y proponemos una solución eficiente para la búsqueda de texto de viaje en el tiempo extendiendo el índice de archivos invertidos para prepararlo para la búsqueda temporal. Introducimos a la coalescación temporal aproximada como un método sintonizable para reducir el tamaño del índice sin afectar significativamente la calidad de los resultados. Para mejorar aún más el rendimiento de las consultas de viaje en el tiempo, presentamos dos técnicas de principios para intercambiar el tamaño del índice por su rendimiento. Estas técnicas pueden formularse como problemas de optimización que se pueden resolver a casi óptimos. Finalmente, nuestro enfoque se evalúa en una serie completa de experimentos en dos conjuntos de datos del mundo real a gran escala. Los resultados muestran inequívocamente que nuestros métodos permiten construir una máquina de tiempo eficiente escalable a grandes colecciones de texto de versiones. Categorías y descriptores de sujetos H.3.1 [Análisis e indexación de contenido]: métodos de indexación;H.3.3 [Búsqueda y recuperación de información]: modelos de recuperación, algoritmos de términos generales del proceso de búsqueda, experimentación, rendimiento 1. Introducción En este trabajo, abordamos la búsqueda de texto de viaje en el tiempo a través de colecciones de documentos versionadas temporalmente. Dada una consulta de palabras clave, Q y un tiempo en nuestro objetivo es identificar y clasificar los documentos relevantes como si la colección estuviera en su estado a partir del tiempo t.Un número creciente de tales colecciones de documentos versionadas está disponible hoy, incluidos archivos web, entornos de autoría colaborativa como wikis o feeds de información de tiempo de tiempo. La búsqueda de texto en estas colecciones, sin embargo, es principalmente firme en el tiempo: mientras que la colección buscada cambia con el tiempo, a menudo solo la versión más reciente de un documento está indexada o las versiones se indexan de forma independiente y se tratan como documentos separados. Peor aún, para algunas colecciones, en particular los archivos web como el Archivo de Internet [18], una funcionalidad integral de búsqueda de texto a menudo falta por completo. La búsqueda de texto de viaje en el tiempo, como lo desarrollamos en este documento, es una herramienta crucial para explorar estas colecciones y desarrollar su máximo potencial como lo demuestra el siguiente ejemplo. Para un documental sobre un escándalo político pasado, un periodista necesita investigar opiniones y declaraciones tempranas hechas por los políticos involucrados. Al enviar una consulta apropiada a un motor de búsqueda web importante, la mayoría de los resultados devueltos contienen solo una cobertura reciente, ya que muchas de las primeras páginas web han desaparecido y solo se conservan en los archivos web. Si la consulta pudiera enriquecerse con un punto de tiempo, digamos el 20 de agosto de 2003, ya que el día después del escándalo se reveló, y se emitió contra un archivo web, solo las páginas que existían específicamente en ese momento podrían recuperarse, satisfaciendo mejor la necesidad de la información de los periodistas.. Las colecciones de documentos como Web o Wikipedia [32], como las orientamos aquí, ya son grandes si solo se considera una sola instantánea. Al observar su historia evolutiva, nos enfrentamos a volúmenes de datos aún más grandes. Como consecuencia, los enfoques de la búsqueda de texto de viajes en el tiempo fallan, y los enfoques viables deben ampliarse bien a tales grandes volúmenes de datos. Este documento presenta una solución eficiente para la búsqueda de texto de viaje en el tiempo al hacer las siguientes contribuciones clave: 1. El popular índice de archivos invertidos bien estudiados [35] se extiende de manera transparente para habilitar la búsqueda de texto de viaje en tiempo.2. Se introduce la coalescencia temporal para evitar una explosión de índice y mantener los resultados altamente precisos.3. Desarrollamos dos técnicas de materialización sublista para mejorar el rendimiento del índice que permiten el comercio fuera del espacio frente al rendimiento.4. En una evaluación experimental integral, nuestro enfoque se evalúa en la wikipedia inglesa y las partes del archivo de Internet como dos conjuntos de datos del mundo real a gran escala con documentos versionados. El resto de este documento está organizado de la siguiente manera. El trabajo presentado se pone en contexto con el trabajo relacionado en la Sección 2. Delineamos nuestro modelo de una recopilación de documentos versionada temporalmente en la Sección 3. Presentamos nuestro índice invertido de viaje en el tiempo en la Sección 4. Sobre la base de él, la fusión temporal se describe en la Sección 5. En la Sección 6 describimos técnicas de principios para mejorar el rendimiento del índice, antes de presentar los resultados de nuestra evaluación experimental en la Sección 7. 2. Trabajo relacionado Podemos clasificar el trabajo relacionado principalmente en las siguientes dos categorías: (i) Métodos que tratan explícitamente con colecciones de documentos versionados o bases de datos temporales, y (ii) métodos para reducir el tamaño del índice explotando la superposición del contenido de documento o la superposición o la superposiciónAl podar porciones del índice. Revisamos brevemente el trabajo en estas categorías aquí. Hasta donde sabemos, hay muy poco trabajo previo que se ocupe de la búsqueda histórica sobre documentos versionados temporalmente. Anick y Flynn [3], mientras son pioneros en esta investigación, describen un sistema de compensación de ayuda que respalda consultas históricas. Los costos de acceso están optimizados para los accesos a las versiones más recientes y aumentan a medida que uno se mueve más al pasado. Burrows y Hisgen [10], en una descripción de la patente, delinean un método para indexar valores basados en el rango y mencionar su uso potencial para buscar en función de las fechas asociadas con los documentos. Trabajo reciente de Nørv˚ag y Nybø [25] y sus propuestas anteriores se concentran en el problema relativamente más simple de apoyar solo consultas de contenido de texto y descuidar la puntuación de relevancia de los resultados. Stack [29] informa experiencias prácticas hechas al adaptar la Nutch de motores de búsqueda de código abierto para buscar archivos web. Sin embargo, esta adaptación no proporciona la funcionalidad prevista de búsqueda de texto de viaje en el tiempo. Por el contrario, la investigación en bases de datos temporales ha producido varias estructuras de índice adaptadas para bases de datos que evolucionan en el tiempo;Una descripción completa del estado de arte está disponible en [28]. A diferencia del índice de archivos invertidos, su aplicabilidad a la búsqueda de texto no se entiende bien. Pasando a la segunda categoría de trabajo relacionado, Broder et al.[8] Describa una técnica que explota un gran contenido se superpone entre los documentos para lograr una reducción en el tamaño del índice. Su técnica hace supuestos fuertes sobre la estructura de las superposiciones de documentos que lo hace inaplicable a nuestro contexto. Enfoques más recientes de Hyovici et al.[17] y Zhang y suel [34] explotan el contenido arbitrario se superponen entre documentos para reducir el tamaño del índice. Sin embargo, ninguno de los enfoques considera el tiempo explícitamente o proporciona la funcionalidad de búsqueda de texto de viaje en el tiempo deseado. Las técnicas de impulso de índice estático [11, 12] tienen como objetivo reducir el tamaño efectivo del índice, eliminando partes del índice que se espera que tengan un bajo impacto en el resultado de la consulta. Tampoco consideran aspectos temporales de los documentos y, por lo tanto, son técnicamente bastante diferentes de nuestra propuesta a pesar de tener un objetivo compartido de reducción del tamaño del índice. Cabe señalar que las técnicas de invitación de índice pueden adaptarse para funcionar junto con el índice de texto temporal que proponemos aquí.3. Modelo En el presente trabajo, tratamos con una colección de documentos versionada temporalmente que se modela como se describe a continuación. Cada documento d ∈ D es una secuencia de sus versiones d = dt1, dt2 ,.... Cada versión DTI tiene una marca de tiempo asociada TI que refleja cuándo se creó la versión. Cada versión es un vector de términos o características de búsqueda. Cualquier modificación a una versión de documento da como resultado la inserción de una nueva versión con la marca de tiempo correspondiente. Empleamos una definición discreta de tiempo, de modo que las marcas de tiempo son enteros no negativos. La eliminación de un documento en el tiempo TI, es decir, su desaparición del estado actual de la colección, se modela como la inserción de una versión especial de lápida ⊥. La validez de tiempo intervalo de tiempo Val (DTI) de una versión DTI es [Ti, Ti+1), si existe una versión más nueva con la marca de tiempo Asociada Ti+1, y [TI, ahora), de lo contrario, ahora apunta al mayor valor posible deuna marca de tiempo (es decir, ∀t: t <ahora). Al poner todo esto, definimos el estado DT de la colección en el tiempo t (es decir, el conjunto de versiones válidas en t que no son deleciones) como dt = [d∈D {dti ∈ D |t ∈ Val (dti) ∧ dti = ⊥}. Como se mencionó anteriormente, queremos enriquecer una consulta de palabras clave Q con una marca de tiempo T, de modo que Q se evalúe sobre DT, es decir, el estado de la colección en el momento t.La consulta enriquecida de viajes en el tiempo está escrita como q t para brevedad. Como modelo de recuperación en este trabajo, adoptamos OKAPI BM25 [27], pero tenga en cuenta que las técnicas propuestas no dependen de esta elección y también son aplicables a otros modelos de recuperación como TF-IDF [4] o modelos de idiomas [26]. Para nuestra configuración considerada, adaptamos ligeramente OKAPI BM25 como W (Q T, Dti) = x V∈Q WTF (V, DTI) · Widf (V, T). En la fórmula anterior, se define la relevancia W (Q T, DTI) de una versión de documento DTI a la consulta de viaje en el tiempo Q t. Reiteramos que Q T se evalúa sobre DT para que solo se considera la versión DTI válida en el tiempo T. El primer factor WTF (V, DTI) en la suma, que se conoce más además, el TFScore se define como wtf (v, dti) = (k1 + 1) · tf (v, dti) k1 · ((1 - b) +b · dl (d ti) avdl (ti)) + tf (v, dti). Considera la frecuencia de término simple TF (V, DTI) del término V en la versión DTI que lo normaliza, teniendo en cuenta tanto la longitud DL (DTI) de la versión como la longitud promedio de la longitud del documento (TI) en la colección en el tiempo TI. El parámetro de longitud-normalización B y el parámetro de saturación TF K1 se heredan del OKAPI BM25 original y se establecen comúnmente en los valores 1.2 y 0.75 respectivamente. El segundo factor widf (v, t), al que nos referimos como el puntaje de IDF en el resto, transmite la frecuencia del documento inverso del término V en la colección en el tiempo t y se define como widf (v, t) = log n(t) - df (v, t) + 0.5 df (v, t) + 0.5 donde n (t) = | dt |es el tamaño de la colección en el tiempo t y df (v, t) proporciona el número de documentos en la colección que contienen el término V en el momento t.Mientras que la puntuación de IDF depende de todo el corpus a partir del tiempo de consulta T, el puntaje TF es específico de cada versión.4. Time-TravelInvertedFileIndex El índice de archivos invertidos es una técnica estándar para la indexación de texto, implementada en muchos sistemas. En esta sección, revisamos brevemente esta técnica y presentamos nuestras extensiones al índice de archivos invertidos que lo preparan para la búsqueda de texto de viaje en el tiempo.4.1 Índice de archivos invertidos Un índice de archivos invertidos consiste en un vocabulario, comúnmente organizado como un b+-tree, que asigna cada término a su IDFScore y una lista invertida. La lista de índices LV que pertenece al término V contiene publicaciones del formulario (d, p) donde D es un identificador de documentos y P es la llamada carga útil. La carga útil P contiene información sobre el término frecuencia de V en D, pero también puede incluir información posicional sobre dónde aparece el término en el documento. El orden de clasificación de las listas de índice depende de qué consultas deben ser compatibles de manera eficiente. Para consultas booleanas, es favorable clasificar las listas de índices en el orden de documento. Las listas de índices ordenados de orden de frecuencia y orden de impacto son beneficiosos para las consultas clasificadas y permiten el procesamiento de consultas optimizado que se detiene temprano después de haber identificado los K documentos más relevantes [1, 2, 9, 15, 31]. Se han propuesto una variedad de técnicas de compresión, como la codificación de identificadores de documentos de manera más compacta, [33, 35] para reducir el tamaño de las listas de índices. Para una excelente encuesta reciente sobre índices de archivos invertidos, nos referimos [35].4.2 Índice de archivos invertido de viaje en el tiempo Para preparar un índice de archivos invertidos para viajes en tiempo, ampliamos tanto las listas invertidas como la estructura de vocabulario incorporando explícitamente información temporal. La idea principal de las listas invertidas es que incluimos un interval de validez [TB, TE) en las publicaciones para denotar cuándo era válida la información de carga útil. Las publicaciones en nuestro índice de archivos invertido de viaje en tiempo son, por lo tanto, del formulario (d, p, [tb, te)) donde d y p se definen como en el índice de archivos invertido estándar anterior y [tb, te) es el tiempo de validez-intervalo. Como ejemplo concreto, en nuestra implementación, para una versión DTI que tiene el OKAPI BM25 TF-score WTF (V, DTI) para el término V, la lista de índice LV contiene la publicación (D, WTF (V, DTI), [TI,ti+1)). Del mismo modo, la estructura de vocabulario extendida mantiene para cada término una serie de tiempo de puntajes IDF organizados como un árbol B+. A diferencia de la puntuación TF, el puntaje IDF de cada término podría variar con cada cambio en el corpus. Por lo tanto, adoptamos un enfoque simplificado para el mantenimiento del puntaje de IDF, calculando las puntuaciones de las FDI para todos los términos en el corpus en momentos específicos (posiblemente periódicos).4.3 Procesamiento de consultas durante el procesamiento de una consulta de viaje en el tiempo Q T, para cada término de consulta, el puntaje IDF correspondiente válido en el tiempo T se recupera del vocabulario extendido. Luego, las listas de índice se leen secuencialmente del disco, acumulando así la información contenida en las publicaciones. Extendemos de manera transparente la lectura secuencial, que es, lo mejor de nuestro conocimiento, a todas las técnicas de procesamiento de consultas en índices de archivos invertidos, lo que las hace adecuadas para el procesamiento de consultas de viaje en el tiempo. Para este fin, la lectura secuencial se extiende omitiendo todas las publicaciones cuya validez intervalo de tiempo no contiene t (es decir, t ∈ [Tb, TE)). Si se puede omitir una publicación solo se puede decidir después de que la publicación se haya transferido del disco a la memoria y, por lo tanto, aún incurra en un costo significativo de E/S. Como remedio, proponemos técnicas de organización índice en la Sección 6 que tienen como objetivo reducir significativamente la sobrecarga de E/S. Observamos que nuestra extensión propuesta del índice de archivos invertidos no hace suposiciones sobre el orden de clasificación de las listas de índice. Como consecuencia, las técnicas de procesamiento de consultas existentes y la mayoría de las optimizaciones (por ejemplo, técnicas de compresión) siguen siendo igualmente aplicables.5. Counsescing temporal Si empleamos el índice invertido de viaje en el tiempo, como se describe en la sección anterior, a una recopilación de documentos versionada, obtenemos una publicación por término por versión de documento. Para términos frecuentes y grandes colecciones altamente dinámicas, esta puntuación de tiempo no coalimentó la Figura 1: la coalescación temporal aproximada conduce a listas de índices extremadamente largas con un rendimiento de consulta muy pobre. La técnica de fusión temporal aproximada que proponemos en esta sección contrarresta esta explosión en el tamaño de la lista de índices. Se basa en la observación de que la mayoría de los cambios en una recopilación de documentos versionada son menores, dejando intactos grandes partes del documento. Como consecuencia, la carga útil de muchas publicaciones pertenecientes a versiones temporalmente adyacentes diferirá solo ligeramente o no. La coalcación temporal aproximada reduce el número de publicaciones en una lista de índices fusionando dicha secuencia de publicaciones que tienen cargas útiles casi iguales, mientras mantienen el error máximo limitado. Esta idea se ilustra en la Figura 1, que traza puntajes no coalimentados y fusionados de publicaciones que pertenecen a un solo documento. La fusión temporal aproximada es muy efectiva dada tales cargas útiles fluctuantes y reduce el número de publicaciones de 9 a 3 en el ejemplo. La noción de fusión temporal se introdujo originalmente en la investigación de la base de datos temporal por B¨ohlen et al.[6], donde se consideró el problema más simple de fusionar solo información igual. A continuación, declaramos formalmente el problema tratado en una fusión temporal aproximada y discutimos el cálculo de soluciones óptimas y aproximadas. Tenga en cuenta que la técnica se aplica a cada lista de índices por separado, de modo que las siguientes explicaciones asumen un término V y una lista de índice LV. Como entrada, se nos da una secuencia de publicaciones temporalmente adyacentes i = (d, pi, [ti, ti+1)) ,..., (d, pn - 1, [tn - 1, tn))). Cada secuencia representa un período de tiempo contiguo durante el cual el término estuvo presente en un solo documento d.Si un término desaparece de D pero reaparece más tarde, obtenemos múltiples secuencias de entrada que se tratan por separado. Buscamos generar la secuencia de salida de longitud mínima de las publicaciones o = (d, pj, [tj, tj+1)) ,..., (d, pm-1, [tm-1, tm))), que se adhiere a las siguientes restricciones: Primero, O y yo debemos cubrir el mismo rango de tiempo, es decir, Ti = tj y tn = tm. En segundo lugar, al fusionar una subsecuencia de publicaciones de la entrada en una sola publicación de la salida, queremos que el error de aproximación esté por debajo de un umbral. En otras palabras, If (D, Pi, [Ti, Ti+1)) y (D, PJ, [TJ, TJ+1)) son publicaciones de I y O respectivamente, entonces lo siguiente debe mantener una función de error elegiday un umbral: tj ≤ ti ∧ ti+1 ≤ tj+1 ⇒ error (pi, pj) ≤. En este documento, como función de error, empleamos el error relativo entre las cargas útiles (es decir, puntajes TF) de un documento en I y O, definido como: Errrel (Pi, Pj) = | Pi-Pj |/ | Pi |. Encontrar una secuencia óptima de salida de publicaciones se puede lanzar en la búsqueda de una representación en constante parte para los puntos (Ti, PI) que utiliza un número mínimo de segmentos mientras conserva la garantía de aproximación anterior. Se producen problemas similares en la segmentación de la serie temporal [21, 30] y la construcción de histogramas [19, 20]. La programación típicamente dinámica se aplica para obtener una solución óptima en el tiempo O (N2 M ∗) [20, 30] con M ∗ el número de segmentos en una secuencia óptima. En nuestro entorno, como una diferencia clave, solo se conserva una garantía del error local, en contraste con una garantía sobre el error global en la configuración mencionada anteriormente. Explotando este hecho, una solución óptima es computable mediante la inducción [24] en el tiempo O (N2). Los detalles del algoritmo óptimo se omiten aquí, pero se pueden encontrar en el informe técnico acompañante [5]. La complejidad cuadrática del algoritmo óptimo lo hace inapropiado para los grandes conjuntos de datos encontrados en este trabajo. Como alternativa, presentamos un algoritmo aproximado de tiempo lineal que se basa en el algoritmo de ventana deslizante dada en [21]. Este algoritmo produce secuencias de salida casi óptimas que conservan el límite en el error relativo, pero posiblemente requieren algunos segmentos adicionales más que una solución óptima. Algoritmo 1 Coalcing temporal (aproximado) 1: i = (d, pi, [ti, ti+1)) ,... O = 2: pmin = pi pMax = pi p = pi tb = ti te = ti+1 3: para (d, pj, [tj, tj+1)) ∈ I do 4: pmin = min (pmin, pj)pMax = max (pMax, pj) 5: p = optrep (pmin, pMax) 6: if errrel (pmin, p) ≤ ∧ errrel (pMax, p) ≤ entonces 7: pmin = pmin pMax = pMax p = p te =tj+1 8: else 9: o = o ∪ (d, p, [tb, te)) 10: pmin = pj pMax = pj p = pj tb = tj te = tj+1 11: final si 12: final para13: O = O ∪ (D, P, [Tb, TE)) Algoritmo 1 hace que uno pase sobre la secuencia de entrada I. Mientras lo hace, fusiona secuencias de publicaciones que tienen una longitud máxima. El representante óptimo para una secuencia de publicaciones depende solo de su carga útil mínima y máxima (PMIN y PMAX) y se puede buscar con Optrep en O (1) (ver [16] para más detalles). Al leer la próxima publicación, el algoritmo intenta agregarlo a la secuencia actual de publicaciones. Calcula el nuevo representante hipotético P y verifica si conservaría la garantía de aproximación. Si esta prueba falla, se agrega una publicación fusionada del antiguo representante a la secuencia de salida O y, después de eso, la contabilidad se reinicializa. La complejidad del tiempo del algoritmo está en O (N). Tenga en cuenta que, dado que no hacemos suposiciones sobre el orden de clasificación de las listas de índices, los algoritmos temporales de coalesidad tienen un costo de preprocesamiento adicional en o (| lv | log | lv |) para clasificar la lista de índices y cortarlo en subsecuencias para cada documento.6. La eficiencia de materialización sublista de procesar una consulta Q t en nuestro índice invertido de viaje en el tiempo está influenciada adversamente por la E/S desperdiciada debido a las publicaciones de lectura pero omitidas. La fusión temporal aborda implícitamente este problema al reducir el tamaño general de la lista de índices, pero sigue siendo una sobrecarga significativa. En esta sección, abordamos este problema proponiendo la idea de materializar sublistas, cada uno de los cuales corresponde a un subintervalo contiguo de tiempo abarcado por el índice completo. Cada uno de estos sublists contiene todas las publicaciones fusionadas que se superponen con el intervalo de tiempo correspondiente del sublista. Tenga en cuenta que todas las publicaciones cuya intervalo de tiempo de validez abarca los límites temporales de varios sublistas se replican en cada uno de los sublistas abarcados. Por lo tanto, para procesar la consulta Q t Tiempo T1 T2 T3 T4 T5 T6 T7 T8 T9 T10 D1 D2 D3 Documento 1 2 3 4 5 6 7 8 9 10 Figura 2: Materialización Sublista Es suficiente para escanear cualquier sublist materializado cuyo TimeInterval contienet.Ilustramos la idea de la materialización sublista utilizando un ejemplo que se muestra en la Figura 2. La lista de índice LV visualizado en la figura contiene un total de 10 publicaciones de tres documentos D1, D2 y D3. Para facilitar la descripción, tenemos límites numerados de intervalos de tiempo de validez, en el aumento de tiempo de tiempo, como T1 ,..., T10 y numeró las publicaciones en sí como 1 ,..., 10. Ahora, considere el procesamiento de una consulta Q t con t ∈ [T1, T2) usando esta lista invertida. Aunque solo tres publicaciones (Publicaciones 1, 5 y 8) son válidas en el tiempo T, toda la lista invertida debe leerse en el peor de los casos. Supongamos que dividimos el eje de tiempo de la lista en el tiempo T2, formando dos sublistas con publicaciones {1, 5, 8} y {2, 3, 4, 5, 6, 7, 8, 9, 10} respectivamente. Luego, podemos procesar la consulta anterior con un costo óptimo leyendo solo aquellas publicaciones que existieron en esta t.A primera vista, puede parecer contradictorio reducir el tamaño del índice en el primer paso (usando un fase temporal), y luego aumentarlo nuevamente utilizando las técnicas de materialización sublista presentadas en esta sección. Sin embargo, reiteramos que nuestro objetivo principal es mejorar la eficiencia de las consultas de procesamiento, no reducir el tamaño del índice solo. El uso de la fusión temporal mejora el rendimiento al reducir el tamaño del índice, mientras que la materialización sublista mejora el rendimiento al replicar juiciosamente las entradas. Además, las dos técnicas se pueden aplicar por separado y son independientes. Sin embargo, si se aplica en conjunto, existe un efecto sinérgico: los sublistas que se materializan a partir de un índice temporalmente fusionado son generalmente más pequeños. Empleamos la notación LV: [Ti, TJ) para referirnos al sublista materializado para el intervalo de tiempo [Ti, TJ), que se define formalmente como, LV: [Ti, Tj) = {(D, P, [Tb,te)) ∈ LV |tb <tj ∧ te> ti}. Para ayudar a la presentación en el resto del documento, primero proporcionamos algunas definiciones. Sea t = t1...Sea la secuencia ordenada de todos los límites únicos de intervalo de tiempo de una lista invertida LV. Entonces definimos e = {[ti, ti+1) |1 ≤ i <n} para ser el conjunto de intervalos de tiempo elementales. Nos referimos al conjunto de intervalos de tiempo para los cuales los sublistas se materializan como M ⊆ {[Ti, TJ) |1 ≤ i <j ≤ n}, y demanda ∀ t ∈ [t1, tn) ∃ m ∈ M: t ∈ M, es decir, los intervalos de tiempo en M deben cubrir completamente el intervalo de tiempo [T1, TN), de modo que ese tiempo-Se se puede procesar las consultas de contrato q t para todos t ∈ [t1, tn). También suponemos que los intervalos en M son disjuntos. Podemos hacer esta suposición sin descartar ninguna solución óptima con respecto al espacio o el rendimiento definido a continuación. El espacio requerido para la materialización de los sublistas en un conjunto m se define como s (m) = x m∈M | lv: m |, es decir, la longitud total de todas las listas en M. Dada un conjunto m, dejamos π ([ti, ti+1)) = [tj, tk) ∈ M: [ti, ti+1) ⊆ [tj, tk) denota el intervalo de tiempo que se utiliza para procesar consultas Q t con t ∈ [ti, ti+1). El rendimiento de las consultas de procesamiento q t para t ∈ [ti, ti+1) inversamente depende de su costo de procesamiento PC ([Ti, ti+1)) = | LV: π ([Ti, Ti+1)) |, que se supone que es proporcional a la longitud de la lista LV: π ([ti, ti+1)). Por lo tanto, para optimizar el rendimiento de las consultas de procesamiento, minimizamos sus costos de procesamiento.6.1 Enfoques de rendimiento/espacio-óptimo Una estrategia para eliminar el problema de las publicaciones omitidas es materializar con entusiasmo los sublistas para todos los intervalos de tiempo elementales, es decir, elegir M = E. Al hacerlo, para cada consulta solo las publicaciones válidas en el momento T sonLeer y, por lo tanto, se logra el mejor rendimiento posible. Por lo tanto, nos referiremos a este enfoque como Popt en el resto. El enfoque inicial descrito anteriormente que mantiene solo la lista completa LV y, por lo tanto, elige M = {[t1, tn)} se conoce como SOPT en el resto. Este enfoque requiere un espacio mínimo, ya que mantiene cada una publicación exactamente una vez. POPT y SOPT son extremos: el primero proporciona el mejor rendimiento posible pero no es eficiente en el espacio, este último requiere un espacio mínimo pero no proporciona un buen rendimiento. Los dos enfoques presentados en el resto de esta sección permiten operar mutuamente el espacio y el rendimiento y, por lo tanto, pueden considerarse como un medio para explorar el espectro de configuración entre el enfoque POPT y SOPT.6.2 Enfoque de garantía de rendimiento El enfoque POPT claramente desperdicia mucho espacio que materializa muchos sublistas casi idénticos. En el ejemplo ilustrado en la Figura 2 sublistas materializados para [T1, T2) y [T2, T3) difieren solo por una publicación. Si el sublista para [T1, T3) se materializara en su lugar, se podría ahorrar espacio significativo al tiempo que incurra solo en una sobrecarga de una publicación omitida para todos T ∈ [T1, T3). La técnica presentada a continuación está impulsada por la idea de que se pueden lograr ahorros de espacio significativos sobre POPT, si se puede tolerar una pérdida superior en el rendimiento, o para decirlo de manera diferente, si se debe conservar una garantía de rendimiento en relación con la óptima. En detalle, la técnica, a la que nos referimos como PG (garantía de rendimiento) en el resto, encuentra un conjunto M que tiene un espacio mínimo requerido, pero garantiza cualquier intervalo de tiempo elemental [Ti, Ti+1) (y, por lo tanto, para cualquier consultaq t con t ∈ [ti, ti+1)) que el rendimiento es peor que el óptimo por lo sumo un factor de γ ≥ 1. Formalmente, este problema puede declararse como argmin m s (m) s.t.∀ [Ti, ti+1) ∈ E: PC ([Ti, Ti+1)) ≤ γ · | LV: [Ti, Ti+1) |. Se puede calcular una solución óptima al problema mediante la inducción utilizando la recurrencia c ([t1, tk+1)) = min {c ([t1, tj))+| lv: [tj, tk+1) ||1 ≤ j ≤ k ∧ condición}, donde c ([t1, tj)) es el costo óptimo (es decir, el espacio requerido) para el subproblema de prefijo {[ti, ti+1) ∈ E |[Ti, ti+1) ⊆ [t1, tj)} y la condición significa ∀ [ti, ti+1) ∈ E: [Ti, Ti+1) ⊆ [tj, tk+1) ⇒ | lv: [tj, tk+1) |≤ γ · | lv: [ti, ti+1) |. Intuitivamente, la recurrencia establece que una solución óptima para [T1, TK+1) se combina de una solución óptima a un subproblema de prefijo C ([T1, TJ)) y un intervalo de tiempo [TJ, TK+1) que se puede materializarsin violar la garantía de rendimiento. El seudocódigo del algoritmo se omite por razones de espacio, pero se puede encontrar en el informe técnico acompañante [5]. La complejidad del tiempo del algoritmo está en O (N2): para cada subproblema de prefijo se debe evaluar la recurrencia anterior, lo cual es posible en tiempo lineal si los tamaños de la lista | L: [Ti, TJ) |son precomputados. La complejidad del espacio está en O (N2): el costo de mantener las longitudes sublistas precomputadas y memorando soluciones óptimas para los subproblemas prefijos.6.3 Enfoque en el espacio hasta ahora consideramos el problema de materializar a los sublistas que ofrecen una garantía sobre el rendimiento al tiempo que requieren un espacio mínimo. Sin embargo, en muchas situaciones, el espacio de almacenamiento es muy importante y el objetivo sería materializar un conjunto de sublistas que optimice el rendimiento esperado sin exceder un límite de espacio dado. La técnica presentada a continuación, que se llama SB, aborda este mismo problema. La restricción de espacio se modela mediante un parámetro especificado por el usuario κ ≥ 1 que limita la explosión máxima permitida en el tamaño del índice de la solución óptima de espacio proporcionada por SOPT. La técnica SB busca encontrar un conjunto M que se adhiera a este límite de espacio pero minimiza el costo de procesamiento esperado (y, por lo tanto, optimiza el rendimiento esperado). En la definición del costo de procesamiento esperado, P ([Ti, Ti+1)) denota la probabilidad de que un punto de tiempo de consulta esté en [Ti, Ti+1). Formalmente, este problema de materiales sublistas unidos al espacio puede establecerse como argmin m x [ti, ti+1) ∈ E P ([Ti, Ti+1)) · PC ([Ti, Ti+1)) S.T. X m∈M | lv: m |≤ κ | LV |. El problema se puede resolver mediante el uso de la programación dinámica en un número cada vez mayor de intervalos de tiempo: en cada intervalo de tiempo en E, los algoritmos decide si comenzar un nuevo intervalo de tiempo de materialización, utilizando la mejor decisión de materialización conocida de los intervalos de tiempo anteriores y manteniendorastrear del consumo de espacio requerido para la materialización. Aquí se omite una descripción detallada del algoritmo, pero se puede encontrar en el informe técnico acompañante [5]. Desafortunadamente, el algoritmo tiene complejidad de tiempo en O (N3 | lv |) y su complejidad espacial está en O (N2 | LV |), que no es práctica para grandes conjuntos de datos. Obtenemos una solución aproximada al problema utilizando recocido simulado [22, 23]. El recocido simulado toma un número fijo R de rondas para explorar el espacio de la solución. En cada ronda se analiza un sucesor aleatorio de la solución actual. Si el sucesor no se adhiere al límite de espacio, siempre se rechaza (es decir, la solución actual se mantiene). Siempre se acepta un sucesor que se adhiere al límite de espacio si logra un costo de procesamiento esperado más bajo que la solución actual. Si logra un mayor costo de procesamiento esperado, se acepta aleatoriamente con probabilidad e - ∆/R donde ∆ es el aumento en el costo de procesamiento esperado y R ≥ R ≥ 1 denota el número de rondas restantes. Además, en todas las rondas, el método realiza un seguimiento de la mejor solución que se ve hasta ahora. El espacio de solución para el problema en cuestión se puede explorar eficientemente. Como argumentamos anteriormente, solo tenemos que mirar los conjuntos M que cubren completamente el intervalo de tiempo [T1, TN) y no contienen intervalos de tiempo superpuestos. Representamos tal conjunto m como una matriz de n variables booleanas b1...bn que transmiten los límites de los intervalos de tiempo en el conjunto. Tenga en cuenta que B1 y Bn siempre están configurados en verdadero. Inicialmente, todas las variables intermedias n - 2 suponen falsas, que corresponde al conjunto M = {[t1, tn)}. Un sucesor aleatorio ahora se puede generar fácilmente cambiando el valor de una de las variables intermedias N - 2. La complejidad del tiempo del método está en O (N2): el costo de procesamiento esperado debe calcularse en cada ronda. Su complejidad espacial está en o (n), para mantener las variables n booleanas. Como observación secundaria, tenga en cuenta que para κ = 1.0 el método SB no necesariamente produce la solución que se obtiene de SOPT, pero puede producir una solución que requiere la misma cantidad de espacio al tiempo que alcanza un mejor rendimiento esperado.7. Evaluación experimental realizamos una serie completa de experimentos en dos conjuntos de datos del mundo real para evaluar las técnicas propuestas en este documento.7.1 Configuración y conjuntos de datos Las técnicas descritas en este documento se implementaron en un sistema prototipo utilizando Java JDK 1.5. Todos los experimentos descritos a continuación se ejecutaron en una sola máquina SUN V40Z con cuatro CPU de Opteron AMD, 16 GB de RAM, una gran matriz de disco RAID-5 conectado a la red y ejecutando Microsoft Windows Server 2003. Todos los datos e índices se mantienen en una base de datos Oracle 10G que se ejecuta en la misma máquina. Para nuestros experimentos utilizamos dos conjuntos de datos diferentes. El historial de revisión de Wikipedia en inglés (denominado wiki en el resto) está disponible para descargar gratuita como un solo archivo XML. Este gran conjunto de datos, con un total de 0.7 Tbytes, contiene la historia de edición completa de la Wikipedia inglesa de enero de 2001 a diciembre de 2005 (la hora de nuestra descarga). Indexamos todos los artículos de Enciclopedia, excluyendo versiones que fueron marcadas como resultado de una edición menor (por ejemplo, la corrección de errores de ortografía, etc.). Esto produjo un total de 892,255 documentos con 13,976,915 versiones que tienen una media (µ) de 15.67 versiones por documento en desviación estándar (σ) de 59.18. Construimos una carga de trabajo de consulta de viaje en el tiempo utilizando el registro de consultas disponible temporalmente recientemente por AOL Research de la siguiente manera: primero extrajimos las 300 consultas de palabras clave más frecuentes que arrojaron un resultado, haga clic en un artículo de Wikipedia (por ejemplo, la revolución francesa, la temporada 2005 de huracanes, la temporada 2005, Código Da Vinci, etc.). Las consultas extraídas contenían un total de 422 términos distintos. Para cada consulta extraída, elegimos aleatoriamente un punto de tiempo para cada mes cubierto por el conjunto de datos. Esto dio como resultado un total de 18, 000 (= 300 × 60) consultas de viaje en el tiempo. El segundo conjunto de datos utilizado en nuestros experimentos se basó en un subconjunto del archivo europeo [13], que contiene rastreos semanales de 11 sitios web .gov.uk a lo largo de los años 2004 y 2005 que equivalen a 2 tbytes de datos sin procesar. Filtramos documentos que no pertenecen al texto de tipos mime/simple y texto/html, para obtener un conjunto de datos que totaliza 0.4 tbytes y que nos referimos como UKGOV en el resto del documento. Esto incluyó un total de 502,617 documentos con 8,687,108 versiones (µ = 17.28 y σ = 13.79). Construimos una carga de trabajo de consulta correspondiente como se mencionó anteriormente, esta vez eligiendo consultas de palabras clave que condujeron a un sitio en el dominio .gov.uk (por ejemplo, salario mínimo, impuesto a la herencia, fechas de la ceremonia de ciudadanía, etc.) y muestras aleatorios de un punto de tiempo paraCada mes dentro del período de dos años abarcado por el conjunto de datos. Por lo tanto, obtuvimos un total de 7,200 (= 300 × 24) consultas de viaje en el tiempo para el conjunto de datos UKGOV. En total, 522 términos aparecen en las consultas extraídas. Las estadísticas de recolección (es decir, N y AVDL) y las estadísticas de término (es decir, DF) se calcularon en granularidad mensual para ambos conjuntos de datos.7.2 Impacto de la fusión temporal Nuestro primer conjunto de experimentos tiene como objetivo evaluar la técnica de fusión temporal aproximada, descrita en la Sección 5, en términos de reducción del tamaño del índice y su efecto sobre la calidad de los resultados. Para los conjuntos de datos Wiki y Ukgov, comparamos los índices temporalmente fusionados para diferentes valores del umbral de error calculado usando el algoritmo 1 con el índice no coalconizado como línea de base. Wiki UKGov # Publicaciones Ratio # Publicaciones Ratio - 8,647,996,223 100.00% 7,888,560,482 100.00% 0.00 7,769,776,831 89.84% 2,926,731,708 37.10% 0.01 1,616,014,825 18.6.69.69,44,44,84199999999.69% 79. % 0.05 0.05 556,204,068 6.43% 259,947,199 3.30% 0.10 0.10 379,962,802 4,39% 187,387,342 2.38% 0.25 252,581,230 2.92% 158,107,198 2.00% 2.00% al% 2.00%% al% 2.00%%% al% 2.00% al% 2.00% al% 2.00% al% 2.00% al% 2.00%%% al% 2.00% al%.0.50 203,269,464 2.35% 155,434,617 1.97% Tabla 1: Tamaños de índice para índice no coalcado (-) e índices fusionados para diferentes valores de la Tabla 1 resume los tamaños de índice medidos como el número total de publicaciones. Como estos resultados demuestran, la coalescación temporal aproximada es altamente efectiva para reducir el tamaño del índice. Incluso un pequeño valor umbral, p.= 0.01, tiene un efecto considerable al reducir el tamaño del índice casi por orden de magnitud. Tenga en cuenta que en el conjunto de datos de UKGOV, incluso un coalcado preciso (= 0) logra reducir el tamaño del índice a menos del 38% del tamaño original. El tamaño del índice continúa reduciendo en ambos conjuntos de datos, a medida que aumentamos el valor de. ¿Cómo afecta la reducción en el tamaño del índice los resultados de la consulta? Para evaluar este aspecto, comparamos los resultados de Top-K calculados utilizando un índice fusionado contra el resultado de la verdad en tierra obtenida del índice original, para diferentes niveles de corte k.Deje que GK y CK sean los documentos de Top-K del resultado de la verdad en tierra y del índice fusionado respectivamente. Utilizamos las siguientes dos medidas para la comparación: (i) retiro relativo en el nivel de corte K (RR@K), que mide la superposición entre GK y CK, que varía en [0, 1] y se define como RR@K = |Gk ∩ ck |/k.(ii) Kendalls τ (ver [7, 14] para una definición detallada) en el nivel de corte K (KT@K), midiendo el acuerdo entre dos resultados en el orden relativo de los elementos en GK ∩ CK, con el valor 1 (o - o -1) Indicando un acuerdo total (o desacuerdo). Figura 3 Gráficos, para los niveles de corte 10 y 100, la media de RR@K y Kt@K junto con percentiles de 5% y 95%, para diferentes valores del umbral a partir de 0.01. Tenga en cuenta que para = 0, los resultados coinciden con los obtenidos por el índice original y, por lo tanto, se omiten del gráfico. Es tranquilizador ver a partir de estos resultados que la coalización temporal aproximada induce una interrupción mínima a los resultados de la consulta, ya que RR@K y Kt@K están dentro de los límites razonables. Para = 0.01, el valor más pequeño de en nuestros experimentos, RR @ 100 para wiki es 0.98 que indica que los resultados son -1 -0.5 0 0.5 1 ε 0.01 0.05 0.10 0.25 0.50 RECUERDO RELATIVO @ 10 (wiki) Kendalls τ @ 10 (wiki) RECUERDO RELATIVO @ 10 (UKGOV) KENDALLS τ @ 10 (UKGOV) (a) @ 10 -1 -0.5 0 0.5 1 ε 0.01 0.05 0.10 0.25 0.50 RECURSO RELATIVO @ 100 (Wiki) Kendalls τ @ 100 (Wiki) Relativo @100 (UKGOV) Kendalls τ @ 100 (Ukgov) (b) @ 100 Figura 3: RECREINO RELATIVO Y KENDALLS τ observados en índices fusionados para diferentes valores de casi indistinguibles de los obtenidos a través del índice original. Incluso el orden relativo de estos resultados comunes es bastante alto, ya que la media KT@100 está cerca de 0.95. Para el valor extremo de = 0.5, que da como resultado un tamaño de índice de solo el 2.35% del original, el RR@100 y KT@100 son aproximadamente 0.8 y 0.6 respectivamente. En el conjunto de datos UKGOV relativamente menos dinámico (como se puede ver en los valores σ anteriores), los resultados fueron aún mejores, con altos valores de RR y KT observados en todo el espectro de valores para ambos valores de corte.7.3 Materialización sublista Ahora dirigimos nuestra atención hacia la evaluación de las técnicas de materialización sublista introducidas en la Sección 6. Para ambos conjuntos de datos, comenzamos con el índice fusionado producido por una configuración de umbral moderado de = 0.10. Para reducir el esfuerzo computacional, los límites de los intervalos de tiempo elementales se redondearon a la granularidad del día antes de calcular las materializaciones sublistas. Sin embargo, tenga en cuenta que las publicaciones en los sublistas materializados aún conservan sus marcas de tiempo originales. Para una evaluación comparativa de los cuatro enfoques: POPT, SOPT, PG y SB, medimos el espacio y el rendimiento de la siguiente manera. El espacio requerido S (M), como se definió anteriormente, es igual al número total de publicaciones en los sublistas materializados. Para evaluar el rendimiento, calculamos el costo de procesamiento esperado (EPC) para todos los términos en la carga de trabajo de consulta respectiva, suponiendo una distribución de probabilidad uniforme entre los puntos de tiempo de consulta. Reportamos la EPC media, así como el 5%y 95%-porcentil. En otras palabras, la EPC media refleja la longitud esperada de la lista de índices (en términos de publicaciones de índice) que deben escanear para un punto de tiempo aleatorio y un término aleatorio de la carga de trabajo de consulta. Los enfoques SOPT y POPT son, por su definición, sin parámetros. Para el enfoque PG, variamos su parámetro γ, lo que limita la degradación máxima del rendimiento, entre 1.0 y 3.0. Análogamente, para el enfoque SB, el parámetro κ, como un límite superior en la explosión espacial permitida, varió entre 1.0 y 3.0. Se obtuvieron soluciones para el enfoque SB que ejecuta el recocido simulado para R = 50, 000 rondas. La Tabla 2 enumera las cifras de espacio y rendimiento obtenidas. Tenga en cuenta que los valores de EPC son más pequeños en Wiki que en Ukgov, ya que los términos en la carga de trabajo de consulta empleada para wiki son relativamente más raras en el corpus. Según los resultados representados, hacemos las siguientes observaciones clave.i) Como se esperaba, Popt logra un rendimiento óptimo a costa de un enorme consumo de espacio. Sopt, por el contrario, al consumir una cantidad óptima de espacio, proporciona solo un costo de procesamiento esperado deficiente. Los métodos PG y SB, para diferentes valores de su parámetro respectivo, producen soluciones cuyo espacio y rendimiento se encuentran entre los extremos que representan Popt y SOPT.ii) Para el método PG, vemos que para una degradación de rendimiento aceptable de solo 10% (es decir, γ = 1.10), el espacio requerido cae en más de un orden de magnitud en comparación con POPT en ambos conjuntos de datos.iii) el enfoque SB logra un rendimiento cercano a óptimo en ambos conjuntos de datos, si se permite consumir como máximo tres veces la cantidad óptima de espacio (es decir, κ = 3.0), que en nuestros conjuntos de datos aún corresponde a una reducción de espacio sobre POPT porMás de un orden de magnitud. También medimos los tiempos de reloj de pared en una muestra de las consultas con resultados que indican mejoras en el tiempo de ejecución hasta un factor de 12. 8. Conclusiones En este trabajo, hemos desarrollado una solución eficiente para la búsqueda de texto de viaje en tiempo a través de colecciones de documentos versionadas temporalmente. Los experimentos en dos conjuntos de datos del mundo real mostraron que una combinación de las técnicas propuestas puede reducir el tamaño del índice hasta un orden de magnitud al tiempo que logran un rendimiento casi óptimo y resultados altamente precisos. El presente trabajo abre muchas preguntas interesantes para futuras investigaciones, p.: ¿Cómo podemos mejorar aún más el rendimiento aplicando (y posiblemente extendiendo) la codificación, la compresión y las técnicas de omisión [35]? ¿Cómo podemos extender el enfoque de consultas Q [TB, TE] especificando un intervalo de tiempo en lugar de un punto de tiempo? ¿Cómo puede la funcionalidad de búsqueda de texto de viaje en el tiempo descrito habilitar o acelerar la minería de texto a lo largo del eje de tiempo (por ejemplo, rastrear los cambios de sentimiento en las opiniones de los clientes)?9. Agradecimientos Agradecemos a los revisores anónimos por sus valiosos comentarios, en particular al revisor que señaló la oportunidad de mejoras algorítmicas en la Sección 5 y la Sección 6.2.10. Referencias [1] V. N. Anh y A. Moffat. Evaluación de consultas podadas utilizando impactos precomputados. En Sigir, 2006. [2] V. N. Anh y A. Moffat. Estrategias de poda para consultas en modo mixto. En Cikm, 2006. Wiki Ukgov S (M) EPC S (M) EPC 5% Media 95% 5% Media 95% POPT 54,821,634,137 11.22 3,132.29 15,658.42 21,372,607,052 39.93 15,593.60 66,938.86 SOPT 379,962,8014.021. 9,820.1 187,387,342 63.15 22,852.67 102,923.85 pg γ = 1.10 3,814,444,654 11.30 3.306.71 16,512.88 1,155,833,516 40.6616,105.61 71,134.99 pg γ = 1.25 1,827,163,576 12.37 3,629.05 18,120.86 649,884,260 43.62 17,059.47 75,749.00 pg γ = 1.50 1,121,661,751 13.96 4,04. , 578,665 46.68 18,379.69 78,115.89 pg γ = 1.75 878,959,582 15.48 4,560.99 22,476.77 345,422,898 51.26 19,150.06 82,028.48 pg γ = 2.00 744,344,284,284,394 4. 53 24,637.62 306,944,062 51.48 19,499.78 87,136.31PG γ = 2.50 614,258,576 18.28 5,801.66 28,849.02 269,178,107 53.36 20,279.62 87,897.95 pg γ = 3.00 552,796,130 21.04 6,485.44 32,361.93 247,67,66,82. 9,591.94 SB κ = 1.10 412,383,387 38.97 12,723.68 60,350.60 194,287,671 63.09 22,574.54 102,208.58 SB κ = 1.25 467,537,173 26.87 9,011.81 45,11,11. 22,036.39 95,337.33 SB κ= 1.50 557,341,140 19.84 6,699.36 32,810.85 246,323,383 53.24 20,566.68 91,691.38 SB κ = 1.75 647,187,522 16.59 5,769.40 28,272.89 296,345,999999999999997. , 377.44 SB κ = 2.00 737,819,354 15.86 5,358.99 27,112.01 336,445,773 47.58 18,569.08 81,386.02 SB κ = 2.50 916,308,766 13.99 4,639.77 23,034 427,127,122,1222,122,422,422,122,422,422,422,422,222,222,222,222,222. 9 17,153.94 74,449.28 SB κ = 3.001,094,973,140 13.01 4,343.72 22,708.37 511,470,192 42.15 16,772.65 72,307.43 Tabla 2: Espacio requerido y costo de procesamiento esperado (en # Publicaciones) observados en índices coalecidos (= 0.10) [3] P. G. Anick y R. Flynn. Versión de un sistema de recuperación de información de texto completo. En Sigir, 1992. [4] R. A. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. Addison-Wesley, 1999. [5] K. Berberich, S. Bedathur, T. Neumann y G. Weikum. Una máquina del tiempo para la búsqueda de texto. Informe técnico MPI-I-2007-5-002, Instituto de Informática Max-Planck, 2007. [6] M. H. B¨ohlen, R. T. Snodgrass y M. D. Soo. Falta en bases de datos temporales. En VLDB, 1996. [7] P. Boldi, M. Santini y S. Vigna. Haga lo mejor para hacer lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. En Waw, 2004. [8] A. Z. Broder, N. Eiron, M. Fontoura, M. Herscovici, R. Lempel, J. McPherson, R. Qi y E. J. Shekita. Indexación de contenido compartido en sistemas de recuperación de información. En EDBT, 2006. [9] C. Buckley y A. F. Lewit. Optimización de búsquedas vectoriales invertidas. En Sigir, 1985. [10] M. Burrows y A. L. Hisgen. Método y aparato para generar y buscar el índice de ubicaciones de palabras basadas en el rango. Patente de EE. UU. 5.915,251, 1999. [11] S. B¨uttcher y C. L. A. Clarke. Un enfoque centrado en el documento para la poda de índice estático en los sistemas de recuperación de texto. En Cikm, 2006. [12] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. S. Maarek y A. Soffer. Poda de índice estático para sistemas de recuperación de información. En Sigir, 2001. [13] http://www.europarchive.org.[14] R. Fagin, R. Kumar y D. Sivakumar. Comparación de las listas K superiores. Siam J. Discrete Math., 17 (1): 134-160, 2003. [15] R. Fagin, A. Lotem y M. Naor. Algoritmos de agregación óptimos para el middleware. J. Comput. Syst. Sci., 66 (4): 614-656, 2003. [16] S. Guha, K. Shim y J. Cortejar. Rehist: algoritmos de construcción de histograma de error relativo. En VLDB, 2004. [17] M. Hallovici, R. Lempel y S. Yogev. Indexación eficiente de secuencias de documentos versionadas. En ECIR, 2007. [18] http://www.archive.org.[19] Y. E. Ioannidis y V. Poosala. Equilibrar la optimización del histograma y la practicidad para la estimación del tamaño del resultado de la consulta. En Sigmod, 1995. [20] H. V. Jagadish, N. Koudas, S. Muthukrishnan, V. Poosala, K. C. Sevcik y T. Suel. Histogramas óptimos con garantías de calidad. En VLDB, 1998. [21] E. J. Keogh, S. Chu, D. Hart y M. J. Pazzani. Un algoritmo en línea para segmentar series de tiempo. En ICDM, 2001. [22] S. Kirkpatrick, D. G. Jr. y M. P. Vecchi. Optimización por recocido simulado. Science, 220 (4598): 671-680, 1983. [23] J. Kleinberg y E. Tardos. Diseño de algoritmo. Addison-Wesley, 2005. [24] U. Manber. Introducción a los algoritmos: un enfoque creativo. Addison-Wesley, 1989. [25] K. Nørv˚ag y A. O. N. Nybø. DIST: indexación de texto temporal dinámico y escalable. En el tiempo, 2006. [26] J. M. Ponte y W. B. Croft. Un enfoque de modelado de idiomas para la recuperación de información. En Sigir, 1998. [27] S. E. Robertson y S. Walker. Okapi/Keenbow en TREC-8. En Trec, 1999. [28] B. Salzberg y V. J. Tsotras. Comparación de métodos de acceso para datos que evolucionan en el tiempo. ACM Comput. Surv., 31 (2): 158-221, 1999. [29] M. Stack. Búsqueda de texto completo de colecciones de archivos web. En IWAW, 2006. [30] E. Terzi y P. Tsaparas. Algoritmos eficientes para la segmentación de secuencia. En Siam-DM, 2006. [31] M. Theobald, G. Weikum y R. Schenkel. Evaluación de consultas de Top-K con garantías probabilísticas. En VLDB, 2004. [32] http://www.wikipedia.org.[33] I. H. Witten, A. Moffat y T. C. Bell. Gestión de gigabytes: compresión e indexación de documentos e imágenes. Morgan Kaufmann Publishers Inc., 1999. [34] J. Zhang y T. Suel. Búsqueda eficiente en grandes colecciones textuales con redundancia. En www, 2007. [35] J. Zobel y A. Moffat. Archivos invertidos para motores de búsqueda de texto. ACM Comput. Surv., 38 (2): 6, 2006.