Diseño óptimo de Laplacian para la recuperación de imágenes Xiaofei He Yahoo! Burbank, CA 91504 hex@yahoo-inc.com Wanli Min Ibm Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Departamento, UIUC Urbana, IL 61801 Dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com Resumen La retroalimentación de relevancia es una técnica poderosa para mejorar el rendimiento de recuperación de imágenes basada en el contenido (CBIR). Solicita a los usuarios juicios de relevancia sobre las imágenes recuperadas devueltas por los sistemas CBIR. El etiquetado de los usuarios se usa para aprender un clasificador para distinguir entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes devueltas superiores pueden no ser las más informativas. Por lo tanto, el desafío es determinar qué imágenes no etiquetadas serían la más informativa (es decir, mejorar el clasificador) si se etiquetaron y se usan como muestras de entrenamiento. En este documento, proponemos un nuevo algoritmo de aprendizaje activo, llamado Laplacian Optimal Design (LOD), para la recuperación de la imagen de retroalimentación relevante. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error de mínimo cuadrado en las imágenes medidas (o etiquetadas) y preserva simultáneamente la estructura geométrica local del espacio de la imagen. Específicamente, suponemos que si dos imágenes están suficientemente cercanas entre sí, entonces sus medidas (o etiquetas) también están cerca. Al construir un gráfico vecino más cercano, la estructura geométrica del espacio de la imagen puede describirse con el gráfico Laplacian. Discutimos cómo se pueden utilizar los resultados del campo del diseño experimental óptimo para guiar nuestra selección de un subconjunto de imágenes, lo que nos brinda la mayor cantidad de información. Los resultados experimentales en la base de datos COREL sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de la imagen de retroalimentación relevante. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: Búsqueda de información y retroalimentación de recuperación de recuperación;G.3 [Matemáticas de la informática]: probabilidad y estadística-experiencia Experimental Algoritmos de términos generales, rendimiento, teoría 1. Introducción En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados, pero las etiquetas son caras. Por lo tanto, el desafío es determinar qué muestras no etiquetadas serían las más informativas (es decir, mejorar el clasificador más) si se etiquetaron y se usan como muestras de entrenamiento. Este problema generalmente se llama aprendizaje activo [4]. Aquí la tarea es minimizar un costo total, que depende tanto de la precisión del clasificador como del costo de la recopilación de datos. Muchas aplicaciones del mundo real se pueden iniciar en el marco de aprendizaje activo. Particularmente, consideramos el problema de relevancia de la recuperación de imágenes basada en contenido basada en retroalimentación (CBIR) [13]. La recuperación de imágenes basada en el contenido ha atraído intereses sustanciales en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, la retroalimentación de relevancia se introduce en CBIR [12]. En muchos de los sistemas CBIR impulsados por la retroalimentación de relevancia actual, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes superiores devueltas por el sistema. Las imágenes etiquetadas se usan para entrenar un clasificador para separar las imágenes que coinciden con el concepto de consulta de las que no lo hacen. Sin embargo, en general, las imágenes devueltas superiores pueden no ser las más informativas. En el peor de los casos, todas las imágenes superiores etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas de clasificación estándar no se pueden aplicar debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están previas, en la recuperación de la imagen de retroalimentación relevante, el sistema puede seleccionar activamente las imágenes para etiquetar. Por lo tanto, el aprendizaje activo puede introducirse naturalmente en la recuperación de imágenes. A pesar de muchas técnicas de aprendizaje activo existentes, el aprendizaje activo de la máquina de vectores de soporte (SVM) y el aprendizaje activo basado en la regresión [1] han recibido la mayoría de los intereses. Según la observación de que cuanto más cerca del límite SVM es una imagen, cuanto menos confiable es su clasificación, SVM Active Learning selecciona aquellas imágenes sin etiqueta más cercanas al límite para solicitar la retroalimentación de los usuarios para lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo SVM es que el límite estimado puede no ser lo suficientemente preciso. Además, puede no aplicarse al comienzo de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadísticas, el problema de seleccionar muestras a etiqueta generalmente se conoce como diseño experimental. La muestra X se conoce como experimento, y su etiqueta Y se conoce como medición. El estudio del diseño experimental óptimo (OED) [1] se refiere al diseño de experimentos que se espera que minimicen las variaciones de un modelo parametrizado. La intención de un diseño experimental óptimo generalmente es maximizar la confianza en un modelo dado, minimizar las variaciones de parámetros para la identificación del sistema o minimizar la varianza de salida de los modelos. Los enfoques clásicos de diseño experimental incluyen diseño óptimo A, diseño óptimo D y diseño óptimo E-óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en el cálculo. Sin embargo, este tipo de enfoques solo tiene en cuenta los datos medidos (o, etiquetados) en su función objetivo, mientras que los datos no medidos (o sin etiquetar) se ignoran. Beneficio de los progresos recientes en un diseño experimental óptimo y un aprendizaje semi-supervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para la recuperación de imágenes, llamado Laplacian Optimal Design (LOD). A diferencia de los métodos de diseño experimentales tradicionales cuyas funciones de pérdida solo se definen en los puntos medidos, la función de pérdida de nuestro algoritmo LOD propuesto se define en los puntos medidos y no medidos. Específicamente, presentamos un regularizador de preservación de la localidad en la función de pérdida basada en el error de mínimo cuadrado estándar. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, entonces se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para el etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las imágenes devueltas. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo de diseño óptimo de Laplacian propuesto se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos estatales o del arte y presentamos los resultados experimentales en la recuperación de imágenes. Finalmente, proporcionamos algunos comentarios y sugerencias finales para el trabajo futuro en la Sección 5. 2. Trabajo relacionado ya que nuestro algoritmo propuesto se basa en el marco de regresión. El trabajo más relacionado es el diseño experimental óptimo [1], incluido el diseño óptimo A, el diseño óptimo D y el diseño óptimo. En esta sección, damos una breve descripción de estos enfoques.2.1 El problema de aprendizaje activo El problema genérico del aprendizaje activo es el siguiente. Dado un conjunto de puntos a = {x1, x2, · · ·, xm} en rd, encuentre un subconjunto b = {z1, z2, · · ·, zk} ⊂ A que contiene los puntos más informativos. En otras palabras, los puntos Zi (i = 1, · · ·, k) pueden mejorar el clasificador más si están etiquetados y utilizados como puntos de entrenamiento.2.2 Diseño experimental óptimo Consideramos un modelo de regresión lineal Y = WT x + (1) donde y es la observación, x es la variable independiente, W es el vector de peso y es un error desconocido con media cero. Diferentes observaciones tienen errores que son independientes, pero con variaciones ácidas σ2. Definimos f (x) = wt x como la salida de los alumnos dada la entrada x y el vector de peso w.Supongamos que tenemos un conjunto de puntos de muestra etiquetados (Z1, Y1), · · ·, (Zk, YK), donde Yi es la etiqueta de Zi. Por lo tanto, la estimación de máxima probabilidad para el vector de peso, ˆW, es lo que minimiza el error cuadrado de suma JSSE (W) = K I = 1 WT Zi - Yi 2 (2) La estimación ˆW nos da una estimación de la salida en una novelaEntrada: ˆy = ˆwt x. Por el teorema de Gauss-Markov, sabemos que ˆW-W tiene una media cero y una matriz de covarianza dada por σ2 H-1 SSE, donde HSSE es el Hessian de JSSE (W) HSSE = ∂2 JSSE ∂W2 = K I = 1 Zizti = zzt donde z = (z1, z2, · · ·, zk). Las tres medidas escalar más comunes del tamaño de la matriz de covarianza de parámetros en un diseño experimental óptimo son: • Diseño óptimo D: determinante de HSSE.• Diseño óptimo A: traza de HSSE.• Diseño óptimo e óptimo: valor propio máximo de HSSE. Dado que el cálculo de los valores propios y propios de una matriz es mucho más costoso que el cálculo de la traza de matriz, el diseño óptimo A es más eficiente que los otros dos. Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16].3. El diseño óptimo de Laplacian Dado que la matriz de covarianza HSSE utilizada en los enfoques tradicionales solo depende de las muestras medidas, es decir, ZIS, estos enfoques no pueden evaluar los errores esperados en las muestras no medidas. En esta sección, presentamos un nuevo algoritmo de aprendizaje activo llamado Laplacian Optimal Design (LOD) que hace un uso eficiente de muestras medidas (etiquetadas) y no medidas (sin etiquetar).3.1 La función objetivo En muchos problemas de aprendizaje automático, es natural suponer que si dos puntos Xi, XJ están suficientemente cerca el uno del otro, entonces sus mediciones (F (XI), F (XJ)) también están cerca. Sea s una matriz de similitud. Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: j0 (w) = k i = 1 f (zi) −yi 2 + λ 2 m i, j = 1 f (xi) −f(xj) 2 Sij (3) donde yi es la medición (o, etiqueta) de Zi. Tenga en cuenta que la función de pérdida (3) es esencialmente la misma que la que se usa en la regresión regularizada de Laplacian (LRR, [2]). Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se dan los datos de capacitación. En este artículo, estamos enfocados en cómo seleccionar los datos más informativos para la capacitación. La función de pérdida con nuestra elección de pesos simétricos SiJ (Sij = SJI) incurre en una gran penalización si los puntos vecinos XI y XJ están muy separados. Por lo tanto, minimizar J0 (W) es un intento de garantizar que si Xi y XJ estén cerca, F (Xi) y F (XJ) también estén cerca. Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si Xi se encuentra entre los vecinos P más cercanos de XJ, o XJ se encuentra entre los vecinos P más cercanos de Xi;0, de lo contrario.(4) Sea D una matriz diagonal, DII = J Sij y L = D - S. La matriz L se llama gráfica laplacian en la teoría del gráfico espectral [3]. Sea y = (y1, · · ·, yk) t y x = (x1, · · ·, xm). Siguiendo algunos pasos algebraicos simples, vemos que: j0 (w) = k i = 1 wt zi - yi 2 + λ 2 m i, j = 1 wt xi - wt xj 2 sij = y - zt w t y - zt w + λwtm i = 1 Diixixting i - m i, j = 1 sijxixt J w = yt y - 2wt zy + wt zzt w + λwt xdxt - xsxt w = yt y - 2wt zy + wt zzt + λxlxt w la hessia de j0 (w) puede ser puede serCalculado de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λxlxt En algunos casos, la matriz ZZT + λxlxt es singular (por ejemplo, si m <d). Por lo tanto, no existe una solución estable para el problema de optimización Eq.(3). Una forma común de lidiar con este problema mal plenado es introducir un regularizador de tikhonov en nuestra función de pérdida: j (w) = k i = 1 wt zi-yi 2 + λ1 2 m i, j = 1 wt xi-wt xj 2 Sij+ λ2 W 2 (5) La Hessia de la nueva función de pérdida viene dada por: H = ∂2 J ∂w2 = ZZT + λ1xlxt + λ2i: = Zzt + λ donde i es una matriz de identidad y λ = λ1xlxt + λ2i. Claramente, H es de rango completo. Requerir que el gradiente de J (W) con respecto a W desaparezca, proporciona la estimación óptima ˆW: ˆW = H - 1 ZY La siguiente proposición establece el sesgo y las propiedades de varianza del estimador para el vector coeficiente w.Proposición 3.1. E (ˆW - W) = −H - 1 λW, CoV (ˆW) = σ2 (H - 1 - H - 1 λH - 1). Dado que y = zt w + y e () = 0, se deduce que e (ˆw - w) (6) = h - 1 zzt w - w = h - 1 (zzt + λ - λ) w - w = (i- h - 1 λ) w - w = −h - 1 λw (7) aviso cov (y) = σ2 i, la matriz de covarianza de ˆw tiene la expresión: cov (ˆw) = h - 1 zCov (y) zt h h−1 = σ2 H - 1 ZZT H - 1 = σ2 H - 1 (H - λ) H - 1 = σ2 (H - 1 - H - 1 λH - 1) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes Wes e (w - ˆw) (w - ˆw) t (9) = h - 1 λwwt λh - 1 + σ2 (h - 1 - h - 1 λh - 1) (10) para cualquier x, let ˆy = ˆwt xser su observación predicha. El error de predicción al cuadrado esperado es E (y - ˆy) 2 = E ( + wt x - ˆwt x) 2 = σ2 + xt [e (w - ˆw) (w - ˆw) t] x = σ2 + xt [h−1 λwwt λh - 1 + σ2 h - 1 - σ2 h - 1 λh - 1] claramente el error de predicción cuadrada esperada depende de la variable explicativa x, por lo tanto, el error predictivo cuadrado promedio esperado sobre el conjunto de datos completo A es 1 m m i = 1E (yi - ˆwt xi) 2 = 1 m m i = 1 xt i [h - 1 λwwt λH - 1 + σ2 h - 1 - σ2 h - 1 λH - 1] xi + σ2 = 1 M TR (xt [σ2 h−1 + h - 1 λwwt λH -1 - 1 σ2 h -1 λH - 1] x) + σ2 ya desde TR (TR (XT [H - 1 λWWT λHT λH -1 - 1 - 1 σ2 h - 1 λH - 1] x) TR (σ2 tern HOWS HEDS HEDS HEDS HEDS HEDO ALDO ALLO ALLO ALDO ALLO ALLOododos−1 x), nuestro criterio de optimización laplaciana se formula así minimizando el rastro de XT H - 1 X. Definición 1. Diseño óptimo de Laplacian Min Z = (Z1, ···, Zk) TR XT ZZT + λ1XLXT + λ2I −1 x (11) donde Z1, · · ·, Zk se seleccionan de {x1, · · ·, xm}.4. Enfoques de diseño experimental canónico de diseño luplacio del núcleo (p. Ej. Diseño óptimo A, diseño D-óptimo y E-óptimo) solo consideran funciones lineales. No pueden descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal. En esta sección, describimos cómo realizar el diseño experimental de la laplacia en la reproducción del espacio de núcleo de núcleo Hilbert (RKHS) que da lugar al diseño experimental de el núcleo laplaciano (KLOD). Para los puntos de datos dados x1, · · ·, xm ∈ X con un núcleo Mercer definido positivo K: x × x → R, existe un RKHS HK único de funciones valoradas reales en X. Deje que KT (s) sea la función de S obtenida fijando T y permitiendo KT (s).= K (s, t). HK consiste en todas las combinaciones lineales finitas de la forma l i = 1 αikti con ti ∈ X y límites de funciones tales a medida que el Ti se vuelve denso en X. Tenemos ks, kt hk = k (s, t).4.1 Derivación de LOD en la reproducción del espacio del núcleo Hilbert Considere el problema de optimización (5) en RKHS. Por lo tanto, buscamos una función f ∈ Hk de tal manera que la siguiente función objetivo se minimice: min f∈Hk k i = 1 f (zi) −yi 2 + λ1 2 m i, j = 1 f (xi) −f (xj) 2SiJ+λ2 F 2 HK (12) Tenemos la siguiente proposición. Proposición 4.1. Sea h = {m i = 1 αik (·, xi) | αi ∈ R} Sea un subespacio de HK, la solución al problema (12) está en H. prueba. Sea H⊥ el complemento ortogonal de H, es decir, HK = H ⊕ H⊥. Por lo tanto, para cualquier función f ∈ Hk, tiene descomposición ortogonal de la siguiente manera: f = fh + fh⊥ ahora, evaluemos f en xi: f (xi) = f, kxi hk = fh + fh⊥, kxi hk = fh,Kxi hk + fh⊥, kxi hk observa que kxi ∈ H mientras fh⊥ ∈ H⊥. Esto implica que FH⊥, KXI HK = 0. Por lo tanto, f (xi) = fh, kxi hk = fh (xi) Esto completa la prueba. La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación F ∗ = M I = 1 αik (·, xi). Consulte [2] para ver los detalles. Sea φ: rd → h un mapa de características del espacio de entrada rd a h, y k (xi, xj) = <φ (xi), φ (xj)>. Deje que X denote la matriz de datos en RKHS, x = (φ (x1), φ (x2), · · ·, φ (xm)). Del mismo modo, definimos z = (φ (z1), φ (z2), · · ·, φ (zk)). Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: Min Z TR XT ZZT + λ1XLXT + λ2I −1 x (13) Dado que la función de mapeo φ es generalmente desconocida, no hay una forma directa de resolver el problema (13). A continuación, aplicamos trucos de kernel para resolver este problema de optimización. Sea X-1 el inverso Moore-Penrose (también conocido como pseudo inverso) de X. Por lo tanto, tenemos: xt zzt + λ1xlxt + λ2i −1 x = xt xx - 1 zzt + λ1xlxt + λ2i −1 (xt) −1 xt x = xt x zzt x + λ1xlxt x + λ2x −1 (xt) −1Xt x = xt x xt zzt x + λ1xt xlxt x + λ2xt x −1 xt x = kxx kxzkzxx + λ1kxxxlkxx + λ2kxx −1 kxx donde kxx es una matriz m × m (kxx, ij = k (xi, xj)), kxzes una matriz m × k (kxz, ij = k (xi, zj)), y kzx es una matriz K × m (kzx, ij = k (zi, xj)). Por lo tanto, el diseño óptimo de Kernel Laplacian se puede definir de la siguiente manera: Definición 2. Diseño óptimo de Kernel Laplacian Minz = (Z1, ···, Zk) TR KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Esquema de optimización En esta subsección, discutimos cómo resolver los problemas de optimización (11) y (14). Particularmente, si seleccionamos un núcleo lineal para Klod, entonces se reduce a LOD. Por lo tanto, nos centraremos en el problema (14) en el siguiente. Se puede demostrar que el problema de optimización (14) es NP-HARD. En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14). Supongamos que se han seleccionado N puntos, denotados por una matriz Zn = (Z1, · · ·, Zn). El (n+1) -th Point Zn+1 se puede seleccionar resolviendo el siguiente problema de optimización: Max Zn+1 = (Zn, Zn+1) TR KXX KXZN+1 KZN+1X+λ1KXXLKXX+λ2KXX −1 KXX (15) Las matrices de núcleo KXZN+1 y KZN+1X se pueden reescribir de la siguiente manera: KXZN+1 = KXZN, KXZN+1, KZN+1X = KZNX KZN+1X Por lo tanto, tenemos: KXZN+1 KZN+1X = KXZN KZNX+ Kxzn + 1 kzn + 1x Definimos: a = kxzn kznx + λ1kxxlkxx + λ2kxx A solo depende de x y zn. Por lo tanto, el (n+1) -th Point Zn+1 viene dado por: Zn+1 = arg min zn+1 tr kxx a+kxzn+1 kzn+1x −1 kxx (16) Cada vez que seleccionamos un nuevo puntoZn+1, la matriz A se actualiza por: A ← A+KXZN+1 KZN+1X Si la función del núcleo se elige como producto interno k (x, y) = x, y, entonces HK es un espacio funcional lineal y elEl algoritmo se reduce a LOD.5. Recuperación de imágenes basada en el contenido utilizando el diseño óptimo de Laplacian En esta sección, describimos cómo aplicar el diseño óptimo de Laplacian a CBIR. Comenzamos con una breve descripción de la representación de imágenes utilizando características visuales de bajo nivel.5.1 Representación de imágenes de bajo nivel La representación de imágenes de bajo nivel es un problema crucial en CBIR. Las características visuales generales incluyen color, textura, forma, etc. Las características de color y textura son las características visuales más utilizadas en CBIR. En comparación con las características de color y textura, las características de forma generalmente se describen después de que las imágenes se han segmentado en regiones u objetos. Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles. En este trabajo, combinamos un histograma de color 64 dimensional y un momento de textura de color de 64 dimensiones (CTM, [15]) para representar las imágenes. El histograma de color se calcula usando contenedores 4 × 4 × 4 en el espacio HSV. El momento de la textura del color es propuesto por Yu et al.[15], que integra las características de color y textura de la imagen en forma compacta. CTM adopta la transformación local de Fourier como un esquema de representación de textura y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de concurrencia de píxeles de imagen en cada canal del espacio de color (SVCOSH, SVSINH, V). Luego, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de imagen de color natural. Consulte [15] para más detalles.5.2 Relevancia Comentarios REPARACIÓN DE REPARACIÓN DE RELAVANCIÓN RELAVANCIA es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12]. Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar la ponderación de diferentes dimensiones. Este proceso puede verse como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como alumno y el usuario actúa como maestro. El proceso de recuperación típico se describe de la siguiente manera: 1. El usuario envía un ejemplo de imagen de consulta al sistema. El sistema clasifica las imágenes en la base de datos de acuerdo con algunas métricas de distancia predefinidas y presenta al usuario las imágenes clasificadas.2. El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiqueta como relevantes o irrelevantes.3. El sistema utiliza la información de los usuarios proporcionados para volver a relajar las imágenes en la base de datos y devuelve al usuario las imágenes principales. Vaya al paso 2 hasta que el usuario esté satisfecho. Nuestro algoritmo de diseño óptimo de Laplacian se aplica en el segundo paso para seleccionar las imágenes más informativas. Una vez que obtenemos las etiquetas de las imágenes seleccionadas por LOD, aplicamos la regresión regularizada de Laplacian (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador. El clasificador se usa para volver a clasificar las imágenes en la base de datos. Tenga en cuenta que, para reducir la complejidad computacional, no usamos todas las imágenes no etiquetadas en la base de datos, sino solo aquellas dentro de los 500 mejores devoluciones de iteración anterior.6. Resultados experimentales En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una base de datos de imágenes grandes. Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la regresión regularizada laplaciana (LRR, [2]), la máquina de vectores de soporte (SVM), el aprendizaje activo de la máquina de vectores de soporte (SVMactive) [14] y el diseño óptimo A (A-Optimal (Aod). Tanto SVMactive, AOD como LOD son algoritmos de aprendizaje activos, mientras que LRR y SVM son algoritmos de clasificación estándar. SVM solo utiliza las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que utiliza imágenes etiquetadas y sin etiqueta. Para Svmactive, AOD y LOD, se seleccionan 10 imágenes de capacitación por los algoritmos en cada iteración. Mientras que para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento. Sería importante tener en cuenta que SVMactive se basa en la SVM ordinaria, LOD se basa en LRR y AOD se basa en la regresión ordinaria. Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente para ser 0.001 y 0.00001. Para los algoritmos LRR y LOD, utilizamos la misma estructura gráfica (ver Ec. 4) y establecemos que el valor de P (número de vecinos más cercanos) sea 5. Comenzamos con un simple ejemplo sintético para dar alguna intuición sobre cómo funciona LOD.6.1 Ejemplo sintético simple Se da un ejemplo sintético simple en la Figura 1. El conjunto de datos contiene dos círculos. AOD y LOD seleccionan ocho puntos. Como se puede ver, todos los puntos seleccionados por AOD son del Big Circle, mientras que LOD selecciona cuatro puntos del Big Circle y cuatro del pequeño círculo. Los números junto a los puntos seleccionados denotan sus órdenes que se seleccionarán. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados.6.2 Diseño experimental de recuperación de imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos de Corel. Es un conjunto de imágenes grande y heterogéneo. Cada imagen se representa como un vector de 128 dimensiones como se describe en la Sección 5.1. La Figura 2 muestra algunas imágenes de muestra. Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de la recuperación y las comparaciones con otros algoritmos. Enumeramos diferentes aspectos del diseño experimental a continuación.6.2.1 Métricas de evaluación Utilizamos la curva de precisión de alcance y la tasa de precisión [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes. El alcance se especifica mediante el número (n) de las imágenes de alto rango presentadas al usuario. La precisión es la relación del número de imágenes relevantes presentadas al usuario al (a) conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: DatosSelección por algoritmos de aprendizaje activo. Los números junto a los puntos seleccionados denotan sus órdenes que se seleccionarán. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. Tenga en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados.(a) (b) (c) Figura 2: Imágenes de muestra de Bead de categoría, elefante y barco.Alcance N. La curva de precisión de alcance describe la precisión con varios ámbitos y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos. Por otro lado, la tasa de precisión enfatiza la precisión en un valor particular del alcance. En general, es apropiado presentar 20 imágenes en una pantalla. Poner más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas. Por lo tanto, la precisión en el top 20 (n = 20) es especialmente importante. En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no está en la base de datos de imágenes. Para simular dicho entorno, utilizamos una validación cruzada de cinco veces para evaluar los algoritmos. Más precisamente, dividimos toda la base de datos de la imagen en cinco subconjuntos con igual tamaño. Por lo tanto, hay 20 imágenes por categoría en cada subconjunto. En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consultas, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación. La curva de precisión de Precisions y la tasa de precisión se calculan promediando los resultados de la validación cruzada de cinco veces.6.2.2 Esquema de retroalimentación de relevancia automática Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación. Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos.Se seleccionaron 10 imágenes de la base de datos para el etiquetado de los usuarios y el sistema utiliza la información de la etiqueta para volver a clasificar. Tenga en cuenta que las imágenes que se han seleccionado en iteraciones anteriores se excluyen de las selecciones posteriores. Para cada consulta, el mecanismo de retroalimentación de relevancia automática se realiza para cuatro iteraciones. Es importante tener en cuenta que el esquema de retroalimentación de relevancia automática utilizado aquí es diferente de los descritos en [8], [11]. En [8], [11], las cuatro principales imágenes relevantes e irrelevantes se seleccionaron como imágenes de retroalimentación. Sin embargo, esto puede no ser práctico. En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes). Por lo tanto, es difícil para el usuario encontrar cuatro imágenes relevantes e irrelevantes. Es más razonable que los usuarios proporcionen información de retroalimentación solo en las 10 imágenes seleccionadas por el sistema.6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico exigir al usuario que proporcione muchas rondas de comentarios. El rendimiento de recuperación después de las dos primeras rondas de comentarios (especialmente la primera ronda) es más importante. La Figura 3 muestra las curvas de alcance de precisión promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación. Al comienzo de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos. Después de que el usuario proporciona retroalimentación de relevancia, los algoritmos LRR, SVM, SVMactive, AOD y LOD se aplican para volver a clasificar las imágenes. Para reducir la complejidad del tiempo de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos sino de las 500 imágenes principales. Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales. Para SVMactive, AOD y LOD, el usuario debe etiquetar 10 imágenes más informativas seleccionadas por estos algoritmos. Tenga en cuenta que Svmactive solo puede ser AP (a) iteración de retroalimentación 1 (b) iteración de retroalimentación 2 Figura 3: Las curvas promedio de alcance de precisión de diferentes algoritmos para las dos primeras iteraciones de retroalimentación. El algoritmo LOD realiza lo mejor en todo el alcance. Tenga en cuenta que, en la primera ronda de retroalimentación, no se puede aplicar el algoritmo SVMactive. Aplica el SVM ordinario para construir el clasificador inicial.(a) Precisión en el top 10 (b) Precisión en el top 20 (c) Precisión en el top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de la imagen de retroalimentación de relevancia.(a) Precisión en la top 10, (b) Precisión en el top 20 y (c) precisión en el top 30. Como se puede ver, nuestro algoritmo LOD supera constantemente a los otros cuatro algoritmos.Capazado cuando el clasificador ya está construido. Por lo tanto, no se puede aplicar en la primera ronda y usamos el SVM estándar para construir el clasificador inicial. Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el alcance. Además, el algoritmo LRR funciona mejor que SVM. Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria. El algoritmo AOD realiza lo peor. A medida que el alcance se hace más grande, la diferencia de rendimiento entre estos algoritmos se vuelve más pequeña. Al agregar iterativamente los comentarios de los usuarios, los resultados de precisión correspondientes (en el top 10, top 20 y top 30) de los cinco algoritmos se muestran respectivamente en la Figura 4. Como se puede ver, nuestro algoritmo LOD realiza lo mejor en todos los casos y el algoritmo LRR realiza el segundo mejor. Ambos dos algoritmos utilizan las imágenes sin etiquetar. Esto muestra que las imágenes no etiquetadas son útiles para descubrir la estructura geométrica intrínseca del espacio de la imagen y, por lo tanto, mejorar el rendimiento de la recuperación. En el mundo real, el usuario puede no estar dispuesto a proporcionar demasiadas comentarios de relevancia. Por lo tanto, el rendimiento de recuperación en las dos primeras rondas es especialmente importante. Como se puede ver, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, 5.2% para los 20 resultados principales y 4.1% para los 30 mejores resultados, en comparación con el segundo algoritmo mejor (LRR) después de las dos primeras rondas de comentarios de relevancia..6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos COREL. Nos gustaría resaltar varios puntos interesantes: 1. Está claro que el uso del aprendizaje activo es beneficioso en el dominio de recuperación de imágenes. Hay un aumento significativo en el rendimiento del uso de los métodos de aprendizaje activo. Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo LOD propuesto funciona mejor.2. En muchas aplicaciones del mundo real, como la recuperación de la imagen de retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea de etiquetado manual intensivo en mano de obra. Uno es un aprendizaje activo que selecciona las muestras más informativas para etiquetar, y la otra es el aprendizaje semi-supervisado que hace uso de las muestras no etiquetadas para mejorar el rendimiento del aprendizaje. Ambas estrategias se han estudiado ampliamente en el pasado [14], [7], [5], [8]. El trabajo presentado en este documento se centra en el aprendizaje activo, pero también aprovecha los progresos recientes en el aprendizaje semi-supervisado [2]. Específicamente, incorporamos un regularidad de preservación de la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo. De esta manera, el aprendizaje activo y las técnicas de aprendizaje semi-supervisado se unifican sin problemas para aprender un clasificador óptimo.3. La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes. Para los cinco algoritmos, el rendimiento de la recuperación mejora con más comentarios proporcionados por el usuario.7. Conclusiones y trabajos futuros Este documento describe un nuevo algoritmo de aprendizaje activo, llamado diseño óptimo de Laplacian, para permitir una recuperación de imagen de retroalimentación de relevancia más efectiva. Nuestro algoritmo se basa en una función objetivo que simultáneamente minimiza el error empírico y preserva la estructura geométrica local del espacio de datos. Utilizando técnicas del diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar. Estas imágenes etiquetadas y las imágenes no etiquetadas en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos COREL muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de la recuperación. En este artículo, consideramos el problema de recuperación de la imagen en los datos de imagen pequeños, estáticos y de dominio cerrado. Un dominio mucho más desafiante es la World Wide Web (www). Para la búsqueda de imágenes web, es posible recopilar una gran cantidad de información de clics del usuario. Esta información se puede utilizar naturalmente para construir el gráfico de afinidad en nuestro algoritmo. Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial. Además, aunque nuestro interés principal en este documento se centra en la recuperación de la imagen de retroalimentación de relevancia, nuestros resultados también pueden ser de interés para los investigadores en el reconocimiento de Patten y el aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles, pero solo se pueden etiquetar muestras limitadas..8. Referencias [1] A. C. Atkinson y A. N. Donv. Diseños experimentales óptimos. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi y V. Sindhwani. Manifold regularización: un marco geométrico para aprender de ejemplos. Journal of Machine Learning Research, 7: 2399-2434, 2006. [3] F. R. K. Chung. Teoría del gráfico espectral, Volumen 92 de la serie de conferencias regionales en matemáticas. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Journal of Artificial Intelligence Research, 4: 129-145, 1996. [5] A. Dong y B. Bhanu. Un nuevo algoritmo EM semi-supervisado para la recuperación de imágenes. En IEEE conf.Sobre la visión por computadora y el reconocimiento de patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin. Diseño robusto de experimentos biológicos. En Avances en Sistemas de Procesamiento de Información Neural 18, Vancouver, Canadá, 2005. [7] K.-S.Goh, E. Y. Chang y W.-C.Lai. Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X. Él. Aprendizaje de subespacio semi-supervisado incremental para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu. Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes. En la Conferencia Internacional IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe. Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en el contenido: agregue la generalidad y normalice el alcance. Transacciones IEEE en análisis de patrones e inteligencia de máquinas, 27 (2): 245-251, 2005. [11] Y.-Y. Lin, T.-L.Liu y H.-T.Chen. Aprendizaje múltiple semántico para la recuperación de imágenes. En Actas de la Conferencia de ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra. Comentarios de relevancia: una herramienta eléctrica para la recuperación de imágenes basada en contenido interativo. Transacciones IEEE en circuitos y sistemas para tecnología de video, 8 (5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain. Recuperación de imágenes basada en el contenido al final de los primeros años. Transacciones IEEE en análisis de patrones e inteligencia de máquinas, 22 (12): 1349-1380, 2000. [14] S. Tong y E. Chang. Apoyo a la máquina vectorial Aprendizaje activo para la recuperación de imágenes. En Actas de la Novena Conferencia Internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang y J. Feng. Momentos de textura de color para la recuperación de imágenes basada en el contenido. En la Conferencia Internacional sobre Procesamiento de Imagen, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp. Aprendizaje activo a través del diseño experimental transductivo. En Actas de la 23a Conferencia Internacional sobre Aprendizaje Autor, Pittsburgh, PA, 2006.