Expansión del concepto latente utilizando los campos aleatorios de Markov Donald Metzler metzler@cs.umass.edu W. Bruce croft croft@cs.umass.edu Centro para la información inteligente Departamento de Recuperación de la Información Universidad de Massachusetts Amherst, MA 01003 Expansión de consultas abstractas, en forma de formaciónDe la retroalimentación de pseudo-relevancia o la retroalimentación de relevancia, es una técnica común utilizada para mejorar la efectividad de la recuperación. La mayoría de los enfoques anteriores han ignorado temas importantes, como el papel de las características y la importancia de modelar dependencias de términos. En este documento, proponemos una técnica de expansión de consulta robusta basada en el modelo de campo aleatorio de Markov para la recuperación de información. La técnica, llamada expansión del concepto latente, proporciona un mecanismo para modelar dependencias de términos durante la expansión. Además, el uso de características arbitrarias dentro del modelo proporciona un marco poderoso para ir más allá de las características de ocurrencia de términos simples que son implícitamente utilizadas por la mayoría de las otras técnicas de expansión. Evaluamos nuestra técnica contra los modelos de relevancia, una técnica de expansión de consulta de modelado de idiomas de última generación. Nuestro modelo demuestra mejoras consistentes y significativas en la efectividad de la recuperación en varios conjuntos de datos TREC. También describimos cómo nuestra técnica se puede utilizar para generar conceptos significativos de múltiples medios para tareas como la sugerencia de consulta/reformulación. Categorías y descriptores de sujetos H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información Términos generales Algoritmos, Experimentación, Teoría 1. Introducción Los usuarios de los sistemas de recuperación de información son necesarios para expresar necesidades complejas de información en términos de expresiones booleanas, una breve lista de palabras clave, una oración, una pregunta o posiblemente una narración más larga. Se pierde una gran cantidad de información durante el proceso de traducción de la necesidad de información a la consulta real. Por esta razón, ha habido un gran interés en las técnicas de expansión de consultas. Dichas técnicas se utilizan para aumentar la consulta original para producir una representación que refleje mejor la necesidad de información subyacente. Las técnicas de expansión de la consulta se han estudiado bien para varios modelos en el pasado y han demostrado mejorar significativamente la efectividad tanto en la retroalimentación de relevancia como en la configuración de retroalimentación de pseudo-relevancia [12, 21, 28, 29]. Recientemente, se propuso un modelo de campo aleatorio de Markov (MRF) para la recuperación de información que va más allá de la bolsa simplista de palabras que subyace en el enfoque de modelado de idiomas BM25 y (unigram) para la recuperación de información [20, 22]. El modelo MRF generaliza el Unigram, BigRam y otros modelos de dependencia diversos [14]. La mayoría de los modelos de dependencia del término pasado no han podido mostrar mejoras consistentes y significativas sobre las líneas de base unigram, con pocas excepciones [8]. Sin embargo, se ha demostrado que el modelo MRF es altamente efectivo en una serie de tareas, incluida la recuperación ad hoc [14, 16], la búsqueda de PAGE con nombre [16] y la búsqueda web de idioma japonés [6]. Hasta ahora, el modelo se ha utilizado únicamente para clasificar documentos en respuesta a una consulta dada. En este trabajo, mostramos cómo el modelo se puede extender y usar para la expansión de consultas utilizando una técnica que llamamos expansión de concepto latente (LCE). Hay tres contribuciones principales de nuestro trabajo. Primero, LCE proporciona un mecanismo para combinar la dependencia del término con la expansión de la consulta. Las técnicas de expansión de consultas anteriores se basan en la bolsa de modelos de palabras. Por lo tanto, al realizar la expansión de la consulta utilizando el modelo MRF, podemos estudiar la dinámica entre la dependencia del término y la expansión de la consulta. A continuación, como mostraremos, el modelo MRF permite utilizar características arbitrarias dentro del modelo. Las técnicas de expansión de consultas en el pasado solo han utilizado implícitamente las características de ocurrencia del término. Al usar conjuntos de características más sólidos, es posible producir mejores términos de expansión que discriminen mejor los documentos relevantes y no relevantes. Finalmente, nuestro enfoque propuesto proporciona a la perfección un mecanismo para generar conceptos individuales y múltiples. La mayoría de las técnicas anteriores, por defecto, generan términos de forma independiente. Ha habido varios enfoques que utilizan conceptos generalizados, sin embargo, tales enfoques fueron algo heurísticos y realizados fuera del modelo [19, 28]. Nuestro enfoque está formalmente motivado y una extensión natural del modelo subyacente. El resto de este documento se presenta de la siguiente manera. En la Sección 2 describimos enfoques de expansión de consultas relacionadas. La Sección 3 proporciona una visión general del modelo MRF y detalla nuestra técnica de expansión de concepto latente propuesta. En la Sección 4 evaluamos nuestro modelo propuesto y analizamos los resultados. Finalmente, la Sección 5 concluye el documento y resume los principales resultados.2. Trabajo relacionado Uno de los enfoques clásicos y más utilizados para la expansión de la consulta es el algoritmo Rocchio [21]. El enfoque de Rocchios, que se desarrolló dentro del modelo espacial vectorial, vuelve a sweswing el vector de consulta original al mover los pesos hacia el conjunto de documentos relevantes o pseudo relevantes y lejos de los documentos no relevantes. Desafortunadamente, no es posible aplicar formalmente el enfoque de Rocchios a un modelo de recuperación estadística, como el modelado de idiomas para la recuperación de información. Se han desarrollado una serie de técnicas de expansión de consultas formalizadas para el marco de modelado de idiomas, incluidos los modelos de relevancia de Lavrenko y Crofts de Zhai y Laffertys y los modelos de relevancia de Lavrenko y Crofts [12, 29]. Ambos enfoques intentan usar documentos pseudo-relevantes o relevantes para estimar un mejor modelo de consulta. La retroalimentación basada en modelos encuentra el modelo que mejor describe los documentos relevantes al tener en cuenta un modelo de antecedentes (ruido). Esto separa el modelo de contenido del modelo de fondo. El modelo de contenido se interpola con el modelo de consulta original para formar la consulta ampliada. La otra técnica, los modelos de relevancia, está más estrechamente relacionado con nuestro trabajo. Por lo tanto, entramos en los detalles del modelo. Al igual que la retroalimentación basada en el modelo, los modelos de relevancia estiman un modelo de consulta mejorado. La única diferencia entre los dos enfoques es que los modelos de relevancia no modelan explícitamente los documentos relevantes o pseudo-relevantes. En cambio, modelan una noción más generalizada de relevancia, como ahora mostramos. Dada una consulta Q, un modelo de relevancia es una distribución multinomial, p (· | q), que codifica la probabilidad de cada término dada la consulta como evidencia. Se calcula como: p (w | q) = d p (w | d) p (d | q) ≈ d∈Rq p (w | d) p (q | d) p (d) w d∈Rq p (w | d) p (q | d) p (d) (1) donde rq es el conjunto de documentos que son relevantes o pseudorelevantes para la consulta Q. En el caso pseudo-relevante, estos son los documentos mejor clasificados para la consulta Q. Además, se supone que P (d) es uniforme sobre este conjunto. Estos suaves supuestos hacen que la calculación del posterior bayesiano sea más práctico. Después de estimar el modelo, los documentos se clasifican recortando el modelo de relevancia eligiendo los términos K más probables de P (· | Q). Esta distribución recortada se interpola con el modelo original de consulta de máxima probabilidad [1]. Esto puede considerarse expandiendo la consulta original por K ponderados. A lo largo del resto de este trabajo, nos referimos a esta instanciación de modelos de relevancia como RM3. Se ha realizado relativamente poco trabajo en el área de expansión de la consulta en el contexto de los modelos de dependencia [9]. Sin embargo, ha habido varios intentos de expandirse utilizando conceptos de múltiples medios. El método de análisis de contexto local de Xu y Crofts (LCA) combinó la recuperación a nivel de paso con la expansión del concepto, donde los conceptos fueron términos y frases individuales [28]. Los conceptos de expansión se eligieron y se ponderaron utilizando una métrica basada en estadísticas de concurrencia. Sin embargo, no está claro en base al análisis realizado cuánto ayudaron solo a los términos únicos. Papka y Allan investigan utilizando comentarios de relevancia para realizar una expansión de conceptos de múltiples medios para el enrutamiento de documentos [19]. Los conceptos utilizados en su trabajo son más generales que los utilizados en LCA, e incluyen estructuras de lenguaje de consulta de consulta, como #UW50 (Casa Blanca), que corresponde al concepto que ocurren los términos blancos y la casa, en cualquier orden, dentro de 50 términosel uno del otro. Los resultados mostraron que la combinación de conceptos de un solo término y ventana múltiple de ventana mejoró significativamente la efectividad. Sin embargo, no está claro si el mismo enfoque también es efectivo para la recuperación ad hoc, debido a las diferencias en las tareas.3. Modele esta sección detalla nuestra técnica de expansión de concepto latente propuesta. Como se mencionó anteriormente, la técnica es una extensión del modelo MRF para la recuperación de información [14]. Por lo tanto, comenzamos proporcionando una visión general del modelo MRF y nuestras extensiones propuestas.3.1 MRFS para IR 3.1.1 Conceptos básicos Markov Los campos aleatorios, que son modelos gráficos no dirigidos, proporcionan una forma compacta y robusta de modelar una distribución conjunta. Aquí, estamos interesados en modelar la distribución conjunta a través de una consulta Q = Q1 ,..., Qn y un documento D. Se supone que la distribución subyacente sobre pares de documentos y consultas es una distribución de relevancia. Es decir, el muestreo de la distribución ofrece pares de documentos y consultas, de modo que el documento es relevante para la consulta. Un MRF se define mediante un gráfico G y un conjunto de funciones potenciales no negativas sobre las camarillas en G. Los nodos en el gráfico representan las variables aleatorias y los bordes definen la semántica de independencia de la distribución. Un MRF satisface la propiedad de Markov, que establece que un nodo es independiente de todos sus nodos que no son de vecinos dados valores observados para sus vecinos. Dado un gráfico G, un conjunto de potenciales ψi y un vector de parámetro λ, la distribución de la junta sobre Q y D viene dada por: PG, λ (Q, D) = 1 zλ c∈C (g) ψ (c; λ) donde z es una constante de normalización. Seguimos la convención común y parametrizamos los potenciales como ψi (c; λ) = exp [λifi (c)], donde fi (c) es una función de características de valor real.3.1.2 Construcción de G Dada una consulta q, el gráfico G se puede construir de varias maneras. Sin embargo, después del trabajo anterior, consideramos tres variantes simples [14]. Estas variantes son la independencia total, donde cada término de consulta es independiente entre sí dado un documento, dependencia secuencial, lo que supone que existe una dependencia entre los términos de consulta adyacentes y la plena dependencia, lo que no hace supuestos de independencia.3.1.3 Parametrización Los MRF se parametrizan comúnmente en función de las camarillas máximas de G. Sin embargo, dicha parametrización es demasiado grosera para nuestras necesidades. Necesitamos una parametrización que nos permita asociar funciones de características con camarillas en un nivel de grano más fino, al tiempo que mantiene el número de características y, por lo tanto, el número de parámetros, razonable. Por lo tanto, permitimos que las camarillas compartan funciones y parámetros de características basados en conjuntos de camarillas. Es decir, todas las camarillas dentro de un conjunto de camarillas están asociadas con la misma función de características y comparten un solo parámetro. Esto une efectivamente los parámetros de las características asociadas con cada conjunto, lo que reduce significativamente el número de parámetros al tiempo que proporciona un mecanismo para ajustar en el nivel de conjuntos de camarillas. Proponemos siete conjuntos de camarillas para su uso con recuperación de información. Los primeros tres conjuntos de camarillas consisten en camarillas que contienen uno o más términos de consulta y el nodo del documento. Las características sobre estas camarillas deben codificar qué tan bien los términos en la configuración de la camarilla describen el documento. Estos conjuntos son: • TD - Conjunto de camarillas que contienen el nodo del documento y exactamente un término de consulta.• OD: conjunto de camarillas que contienen el nodo del documento y dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta.• UD: conjunto de camarillas que contienen el nodo del documento y dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Tenga en cuenta que UD es un superconjunto de OD. Al atar los parámetros entre las camarillas dentro de cada conjunto, podemos controlar cuánta influencia tiene cada tipo. Esto también evita el problema de tratar de determinar cómo estimar los pesos para cada camarilla dentro de los conjuntos. En cambio, ahora solo debemos estimar un solo parámetro por conjunto. A continuación, consideramos camarillas que solo contienen nodos de término de consulta. Estas camarillas, que no se consideraron en [14], se definen de manera análoga a las que se acaban de definir, excepto que las camarillas solo se componen de nodos de término de consulta y no contienen el nodo del documento. Las funciones de características sobre estas camarillas deben capturar cuán compatibles son los términos de consulta entre sí. Estas características de la camarilla pueden asumir la forma de modelos de lenguaje que imponen la bien formación de los términos. Por lo tanto, definimos los siguientes conjuntos de camarillas dependientes de la consulta: • TQ - conjunto de camarillas que contienen exactamente un término de consulta.• OQ: conjunto de camarillas que contienen dos o más términos de consulta que aparecen en orden secuencial dentro de la consulta.• UQ: conjunto de camarillas que contienen dos o más términos de consulta que aparecen en cualquier orden dentro de la consulta. Finalmente, está la camarilla que solo contiene el nodo del documento. Las características sobre este nodo se pueden usar como un tipo de documento anterior, codificando propiedades centradas en el documento. Este conjunto de camarillas trivial es: • D - El conjunto de camarilla que contiene solo el nodo Singleton D, observamos que nuestros conjuntos de camarones forman una cubierta establecida sobre las camarillas de G, pero no son una partición, ya que algunas camarillas aparecen en múltiples conjuntos de camarillas. Después de unir los parámetros en nuestra camarilla se establece y usar la forma de función de potencial exponencial, terminamos con la siguiente forma simplificada de la distribución conjunta: log pg, λ (q, d) = λtd c∈Td ftd (c) + λodc∈D fod (c) + λud c∈Ud Fud (c) fdq (d, q) - documento y consulta dependiente + λtq c∈Tq ftq (c) + λoq c∈Oq foq (c) + λuq c∈Uqfuq (c) fq (q) - consulta dependiente de la consulta + λdfd (d) fd (d) - Documento dependiente del documento - log Zλ Documento + consulta independiente donde FDQ, FQ y FD son funciones de conveniencia definidas por el documento y la consulta dependiente de la consulta, la consulta dependiente de la consultay componentes dependientes del documento de la distribución articular, respectivamente. Estos se utilizarán para simplificar y aclarar expresiones derivadas en todo el resto del documento.3.1.4 Características Cualquier función de característica arbitraria sobre configuraciones de camarilla se puede usar en el modelo. La elección correcta de las características depende en gran medida de la tarea de recuperación y la métrica de evaluación. Por lo tanto, es probable que no haya un conjunto único de características universalmente aplicables. Para proporcionar una idea de la gama de características que se pueden usar, ahora describimos brevemente los posibles tipos de características que podrían usarse. Las posibles características dependientes del término de consulta incluyen TF, IDF, entidades nombradas, proximidad de término y estilo de texto, por nombrar algunos. También se pueden utilizar muchos tipos de características dependientes de documentos, incluida la longitud de los documentos, el PageRank, la legibilidad y el género, entre otros. Dado que no es nuestro objetivo aquí encontrar características óptimas, utilizamos un conjunto simple y fijo de características que se ha demostrado que son efectivas en trabajos anteriores [14]. Consulte la Tabla 1 para obtener una lista de características utilizadas. Estas características intentan capturar la ocurrencia del término y la proximidad del término. Una mejor selección de características en el futuro probablemente conducirá a una mayor efectividad.3.1.5 Ranking Dada una consulta q, deseamos clasificar los documentos en orden descendente de acuerdo con PG, λ (d | Q). Después de soltar expresiones independientes del documento de log PG, λ (q, d), derivamos la siguiente función de clasificación: PG, λ (d | q) rango = fdq (d, q) + fd (d) (2) que es unCombinación lineal ponderada simple de funciones de características que se pueden calcular de manera eficiente para gráficos razonables.3.1.6 Estimación de parámetros Ahora que el modelo ha sido completamente especificado, el paso final es estimar los parámetros del modelo. Aunque los MRF son modelos generativos, es inapropiado entrenarlos utilizando el valor de características FTD (Qi, D) log (1 - α) TFQI, D | D |+ α cfqi | c |FOD (Qi, Qi+1 ..., Qi+K, D) log (1 - β) TF#1 (Qi ... Qi+K), D | D |+ β cf#1 (qi ... qi+ k) | c |FUD (Qi, ..., QJ, D) log (1 - β) tf#uw (qi ... qj), d | d |+ β cf#uw (qi ... qj) | c |ftq (qi) - log cfqi | c |foq (qi, qi+1 ..., qi+k) - log cf#1 (qi ... qi+k) | c |fuq (qi, ..., qj) - log cf#uw (qi ... qj) | c |FD 0 Tabla 1: Funciones de características utilizadas en el modelo de campo aleatorio de Markov. Aquí, TFW, D es el número de veces que el término W ocurre en el documento D, TF#1 (Qi ... Qi+K), D denota el número de veces la frase exacta Qi...Qi+K ocurre en el documento d, tf#uw (qi ... qj), d es el número de veces los términos qi ,...QJ aparece ordenado o desordenado dentro de una ventana de n Términos, y | D |es la longitud del documento D. el CF y | C |Los valores se definen análogos en el nivel de colección. Finalmente, α y β son hiperparámetros modelo que controlan el suavizado para las características de un solo término y frase, respectivamente.Enfoques convencionales basados en la probabilidad debido a la divergencia métrica [17]. Es decir, es poco probable que la estimación de máxima probabilidad sea la estimación que maximice nuestra métrica de evaluación. Por esta razón, capacitamos discriminativamente nuestro modelo para maximizar directamente la métrica de evaluación bajo consideración [14, 15, 25]. Dado que nuestro espacio de parámetros es pequeño, utilizamos una estrategia de escalada simple, aunque son posibles otros enfoques más sofisticados [10].3.2 Expansión del concepto latente En esta sección describimos cómo este modelo MRF extendido puede usarse de una manera novedosa para generar conceptos individuales y multitermos que están relacionados tópicamente con alguna consulta original. Como mostraremos, los conceptos generados utilizando nuestra técnica se pueden utilizar para la expansión de consultas u otras tareas, como sugerir formulaciones de consultas alternativas. Suponemos que cuando un usuario formula su consulta original, tiene algún conjunto de conceptos en mente, pero solo puede expresar un pequeño número de ellos en forma de consulta. Tratamos los conceptos que el usuario tiene en mente, pero no expresó explícitamente en la consulta, como conceptos latentes. Estos conceptos latentes pueden consistir en un solo término, múltiples términos o alguna combinación de los dos. Es, por lo tanto, nuestro objetivo recuperar estos conceptos latentes dada alguna consulta original. Esto se puede lograr dentro de nuestro marco expandiendo primero el gráfico original G para incluir el tipo de concepto que estamos interesados en generar. Llamamos a este gráfico ampliado H. En la Figura 1, el gráfico intermedio proporciona un ejemplo de cómo construir un gráfico ampliado que pueda generar conceptos de un solo término. Del mismo modo, el gráfico de la derecha ilustra un gráfico ampliado que genera conceptos de dos términos. Aunque estos dos ejemplos utilizan la suposición de dependencia secuencial (es decir, dependencias entre los términos de consulta adyacentes), es importante tener en cuenta que tanto la consulta original como los conceptos de expansión pueden usar cualquier estructura de independencia. Después de construir h, calculamos pH, λ (e | q), una distribución de probabilidad sobre conceptos latentes, según: pH, λ (e | q) = d∈R pH, λ (q, e, d) d∈R e ph, λ (q, e, d) donde r es el universo de todos los documentos posibles y E es un concepto latente que puede consistir en uno o más términos. Como no es práctico calcular esta suma, debemos aproximarlo. Notamos que el pH, λ (Q, E, D) es probable que alcance su punto máximo alrededor de los documentos d que están altamente clasificados de acuerdo con la consulta Q. Por lo tanto, aproximamos el pH, λ (e | q) sumando solo un pequeño subconjunto de documentos relevantes o pseudo-relevantes para la consulta Q. Esto se calcula de la siguiente manera: pH, λ (e | q) ≈ d∈Rq pH, λ (q, e, d) d∈Rq e pH, λ (q, e, d) (3) ∝ d∈Rq exppFqd (q, d) + fd (d) + fqd (e, d) + fq (e) donde rq es un conjunto de documentos relevantes o pseudo relevantes para la consulta Q y todos los conjuntos de camarillas se construyen usando H., la contribución de probabilidad para cada documento en RQ es una combinación de la puntuación de consultas original para el documento (ver Ecuación 2), puntaje de concepto para el documento y el puntaje independiente del documento ES. Por lo tanto, esta ecuación puede interpretarse como midiendo qué tan bien Q y E explican los documentos mejor clasificados y la bondad de E, independientemente de los documentos. Para obtener la máxima robustez, utilizamos un conjunto diferente de parámetros para FQD (Q, D) y FQD (E, D), que nos permite ponderar el término, ordenado y las características de la ventana desordenada de manera diferente para la consulta original y el concepto de expansión del candidato.3.2.1 Expansión de consulta Para usar este marco para la expansión de la consulta, primero elegimos un gráfico de expansión que codifica la estructura de concepto latente que estamos interesados en expandir la consulta utilizando. Luego seleccionamos los conceptos latentes K con la mayor probabilidad dada por la ecuación 3. Se construye un nuevo gráfico G aumentando el gráfico original G con los conceptos de expansión K E1 ,..., Ek. Finalmente, los documentos se clasifican de acuerdo con PG, λ (D | Q, E1, ..., Ek) utilizando la ecuación 2. 3.2.2 Comparación con los modelos de relevancia Las ecuaciones 1 y 3 revela la conexión estrecha que existe entre los modelos de LCE y relevancia. Ambas Figura 1: Representaciones gráficas del modelo de modelado de relevancia (izquierda), expansión del concepto latente utilizando conceptos de un solo término (medio) y expansión de conceptos latentes utilizando conceptos de dos términos (derecho) para una consulta de tres términos.Los modelos esencialmente calculan la probabilidad de un término (o concepto) de la misma manera. Es fácil ver que al igual que el modelo MRF puede verse como una generalización del modelado de idiomas, también se puede ver como una generalización de los modelos de relevancia. Existen diferencias importantes entre MRF/LCE y modelos de lenguaje unigram/modelos de relevancia. Consulte la Figura 1 para las representaciones de modelos gráficos de ambos modelos. Los modelos de lenguaje unigram y los modelos de relevancia se basan en la distribución multinomial. Esta suposición de distribución bloquea el modelo en la representación de la bolsa de las palabras y el uso implícito de las características de ocurrencia del término. Sin embargo, la distribución subyacente al modelo MRF nos permite ir más allá de ambos supuestos, modelando ambas dependencias entre los términos de consulta y permitiendo que las características arbitrarias se usen explícitamente. Mover más allá de la bolsa simplista de la suposición de palabras de esta manera da como resultado un modelo general y robusto y, como mostramos en la siguiente sección, se traduce en mejoras significativas en la efectividad de la recuperación.4. Resultados experimentales Para comprender mejor las fortalezas y debilidades de nuestra técnica, lo evaluamos en una amplia gama de conjuntos de datos. La Tabla 2 proporciona un resumen de los conjuntos de datos TREC considerados. Las colecciones WSJ, AP y robustas son más pequeñas y consisten completamente en artículos de Newswire, mientras que WT10G y Gov2 son grandes colecciones web. Para cada conjunto de datos, dividimos los temas disponibles en un conjunto de capacitación y prueba, donde el conjunto de capacitación se usa únicamente para la estimación de parámetros y el conjunto de pruebas se usa para fines de evaluación. Todos los experimentos se llevaron a cabo utilizando una versión modificada de Indri, que forma parte del kit de herramientas Lemur [18, 23]. Todas las colecciones se dejaron de usar una lista estándar de 418 términos comunes y se encuentran con un Porter Stemmer. En todos los casos, solo la parte del título de los temas de TREC se utiliza para construir consultas. Construimos G utilizando la suposición de dependencia secuencial para todos los conjuntos de datos [14].4.1 Resultados de recuperación ad-hoc ahora investigamos qué tan bien funciona nuestro modelo en la práctica en una configuración de retroalimentación de pseudo-relevancia. Comparamos el modelado de lenguaje unigram (con suavizado de Dirichlet), el modelo MRF (sin expansión), modelos de relevancia y LCE para comprender mejor cómo se desempeña cada modelo en los diversos conjuntos de datos. Para el modelo de idioma unigram, el parámetro de suavizado fue entrenado. Para el modelo MRF, capacitamos los parámetros del modelo (es decir, Λ) y hiperparámetros del modelo (es decir, α, β). Para RM3 y LCE, también entrenamos el número de Pseudoname Descripción # Docs Temas de prueba Temas de prueba WSJ Wall St. Journal 87-92 173,252 51-150 151-200 AP Assoc. Presione 88-90 242,918 51-150 151-200 robustos sólidos 2004 datos 528,155 301-450 601-700 WT10g TREC Web Collection 1,692,096 451-500 501-550 Gov2 2004 Crawl de .govomán 25,205,179 701-750 751-800 Tabla 2:Descripción general de las colecciones y temas de TREC.Documentos de retroalimentación relevantes utilizados y el número de términos de expansión.4.1.1 Expansión con conceptos de un solo término Comenzamos evaluando qué tan bien funciona nuestro modelo cuando se expande usando solo términos individuales. Antes de describir y analizar los resultados, establecemos explícitamente cómo se calculan las probabilidades del término de expansión bajo esta configuración (es decir, utilizando la suposición de dependencia secuencial, expandiéndose con conceptos de un solo término y utilizando nuestro conjunto de características). Las probabilidades del término de expansión se calculan de la siguiente manera: pH, λ (e | q) ∝ d∈Rq exp λtd w∈Q log (1 - α) tfw, d | d |+ α CFW | C |+ λod b∈Q log (1 - β) tf#1 (b), d | d |+ β cf#1 (b) | c |+ λud b∈Q log (1 - β) tf#uw (b), d | d |+ β cf#uw (b) | c |+ log (1 - α) tfe, d | d |+ α cfe | c |λtd cfe | c |λtq (4) donde b ∈ Q denota el conjunto de bigrams en Q. Esta ecuación muestra claramente cómo LCE difiere de los modelos de relevancia. Cuando establecemos λtd = λt, d = 1 y todos los demás parámetros a 0, obtenemos la fórmula exacta que se usa para calcular las probabilidades de términos en el marco de modelado de relevancia. Por lo tanto, LCE agrega dos factores muy importantes a la ecuación. Primero, agrega las características de ventana ordenadas y desordenadas que se aplican a la consulta original. En segundo lugar, aplica una forma intuitiva de TF.IDF al término de expansión del candidato w.El factor de las FDI, que no está presente en los modelos de relevancia, juega un papel importante en la selección de términos de expansión.<= −100%(−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%RM3 LCE 05101520 AP <= −100%(−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%RM3 LCE 05101520253035 robusto<= −100%(−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%]> 100%RM3 LCE 0510152025 WT10G Figura 2: Histopramas que demuestran y comparan la robustez de los modelos de relevancia (RM3) y la expansión del concepto latente (LCE) con respecto aal modelo de probabilidad de consulta (QL) para conjuntos de datos AP, robustos y WT10G. Los resultados, evaluados usando precisión promedio media, se dan en la Tabla 3. Como vemos, el modelo MRF, los modelos de relevancia y la LCE siempre superan significativamente el modelo de idioma unigram. Además, LCE muestra mejoras significativas sobre los modelos de relevancia en todos los conjuntos de datos. Las mejoras relativas sobre los modelos de relevancia son 6.9% para AP, 12.9% para WSJ, 6.5% para robusto, 16.7% para WT10G y 7.3% para GOV2. Además, el LCE muestra mejoras pequeñas, pero no significativas, sobre el modelado de relevancia para métricas como la precisión en 5, 10 y 20. Sin embargo, tanto el modelado de relevancia como el LCE muestran mejoras estadísticamente significativas en tales métricas sobre el modelo de idioma unigram. Otro resultado interesante es que el modelo MRF es estadísticamente equivalente a los modelos de relevancia en los dos conjuntos de datos web. De hecho, el modelo MRF supera a los modelos de relevancia en el conjunto de datos WT10G. Esto reitera la importancia de las características no unigramas basadas en la proximidad para la búsqueda web basada en el contenido observadas anteriormente [14, 16]. Aunque nuestro modelo tiene más parámetros libres que modelos de relevancia, sorprendentemente hay poco acogedora. En cambio, el modelo exhibe buenas propiedades de generalización.4.1.2 Expansión con conceptos de múltiples plazos También investigamos la expansión utilizando conceptos de palabras individuales y dos. Para cada consulta, nos expandimos usando un conjunto de conceptos de un solo término y un conjunto de conceptos de dos términos. Los conjuntos fueron elegidos de forma independiente. Desafortunadamente, solo se observaron aumentos insignificantes en la precisión promedio media. Este resultado puede deberse al hecho de que existen fuertes correlaciones entre los conceptos de expansión de un solo término. Descubrimos que los conceptos de dos palabras elegidos a menudo consistían en dos términos altamente correlacionados que también se eligen como conceptos de un solo término. Por ejemplo, se eligió el mercado de valores conceptual de dos términos, mientras que también se eligieron las acciones y el mercado de conceptos de un solo término. Por lo tanto, es poco probable que muchos conceptos de dos palabras aumenten el poder discriminativo de la consulta ampliada. Este resultado sugiere que los conceptos deben elegirse de acuerdo con algunos criterios que también tienen en cuenta las correlaciones de novedad, diversidad o término. Otro problema potencial es el conjunto de características utilizado. Otros conjuntos de características pueden generar resultados diferentes, especialmente si reducen la correlación entre los conceptos de expansión. Por lo tanto, nuestros experimentos no producen resultados concluyentes con respecto a la expansión utilizando conceptos de múltiples medios. En cambio, los resultados introducen preguntas e instrucciones abiertas interesantes para la exploración futura. LM MRF RM3 LCE WSJ .3258 .3425α .3493α .3943αβγ AP .2077 .2147α .2518αβ .2692αβγ robusto .2920 .3096α .3382αβ .3601αβγ γ WT10G .1861 .205533334x. .3520α .3656α .3924αβγ tabla3: Prueba de prueba Precisión promedio media para el modelado de lenguaje (LM), el campo aleatorio de Markov (MRF), los modelos de relevancia (RM3) y la expansión del concepto latente (LCE). Los superíndices α, β y γ indican mejoras estadísticamente significativas (P <0.05) sobre LM, MRF y RM3, respectivamente.4.2 Robustez Como hemos demostrado, los modelos de relevancia y la expansión del concepto latente pueden mejorar significativamente la efectividad de la recuperación en el modelo de probabilidad de consulta basal. En esta sección analizamos la robustez de estos dos métodos. Aquí, definimos la robustez como las consultas numéricas cuya efectividad se mejoran/duele (y por cuánto) como resultado de aplicar estos métodos. Una técnica de expansión altamente robusta mejorará significativamente muchas consultas y solo dañó unas pocas. La Figura 2 proporciona un análisis de la robustez del modelado de relevancia y la expansión del concepto latente para los conjuntos de datos AP, robustos y WT10G. El análisis para los dos conjuntos de datos que no se muestran es similar. Los histogramas proporcionan, para diversos rangos de disminuciones relativas/aumentos en la precisión promedio media, el número de consultas que se dolieron/mejoraron con respecto a la línea de base de la probabilidad de consulta. Como muestran los resultados, LCE exhibe una fuerte robustez para cada conjunto de datos. Para AP, los modelos de relevancia mejoran 38 consultas y duelen 11, mientras que LCE mejora 35 y duele 14. Aunque los modelos de relevancia mejoran la efectividad de 3 consultas más que LCE, la mejora relativa exhibida por LCE es significativamente mayor. Para el conjunto de datos robusto, los modelos de relevancia mejoran 67 consultas y duelen 32, y LCE mejora 77 y duele 22. Finalmente, para la colección WT10G, los modelos de relevancia mejoran 32 consultas y lastimadas 16, y LCE mejora 35 y perjudica 14. Al igual que con AP, la cantidad de mejora exhibida por los modelos de LCE versus relevancia es significativamente mayor para los conjuntos de datos robustos y WT10G. Además, cuando LCE perjudica el rendimiento, es menos probable que lastime tanto como el modelado de relevancia, que es una propiedad deseable.1 word concepts 2 word concepts 3 word concepts telescope hubble telescope hubble space telescope hubble space telescope hubble telescope space space hubble space space telescope hubble mirror telescope mirror space telescope NASA NASA telescope hubble hubble telescope astronomy launch mirror telescope NASA hubble space astronomy telescope NASA space telescopemirror shuttle telescope space telescope space NASA test hubble mirror hubble telescope mission new NASA hubble mirror mirror mirror discovery telescope astronomy space telescope launch time telescope optical space telescope discovery universe hubble optical shuttle space telescope optical telescope discovery hubble telescope flaw light telescope shuttle two hubble space Table4: Quince más probables Conceptos de uno, dos y tres palabras construidos utilizando los 25 principales documentos recuperados para los logros del telescopio de la consulta en la colección robusta. En general, LCE mejora la efectividad para 65% -80% de las consultas, según el conjunto de datos. Cuando se usa en combinación con un sistema de predicción de rendimiento de consultas altamente preciso, puede ser posible expandir selectivamente consultas y minimizar la pérdida asociada con el rendimiento de la subcuina.4.3 Generación de conceptos multi-plazo Aunque encontramos que la expansión que usa conceptos de múltiples medios no pudo producir mejoras concluyentes en la efectividad, existen otras tareas potenciales para las que estos conceptos pueden ser útiles, como la sugerencia de consulta/reformulación, resumen y minería conceptual. Por ejemplo, para una tarea de sugerencia de consulta, la consulta original podría usarse para generar un conjunto de conceptos latentes que corresponden a formulaciones de consultas alternativas. Aunque evaluar nuestro modelo en estas tareas está más allá del alcance de este trabajo, deseamos mostrar un ejemplo ilustrativo de los tipos de conceptos generados utilizando nuestro modelo. En la Tabla 4, presentamos los conceptos más probables de uno, dos y tres términos generados utilizando LCE para los logros del telescopio del Hubble de consulta utilizando los 25 documentos clasificados principales de la colección robusta. Es bien sabido que la generación de conceptos multimotruales utilizando un modelo basado en unigram produce resultados insatisfactorios, ya que no considera las dependencias de términos. Este no es el caso al generar conceptos multimotrientes que usan nuestro modelo. En cambio, la mayoría de los conceptos generados están bien formados y significativos. Hay varios casos en los que los conceptos son menos coherentes, como el espejo espejo espejo. En este caso, la probabilidad de que el término espejo aparezca en un documento pseudo-relevante supera las características de modelado de idiomas (por ejemplo, FOQ), lo que hace que este concepto no coherente tenga una gran probabilidad. Sin embargo, tales ejemplos están en minoría. Los conceptos generados no solo son bien formados y significativos, sino que también son tópicamente relevantes para la consulta original. Como vemos, todos los conceptos generados están sobre el tema y de alguna manera relacionados con el telescopio Hubble. Es interesante ver que la falla del telescopio conceptual Hubble es uno de los conceptos de tres términos más probables, dado que es algo contradictorio para la consulta original. A pesar de esta contradicción, también es probable que los documentos que discutan los fallas del telescopio describan los éxitos, y por lo tanto, este es un concepto significativo. Una cosa importante a tener en cuenta es que los conceptos que genera LCE son de una naturaleza diferente a las que se generarían utilizando un modelo de relevancia BigRam. Por ejemplo, es poco probable que un modelo BigRam genere la NASA del espacio del telescopio conceptual, ya que ninguno de los BigRams que componen el concepto tiene una alta probabilidad. Sin embargo, dado que nuestro modelo se basa en varias características diferentes sobre varios tipos de camarillas, es más general y robusto que un modelo BigRam. Aunque solo proporcionamos los conceptos generados para una sola consulta, observamos que el mismo análisis y conclusiones se generalizan en otros conjuntos de datos, con conceptos coherentes y tópicos que se generan constantemente utilizando LCE.4.4 Discusión Nuestra técnica de expansión del concepto latente captura dos tipos de dependencia semiNthoGonal. En la recuperación de la información, ha habido un interés a largo plazo en comprender el papel de la dependencia del término. De esta investigación, se han identificado dos tipos generales de dependencias. El primer tipo de dependencia es la dependencia sintáctica. Este tipo de dependencia cubre frases, proximidad del término y coincidencia de término [2, 4, 5, 7, 26]. Estos métodos capturan el hecho de que las consultas imponen implícita o explícitamente un cierto conjunto de dependencias posicionales. El segundo tipo es la dependencia semántica. Ejemplos de dependencia semántica son la retroalimentación de relevancia, la retroalimentación de pseudo-relevancia, los sinónimos y, en cierta medida, la derivación [3]. Estas técnicas se han explorado tanto en la consulta como en el lado del documento. En el lado de la consulta, esto generalmente se hace utilizando alguna forma de expansión de consulta, como modelos de relevancia o LCE. En el lado del documento, esto se realiza como expansión del documento o suavizado de documentos [11, 13, 24]. Aunque puede haber cierta superposición entre las dependencias sintácticas y semánticas, en su mayoría son ortogonales. Nuestro modelo utiliza ambos tipos de dependencias. El uso de características de frases y proximidad dentro del modelo captura dependencias sintácticas, mientras que LCE captura la dependencia semántica del lado de la consulta. Esto explica por qué la mejora inicial en la efectividad lograda mediante el uso del modelo MRF no se pierde después de la expansión de la consulta. Si los mismos tipos de dependencias fueran capturados por dependencias sintácticas y semánticas, se esperaría que LCE funcione por igual como modelos de relevancia. Por lo tanto, al modelar ambos tipos de dependencias vemos un efecto aditivo, en lugar de un efecto absorbente. Un área interesante del trabajo futuro es determinar si modelar dependencias semánticas del lado del documento puede agregar algo al modelo. Los resultados anteriores que tienen dependencias semánticas combinadas de consultas y documentos han mostrado resultados mixtos [13, 27].5. Conclusiones En este documento propusimos una sólida técnica de expansión de consultas llamada expansión de concepto latente. Se demostró que la técnica es una extensión natural del modelo de campo aleatorio de Markov para la recuperación de información y una generalización de los modelos de relevancia. LCE es novedoso porque realiza una expansión simple o múltiple dentro de un marco que permite el modelado de dependencias de términos y el uso de características arbitrarias, mientras que el trabajo previo se ha basado en la bolsa de palabras y las características de ocurrencia de términos. Demostramos que la técnica se puede utilizar para producir conceptos de expansión multiclipmonte de alta calidad, bien formados y tópicamente relevantes. Los conceptos generados se pueden usar en un módulo de sugerencia de consulta alternativa. También mostramos que el modelo es altamente efectivo. De hecho, logra mejoras significativas en los modelos de precisión promedio media sobre la relevancia en una selección de conjuntos de datos TREC. También se mostró que el modelo MRF en sí, sin ninguna expansión de consulta, supera a los modelos de relevancia en grandes conjuntos de datos web. Esto reconfirma las observaciones anteriores de que el modelado de dependencias mediante el uso de características de proximidad dentro del MRF tiene un mayor impacto en las colecciones más grandes y ruidosas que las más pequeñas y bien emprendidas. Finalmente, reiteramos la importancia de elegir términos de expansión que modelen la relevancia, en lugar de los documentos relevantes y mostramos cómo LCE captura dependencias semánticas sintácticas y de consulta. El trabajo futuro también analizará la incorporación de dependencias del lado del documento. Agradecimientos Este trabajo fue apoyado en parte por el Centro para la Recuperación de Información Inteligente, en parte por NSF Grant #CNS-0454018, en parte por Arda y NSF Grant #CCF-0205575, y en parte por Microsoft Live Labs. Cualquier opinión, hallazgos y conclusiones o recomendaciones expresadas en este material son las del autor (s) y no reflejan necesariamente las del patrocinador.6. Referencias [1] N. Abdul-Jaleel, J. Allan, W. B. Croft, F. Díaz, L. Larkey, X. Li, M. D. Smucker y C. Wade. UMass en Trec 2004: Novedad y duro. En los procedimientos en línea de la conf. De recuperación de texto de 2004, 2004. [2] C. L. A. Clarke y G. V. Cormack. Recuperación y clasificación de substrato más corto. ACM Trans. Inf. Syst., 18 (1): 44-78, 2000. [3] K. Collins-Thompson y J. Callan. Expansión de consulta utilizando modelos de caminata aleatorias. En Proc.14th intl. Conf.Sobre la gestión de información y conocimiento, páginas 704-711, 2005. [4] W. B. Croft. Consultas booleanas y dependencias de términos en modelos de recuperación probabilística. Journal of the American Society for Information Science, 37 (4): 71-77, 1986. [5] W. B. Croft, H. Turtle y D. Lewis. El uso de frases y consultas estructuradas en la recuperación de información. En Proc.14th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 32-45, 1991. [6] K. Eguchi. Experimentos de expansión de la consulta NTCIR-5 utilizando modelos de dependencia de términos. En Proc.de la quinta reunión del taller de NTCIR sobre la evaluación de tecnologías de acceso a la información, páginas 494-501, 2005. [7] J. Fagan. Indexación de frases automáticas para la recuperación de documentos: un examen de los métodos sintácticos y no sintácticos. En Proc.Décima Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 91-101, 1987. [8] J. Gao, J. Nie, G. Wu y G. Cao. Modelo de lenguaje de dependencia para la recuperación de información. En Proc.27th Ann. Intl. ACM Sigir Conf.Sobre la investigación y el desarrollo en la recuperación de la información, páginas 170-177, 2004. [9] D. Harper y C. J. Van Rijsbergen. Una evaluación de la retroalimentación en la recuperación de documentos utilizando datos de concurrencia. Journal of Documation, 34 (3): 189-216, 1978. [10] T. Joachims. Un método de vector de soporte para medidas de rendimiento multivariadas. En Proc.de la Conf. Internacional.En el aprendizaje automático, páginas 377-384, 2005. [11] O. Kurland y L. Lee. Estructura del corpus, modelos de idiomas y recuperación de información ad-hoc. En Proc.27th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 194-201, 2004. [12] V. Lavrenko y W. B. Croft. Modelos de idiomas basados en relevancia. En Proc.24th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 120-127, 2001. [13] X. Liu y W. B. Croft. Recuperación basada en clúster utilizando modelos de lenguaje. En Proc.27th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 186-193, 2004. [14] D. Metzler y W. B. Croft. Un modelo de campo aleatorio de Markov para dependencias de términos. En Proc.28 Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 472-479, 2005. [15] D. Metzler y W. B. Croft. Modelos basados en características lineales para recuperación de información. Recuperación de información, para aparecer, 2006. [16] D. Metzler, T. Strohman, Y. Zhou y W. B. Croft. Indri en Terabyte Track 2005. En las actas en línea de la conf. De recuperación de texto de 2005, 2005. [17] W. Morgan, W. Greiff y J. Henderson. Maximización directa de la precisión promedio mediante la escalada con una comparación con un enfoque de entropía máxima. Informe técnico, Miter, 2004. [18] P. Ogilvie y J. P. Callan. Experimentos utilizando el kit de herramientas Lemur. En Proc.del texto Conf., 2001. [19] R. Papka y J. Allan. Por qué las ventanas más grandes son mejores que las más pequeñas. Informe técnico, Universidad de Massachusetts, Amherst, 1997. [20] S. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu y M. Gatford. Okapi en TREC-3. En Actas en línea de la tercera conf. De recuperación de texto, páginas 109-126, 1995. [21] J. J. Rocchio. Comentarios de relevancia en la recuperación de la información, páginas 313-323. Prentice-Hall, 1971. [22] F. Song y W. B. Croft. Un modelo de idioma general para la recuperación de información. En Proc.Octava Conferencia Internacional sobre Gestión de Información y Conocimiento (CIKM 99), páginas 316-321, 1999. [23] T. Strohman, D. Metzler, H. Turtle y W. B. Croft. Indri: un motor Serach basado en modelos de idiomas para consultas complejas. En Proc.de la Conf. Internacional.en análisis de inteligencia, 2004. [24] T. Tao, X. Wang, Q. Mei y C. Zhai. Recuperación de información del modelo de idioma con expansión de documentos. En Proc.de HLT/NAACL, páginas 407-414, 2006. [25] B. Taskar, C. GuestRin y D. Koller. Redes de Margin Margin Max. En Proc.de avances en sistemas de procesamiento de información neural (NIPS 2003), 2003. [26] C. J. Van Rijsbergen. Una base teórica para el uso de datos de coincurrencia en la recuperación de información. Journal of Documation, 33 (2): 106-119, 1977. [27] X. Wei y W. B. Croft. Modelos de documentos basados en LDA para recuperación ad-hoc. En Proc.29th Ann. Intl. ACM Sigir Conf.sobre investigación y desarrollo en recuperación de información, páginas 178-185, 2006. [28] J. Xu y W. B. Croft. Mejora de la efectividad de la recuperación de información con el análisis de contexto local. ACM Trans. Inf. Syst., 18 (1): 79-112, 2000. [29] C. Zhai y J. Lafferty. Comentarios basados en modelos en el enfoque de modelado de idiomas para la recuperación de información. En Proc.10º intl. Conf.Sobre la gestión de información y conocimiento, páginas 403-410, 2001.