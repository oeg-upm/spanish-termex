Comprensión del comportamiento del usuario en los comentarios de comentarios en línea Arjun Talwar Ecole Polytechnique F´Ed´erale de Lausanne (EPFL) Laboratorio de inteligencia artificial Lausana, Suiza arjun@math.stanford.edu Radu Jurca Ecole Polytechnique F´Ed'Edie de lausanne (EPFL) INTELIGENCIA ARTEFÍALaboratorio Lausana, Suiza radu.jurca@epfl.ch Boi Faltings Ecole Polytechnique F´Ed´erale de Lausanne (EPFL) Artificial Intelligence Lab Lausanne, Switzerland boi.faltings@epfl.ch Resumen Las revisiones en línea se han vuelto cada vez más populares como una forma de juzgar a juzgarLa calidad de varios productos y servicios. El trabajo previo ha demostrado que los informes contradictorios y los sesgos subyacentes de los usuarios dificultan juzgar el verdadero valor de un servicio. En este documento, investigamos los factores subyacentes que influyen en el comportamiento del usuario al informar comentarios. Observamos dos fuentes de información además de las calificaciones numéricas: evidencia lingüística del comentario textual que acompaña a una revisión y patrones en la secuencia de tiempo de los informes. Primero mostramos que los grupos de usuarios que discuten ampliamente una determinada característica tienen más probabilidades de acordar una calificación común para esa característica. En segundo lugar, mostramos que una calificación de usuarios refleja en parte la diferencia entre la verdadera calidad y la expectativa previa de calidad a medida que se infiere de las revisiones anteriores. Ambos nos dan una forma menos ruidosa de producir estimaciones de calificación y revelar las razones detrás del sesgo del usuario. Nuestras hipótesis fueron validadas por evidencia estadística de revisiones de hoteles en el sitio web de TripAdvisor. Categorías y descriptores de sujetos J.4 [Ciencias Sociales y del Comportamiento]: Economía Términos generales Generales Economía, experimentación, confiabilidad 1. Motivaciones La propagación de Internet ha hecho posible que los foros de retroalimentación en línea (o mecanismos de reputación) se conviertan en un canal importante para el boca a boca con respecto a los productos, servicios u otros tipos de interacciones comerciales. Numerosos estudios empíricos [10, 15, 13, 5] muestran que los compradores consideran seriamente los comentarios en línea al tomar decisiones de compra y están dispuestos a pagar primas de reputación por productos o servicios que tienen una buena reputación. Sin embargo, un análisis reciente plantea preguntas importantes sobre la capacidad de los foros existentes para reflejar la calidad real de un producto. En ausencia de incentivos claros, los usuarios con una perspectiva moderada no se molestarán en expresar sus opiniones, lo que lleva a una muestra no representativa de revisiones. Por ejemplo, [12, 1] muestran que las calificaciones de Amazon1 de libros o CD siguen con una gran probabilidad de distribuciones bi-modales en forma de U donde la mayoría de las clasificaciones son muy buenas o muy malas. Los experimentos controlados, por otro lado, revelan opiniones sobre los mismos elementos que normalmente se distribuyen. En estas circunstancias, el uso de la media aritmética para predecir la calidad (como lo hacen la mayoría de los foros) le da al usuario típico un estimador con una alta varianza que a menudo es falsa. Mejorar la forma en que agregamos la información disponible de las revisiones en línea requiere una comprensión profunda de los factores subyacentes que sesgan el comportamiento de calificación de los usuarios. Hu et al.[12] propone el modelo de fanfjeamiento y moan donde los usuarios califican solo si su utilidad del producto (extraída de una distribución normal) cae fuera de un intervalo mediano. Los autores concluyen que el modelo explica la distribución empírica de los informes y ofrece información sobre formas más inteligentes de estimar la verdadera calidad del producto. En el presente documento, ampliamos esta línea de investigación e intentamos explicar más hechos sobre el comportamiento de los usuarios al informar comentarios en línea. Utilizando las revisiones de hotel reales del sitio web de TripAdvisor2, consideramos dos fuentes adicionales de información además de las calificaciones numéricas básicas enviadas por los usuarios. El primero es la evidencia lingüística simple de la revisión textual que generalmente acompaña las calificaciones numéricas. Utilizamos técnicas de minería de texto similares a [7] y [3], sin embargo, solo estamos interesados en identificar qué aspectos del servicio está discutiendo, sin calcular la orientación semántica del texto. Encontramos que los usuarios que comentan más sobre la misma característica tienen más probabilidades de acordar una calificación numérica común para esa característica en particular. Intuitivamente, los largos comentarios revelan la importancia de la característica para el usuario. Dado que las personas tienden a tener más conocimiento en los aspectos que consideran importantes, se puede suponer que los usuarios que discuten una característica dada en más detalles tienen más autoridad para evaluar esa característica. En segundo lugar, investigamos la relación entre una revisión 1 http://www.amazon.com 2 http://www.tripadvisor.com/ 134 Figura 1: La página de TripAdvisor que muestra reseñas para un popular hotel de Boston. El nombre del hotel y los anuncios se borró deliberativamente.y las revisiones que lo precedieron. Una lectura de las revisiones en línea muestra que las calificaciones a menudo son parte de los hilos de discusión, donde una publicación no es necesariamente independiente de otras publicaciones. Uno puede ver, por ejemplo, usuarios que hacen un esfuerzo para contradecir o estar con vehemencia con los comentarios de los usuarios anteriores. Al analizar la secuencia de tiempo de los informes, concluimos que las revisiones pasadas influyen en los informes futuros, ya que crean algunas expectativas previas con respecto a la calidad del servicio. La percepción subjetiva del usuario está influenciada por la brecha entre la expectativa previa y el rendimiento real del servicio [17, 18, 16, 21] que luego se reflejará en la calificación de los usuarios. Proponemos un modelo que captura la dependencia de las calificaciones de las expectativas previas y validamoslo utilizando los datos empíricos que recopilamos. Ambos resultados pueden usarse para mejorar la forma en que los mecanismos de reputación agregan la información de las revisiones individuales. Nuestro primer resultado se puede utilizar para determinar una estimación de la calidad de la característica de la calidad, donde para cada característica, se considera un subconjunto diferente de revisiones (es decir, aquellos con largos comentarios de esa característica). El segundo conduce a un algoritmo que genera una estimación más precisa de la calidad real.2. El conjunto de datos que utilizamos en este documento Real Hotel Reviews recopiladas del popular sitio de viajes TripAdvisor. TripAdvisor indexa hoteles de ciudades de todo el mundo, junto con revisiones escritas por viajeros. Los usuarios pueden buscar el sitio dando el nombre y la ubicación de los hoteles (opcional). Las reseñas para un hotel determinado se muestran como una lista (ordenada de la más reciente a la más antigua), con 5 reseñas por página. Las revisiones contienen: • Información sobre el autor de la revisión (por ejemplo, fechas de estadía, nombre de usuario del revisor, ubicación del revisor);• la calificación general (de 1, más baja, a 5, más alta);• Una revisión textual que contiene un título para la revisión, los comentarios gratuitos y las cosas principales que al revisor les gustó y no le gustaba;• Calificaciones numéricas (de 1, más bajas, 5, más altas) para diferentes características (por ejemplo, limpieza, servicio, ubicación, etc.) Debajo del nombre del hotel, TripAdvisor muestra la dirección del hotel, información general (número de habitaciones, número de estrellas, descripción corta, etc.), la calificación general promedio, la clasificación de TripAdvisor y una calificación promedio para cada característica. La Figura 1 muestra la página para un popular hotel de Boston cuyo nombre (junto con anuncios) se borró explícitamente. Seleccionamos tres ciudades para este estudio: Boston, Sydney y Las Vegas. Para cada ciudad consideramos todos los hoteles que tenían al menos 10 reseñas y registraron todas las críticas. La Tabla 1 presenta el número de hoteles considerados en cada ciudad, el número total de revisiones registradas para cada ciudad y la distribución de hoteles con respecto a la clasificación de estrellas (como está disponible en el sitio de TripAdvisor). Tenga en cuenta que no todos los hoteles tienen una calificación de estrellas. Tabla 1: Un resumen del conjunto de datos. Ciudad # Reseñas # Hoteles # de hoteles con 1,2,3,4 y 5 estrellas Boston 3993 58 1+3+17+15+2 Sydney 1371 47 0+0+9+13+10 Las Vegas 5593 40 0+3+10+9+6 Para cada revisión registramos la calificación general, la revisión textual (título y cuerpo de la revisión) y la calificación numérica en 7 características: habitaciones (R), servicio (s), limpieza (c), valor(V), comida (f), ubicación (l) y ruido (n). TripAdvisor no requiere que los usuarios envíen otra cosa que no sea la calificación general, por lo tanto, una revisión típica califica pocas características adicionales, independientemente de la discusión en el comentario textual. Solo las características de las habitaciones (R), el servicio (s), la limpieza (c) y el valor (v) son calificadas por un número significativo de usuarios. Sin embargo, también seleccionamos las características de alimentos (f), ubicación (l) y ruido (n) porque se hace referencia en un número significativo de comentarios textuales. Para cada característica grabamos la calificación numérica dada por el usuario, o 0 cuando falta la calificación. La longitud típica del comentario textual equivale a aproximadamente 200 palabras. Todos los datos se recopilaron arrastrando el sitio de TripAdvisor en septiembre de 2006. 2.1 Notación formal Nos referiremos formalmente a una revisión por una tupla (r, t) donde: • r = (rf) es un vector que contiene las calificaciones rf ∈ {0,1 ,...5} para las características f ∈ F = {O, R, S, C, V, F, L, N};Tenga en cuenta que la calificación general, RO, se registra abusivamente como la calificación de la característica general (O);• T es el comentario textual que acompaña a la revisión.135 revisiones se indexan de acuerdo con la variable I, de modo que (RI, TI) es la revisión IPI en nuestra base de datos. Como no grabamos el nombre de usuario del revisor, también diremos que la revisión del IPI en nuestro conjunto de datos fue enviado por el usuario I. Cuando necesitamos considerar solo las revisiones de un hotel determinado, h, usaremos (RI (H), TI (H)) para denotar la I -ésima revisión sobre el Hotel H.3. Evidencia de comentarios textuales Los comentarios textuales gratuitos asociados a las revisiones en línea son una valiosa fuente de información para comprender las razones detrás de las calificaciones numéricas dejadas por los revisores. El texto puede, por ejemplo, revelar ejemplos concretos de aspectos que al usuario le gustaban o no le gustaba, lo que justifica algunas de las calificaciones altas y respectivamente bajas para ciertas características. El texto también puede ofrecer pautas para comprender las preferencias del revisor y los pesos de diferentes características al calcular una calificación general. El problema, sin embargo, es que los comentarios textuales gratuitos son difíciles de leer. Los usuarios deben desplazarse a través de muchas revisiones y leer en su mayoría información repetitiva. Se obtendrían mejoras significativas si las revisiones se interpretaran automáticamente y se agregan. Desafortunadamente, esto parece una tarea difícil para las computadoras, ya que los usuarios humanos a menudo usan un lenguaje ingenioso, abreviaturas, frases culturales específicas y el estilo figurativo. Sin embargo, varios resultados importantes utilizan los comentarios textuales de las revisiones en línea de manera automatizada. El uso de técnicas de lenguaje natural bien establecidos, las revisiones o partes de las revisiones pueden clasificarse como una orientación semántica positiva o negativa. Pang et al.[2] Clasifique las reseñas de películas en positivo/negativo mediante el entrenamiento de tres clasificadores diferentes (Bayes ingenuos, entropía máxima y SVM) utilizando características de clasificación basadas en unigramas, bigrams o etiquetas de parte de voz. Dave et al.[4] Analice las revisiones de CNET y Amazon, y sorprendentemente muestran que las características de clasificación basadas en unigrams o BigRams funcionan mejor que los N-Grams de orden superior. Este resultado es desafiado por Cui et al.[3] quienes miran grandes colecciones de revisiones arrastradas de la web. Muestran que el tamaño del conjunto de datos es importante, y que los conjuntos de capacitación más grandes permiten a los clasificadores utilizar con éxito características de clasificación más complejas basadas en N-Grams. Hu y Liu [11] también rastrean la web para revisiones de productos e identifican automáticamente los atributos de productos que han sido discutidos por los revisores. Utilizan WordNet para calcular la orientación semántica de las evaluaciones de productos y resumen las revisiones de los usuarios al extraer evaluaciones positivas y negativas de diferentes características del producto. Popescu y Etzioni [20] analizan una configuración similar, pero usan los contados del motor de búsqueda para identificar los atributos del producto;La orientación semántica se asigna a través de la técnica de etiquetado de relajación. Ghose et al.[7, 8] Analice las revisiones de los vendedores del mercado secundario de Amazon para identificar las diferentes dimensiones (por ejemplo, entrega, embalaje, atención al cliente, etc.) de reputación. Analizan el texto y etiquetan la parte del discurso para cada palabra. Los sustantivos frecuentes, las frases de sustantivos y las frases verbales se identifican como dimensiones de reputación, mientras que los modificadores correspondientes (es decir, adjetivos y adverbios) se utilizan para obtener puntajes numéricos para cada dimensión. La medida de reputación mejorada se correlaciona mejor con la información de precios observada en el mercado. Pavlou y Dimoka [19] analizan las revisiones de eBay y encuentran que los comentarios textuales tienen un impacto importante en las primas de reputación. Nuestro enfoque es similar a las obras mencionadas anteriormente, en el sentido de que identificamos los aspectos (es decir, las características del hotel) discutidos por los usuarios en las revisiones textuales. Sin embargo, no calculamos la orientación semántica del texto, ni intentamos inferir las calificaciones faltantes. Definimos el peso, Wi F, de la característica f ∈ F en el texto Ti asociado con la revisión (RI, TI), como la fracción de Ti dedicada a discutir aspectos (tanto positivos como negativos) relacionados con la característica f.Proponemos un método elemental para aproximar los valores de estos pesos. Para cada característica, construimos manualmente la lista de palabras LF que contiene aproximadamente 50 palabras que se asocian más comúnmente a la característica F.Las palabras iniciales se seleccionaron al leer algunas de las revisiones y ver qué palabras coinciden con la discusión de qué características. La lista se extendió luego agregando todas las entradas de tesauro que estaban relacionadas con las palabras iniciales. Finalmente, hicimos una lluvia de ideas para palabras faltantes que normalmente se asociarían con cada una de las características. Deje que LF ∩ti sea la lista de términos comunes a LF y TI. Cada término de LF se cuenta el número de veces que aparece en TI, con dos excepciones: • En los casos en que el usuario envía un título a la revisión, contabilizamos el texto del título al agregarlo tres veces al texto de revisión TI. La suposición intuitiva es que la opinión de los usuarios se refleja más fuertemente en el título, más que en el cuerpo de la revisión. Por ejemplo, muchas revisiones se resumen con precisión por títulos como un excelente servicio, ubicación terrible o mal valor por dinero;• Ciertas palabras que ocurren solo una vez en el texto se cuentan varias veces si su relevancia para esa característica es particularmente fuerte. Estas fueron palabras raíz para cada característica (por ejemplo, el personal es una palabra raíz para el servicio de características), y se ponderó 2 o 3. Cada característica se asignó hasta 3 palabras raíz de esas, por lo que casi todas las palabras se cuentan solo una vez. La lista de palabras para las salas de características se da como referencia en el Apéndice A. El peso wi f se calcula como: wi f = | lf ∩ ti |f∈F | lf ∩ ti |(1) donde | lf ∩ti |es el número de términos comunes a LF y TI. El peso para la función en general se estableció en min {| t i |5000, 1} donde | Ti |es el número de carácter en ti. La siguiente es una revisión de TripAdvisor para un hotel de Boston (se omite el nombre del hotel): Comenzaré diciendo que soy más una persona de vacaciones que un tipo ***. Así que me siento frustrado cuando pago el doble de la tarifa de la habitación y obtengo la mitad de las comodidades que tengo en Hampton Inn o Holiday Inn. La ubicación fue definitivamente el activo principal de este lugar. Estaba a solo unas pocas cuadras de la parada del metro del Centro Hynes y fue fácil caminar a algunos buenos restaurantes en el área de la bahía. Boylston no está muy lejos. Así que no tuve problemas para renunciar a un auto de alquiler y llevar el metro desde el aeropuerto al hotel y usar el metro para cualquier otro viaje. De lo contrario, te hacen pagar cualquier cosa y todo.136 Y cuando ya haya caído $ 215/noche en la habitación, eso se vuelve frustrante. La habitación en sí era decente, sobre lo que esperaría. El personal también era promedio, no malo y no excelente. Nuevamente, creo que estás pagando por la ubicación y la capacidad de caminar a muchas cosas buenas. Pero creo que la próxima vez me quedaré en Brookline, obtendré más comodidades y usaré el metro un poco más. Estas calificaciones numéricas asociadas a esta revisión son RO = 3, RR = 3, RS = 3, RC = 4, RV = 2 para características en general (O), habitaciones (R), servicio (s), limpieza (c) y valor(V) respectivamente. Las clasificaciones para las características de los alimentos (F), la ubicación (L) y el ruido (n) están ausentes (es decir, RF = RL = RN = 0). Los pesos WF se calculan a partir de las siguientes listas de términos comunes: lr ∩ t = {habitación};wr = 0.066 ls ∩ t = {3 * personal, comodidades};ws = 0.267 lc ∩ t = ∅;wc = 0 lv ∩ t = {$, tasa};wv = 0.133 lf ∩ t = {restaurante};wf = 0.067 ll ∩ t = {2 * centro, 2 * caminata, 2 * ubicación, área};wl = 0.467 ln ∩ t = ∅;Wn = 0 Las palabras raíz y el centro se triplicaron y duplicaron respectivamente. El peso total de la revisión textual es WO = 0.197. Estos valores explican razonablemente bien para los pesos de diferentes características en la discusión del revisor. Un punto a tener en cuenta es que algunos términos en las listas LF poseen una orientación semántica inherente. Por ejemplo, la palabra mugre (perteneciente a la lista LC) se usaría con mayor frecuencia para afirmar la presencia, y no la ausencia de mugre. Esto es inevitable, pero se tuvo cuidado para garantizar que se utilizaran palabras de ambos lados del espectro. Por esta razón, algunas listas como LR contienen solo sustantivos de objetos que típicamente uno describiría en una habitación (ver Apéndice A). El objetivo de esta sección es analizar la influencia de los pesos con las calificaciones numéricas Ri f. Intuitivamente, los usuarios que pasaron mucho tiempo discutiendo una característica F (es decir, WI F es alta) tenían algo que decir sobre su experiencia con respecto a esta característica. Obviamente, la característica F es importante para el usuario i. Dado que las personas tienden a tener más conocimientos en los aspectos que consideran importantes, nuestra hipótesis es que las calificaciones Ri F (correspondientes a los altos pesos WI F) constituyen un subconjunto de calificaciones expertas para la característica f.La Figura 2 traza la distribución de las tarifas R I (H) C con respecto a los pesos W (H) C para la limpieza de un hotel Las Vegas, h.Aquí, las altas calificaciones están restringidas a las revisiones que discuten poco la limpieza. Cada vez que aparece la limpieza en la discusión, las calificaciones son bajas. Muchos hoteles exhiben patrones de calificación similares para diversas características. Las clasificaciones correspondientes a pesos bajos abarcan todo el espectro de 1 a 5, mientras que las clasificaciones correspondientes a pesos altos están más agrupados (ya sea alrededor de las calificaciones buenas o malas). Por lo tanto, hacemos la siguiente hipótesis: Hipótesis 1. Las calificaciones RI F correspondientes a las revisiones donde WI F es altas, son más similares entre sí que a la colección general de calificaciones. Para probar la hipótesis, tomamos todo el conjunto de revisiones y característica por característica, calculamos la desviación estándar de las calificaciones con altos pesos y la desviación estándar de todo el conjunto de calificaciones. Los pesos altos se definieron como los que pertenecen al 20% superior del rango de peso para la característica correspondiente. Si la hipótesis 1 fuera cierta, la desviación estándar de todas las clasificaciones debería ser mayor que la desviación estándar de las clasificaciones con altos pesos.0 1 2 3 4 5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 Peso de calificación Figura 2: La distribución de clasificaciones contra el peso de la función de limpieza. Utilizamos una prueba t estándar para medir la importancia de los resultados. Ciudad por ciudad y característica por característica, la Tabla 2 presenta la desviación estándar promedio de todas las calificaciones y la desviación estándar promedio de las calificaciones con altos pesos. De hecho, las calificaciones con pesos altos tienen una desviación estándar más baja, y los resultados son significativos en el umbral de significancia de 0.05 estándar (aunque para ciertas ciudades tomadas independientemente no parece haber una diferencia significativa, los resultados son significativos para todo el conjunto de datos). Tenga en cuenta que solo se consideraron las características O, R, S, C y V, ya que para los demás (F, L y N) no teníamos suficientes calificaciones. Tabla 2: Desviación estándar promedio para todas las clasificaciones y desviación estándar promedio para calificaciones con altos pesos. En los soportes cuadrados, los valores p correspondientes para una diferencia positiva entre los dos. Ciudad O R S C V All 1.189 0.998 1.144 0.935 1.123 Boston High 0.948 0.778 0.954 0.767 0.891 P-Val [0.000] [0.004] [0.045] [0.080] [0.009] todo 1.040 0.832 1.101 0.847 0.963 Sydney High P-Val [0.012] [0.023] [0.000] [0.377] [0.037] Todos 1.272 1.142 1.184 1.119 1.242 Vegas altos 1.072 0.752 1.169 0.907 1.003 P-Val [0.0185] [0.001] [0.918] [0.120] [0.126] Hypothess 1 no solo proporciona 1 no solo proporciona 1 no solo proporciona 1 no solo proporciona 1 no solo proporciona 1 no solo, 1, 1, 1, 1, 1 no es la hipótesis 1, 1 no es la hipótesis.Alguna comprensión básica sobre el comportamiento de calificación de los usuarios en línea, también sugiere algunas formas de calcular estimaciones de mejor calidad. Podemos, por ejemplo, construir una estimación de calidad característica por función con una varianza mucho más baja: para cada característica tomamos el subconjunto de revisiones que discuten ampliamente esa característica y la salida como una estimación de calidad de la calificación promedio para este subconjunto. Los experimentos iniciales sugieren que las clasificaciones promedio de características por funciones calculadas de esta manera son diferentes de las clasificaciones promedio calculadas en todo el conjunto de datos. Dado que, de hecho, los pesos altos son indicadores de opiniones de expertos, las estimaciones obtenidas de esta manera son más precisas que las actuales. Sin embargo, la validación de esta suposición subyacente requiere más experimentos controlados.137 4. La influencia de las calificaciones pasadas se realizan dos suposiciones importantes sobre las revisiones presentadas a foros en línea. La primera es que las calificaciones reflejan sinceramente la calidad observada por los usuarios;El segundo es que las revisiones son independientes entre sí. Mientras que la evidencia anecdótica [9, 22] desafía la primera suposición3, en esta sección, nos dirigimos a la segunda. Una lectura de las revisiones en línea muestra que las revisiones a menudo son parte de los hilos de discusión, donde los usuarios hacen un esfuerzo por contradecir, o de acuerdo con el acuerdo con las observaciones de los usuarios anteriores. Considere, por ejemplo, la siguiente revisión: no entiendo las críticas negativas ... el hotel estaba un poco oscuro, pero ese era el estilo. Fue muy artístico. Sí, estaba cerca de la autopista, pero en mi opinión, ¡el sonido de un auto ruidoso ocasional es mejor que escuchar el ding de máquinas tragamonedas toda la noche! El personal disponible es fabuloso. Las camareras son geniales (y *** no merece la mala crítica que recibió, ¡estaba 100% atenta a nosotros!), Los camareros son amigables y profesionales al mismo tiempo ... Aquí, el usuario fue perturbado por informes negativos anteriores, abordó estas preocupaciones y se puso a tratar de corregirlas. No es sorprendente que sus calificaciones fueron considerablemente más altas que las calificaciones promedio hasta este punto. Parece que los usuarios de TripAdvisor leen regularmente los informes enviados por usuarios anteriores antes de reservar un hotel o antes de escribir una reseña. Las revisiones anteriores crean algunas expectativas previas con respecto a la calidad del servicio, y esta expectativa influye en la revisión presentada. Creemos que esta observación se mantiene para la mayoría de los foros en línea. La percepción subjetiva de la calidad es directamente proporcional a qué tan bien la experiencia real cumple con la expectativa previa, un hecho confirmado por una importante línea de investigación econométrica y de comercialización [17, 18, 16, 21]. La correlación entre las revisiones también ha sido confirmada por investigaciones recientes sobre la dinámica de los foros de revisión en línea [6].4.1 Expectativas previas definimos la expectativa previa del usuario I con respecto a la característica F, como el promedio de las calificaciones disponibles anteriormente en la función F4: EF (I) = J <I, R J F = 0 RJ F J <I, R J F = 0 1Como primera hipótesis, afirmamos que la calificación Ri F es una función de la expectativa previa EF (I): Hipótesis 2. Para un hotel y una característica determinada, dadas las reseñas I y J de tal manera que EF (i) es alto y EF (J) es bajo, la calificación RJ F excede la calificación Ri f. Definimos expectativas altas y bajas como las anteriores, respectivamente por debajo de un cierto valor de corte θ. El conjunto de reseñas precedidas por las altas, respectivamente bajas expectativas, 3 parte de las reseñas de Amazon fueron reconocidas como publicaciones estratégicas por autores o competidores de libros 4 Si no se asignaron calificaciones anteriores para la característica F, EF (i) se le asigna un valor predeterminado de 4. Tabla 3: Calificaciones promedio para revisiones precedidas por las expectativas de bajo (primer valor en la celda) y alto (segundo valor en la celda). Los valores P para una diferencia positiva se dan entre paréntesis cuadrados. Ciudad O R S C V 3.953 4.045 3.985 4.252 3.946 Boston 3.364 3.590 3.485 3.641 3.242 [0.011] [0.028] [0.0086] [0.0168] [0.0034] 4.284 4.358 4.064 4.530 4.428 Sydney 3.756 3.537 3.93. [0.000] [0.035] [0.009] [0.000] 3.494 3.674 3.713 3.689 3.580 Las Vegas 3.140 3.530 2.952 3.530 3.351 [0.190] [0.529] [0.007] [0.529] [0.253] se definen de la siguiente manera: Rhigh F = {Ri F | EF (I)> θ θ θ θ θ θ θ θ θ θ θ θ θ θ θ θ θ θ}Rlow f = {ri f | ef (i) <θ} Estos conjuntos son específicos para cada par (hotel, característica), y en nuestros experimentos tomamos θ = 4. Este valor bastante alto está cerca de la calificación promedio en todas las características en todos los hoteles, y está justificado por el hecho de que nuestro conjunto de datos contiene en su mayoría hoteles de alta calidad. Para cada ciudad, tomamos todos los hoteles y calculamos las clasificaciones promedio en los conjuntos Rhigh F y Rlow F (ver Tabla 3). La calificación promedio entre revisiones después de bajas expectativas anteriores es significativamente más alta que la calificación promedio después de las altas expectativas. Como evidencia adicional, consideramos todos los hoteles para los cuales la función EV (i) (la expectativa para el valor de la característica) tiene un valor alto (mayor que 4) para algunos I, y un valor bajo (menos de 4) para otros i. Intuitivamente, estos son los hoteles para los cuales hay un grado mínimo de variación en la secuencia oportuna de revisiones: es decir, el promedio acumulativo de las calificaciones fue en algún momento de alto y luego se volvió baja, o viceversa. Dichas variaciones se observan durante aproximadamente la mitad de todos los hoteles en cada ciudad. La Figura 3 traza la calificación de la mediana (en hoteles considerados), RV, cuando EF (I) no es más que x sino mayor que x - 0.5.2.5 3 3.5 4 4.5 5 2.5 3 3.5 4 4.5 5 Expectativa de medalofrado Boston Sydney Vegas Figura 3: Las clasificaciones tienden a disminuir a medida que aumenta la expectativa.138 Hay dos formas de interpretar la función EF (i): • El valor esperado para la característica F obtenido por el usuario I antes de su experiencia con el servicio, adquirido por los informes de lectura enviados por usuarios anteriores. En este caso, un valor demasiado alto para EF (i) impulsaría al usuario a enviar un informe negativo (o viceversa), derivado de la diferencia entre el valor real del servicio y la expectativa inflada de este valor adquirido antes de suexperiencia.• El valor esperado de la característica F para todos los visitantes posteriores del Sitio, si el usuario no debía enviar un informe. En este caso, la motivación para un informe negativo que sigue a un valor demasiado alto de EF es diferente: el usuario I busca corregir la expectativa de futuros visitantes al sitio. A diferencia de la interpretación anterior, esto no requiere que el usuario obtenga una expectativa a priori para el valor de f.Tenga en cuenta que ninguna de las interpretaciones implica que el promedio del informe I está inversamente relacionado con la calificación en el informe i. Puede existir una medida de influencia ejercida por informes anteriores que empuja al usuario detrás del Informe I para enviar calificaciones que, en cierta medida, se ajusta a los informes pasados: un valor bajo para EF (i) puede influir en el usuario I para enviar una calificación baja para la característica FPorque, por ejemplo, teme que presentar una calificación alta lo hará ser una persona con bajos estándares5. Esto, al principio, parece contradecir la Hipótesis 2. Sin embargo, esta calificación de conformidad no puede continuar indefinidamente: una vez que el conjunto de informes proyecte una estimación suficientemente desinflada para la FV, los revisores futuros con impresiones relativamente positivas buscarán corregir este error.4.2 Impacto de los comentarios textuales sobre la expectativa de calidad Se puede obtener más información sobre el comportamiento de calificación de los usuarios de TripAdvisor analizando la relación entre los pesos WF y los valores EF (I). En particular, examinamos la siguiente hipótesis: Hipótesis 3. Cuando una gran proporción del texto de una revisión discute una determinada característica, la diferencia entre la calificación para esa característica y la calificación promedio hasta ese punto tiende a ser grande. La intuición detrás de esta afirmación es que cuando el usuario es inflexible en expresar su opinión con respecto a una cierta característica, su opinión difiere de la opinión colectiva de las publicaciones anteriores. Esto se basa en la característica de los sistemas de reputación como foros de retroalimentación en los que un usuario está interesado en proyectar su opinión, con una fuerza particular si esta opinión difiere de lo que él percibe como la opinión general. Para probar la Hipótesis 3, medimos la diferencia absoluta promedio entre la expectativa EF (I) y la Ri F de calificación cuando el peso WI F es alto, respectivamente bajo. Los pesos se clasifican altos o bajos comparándolos con ciertos valores de corte: Wi F es bajo si es menor que 0.1, mientras que Wi F es alto si es mayor que θf. Se usaron diferentes valores de corte para diferentes características: θr = 0.4, θs = 0.4, θc = 0.2 y θv = 0.7. La limpieza tiene un corte más bajo, ya que se trata de una característica rara vez discutida;El valor tiene un alto límite por la razón opuesta. Los resultados se presentan en la Tabla 4. 5 La idea de que los informes negativos pueden fomentar más informes negativos se han sugerido antes [14] Tabla 4: promedio de | ri f −Ef (i) |Cuando los pesos son altos (primer valor en la celda) y bajo (segundo valor en la celda) con valores p para la diferencia en los soportes Sq. Ciudad R S C V 1.058 1.208 1.728 1.356 Boston 0.701 0.838 0.760 0.917 [0.022] [0.063] [0.000] [0.218] 1.048 1.351 1.218 1.318 Sydney 0.752 0.759 0.767 0.908 [0.179] [0.009] [0.445] [0.445] [0.184] [0.184] [0.18 1.18] [0.18 1.18] [0.18 1.18] [0.18 1.18] [0.18 1.18] [0.18 1.18] [0.18 1.18] [0.18 1.18] [0.18 1.18] [0.49T. 78 1.472 1.642 Las Vegas0.772 0.834 0.808 1.043 [0.071] [0.020] [0.006] [0.076] Esto demuestra que cuando los pesos son inusualmente altos, los usuarios tienden a expresar una opinión que no se ajusta al promedio neto de las clasificaciones anteriores. Como es de esperar, para una característica que rara vez era un alto peso en la discusión (por ejemplo, la limpieza) la diferencia es particularmente grande. Aunque la diferencia en el valor de la característica es bastante grande para Sydney, el valor p es alta. Esto se debe a que solo unas pocas revisiones discutieron en gran medida. La razón podría ser cultural o porque había menos razón para discutir esta característica.4.3 Incentivos de informes Los modelos anteriores sugieren que los usuarios que no son muy obstinados no elegirán expresar sus opiniones [12]. En esta sección, ampliamos este modelo para tener en cuenta la influencia de las expectativas. La motivación para enviar comentarios no solo se debe a opiniones extremas, sino también a la diferencia entre la reputación actual (es decir, la expectativa previa del usuario) y la experiencia real. Tal modelo de calificación produce clasificaciones que la mayoría de las veces se desvían de la calificación promedio actual. Las calificaciones que confirman las expectativas anteriores rara vez se presentarán. Probamos en nuestro conjunto de datos la proporción de calificaciones que intentan corregir la estimación actual. Definimos una calificación desviada como una que se desvía de la expectativa actual por al menos algún umbral θ, es decir, | ri f - ef (i) |≥ θ. Para cada una de las tres ciudades consideradas, las siguientes tablas, muestran la proporción de calificaciones desviadas para θ = 0.5 y θ = 1. Tabla 5: Proporción de clasificaciones desviadas con θ = 0.5 Ciudad O R S C V Boston 0.696 0.619 0.676 0.604 0.684 Sydney 0.645 0.615 0.672 0.614 0.675 Las Vegas 0.721 0.641 0.694 0.662 0.724 Tabla 6: proporción de calificaciones de θ 429 0.3170.446 Sydney 0.360 0.367 0.442 0.336 0.489 Las Vegas 0.510 0.421 0.483 0.390 0.472 Los resultados anteriores sugieren que una gran proporción de usuarios (cerca de la mitad, incluso para el valor de umbral alto θ = 1) se desvía del promedio anterior. Esto refuerza la idea de que es más probable que los usuarios envíen un informe cuando creen que tienen algo distintivo para agregar al flujo actual de opiniones para alguna característica. Dichas conclusiones están de acuerdo total con evidencia previa de que la distribución de informes a menudo sigue distribuciones bi-modales en forma de U.139 5. Modelando el comportamiento de los evaluadores para tener en cuenta las observaciones descritas en las secciones anteriores, proponemos un modelo para el comportamiento de los usuarios al enviar revisiones en línea. Para un hotel determinado, suponemos que la calidad experimentada por los usuarios normalmente se distribuye en torno a algún valor VF, lo que representa la calidad del objetivo que ofrece el hotel en la función f.La calificación presentada por el usuario I en la característica F es: ˆri F = ΔF VI F + (1 - ΔF) · Sign VI F - EF (I) C + D (VI F, EF (I) | WI F) (2)Dónde: • VI F es la calidad (desconocida) realmente experimentada por el usuario.VI F se supone normalmente distribuido alrededor de algún valor VF;• ΔF ∈ [0, 1] puede verse como una medida del sesgo al informar la retroalimentación. Los valores altos reflejan el hecho de que los usuarios califican objetivamente, sin ser influenciados por las expectativas previas. El valor de ΔF puede depender de varios factores;arreglamos un valor para cada característica F;• C es una constante entre 1 y 5;• Wi F es el peso de la característica F en el comentario textual de la revisión I, calculado según la ecuación.(1);• D (VI F, EF (I) | Wi F) es una función de distancia entre la expectativa y la observación del usuario i. La función de distancia satisface las siguientes propiedades: - d (y, z | w) ≥ 0 para todas y, z ∈ [0, 5], w ∈ [0, 1];- | d (y, z | w) |<| d (z, x | w) |Si | y - z |<| z - x |;- | d (y, z | w1) |<| d (y, z | w2) |Si w1 <w2;- c + d (vf, ef (i) | wi f) ∈ [1, 5];El segundo término de la ecuación.(2) codifica el sesgo de la calificación. Cuanto mayor sea la distancia entre la verdadera observación VI F y la función EF, mayor será el sesgo.5.1 Validación del modelo Utilizamos el conjunto de datos de revisiones de TripAdvisor para validar el modelo de comportamiento presentado anteriormente. Dividimos por conveniencia los valores de calificación en tres rangos: mal (b = {1, 2}), indiferente (i = {3, 4}) y bueno (g = {5}), y realiza las siguientes dos pruebas:• Primero, usaremos nuestro modelo para predecir las calificaciones que tienen valores extremos. Para cada hotel, tomamos la secuencia de informes, y cada vez que encontramos una calificación que sea buena o mala (pero no indiferente) intentamos predecirlo usando la ecuación.(2) • Segundo, en lugar de predecir el valor de las calificaciones extremas, intentamos clasificarlas como buenas o malas. Para cada hotel, tomamos la secuencia de informes, y para cada informe (independientemente de su valor de TI) lo clasificamos como bueno o malo, sin embargo, para realizar estas pruebas, necesitamos estimar el valor objetivo, VF, que es el promedio deLas verdaderas observaciones de calidad, vi f. El algoritmo que estamos utilizando se basa en la intuición de que se minimiza la cantidad de calificación de conformidad. En otras palabras, el valor VF debe ser tal que con la frecuencia posible, las calificaciones malas siguen las expectativas por encima de la FV y las buenas calificaciones siguen las expectativas por debajo de VF. Formalmente, definimos los conjuntos: γ1 = {i | ef (i) <vf y ri f ∈ B};Γ2 = {i | ef (i)> vf y ri f ∈ G};que corresponden a irregularidades donde, aunque la expectativa en el punto I es más baja que el valor entregado, la calificación es pobre y viceversa. Definimos VF como el valor que minimiza estas uniones de los dos conjuntos: Vf = arg min vf | γ1 ∪ γ2 |(3) En la ecuación.(2) Reemplazamos VI F por el valor VF calculado en la ecuación.(3), y use la siguiente función de distancia: d (vf, ef (i) | wi f) = | vf - ef (i) |vf - ef (i) | vf 2 - ef (i) 2 |· (1 + 2wi f);La constante c ∈ I se estableció en min {max {ef (i), 3}}, 4}. Los valores para ΔF se fijaron en {0.7, 0.7, 0.8, 0.7, 0.6} para las características {en general, habitaciones, servicio, limpieza, valor} respectivamente. Los pesos se calculan como se describe en la Sección 3. Como primer experimento, tomamos los conjuntos de clasificaciones extremas {ri f | ri f /∈ I} para cada hotel y característica. Para cada calificación, ri f, intentamos estimarlo calculando ˆri f usando la ecuación.(2). Comparamos este estimador con el obtenido simplemente promediando las clasificaciones sobre todos los hoteles y características: es decir, ¯rf = j, r j f = 0 rj f j, r j f = 0 1;La Tabla 7 presenta la relación entre el error cuadrado medio de la raíz (RMSE) cuando se usa ˆri F y ¯RF para estimar las calificaciones reales. En todos los casos, la estimación producida por nuestro modelo es mejor que el promedio simple. Tabla 7: Promedio de RMSE (ˆRF) RMSE (¯RF) Ciudad O R S C V Boston 0.987 0.849 0.879 0.776 0.913 Sydney 0.927 0.817 0.826 0.720 0.681 LAS Vegas 0.952 0.870 0.881 0.947 0.904 Como un segundo experimento, lo que intentaremos para intentarlo, lo que intentará para intentarlo, por lo que intentará hacerlo.| ri f ∈ B} y gf = {i | ri f ∈ G} de calificaciones malas, respectivamente buenas en la característica f.Por ejemplo, calculamos el conjunto BF usando el siguiente clasificador (llamado σ): ri f ∈ Bf (σf (i) = 1) ⇔ ˆri f ≤ 4;Las tablas 8, 9 y 10 presentan la precisión (p), recuerdo (r) y s = 2pr p+r para clasificador σ, y lo compara con un clasificador mayoritario ingenuo, τ, τf (i) = 1 ⇔ | bf |≥ | GF |: Vemos que el retiro siempre es más alto para σ y la precisión suele ser ligeramente peor. Para la métrica S S Metric tiende a agregar un 140 Tabla 8: Precisión (P), Recuerdo (R), S = 2Pr P+R, mientras que detecta las calificaciones pobres para Boston o R S C V P 0.678 0.670 0.573 0.545 0.610 σ R 0.626 0.659 0.619 0.612 0.694 S0.651 0.665 0.595 0.577 0.609 p 0.684 0.706 0.647 0.611 0.633 τ r 0.597 0.541 0.410 0.383 0.562 S 0.638 0.613 0.502 0.502 0.471 0.595 Tabla 9: Precisión (P), retransmisión (R), S = 2Pr, mientras que se detiene los puntos de calificación de los pobres.O R S C V P 0.654 0.748 0.592 0.712 0.583 σ R 0.608 0.536 0.791 0.474 0.610 S 0.630 0.624 0.677 0.569 0.596 P 0.685 0.761 0.621 0.748 0.606 τ R 0.542 0.505 0.767 0.445 0.670. 558 0.511 1-20% de mejora sobre τ, mucho más alta enAlgunos casos para hoteles en Sydney. Esto es probable porque las revisiones de Sydney son más positivas que las de las ciudades y casos estadounidenses en los que el número de malas revisiones excedió el número de buenas son raras. Reemplazar el algoritmo de prueba con uno que juega un 1 con probabilidad igual a la proporción de malas revisiones mejora sus resultados para esta ciudad, pero todavía tiene un rendimiento superado en alrededor del 80%.6. Resumen de los resultados y la conclusión El objetivo de este documento es explorar los factores que impulsan a un usuario a enviar una calificación particular, en lugar de los incentivos que lo alentaron a presentar un informe en primer lugar. Para eso, usamos dos fuentes adicionales de información además del vector de las calificaciones numéricas: primero observamos los comentarios textuales que acompañan las revisiones, y segundo consideramos los informes que otros usuarios han presentado previamente. Utilizando algoritmos simples de procesamiento del lenguaje natural, pudimos establecer una correlación entre el peso de una determinada característica en el comentario textual que acompaña a la revisión y el ruido presente en la calificación numérica. Específicamente, parece que los usuarios que discuten ampliamente una determinada característica es probable que acuerden una calificación común. Esta observación permite la construcción de estimadores de calidad característicos por funciones que tienen una varianza más baja y, con suerte, son menos ruidosos. Sin embargo, se requiere más evidencia para respaldar la intuición de que las calificaciones correspondientes a los altos pesos son opiniones de expertos que merecen tener una mayor prioridad al calcular las estimaciones de calidad. En segundo lugar, enfatizamos la dependencia de las calificaciones en informes anteriores. Informes anteriores crean una expectativa de calidad que afecta la percepción subjetiva del usuario. Validamos dos hechos sobre las reseñas del hotel que recolectamos de TripAdvisor: primero, las calificaciones que siguen las bajas expectativas (donde la expectativa se calcula como el promedio de los informes anteriores) es probable que sean más altas que las clasificaciones Tabla 10: Precisión (P),Recuerde (R), S = 2PR P+R Mientras observa las calificaciones pobres para Sydney o R S C V P 0.650 0.463 0.544 0.550 0.580 σ R 0.234 0.378 0.571 0.169 0.592 S 0.343 0.452 0.557 0.259 0.586 P 0.562 0.615 0.600 0.500 0.343 0.452 0.557 0.259. 15 0.175S 0.098 0.168 0.172 0.030 0.271 después de altas expectativas. Intuitivamente, la percepción de calidad (y, en consecuencia, la calificación) depende de qué tan bien la experiencia real del usuario cumpla con sus expectativas. En segundo lugar, incluimos evidencia de los comentarios textuales, y encontramos que cuando los usuarios dedican una gran fracción del texto a discutir una determinada característica, es probable que motiven una calificación divergente (es decir, una calificación que no se ajusta a la expectativa previa). Intuitivamente, esto respalda la hipótesis de que los foros de revisión actúan como grupos de discusión donde los usuarios están interesados en presentar y motivar su propia opinión. Hemos capturado la evidencia empírica en un modelo de comportamiento que predice las calificaciones presentadas por los usuarios. La calificación final depende, como se esperaba, en la verdadera observación y de la brecha entre la observación y la expectativa. La brecha tiende a tener una mayor influencia cuando una fracción importante del comentario textual se dedica a discutir una determinada característica. El modelo propuesto se validó en los datos empíricos y proporciona mejores estimaciones de las calificaciones realmente presentadas. Una suposición que hacemos es sobre la existencia de un valor de calidad objetivo VF para la característica F.Esto rara vez es cierto, especialmente en grandes tramos de tiempo. Otras explicaciones podrían explicar la correlación de las calificaciones con informes anteriores. Por ejemplo, si EF (i) refleja el valor verdadero de F en un punto en el tiempo, la diferencia en las calificaciones después de las expectativas altas y bajas puede explicarse por los modelos de ingresos del hotel que se maximizan cuando el valor se modifica en consecuencia. Sin embargo, la idea de que la variación en las calificaciones no es principalmente una función de la variación en el valor resulta ser útil. Nuestro enfoque para aproximar este valor de objetivo evasivo no es de ninguna manera perfecto, pero se ajusta perfectamente a la idea detrás del modelo. Una dirección natural para el trabajo futuro es examinar las aplicaciones concretas de nuestros resultados. Es probable que se obtengan mejoras significativas de las estimaciones de calidad incorporando todas las pruebas empíricas sobre el comportamiento de calificación. No está claro cómo los diferentes factores afectan las decisiones de los usuarios. La respuesta puede depender de la aplicación, el contexto y la cultura particular.7. Referencias [1] A. admati y P. Pfleiderer. Noisytalk.com: transmitiendo opiniones en un entorno ruidoso. Documento de trabajo 1670R, Universidad de Stanford, 2000. [2] P. B., L. Lee y S. Vaithyanathan. ¿Pulgares hacia arriba?Clasificación de sentimientos utilizando técnicas de aprendizaje automático. En Actas del EMNLP-02, La Conferencia sobre Métodos Empíricos en Procesamiento del Lenguaje Natural, 2002. [3] H. Cui, V. Mittal y M. Datar. Comparativo 141 experimentos sobre clasificación de sentimientos para revisiones de productos en línea. En Actas de AAAI, 2006. [4] K. Dave, S. Lawrence y D. Pennock. Minería La Galería de Peanut: extracción de opinión y clasificación semántica de revisiones de productos. En Actas de la 12ª Conferencia Internacional sobre la World Wide Web (WWW03), 2003. [5] C. Dellarocas, N. Awad y X. Zhang. Explorando el valor de las calificaciones de productos en línea en el pronóstico de ingresos: el caso de las películas. Documento de trabajo, 2006. [6] C. Forman, A. Ghose y B. Wiesenfeld. Un examen múltiple del impacto de las identidades sociales en las transacciones económicas en los mercados electrónicos. Disponible en SSRN: http://ssrn.com/abstract=918978, julio de 2006. [7] A. Ghose, P. ipeirotis y A. Sundararajan. Premios de reputación en mercados electrónicos de igual a igual: análisis de retroalimentación textual y estructura de red. En el tercer taller sobre economía de los sistemas entre pares, (P2Pecon), 2005. [8] A. Ghose, P. ipeirotis y A. Sundararajan. Las dimensiones de la reputación en los mercados electrónicos. Documento de trabajo CEDER-06-02, Universidad de Nueva York, 2006. [9] A. Harmon. Amazon Glitch desenmascara la guerra de revisores. The New York Times, 14 de febrero de 2004. [10] D. Houser y J. Wooders. Reputación en subastas: teoría y evidencia de eBay. Journal of Economics and Management Strategy, 15: 353-369, 2006. [11] M. Hu y B. Liu. Minería y resumen de las revisiones de los clientes. En Actas de la Conferencia Internacional ACM Sigkdd sobre Discovery y Minería de datos (KDD04), 2004. [12] N. Hu, P. Pavlou y J. Zhang. ¿Pueden las revisiones en línea revelar una verdadera calidad de productos? En Actas de la Conferencia ACM sobre Comercio Electrónico (EC 06), 2006. [13] K. Kalyanam y S. McIntyre. Retorno de la reputación en el mercado de subastas en línea. Documento de trabajo 02/03-10-WP, Leavey School of Business, Universidad de Santa Clara., 2001. [14] L. Khopkar y P. Resnick. Auto-selección, deslizamiento, salvamento, holgura y piedra angular: los impactos de la retroalimentación negativa en eBay. En Actas de la Conferencia ACM sobre Comercio Electrónico (EC 05), 2005. [15] M. Melnik y J. Alm. ¿Importa la reputación de un vendedor?Evidencia de subastas de eBay. Journal of Industrial Economics, 50 (3): 337-350, 2002. [16] R. Olshavsky y J. Miller. Expectativas del consumidor, rendimiento del producto y calidad percibida del producto. Journal of Marketing Research, 9: 19-21, febrero de 1972. [17] A. Parasuraman, V. Zeithaml y L. Berry. Un modelo conceptual de calidad del servicio y sus implicaciones para futuras investigaciones. Journal of Marketing, 49: 41-50, 1985. [18] A. Parasuraman, V. Zeithaml y L. Berry. SERVQUAL: una escala de ítems múltiples para medir las percepciones de los consumidores sobre la calidad del servicio. Journal of Retailing, 64: 12-40, 1988. [19] P. Pavlou y A. Dimoka. La naturaleza y el papel de los comentarios de texto de comentarios en los mercados en línea: implicaciones para la construcción de confianza, primas de precios y diferenciación del vendedor. Information Systems Research, 17 (4): 392-414, 2006. [20] A. Popescu y O. Etzioni. Extracción de características del producto y opiniones de las revisiones. En Actas de la Conferencia de Tecnología del Lenguaje Humano y la Conferencia sobre Métodos Empíricos en Procesamiento del Lenguaje Natural, 2005. [21] R. Teas. Expectativas, evaluación del desempeño y percepciones de la calidad de los consumidores. Journal of Marketing, 57: 18-34, 1993. [22] E. White. Charlando a un cantante en las listas de pop. The Wall Street Journal, 15 de octubre de 1999. APÉNDICE A. Lista de palabras, LR, asociada a las salas de características Todas las palabras sirven como prefijos: habitación, espacio, interior, decoración, ambiente, atmósfera, comodidad, baño, inodoro, cama, edificio, pared, ventana, privado, temperatura, hoja, lino, almohada, caliente, agua, frío, agua, ducha, vestíbulo, muebles, alfombras, aire, condición, colchón, diseño, diseño, espejo, techo, iluminación, lámpara, sofá, silla, tocador, armario, armario 142