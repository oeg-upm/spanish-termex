Hits en la web: ¿Cómo se compara? Marc Najork Microsoft Research 1065 La Avenida Mountain View, CA, EE. UU. Najork@microsoft.com Hugo Zaragoza ∗ Yahoo! Investigación Barcelona Ocata 1 Barcelona 08003, España hugoz@es.yahoo-inc.com Michael Taylor Microsoft Research 7 J J Thompson Ave Cambridge CB3 0FB, Reino Unido mitaylor@microsoft.com Resumen Este artículo describe una evaluación a gran escala de la efectividad de los golpes enComparación con otros algoritmos de clasificación basados en enlaces, cuando se usa en combinación con un algoritmo de recuperación de texto de última generación que explota el texto de anclaje. Cuantificamos su efectividad utilizando tres medidas de rendimiento comunes: el rango recíproco medio, la precisión promedio media y las mediciones de ganancia acumulativa con descuento normalizadas. La evaluación se basa en dos grandes conjuntos de datos: un rastreo de búsqueda de amplitud de 463 millones de páginas web que contienen 17.6 mil millones de hipervínculos y hacen referencia a 2.900 millones de URL distintas;y un conjunto de 28,043 consultas muestreadas de un registro de consultas, cada consulta que tiene en promedio 2,383 resultados, aproximadamente 17 de los cuales fueron etiquetados por jueces. Descubrimos que los golpes superan a PageRank, pero es tan efectivo como la página web en el grado. Lo mismo es cierto cuando cualquiera de las características basadas en enlaces se combina con el algoritmo de recuperación de texto. Finalmente, estudiamos la relación entre la especificidad de la consulta y la efectividad de las características seleccionadas, y encontramos que las características basadas en enlaces funcionan mejor para consultas generales, mientras que BM25F funciona mejor para consultas específicas. Categorías y descriptores de sujetos H.3.3 [Búsqueda y recuperación de información]: proceso de búsqueda de información y búsqueda de recuperación, proceso de selección Términos generales Algoritmos, medición, experimentación 1. Se ha demostrado que las características del gráfico de enlaces de introducción, como Inde y PageRank, mejoran significativamente el rendimiento de los algoritmos de recuperación de texto en la web. También se cree que el algoritmo de éxitos es de interés para la búsqueda web;Hasta cierto punto, uno puede esperar que los éxitos sean más informativos de que otras características basadas en enlaces porque depende de la consulta: trata de medir el interés de las páginas con respecto a una consulta dada. Sin embargo, no está claro hoy si existen beneficios prácticos de los éxitos sobre otras medidas de gráficos de enlace. Esto es aún más cierto cuando consideramos que los algoritmos de recuperación modernos utilizados en la web usan una representación de documentos que incorpora el texto de anclaje de documentos, es decir, el texto de los enlaces entrantes. Esto, al menos hasta cierto punto, tiene en cuenta el gráfico de enlace, de manera dependiente de la consulta. Comparar los éxitos con PageRank o en el grado empíricamente no es una tarea fácil. Hay dos dificultades principales: escala y relevancia. La escala es importante porque se sabe que las características basadas en enlaces mejoran en calidad a medida que crece el gráfico de documentos. Si realizamos un pequeño experimento, nuestras conclusiones no se transferirán a gráficos grandes como la web. Sin embargo, la computación golpea de manera eficiente en un gráfico del tamaño de un rastreo web realista es extraordinariamente difícil. La relevancia también es crucial porque no podemos medir el rendimiento de una característica en ausencia de juicios humanos: lo que es crucial es clasificarse en la parte superior de los diez documentos que un usuario examinará. Hasta donde sabemos, este documento es el primer intento de evaluar los golpes a gran escala y compararlo con otras características basadas en enlaces con respecto al juicio evaluado humano. Nuestros resultados confirman muchas de las intuiciones que tenemos sobre las características basadas en enlaces y su relación con los métodos de recuperación de texto que explotan el texto de anclaje. Esto es tranquilizador: en ausencia de un modelo teórico capaz de vincular estas medidas con relevancia, la única forma de validar nuestras intuiciones es llevar a cabo experimentos realistas. Sin embargo, nos sorprendió bastante encontrar que Hits, una característica dependiente de la consulta, es casi tan efectiva como la página web en grado, la característica basada en enlaces más simplificadas de consulta. Esto sigue siendo cierto cuando las características basadas en enlaces se combinan con un algoritmo de recuperación de texto que explota el texto de anclaje. El resto de este documento está estructurado de la siguiente manera: Sección 2 de trabajo relacionado con encuestas. La Sección 3 describe los conjuntos de datos que utilizamos en nuestro estudio. La Sección 4 revisa las medidas de rendimiento que utilizamos. Las secciones 5 y 6 describen los algoritmos de PageRank y golpea con más detalle y dibujan la infraestructura computacional que empleamos para llevar a cabo experimentos a gran escala. La Sección 7 presenta los resultados de nuestras evaluaciones, y la Sección 8 ofrece comentarios finales.2. Trabajo relacionado La idea de usar el análisis de hipervínculos para clasificar los resultados de búsqueda web surgió alrededor de 1997, y se manifestó en los algoritmos de éxitos [16, 17] y PageRank [5, 21]. La popularidad de estos dos algoritmos y el éxito fenomenal del motor de búsqueda de Google, que utiliza PageRank, ha generado una gran cantidad de investigaciones posteriores. Existen numerosos intentos para mejorar la efectividad de los éxitos y el PageRank. Los algoritmos de clasificación basados en enlaces dependientes de la consulta inspirados en los éxitos incluyen salsa [19], golpes aleatorios [20] y phits [7], por nombrar algunos. Los algoritmos de clasificación basados en enlaces independientes de la consulta inspirados en PageRank incluyen Trafficank [22], Blockrank [14] y Trustrank [11] y muchos otros. Otra línea de investigación se refiere a analizar las propiedades matemáticas de los éxitos y PageRank. Por ejemplo, Borodin et al.[3] investigó varias propiedades teóricas de PageRank, golpes, salsa y phits, incluida su similitud y estabilidad, mientras que Bianchini et al.[2] estudió la relación entre la estructura del gráfico web y la distribución de las puntuaciones de PageRank, y Langville y Meyer examinaron las propiedades básicas de PageRank, como la existencia y la singularidad de un vector propio y la convergencia de la iteración de energía [18]. Dada la atención que se ha prestado a mejorar la efectividad de PageRank y los éxitos, y los estudios exhaustivos de las propiedades matemáticas de estos algoritmos, es algo sorprendente que se hayan publicado muy pocas evaluaciones de su efectividad. Somos conscientes de dos estudios que han intentado evaluar formalmente la efectividad de los éxitos y de PageRank. Amento et al.[1] empleó medidas cuantitativas, pero basó sus experimentos en los conjuntos de resultados de solo 5 consultas y el gráfico web inducido por rastreos tópicos en torno al conjunto de resultados de cada consulta. Un estudio más reciente de Borodin et al.[4] se basa en 34 consultas, conjuntos de resultados de 200 páginas por consulta obtenida de Google, y un gráfico de vecindario derivado recuperando 50 en enlace por resultado de Google. Por el contrario, nuestro estudio se basa en más de 28,000 consultas y un gráfico web que cubre 2.9 mil millones de URL.3. Nuestros conjuntos de datos Nuestra evaluación se basa en dos conjuntos de datos: un gráfico web grande y un conjunto sustancial de consultas con resultados asociados, algunos de los cuales fueron etiquetados por jueces humanos. Nuestro gráfico web se basa en un rastreo web que se realizó de manera amplia, y recuperó con éxito 463,685,607 páginas HTML. Estas páginas contienen 17,672,011,890 hipervínculos (después de eliminar hipervínculos duplicados incrustados en la misma página web), que se refieren a un total de 2,897,671,002 URL. Por lo tanto, al final del rastreo había 2.433,985,395 URL en el conjunto de fronteras del rastreador que se había descubierto, pero aún no se descargó. El grado medio de las páginas web rastreadas es 38.11;La media en grados de las páginas descubiertas (ya sea rastreadas o no) es 6.10. Además, vale la pena señalar que hay mucha más variación en los grados que en grados externos;Algunas páginas populares tienen millones de enlaces entrantes. Como veremos, esta propiedad afecta el costo computacional de los éxitos. Nuestro conjunto de consultas se produjo muestras de 28,043 consultas del registro de consultas de búsqueda MSN, y recuperando un total de 66,846,214 URL de resultados para estas consultas (usando tecnología de motores de búsqueda comercial), o aproximadamente 2,838 resultados por consulta en promedio. Es importante señalar que nuestro gráfico web de URL de 2.900 millones no cubre todas estas URL de resultados. De hecho, solo 9,525,566 de las URL de resultados (alrededor del 14,25%) estaban cubiertas por el gráfico.485,656 de los resultados en el conjunto de consultas (aproximadamente el 0,73% de todos los resultados, o aproximadamente 17.3 resultados por consulta) fueron calificados por jueces humanos en cuanto a su relevancia para la consulta dada, y etiquetadas en una escala de seis puntos (las etiquetas son definitivas definitivas, excelente, bueno, justo, malo y perjudicial). Los resultados fueron seleccionados para el juicio en función de la colocación de su motor de búsqueda comercial;En otras palabras, el subconjunto de resultados etiquetados no es aleatorio, sino sesgado hacia documentos considerados relevantes por los algoritmos de clasificación preexistentes. Involucrar a un humano en el proceso de evaluación es extremadamente engorroso y costoso;Sin embargo, los juicios humanos son cruciales para la evaluación de los motores de búsqueda. Esto es así porque aún no se han encontrado características de documento que puedan estimar efectivamente la relevancia de un documento para una consulta de usuario. Dado que las características del partido de contenido son muy poco confiables (y aún más las características de enlace, como veremos), debemos pedirle a un humano que evalúe los resultados para comparar la calidad de las características. La evaluación de los resultados de recuperación de los puntajes de documentos y los juicios humanos no es trivial y ha sido objeto de muchas investigaciones en la comunidad IR. Una buena medida de rendimiento debe correlacionarse con la satisfacción del usuario, teniendo en cuenta que a los usuarios no les gustará tener que profundizar en los resultados para encontrar documentos relevantes. Por esta razón, las medidas de correlación estándar (como el coeficiente de correlación entre el puntaje y el juicio de un documento), o las medidas de correlación de orden (como Kendall Tau entre el puntaje y las órdenes inducidas por el juicio) no son adecuadas.4. Medición del rendimiento En este estudio, cuantificamos la efectividad de varios algoritmos de clasificación utilizando tres medidas: NDCG, MRR y MAP. La medida de ganancias acumuladas con descuento normalizadas (NDCG) [13] descuenta la contribución de un documento al puntaje general a medida que aumenta el rango de documentos (suponiendo que el mejor documento tiene el rango más bajo). Dicha medida es particularmente apropiada para los motores de búsqueda, ya que los estudios han demostrado que los usuarios de los motores de búsqueda rara vez consideran algo más allá de los primeros resultados [12]. Los valores de NDCG están normalizados para estar entre 0 y 1, siendo 1 el NDCG de un esquema de clasificación perfecto que está completamente de acuerdo con la evaluación de los jueces humanos. La ganancia acumulada con descuento en un rango de rango particular t (dcg@t) se define como pt j = 1 1 log (1+j) 2r (j)-1, donde r (j) es la calificación (0 = perjudicial, 1 = malo, 2 = justo, 3 = bueno, 4 = excelente y 5 = definitivo) en el rango j. El NDCG se calcula dividiendo el DCG de una clasificación por el DCG más alto posible que se puede obtener para esa consulta. Finalmente, los NDGC de todas las consultas en el conjunto de consultas se promedian para producir un NDCG medio. El rango recíproco (RR) del conjunto de resultados clasificado de una consulta se define como el valor recíproco del rango del documento relevante de más alto rango en el conjunto de resultados. El RR en el umbral de rango T se define como 0 si ninguno de los documentos T de alojamiento es relevante. El rango recíproco medio (MRR) de un conjunto de consultas es el rango recíproco promedio de todas las consultas en el conjunto de consultas. Dado un conjunto clasificado de n resultados, deje que R (i) sea 1 si el resultado en el Rango I es relevante y 0 de lo contrario. La precisión p (j) en el rango J se define como 1 J Pj I = 1 Rel (i), es decir, la fracción de los resultados relevantes entre los resultados de más alto rango. La precisión promedio (AP) en el umbral de rango K se define como PK I = 1 P (I) Rel (I) Pn I = 1 Rel (I). La precisión promedio media (MAP) de un conjunto de consultas es la media de las precisiones promedio de todas las consultas en el conjunto de consultas. Las definiciones anteriores de MRR y MAP se basan en la noción de un resultado relevante. Investigamos dos definiciones de relevancia: una en la que todos los documentos calificados de manera justa o mejor se consideraron relevantes, y uno fue todos los documentos calificados de buenos o mejor se consideraron relevantes. Por razones de espacio, solo informamos los valores de mapa y MRR calculados utilizando la última definición;Usar la definición anterior no cambia la naturaleza cualitativa de nuestros hallazgos. Del mismo modo, calculamos los valores de NDCG, MAP y MRR para un amplio rango de umbral de rango;Informamos los resultados aquí en el rango 10;Nuevamente, cambiar el umbral de rango nunca nos llevó a diferentes conclusiones. Recuerde que más del 99% de los documentos no están etiquetados. Elegimos tratar todos estos documentos como irrelevantes para la consulta. Sin embargo, para algunas consultas, no se han juzgado todos los documentos relevantes. Esto introduce un sesgo en nuestra evaluación: las características que traen nuevos documentos a la parte superior del rango pueden ser penalizadas. Esto será más agudo para las características menos correlacionadas con los algoritmos de clasificación comercial preexistentes utilizados para seleccionar documentos para el juicio. Por otro lado, la mayoría de las consultas tienen pocos documentos relevantes perfectos (es decir, la página de inicio o las búsquedas de elementos) y con mayor frecuencia estarán dentro del conjunto juzgado.5. Computing PageRank en un gran gráfico web de PageRank es una medida independiente de la consulta de la importancia de las páginas web, basada en la noción de entregamiento de pares: un hipervínculo de la página A a la página B se interpreta como un respaldo del contenido de la página BS tanautor. La siguiente definición recursiva captura esta noción de endoso: r (v) = x (u, v) ∈E r (u) out (u) donde r (v) es el puntaje (importancia) de la página v, (u, v)es un borde (hipervínculo) desde la página U a la página V contenida en el conjunto de borde del gráfico web, y fuera (u) es el grado externo (número de hipervínculos incrustados) de la página u. Sin embargo, esta definición sufre de una deficiencia severa: en el punto fijo de esta ecuación recursiva, solo los bordes que forman parte de un componente fuertemente conectado reciben una puntuación no cero. Para superar esta deficiencia, Page et al.otorgue a cada página un puntaje mínimo garantizado, dando lugar a la definición de PageRank estándar: R (V) = D | V |+ (1 - d) x (u, v) ∈E r (u) out (u) donde | v |es el tamaño del conjunto de vértices (el número de páginas web conocidas), y D es un factor de amortiguación, típicamente establecido entre 0.1 y 0.2. Suponiendo que los puntajes se normalizan para resumir hasta 1, PageRank se puede ver como la distribución de probabilidad estacionaria de una caminata aleatoria en el gráfico web, donde en cada paso de la caminata, el caminante con probabilidad 1 - D se mueve desde su nodo actual u u ua un nodo vecino V, y con la probabilidad D selecciona un nodo uniforme al azar de todos los nodos en el gráfico y salta a él. En el límite, el caminante aleatorio está en el nodo V con probabilidad R (V). Un problema que debe abordarse al implementar PageRank es cómo lidiar con los nodos fregaderos, nodos que no tienen ningún enlace saliente. Una posibilidad sería seleccionar otro nodo uniformemente al azar y la transición a él;Esto es equivalente a agregar bordes de cada fregadero a todos los demás nodos en el gráfico. Elegimos el enfoque alternativo de introducir un solo nodo fantasma. Cada nodo de sumidero tiene un borde al nodo fantasma, y el nodo fantasma tiene un borde en sí mismo. En la práctica, los puntajes de PageRank se pueden calcular utilizando Power Iteration. Dado que PageRank es independiente de la consulta, el cálculo se puede realizar fuera de línea antes del tiempo de consulta. Esta propiedad ha sido clave para el éxito de PageRanks, ya que es un problema de ingeniería desafiante para construir un sistema que pueda realizar cualquier cálculo no trivial en el gráfico web en el momento de la consulta. Para calcular las puntuaciones de PageRank para los 2.900 millones de nodos en nuestro gráfico web, implementamos una versión distribuida de PageRank. El cálculo consta de dos fases distintas. En la primera fase, los archivos de enlace producidos por el rastreador web, que contienen URL de página y sus URL de enlace asociadas en forma textual, se dividen entre las máquinas en el clúster utilizadas para calcular las puntuaciones de PageRank y se convierten en un formato más compacto a lo largo del formato a lo largo delforma. Específicamente, las URL se dividen en las máquinas en el clúster basada en un hash del componente host de URL, y cada máquina en el clúster mantiene una tabla que mapea la URL a un entero de 32 bits. Los enteros se extraen de un espacio densamente empaquetado, a fin de hacer índices adecuados en la matriz que luego sostendrá las puntuaciones de PageRank. Luego, el sistema traduce nuestro registro de páginas y sus hipervínculos asociados a una representación compacta donde las URL de la página y las URL de enlace están representadas por sus enteros asociados de 32 bits. El hashing el componente del host de las URL garantiza que todas las URL del mismo host se asignan a la misma máquina en nuestro clúster de puntuación. Dado que más del 80% de todos los hipervínculos en la web son relativos (es decir, son entre dos páginas en el mismo host), esta propiedad reduce en gran medida la cantidad de comunicación de red requerida por la segunda etapa del cálculo de puntuación distribuido. La segunda fase realiza la iteración de potencia de PageRank real. Tanto los datos de enlace como el vector de PageRank actual residen en el disco y se leen de forma transmisible;mientras que el nuevo Vector PageRank se mantiene en la memoria. Representamos los puntajes de PageRank como números de puntos flotantes de 64 bits. Las contribuciones de PageRank a las páginas asignadas a máquinas remotas se transmiten a la máquina remota a través de una conexión TCP. Utilizamos un clúster de tres máquinas, cada máquina equipada con 16 GB de RAM, para calcular las puntuaciones estándar de PageRank para todas las URL de 2.900 millones que estaban contenidas en nuestro gráfico web. Utilizamos un factor de amortiguación de 0,15 y realizamos 200 iteraciones de potencia. A partir de la iteración 165, la norma L∞ del cambio en el vector de PageRank de una iteración a la siguiente había dejado de disminuir, lo que indica que habíamos alcanzado un punto tan fijo como lo permitirían las limitaciones de la aritmética de punto flotante de 64 bits.0.07 0.08 0.09 0.10 0.11 1 10 100 Número de enlaces posteriores muestreados por resultado ndcg@10 hits-aut-the Hits-Aut-ih Hits-Aut-ID 0.01 0.02 0.03 0.04 1 10 100 Número de enlaces posteriores Mapa de resultados de resultados@10 Hits-Aut-All Hits-Aut-IH Hits-Aut-ID 0.07 0.08 0.09 0.10 0.11 0.12 0.13 0.14 1 10 100 Número de vínculos posteriores muestreados por resultado MRR@10 Hits-Aut-All Hits-Aut-IH Hits Hits-Aut-ID Figura 1: Efectividad de las puntuaciones de autoridad calculadas utilizando diferentes parametrizaciones de golpes. Una fase de postprocesamiento utiliza los vectores de PageRank final (uno por máquina) y las URL de mapeo de la tabla a enteros de 32 bits (que representan índices en cada vector de PageRank) para obtener la URL de resultados en nuestro registro de consultas. Como se mencionó anteriormente, nuestro gráfico web cubrió 9,525,566 de las 66,846,214 URL de resultados. Estas URL fueron anotadas con su puntaje calculado de PageRank;Todas las demás URL recibieron una puntuación de 0. 6. Hits Hits, a diferencia de PageRank, es un algoritmo de clasificación dependiente de la consulta. Los golpes (que representa la búsqueda de temas inducida por hipertexto) se basan en las siguientes dos intuiciones: Primero, los hipervínculos pueden verse como endosos de actualidad: un hipervínculo de una página U dedicado al Tema T a otra página V es probable que respalde la autoridad de V VCon respecto al tema T. En segundo lugar, es probable que el conjunto de resultados de una consulta particular tenga una cierta cantidad de coherencia tópica. Por lo tanto, tiene sentido realizar un análisis de enlaces no en todo el gráfico web, sino solo en el vecindario de las páginas contenidas en el conjunto de resultados, ya que es más probable que este vecindario contenga enlaces tópicamente relevantes. Pero si bien el conjunto de nodos inmediatamente accesibles desde el conjunto de resultados es manejable (dado que la mayoría de las páginas tienen solo un número limitado de hipervínculos incrustados en ellos), el conjunto de páginas que conducen inmediatamente al conjunto de resultados puede ser enorme. Por esta razón, Kleinberg sugiere un muestreo de un subconjunto aleatorio de tamaño fijo de las páginas que vinculan a cualquier página de alto nivel en el conjunto de resultados. Además, Kleinberg sugiere considerar solo enlaces que cruzan los límites del huésped, la justificación es que es probable que los enlaces entre páginas en el mismo host (enlaces intrínsecos) sean navegación o nepotistas y no son relevantes tópicamente. Dado un gráfico web (v, e) con el conjunto de vértices V y el conjunto de borde E ⊆ V × V, y el conjunto de URL de resultados a una consulta (llamada raíz REJE R ⊆ V) como entrada, golpea calcula un gráfico del vecindario que consiste enun conjunto base B ⊆ V (el conjunto de raíces y algunos de sus vértices vecinos) y algunos de los bordes en E inducidos por B. Para formalizar la definición del gráfico del vecindario, es útil introducir primero un operador de muestreo y el concepto de un predicado de LinkSelection. Dado un conjunto A, la notación sn [a] dibuja n elementos uniformemente al azar de a;Sn [a] = a if | a |≤ n.Una sección de enlace predicada P toma un borde (u, v) ∈ E. En este estudio, usamos los siguientes tres predicados de sección de enlace: todos (U, V) ⇔ Verdadero Ih (U, V) ⇔ Host (U) = Host(v) id (u, v) ⇔ dominio (u) = dominio (v) donde el huésped (u) denota el huésped de URL u, y el dominio (u) denota el dominio de la url u. Por lo tanto, todo es cierto para todos los enlaces, mientras que IH es cierto solo para enlaces entre anfitriones, y la identificación es verdadera solo para enlaces entre dominios. La OP de set retirada de la raíz establecida R W.R.T.Se define un predicado de LinkSelection P: OP = [U∈R {V ∈ V: (U, V) ∈ E ∧ P (U, V)} Las ip s de conjunto de insultos del conjunto de raíz R W.R.T.Se define un predicado de enlace a la selección P y un valor de muestreo s: IP s = [v∈R ss [{u ∈ V: (u, v) ∈ E ∧ p (u, v)}] La base establece BPS de la raíz establecida R W.R.T. P y S se define como: BP S = R ∪ IP S ∪ OP El gráfico del vecindario (BP S, NP S) tiene el conjunto base BP S como su conjunto de vértice y un conjunto de borde que contiene esos bordes en E que soncubierto por BP sy permitido por p: np s = {(u, v) ∈ E: u ∈ Bp s ∧ v ∈ Bp s ∧ p (u, v)} para simplificar la notación, escribimos B para denotar bp s,y N para denotar np s. Para cada nodo U en el gráfico del vecindario, los golpes calculan dos puntajes: un puntaje de autoridad A (u), estimando cuán autorizado es U en el tema inducido por la consulta y un puntaje de concentración H (u), lo que indica si U es un buenreferencia a muchas páginas autorizadas. Esto se realiza utilizando el siguiente algoritmo: 1. Para todos los u ∈ B do H (U): = Q 1 | B |, A (U): = Q 1 | B |.2. Repita hasta que H y A convergen: (a) para todos v ∈ B: A (V): = P (U, V) ∈N H (U) (B) para todos los u ∈ B: H (U): = P (P (P (P (P (U, V) ∈N A (V) (C) H: = H 2, A: = A 2 donde x 2 normaliza el vector X a la longitud de la unidad en el espacio euclidiano, es decir, los cuadrados de sus elementos se suman hasta 1. En la práctica, la implementación de un sistema que puede calcular los golpes dentro de las limitaciones de tiempo de un motor de búsqueda importante (donde la carga máxima de consulta se encuentra en miles de consultas por segundo, y el tiempo de respuesta de consulta deseado está muy por debajo de un segundo) es una ingeniería importantedesafío. Entre otras cosas, el gráfico web no puede almacenarse razonablemente en el disco, ya que .221 .106 .105 .104 .102 .095 .092 .090 .038 .036 .035 .034 .032 .032 .011 0.00 0.05 0.10 0.15 0.200.25 BM25F Grado en ID de ID en IH Hits-Aut-ID-25 Hits-Aut-IH-100 Grado en todo PageRank Hits-Aut-All-100 Hits-HIB-ALL-ALL-100 HITS-HUB-IH-100 HITS-HUB-ID-100 Grado-Out-All Grado-IH IH ID-ID Random NDCG@10 .100 .035 .033 .033 .033 .029 .027 .027 .008 .007.007 .006 .006 .006 .002 0.00 0.02 0.04 0.06 0.08 0.10 0.12 BM25F Hits-Aut-ID-9 Grado-ID Hits-Aut-IH-15 Grado en IH PageRank Hits-Aut-Aut-Aut-All-100 HITS-HUB-ALL-100 HITS-HITS-HUB-IH-100 HITS-HUB-ID-ID-100 Grado-ALTO-ALTO-IH IH IH Mapa aleatorio@10 .273 .132 .126.117 .114 .101 .101 .097 .032 .032 .030 .028 .027 .027 .007 0.00 0.05 0.10 0.15 0.20 0.25 0.30 BM25F Hits-Aut-ID-9 Hits-Aut-IH-15 Grado-Id Grado en IH GRADE IN TODO HITS-AUT-ALL-100 PAGERANK HITS-HUB-ALL-100 HITS-HUB-IH-100 HITS-HIB-ID-100 grados-out-threed-IHGrado-Out-ID aleatorio MRR@10 Figura 2: Efectividad de diferentes características.Busque los tiempos de los discos duros modernos son demasiado lentos para recuperar los enlaces dentro de las limitaciones de tiempo, y el gráfico no cabe en la memoria principal de una sola máquina, incluso cuando se usa las técnicas de compresión más agresivas. Para experimentar con golpes y otros algoritmos de clasificación basados en enlaces dependientes de la consulta que requieren accesos no regulares a nodos y bordes arbitrarios en el gráfico web, implementamos un sistema llamado Tienda Hyperlink escalable, o SHS para abreviar. SHS es una base de datos de uso especial, distribuida sobre un número arbitrario de máquinas que mantiene una versión altamente comprimida del gráfico web en la memoria y permite una búsqueda muy rápida de nodos y bordes. En nuestro hardware, se necesita un promedio de 2 microsegundos para asignar una URL a un mango entero de 64 bits llamado UID, 15 microsegundos para buscar todos los UID entrantes o salientes asociados con una página UID y 5 microsegundos para mapear un UIDVolver a una URL (la última funcionalidad que no se requiere por los éxitos). La sobrecarga de RPC es de aproximadamente 100 microsegundos, pero la API SHS permite que muchas búsquedas se llenen en una sola solicitud de RPC. Implementamos el algoritmo HITS utilizando la infraestructura SHS. Compilamos tres bases de datos SHS, una que contiene los 17.6 mil millones de enlaces en nuestro gráfico web (todos), uno que contiene solo enlaces entre páginas que se encuentran en diferentes hosts (IH, para interanjado) y uno que contiene solo enlaces entre páginas que están endiferentes dominios (ID). Consideramos que dos URL pertenecen a diferentes hosts si las partes del host de las URL difieren (en otras palabras, no intentamos determinar si dos nombres de host simbólicos distintos se refieren a la misma computadora), y consideramos que un dominio es el nombrecomprado a un registrador (por ejemplo, consideramos que News.bbc.co.uk y www.bbc.co.uk son diferentes anfitriones pertenecientes al mismo dominio). Usando cada una de estas bases de datos, calculamos los puntajes de la autoridad y el concentrador para varias parametrizaciones de los operadores de muestreo, muestras entre 1 y 100 vínculos posteriores de cada página en el conjunto de raíces. Las URL de resultados que no fueron cubiertas por nuestro gráfico web recibieron automáticamente autoridad y puntajes de HUB de 0, ya que no estaban conectados a ningún otro nodo en el gráfico del vecindario y, por lo tanto, no recibieron ningún endoso. Realizamos cuarenta y cinco cálculos de éxitos diferentes, cada uno combinando uno de los tres predicados de selección de enlaces (todos, IH e ID) con un valor de muestreo. Para cada combinación, cargamos una de las tres bases de datos en un sistema SHS que se ejecuta en seis máquinas (cada una equipada con 16 GB de RAM), y calculamos los puntajes de la autoridad y el concentrador, una consulta a la vez. La combinación de más larga duración (utilizando todas las bases de datos y muestreo de 100 vínculos posteriores de cada vértice de conjunto de raíz) requirió 30,456 segundos para procesar todo el conjunto de consultas, o aproximadamente 1.1 segundos por consulta en promedio.7. Resultados experimentales Para una consulta dada Q, necesitamos clasificar el conjunto de documentos que satisfacen Q (el conjunto de resultados de Q). Nuestra hipótesis es que las buenas características deberían poder clasificar los documentos relevantes en este conjunto más alto que los no relevantes, y esto debería dar como resultado un aumento en cada medida de rendimiento en el conjunto de consultas. Estamos específicamente interesados en evaluar la utilidad de los éxitos y otras características basadas en enlaces. En principio, podríamos hacer esto clasificando los documentos en cada resultado establecido por su valor de característica, y comparar los NDCG resultantes. Llamamos a esta clasificación con características aisladas. Primero examinemos el rendimiento relativo de las diferentes parametrizaciones del algoritmo HITS que examinamos. Recuerde que calculamos los éxitos para cada combinación de tres esquemas de sección de enlaces: todos los enlaces (todos), enlaces entre anfitriones (IH) y solo enlaces entre dominios (ID), con valores de muestreo de retroceso que van de 1 a 100. La Figura 1 muestra el impacto del número de vínculos posteriores muestreados en el rendimiento de recuperación de los puntajes de autoridad de éxitos. Cada gráfico está asociado con una medida de rendimiento. El eje horizontal de cada gráfico representa el número de vínculos posteriores muestreados, el eje vertical representa el rendimiento bajo la medida apropiada y cada curva representa un esquema de selección de enlaces. El esquema de identificación supera ligeramente a IH, y ambos superan enormemente el esquema todo, la eliminación de los enlaces nepotistas vale la pena. El rendimiento de todos los esquemas aumenta a medida que se muestrean más vínculos de retroceso de cada vértice establecido de raíz, mientras que el rendimiento de los esquemas ID e IH alcanza su punto máximo entre 10 y 25 muestras y luego se detiene o incluso disminuyen, dependiendo de la medida de rendimiento. Habiendo comparado diferentes parametrizaciones de golpes, ahora solucionaremos el número de enlaces de retroceso muestreados a 100 y compararemos los tres esquemas de selección de enlaces con otras características aisladas: PageRank, Enlaces de conteo en grados y de grado externo de todas las páginas, de diferentes hosts.Solo y solo de diferentes dominios (todos los conjuntos de datos IH e ID respectivamente), y un algoritmo de recuperación de texto que explota texto de anclaje: BM25F [24]. BM25F es una función de clasificación de última generación basada únicamente en el contenido textual de los documentos y sus textos de anclaje asociados. BM25F es un descendiente de BM25 que combina los diferentes campos textuales de un documento, a saber, el título, el cuerpo y el texto de anclaje. Se ha demostrado que este modelo es una de las funciones de puntuación de búsqueda web con mejor rendimiento en los últimos años [8, 24]. BM25F tiene varios parámetros libres (2 por campo, 6 en nuestro caso);Utilizamos los valores de parámetros descritos en [24]..341 .340 .339 .337 .336 .336 .334 .311 .311 .310 .310 .310 .310 .231 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 grados en ID en IH IH en el grado-Todos los hits-Aut-IH-100 Hits-Aut-All-100 PageRank Hits-Aut-ID-10 Grado-Out-All Hits-Hub-All-100 Grado-IH HITS-HIB-IH-100 GRENDE-id golpea-hub-id-10 BM25F NDCG@10 .152 .152 .151 .150 .150 .149 .149 .137 .136 .136 .128 .127 .127 .100 0.09 0.10 0.11 0.12 0.13 0.14 0.15 0.16 Grado-In-IH Grado en ID Grado en todo Hits-Aut-IH-100 Hits-Aut-All-100 Hits-Aut-ID-10 PageRank Hits-Hub-All-100 Grado-IH Hits-HUB-ID-ID-100 Grado-Out-todo Grado-ID HITS-HUB-IH-100 BM25F MAP@10 .398 .397 .394 .394 .392 .392 .391 .356 .356 .356 .356 .356 .356.355 .273 0.25 0.30 0.35 0.40 grados In-ID Grado en IH Grado en todo Hits-Aut-IH-100 Hits-Aut-All-100 Pagerank Hits-Aut-ID-10 Grado-Out-Out-Out-OutHITS-HUB-ALL-ALL-100 grados-IH HITS-HUB-IH-100 grados-ID HITS-HUB-ID-10 BM25F MRR@10 Figura 3: Medidas de efectividad para combinaciones lineales de características basadas en enlaces con BM25F. La Figura 2 muestra las medidas NDCG, MRR y MAP de estas características. Nuevamente, todas las medidas de rendimiento (y para todos los umbrales de rango que exploramos) están de acuerdo. Como se esperaba, BM25F supera todas las características basadas en enlaces por un gran margen. Las características basadas en el enlace se dividen en dos grupos, con una notable caída de rendimiento entre los grupos. El grupo de mejor rendimiento consiste en las características que se basan en el número y/o la calidad de los enlaces entrantes (puntajes de autoridad en el grado, PageRank y llegan a la autoridad);Y el grupo de peor desempeño consiste en las características que se basan en el número y/o la calidad de los enlaces salientes (puntajes Outdegree and Hits Hub). En el grupo de características basadas en enlaces entrantes, las características que ignoran los enlaces nepotistas funcionan mejor que sus contrapartes utilizando todos los enlaces. Además, usar solo enlaces entre dominios (ID) parece ser marginalmente mejor que usar enlaces intermedentes (IH). El hecho de que las características basadas en enlaces salientes tengan un rendimiento inferior a las basadas en enlaces entrantes coinciden con nuestras expectativas;En todo caso, es un poco sorprendente que los enlaces salientes proporcionen una señal útil para la clasificación. Por otro lado, el hecho de que las características en el grado superan a PageRank en todas las medidas es bastante sorprendente. Una posible explicación es que los spammers de enlaces han estado apuntando al algoritmo de PageRank publicado durante muchos años, y que esto ha llevado a anomalías en el gráfico web que afectan a PageRank, pero no a otras características basadas en enlaces que exploran solo un vecindario a distancia 1 deel conjunto de resultados. Del mismo modo, es sorprendente que las características simples independientes de la consulta, como en el grado, que podrían estimar la calidad global pero no pueden capturar la relevancia para una consulta, superarían las características dependientes de la consulta, como los puntajes de autoridad de los éxitos. Sin embargo, no podemos investigar el efecto de estas características de forma aislada, sin tener en cuenta la función de clasificación general, por varias razones. Primero, las características basadas en el contenido textual de los documentos (a diferencia de las características basadas en enlaces) son los mejores predictores de relevancia. En segundo lugar, las características basadas en enlaces se pueden correlacionar fuertemente con las características textuales por varias razones, principalmente la correlación entre la función de transformación de numerosas y numerosas BM25F T (S) = S PageRank T (S) = log (S + 3 · 10-12-12) Grado-In-* t (s) = log (S + 3 · 10−2) Grado-Out-* t (S) = log (S + 3 · 103) Hits-Aut-* t (S) = log(S + 3 · 10−8) HITS-HUB-* T (S) = log (S + 3 · 10−1) Tabla 1: Funciones de transformación de características casi óptimas.ber de coincidencias de anclaje textual. Por lo tanto, uno debe considerar el efecto de las características basadas en enlaces en combinación con características textuales. De lo contrario, podemos encontrar una característica basada en enlaces que es muy buena de forma aislada, pero que esté fuertemente correlacionada con las características textuales y los resultados no tienen una mejora general;Y viceversa, podemos encontrar una característica basada en enlaces que es débil de forma aislada pero que mejora significativamente el rendimiento general. Por esta razón, hemos estudiado la combinación de las funciones basadas en enlaces anteriores con BM25F. Todas las combinaciones de características se realizaron considerando la combinación lineal de dos características como puntaje de documento, utilizando la puntuación de fórmula (d) = Pn i = 1 witi (fi (d)), donde d es un documento (o par de documentos, en elEl caso de BM25F), Fi (D) (para 1 ≤ I ≤ n) es una característica extraída de D, Ti es una transformación y WI es un peso escalar libre que debe ajustarse. Elegimos funciones de transformación que empíricamente determinamos que son adecuados. La Tabla 1 muestra las funciones de transformación elegidas. Este tipo de combinación lineal es apropiada si suponemos que las características son independientes con respecto a la relevancia y un modelo exponencial para las características de enlace, como se discute en [8]. Sintonizamos los pesos seleccionando un subconjunto aleatorio de 5,000 consultas del conjunto de consultas, utilizamos un proceso de refinamiento iterativo para encontrar pesos que maximizaran una medida de rendimiento dada en ese conjunto de entrenamiento y utilizó las 23.043 consultas restantes para medir el rendimiento de la derivada así derivada.Funciones de puntuación. Exploramos la combinación por pares de BM25F con cada función de puntuación basada en enlaces. La Figura 3 muestra las medidas de NDCG, MRR y MAP de estas combinaciones de características, junto con una puntuación BM25F basal (la barra más derecha en cada gráfico), que se calculó utilizando el mismo subconjunto de 23,045 consultas que se usaron como conjunto de prueba.Para las combinaciones de características. Independientemente de la medida de rendimiento aplicada, podemos hacer las siguientes observaciones generales: 1. La combinación de cualquiera de las características basadas en enlaces con BM25F da como resultado una mejora sustancial del rendimiento sobre BM25F de forma aislada.2. La combinación de BM25F con características basadas en enlaces entrantes (PageRank, en grado y puntajes de autoridad) funciona sustancialmente mejor que la combinación con características basadas en enlaces salientes (golpea las puntuaciones del centro y el grado externo).3. Las diferencias de rendimiento entre las diversas combinaciones de BM25F con características basadas en enlaces entrantes son relativamente pequeñas, y el ordenamiento relativo de las combinaciones de características es bastante estable en el 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0 2 4 6 6 10 12 16 18 20 20 20 20 2022 24 MAP@10 26 374 1640 2751 3768 4284 3944 3001 2617 1871 1367 771 1629 BM25FNORM PAGERANK GRADO-ID HITS-AUT-ID-100 Figura 4: Medidas de efectividad para características aisladas seleccionadas, desglosada por especificidad de la pregunta.Ferentes medidas de rendimiento utilizadas. Sin embargo, la combinación de BM25F con cualquier variante en el grado, y en particular con ID en el grado, supera constantemente la combinación de BM25F con PageRank o Hits Stands de autoridad, y se puede calcular mucho más fácil y más rápido. Finalmente, investigamos si ciertas características son mejores para algunas consultas que para otras. Particularmente, estamos interesados en la relación entre la especificidad de una consulta y el rendimiento de diferentes características de clasificación. La medida más directa de la especificidad de una consulta Q sería el número de documentos en un corpus de motores de búsqueda que satisfacen Q. Desafortunadamente, el conjunto de consultas disponible para nosotros no contenía esta información. Por lo tanto, elegimos aproximar la especificidad de Q resumiendo las frecuencias de documentos inversas de los términos de consulta individuales que comprenden Q. La frecuencia de documento inversa (IDF) de un término T con respecto a un corpus C se define como logn/doc (t), donde Doc (t) es el número de documentos en C que contienen T y N es el número total de documentosEn C. resumiendo los IDF de los términos de la consulta, hacemos la suposición (defectuosa) de que los términos de consulta individuales son independientes entre sí. Sin embargo, aunque no es perfecta, esta aproximación es al menos direccionalmente correcta. Desglosamos nuestra consulta establecida en 13 cubos, cada cubo asociado con un intervalo de valores de IDF de consulta, y calculamos las métricas de rendimiento para todas las funciones de clasificación aplicadas (de forma aislada) a las consultas en cada cubo. Para mantener legibles los gráficos, no mostraremos el rendimiento de todas las características, sino que nos restringiremos a los cuatro más interesantes: PageRank, ID alcanza los puntajes de autoridad, ID en grado y BM25F. La Figura 4 muestra el mapa@10 para los 13 cubos de especificidad de consulta. Los cubos en el extremo izquierdo de cada gráfico representan consultas muy generales;Los cubos en el extremo derecho representan consultas muy específicas. Las figuras en el eje X superior de cada gráfico muestran el número de consultas en cada cubo (por ejemplo, el cubo más derecho contiene 1.629 consultas). BM25F funciona mejor para consultas específicas de mediana, alcanzando su punto máximo en los cubos que representan el intervalo de suma de las FDI [12,14). En comparación, alcanza los picos en el cubo que representa el intervalo de suma de las FDI [4,6), y PageRank y Pico en grados en el cubo que representa el intervalo [6,8), es decir, consultas más generales.8. Conclusiones y trabajo futuro Este documento describe una evaluación a gran escala de la efectividad de los hits en comparación con otros algoritmos de clasificación basados en enlaces, en particular PageRank y en grados, cuando se aplica de forma aislada o en combinación con un algoritmo de recuperación de texto que explota el texto de anclaje(BM25F). La evaluación se lleva a cabo con respecto a una gran cantidad de consultas evaluadas humanas, utilizando tres medidas diferentes de efectividad: NDCG, MRR y MAP. Evaluación de las características basadas en enlaces de forma aislada, encontramos que la página web en el grado supera a PageRank, y es tan efectivo como los puntajes de la autoridad. Los puntajes de HIT HUB y la página web fuera del grado son características de clasificación mucho menos efectivas, pero aún superan a un orden aleatorio. Una combinación lineal de cualquier característica basada en enlaces con BM25F produce una mejora significativa en el rendimiento, y existe una clara diferencia entre la combinación de BM25F con una característica basada en enlaces entrantes (puntajes de autoridad Indegree, Pagerank o Hits) y una característica basada en salientes salientes.Enlaces (llega a las puntuaciones de HUB y un grado externo), pero dentro de esos dos grupos, la elección precisa de la característica basada en enlaces es importante relativamente poco. Creemos que las mediciones presentadas en este documento proporcionan una evaluación sólida de los esquemas de clasificación más conocidos basados en enlaces. Hay muchas variantes posibles de estos esquemas, y se han propuesto muchos otros algoritmos de clasificación basados en enlaces en la literatura, por lo tanto, no reclamamos que este trabajo sea la última palabra sobre este tema, sino el primer paso en un camino largo. El trabajo futuro incluye la evaluación de diferentes parametrizaciones de PageRank y Hits. En particular, nos gustaría estudiar el impacto de los cambios en el factor de amortiguación de PageRank sobre la efectividad, el impacto de varios esquemas destinados a contrarrestar los efectos del spam de enlace y el efecto de pesar hipervínculos de manera diferente dependiendo de si son nepotistas o no. Yendo más allá de PageRank y Hits, nos gustaría medir la efectividad de otros algoritmos de clasificación basados en enlaces, como la salsa. Finalmente, planeamos experimentar con combinaciones de características más complejas.9. Referencias [1] B. Amento, L. Terveen y W. Hill. ¿La autoridad significa calidad? Predicción de calificaciones de calidad de expertos de documentos web. En Proc.de la 23ª Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 296-303, 2000. [2] M. Bianchini, M. Gori y F. Scarselli. Dentro de PageRank. Transacciones ACM sobre tecnología de Internet, 5 (1): 92-128, 2005. [3] A. Borodin, G. O. Roberts y J. S. Rosenthal. Encontrar autoridades y centros de estructuras de enlaces en la red mundial. En Proc.de la décima conferencia internacional de la World Wide Web, páginas 415-429, 2001. [4] A. Borodin, G. O. Roberts, J. S. Rosenthal y P. Tsaparas. Ranking de análisis de enlaces: algoritmos, teoría y experimentos. Transacciones ACM en Tecnología Interet, 5 (1): 231-297, 2005. [5] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes informáticas y sistemas ISDN, 30 (1-7): 107-117, 1998. [6] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton y G. Hullender. Aprendiendo a clasificarse usando descenso de gradiente. En Proc.de la 22ª Conferencia Internacional de Aprendizaje Machine, páginas 89-96, Nueva York, NY, EE. UU., 2005. ACM Press.[7] D. Cohn y H. Chang. Aprender a identificar probabilísticamente documentos autorizados. En Proc.de la 17ª Conferencia Internacional de Aprendizaje Machine, páginas 167-174, 2000. [8] N. Craswell, S. Robertson, H. Zaragoza y M. Taylor. Ponderación de relevancia para la evidencia independiente de la consulta. En Proc.de la 28ª Conferencia Internacional ACM Sigir sobre investigación y desarrollo en recuperación de información, páginas 416-423, 2005. [9] E. Garfield. Análisis de citas como herramienta en la evaluación de la revista. Science, 178 (4060): 471-479, 1972. [10] Z. Gy¨ongyi y H. García-Molina. Taxonomía de spam web. En el primer taller internacional sobre recuperación de información adversa en la Web, 2005. [11] Z. Gy¨ongyi, H. García-Molina y J. Pedersen. Combatir el spam web con Trustrank. En Proc.de la 30ª Conferencia Internacional sobre bases de datos muy grandes, páginas 576-587, 2004. [12] B. J. Jansen, A. Spink, J. Bateman y T. Saracevic. Recuperación de información de la vida real: un estudio de consultas de usuarios en la web. ACM Sigir Forum, 32 (1): 5-17, 1998. [13] K. J¨arvelin y J. Kek¨al¨ainen. Evaluación basada en ganancias acumuladas de técnicas IR. Transacciones ACM en Sistemas de Información, 20 (4): 422-446, 2002. [14] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar los cálculos de PageRank. En Proc.de la 12ª Conferencia internacional de la World Wide Web, páginas 261-270, 2003. [15] M. M. Kessler. Acoplamiento bibliográfico entre artículos científicos. American Documation, 14 (1): 10-25, 1963. [16] J. M. Kleinberg. Fuentes autorizadas en un entorno hipervínculos. En Proc.del noveno Simposio ACM-SIAM anual sobre algoritmos discretos, páginas 668-677, 1998. [17] J. M. Kleinberg. Fuentes autorizadas en un entorno hipervínculos. Journal of the ACM, 46 (5): 604-632, 1999. [18] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Internet Mathematics, 1 (3): 2005, 335-380.[19] R. Lempel y S. Moran. El enfoque estocástico para el análisis de estructura de enlace (SALSA) y el efecto TKC. Redes informáticas y sistemas ISDN, 33 (1-6): 387-401, 2000. [20] A. Y. Ng, A. X. Zheng y M. I. Jordan. Algoritmos estables para el análisis de enlaces. En Proc.de la 24ª Conferencia Anual de Investigación y Desarrollo de la Investigación de la Investigación y Desarrollo ACM, las páginas 258-266, 2001. [21] L. Page, S. Brin, R. Motwani y T. Winograd. Ranking de citas de PageRank: traer orden a la web. Informe técnico, Proyecto de Tecnologías de la Biblioteca Digital de Stanford, 1998. [22] J. A. Tomlin. Un nuevo paradigma para clasificar páginas en la World Wide Web. En Proc.de la 12ª Conferencia Internacional de la World Wide Web, páginas 350-355, 2003. [23] T. Upstill, N. Craswell y D. Hawking. Predecir la fama y la fortuna: ¿PageRank o Indegree? En Proc.del Simposio de Computación de Documentos de Australia, páginas 31-40, 2003. [24] H. Zaragoza, N. Craswell, M. Taylor, S. Saria y S. Robertson. Microsoft Cambridge en TREC-13: pistas web y duras. En Proc.de la 13ª Conferencia de Recuperación de Textos, 2004.